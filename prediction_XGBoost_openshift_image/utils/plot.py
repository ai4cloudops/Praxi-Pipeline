import matplotlib
# matplotlib.rcParams['pdf.fonttype'] = 42
# matplotlib.rcParams['ps.fonttype'] = 42	
matplotlib.rcParams['text.usetex'] = True
import matplotlib.pyplot as plt
import numpy as np
import math, copy
import scipy
# from pylab import *
from matplotlib import cm

def plotting(fig_path, filename, cates_values, labels, cates_stds= None, yaxis_label=None, xaxis_label=None, title=None, figsize=(10, 7)):
    width = 0.4

    fig, ax = plt.subplots(1, 1, figsize=figsize)

    for i, cate_values in enumerate(cates_values):
        bottom = np.zeros(len(labels))
        for cate, value in cate_values.items():
            if labels[0]==None:
                p = ax.bar([float(entry) for entry in cate.split("-")], value, width/len(cates_values), bottom=bottom)
            else:
                p = ax.bar([idx - width/len(cates_values)/2 + i*width/len(cates_values) for idx, _ in enumerate(value)], value, width/len(cates_values), label=cate, bottom=bottom)
            bottom += value
            ax.bar_label(p)
    # if cates_stds!=None:
    #     for i, cate_stds in enumerate(cates_stds):
    #         for cate, (y, yerr) in cate_stds.items():
    #             if labels[0]==None:
    #                 p = ax.bar([float(entry) for entry in cate.split("-")], y, yerr)
    #             else:
    #                 p = ax.bar([idx - width/len(cates_stds)/2 + i*width/len(cates_stds) for idx, _ in enumerate(y)], y, yerr)

    if title == None:
        ax.set_title(" ".join(filename.split("_")))
    else:
        ax.set_title(title, fontsize=20)
    if labels[0]!=None:
        ax.legend(loc="best", prop={'size': 16})
        ax.set_xticks(list(range(len(labels))))
        ax.set_xticklabels(labels)
    if yaxis_label != None:
        ax.set_ylabel(yaxis_label, fontsize=20)
    if xaxis_label != None:
        ax.set_xlabel(xaxis_label, fontsize=20)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=18)

    # plt.show()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()



if __name__ == "__main__":
    # # ###################### Cross-Validated Plots ##############################
#     # # # ###################### data0 ############################################


    fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/figs-1/'

#     filename = "cvf1scores_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     xs=[10, 20, 40, 80]
#     labels = ("F1 Scores Cross Validated with Submodel's Samples", )
#     ys_d0trainingtimerawinput_l=[#models
#         [#dims
#             [
#                 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.991, 1.0, 0.989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.991, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.989, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.989, 1.0, 1.0, 0.991, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0
#             ]
#         ],    
#         [
#             [
#                 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.995, 0.994, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.994, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.994, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0
#             ]
#         ],
#         [
#             [
#                 0.998, 1.0, 1.0, 1.0, 0.995, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998, 1.0, 1.0, 1.0, 0.997, 1.0, 1.0, 1.0, 1.0, 0.998, 1.0, 1.0, 1.0, 0.997, 0.998, 1.0, 1.0, 1.0, 1.0
#             ]
#         ],
#         [
#             [
#                 0.999, 1.0, 0.997, 1.0, 1.0, 0.999, 1.0, 0.997, 1.0, 1.0, 0.999, 1.0, 0.997, 1.0, 1.0
#             ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0trainingtimerawinput_l)):
#         ys_array.append(np.mean(ys_d0trainingtimerawinput_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0trainingtimerawinput_l[m_i], axis=1)/np.sqrt(len(ys_d0trainingtimerawinput_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v", "o", "s"]):
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='^', capsize=10)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
#     ax.set_ylabel("F1 Score", fontsize=20)
#     ax.set_ylim(0.99,1)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()




#     filename = "trainlatency_by_N_models_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     xs=[10, 20, 40, 80]
#     labels = ("Total Training Time (s) for Submodels", )
#     ys_d0trainingtimerawinput_l=[#models
#         [#dims
#             [
#                 [0.644, 0.42, 0.684, 0.819, 0.579, 0.884, 2.204, 10.147], [0.608, 0.352, 0.643, 0.934, 0.537, 0.88, 2.175, 9.785], [0.59, 0.39, 0.642, 0.951, 0.568, 0.888, 2.239, 10.321], [0.599, 0.363, 0.61, 0.942, 0.548, 0.922, 2.208, 10.429], [0.602, 0.372, 0.702, 0.996, 0.593, 0.896, 2.285, 9.878], [0.645, 0.602, 1.471, 0.992, 0.862, 9.166, 0.924, 1.007], [0.697, 0.602, 1.467, 0.994, 0.856, 9.146, 0.927, 1.008], [0.646, 0.59, 1.512, 1.001, 0.863, 9.716, 0.908, 1.025], [0.671, 0.599, 1.489, 0.997, 0.834, 9.973, 0.934, 1.02], [0.653, 0.592, 1.472, 0.994, 0.831, 9.378, 0.924, 0.999], [0.982, 0.494, 1.105, 0.588, 9.233, 0.6, 2.087, 0.677], [1.005, 0.686, 1.129, 0.629, 9.133, 0.602, 2.099, 0.699], [1.004, 0.678, 1.117, 0.606, 9.645, 0.589, 2.105, 0.641], [0.995, 0.651, 1.125, 0.591, 9.587, 0.612, 2.146, 0.688], [0.998, 0.668, 1.11, 0.594, 9.154, 0.6, 2.144, 0.678]
#             ]
#         ],    
#         [
#             [
#                 [2.964, 4.513, 4.406, 42.058], [2.976, 5.196, 4.485, 41.457], [3.009, 5.131, 4.45, 43.875], [2.96, 5.133, 4.39, 42.997], [2.962, 5.129, 4.429, 41.768], [3.69, 8.73, 34.414, 6.352], [3.836, 8.754, 33.727, 6.66], [3.728, 8.796, 35.177, 6.477], [3.681, 8.869, 34.891, 6.395], [3.695, 8.788, 33.353, 6.442], [4.675, 5.429, 33.301, 9.791], [4.783, 5.519, 32.189, 9.737], [4.72, 5.523, 33.118, 9.68], [4.691, 5.444, 34.244, 9.682], [4.71, 5.439, 32.726, 9.706]
#             ]
#         ],
#         [
#             [
#                 [27.973, 163.495], [30.364, 161.446], [30.438, 166.837], [30.318, 167.927], [30.373, 162.891], [46.088, 146.317], [46.361, 144.481], [47.09, 150.83], [46.448, 151.901], [46.562, 146.347], [38.591, 155.273], [38.768, 151.506], [39.134, 157.192], [38.506, 156.736], [38.393, 152.852]
#             ]
#         ],
#         [
#             [
#                 [723.563], [715.752], [735.693], [734.749], [717.41], [717.779], [717.89], [735.082], [734.218], [718.756], [720.906], [707.247], [733.122], [735.112], [717.266]
#             ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0trainingtimerawinput_l)):
#         ys_array.append(np.mean(np.sum(ys_d0trainingtimerawinput_l[m_i],axis=(2,)), axis=(1)))
#         ci_array.append(1.96 * np.std(np.sum(ys_d0trainingtimerawinput_l[m_i],axis=(2,)), axis=1)/np.sqrt(len(np.sum(ys_d0trainingtimerawinput_l[m_i],axis=(2,))[0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v", "o", "s"]):
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='^', capsize=10)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
#     ax.set_ylabel("Training Time(s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/figs-1/'
#     filename = "trainlatency_by_input_size_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[50, 100, 250, 6832, 18000, 27329, 60000, 109319]
#     labels = ("10 labels per Model", "20 labels per Model","40 labels per Model","80 labels per Model")
#     ysestimate_l = [[871.2246/109319*50, 871.2246/109319*100, 871.2246/109319*250, 871.2246/16, 871.2246/109319*18000, 871.2246/4, 871.2246/109319*60000, 871.2246]]
#     ax.scatter(xs, ysestimate_l, label="Estimated with 80 Labels per Model \& 109319 dims", marker="x", s=100)
#     ys_d0trainingtime_l=[#models
#         [#dims
#             [
#                 0.1, 0.109, 0.144, 0.128, 0.117, 0.135, 0.133, 0.12, 0.134, 0.153, 0.128, 0.137, 0.131, 0.118, 0.091, 0.1, 0.102, 0.149, 0.136, 0.125, 0.121, 0.13, 0.139, 0.113, 0.142, 0.146, 0.127, 0.14, 0.129, 0.106, 0.132, 0.112, 0.134, 0.14, 0.131, 0.145, 0.118, 0.155, 0.147, 0.152, 0.134, 0.137, 0.127, 0.119, 0.106, 0.139, 0.102, 0.146, 0.125, 0.123, 0.145, 0.138, 0.143, 0.159, 0.145, 0.151, 0.126, 0.129, 0.128, 0.106, 0.128, 0.113, 0.146, 0.129, 0.133, 0.123, 0.119, 0.151, 0.122, 0.131, 0.129, 0.143, 0.148, 0.146, 0.119, 0.131, 0.117, 0.128, 0.139, 0.141, 0.145, 0.143, 0.151, 0.139, 0.155, 0.128, 0.15, 0.129, 0.168, 0.134, 0.154, 0.135, 0.155, 0.149, 0.138, 0.151, 0.138, 0.127, 0.116, 0.144, 0.132, 0.14, 0.155, 0.122, 0.133, 0.057, 0.054, 0.054, 0.053, 0.053, 0.052, 0.062, 0.057, 0.051, 0.054, 0.057, 0.059, 0.059, 0.055, 0.054
#             ],
#             [
#                 0.102, 0.151, 0.14, 0.137, 0.148, 0.145, 0.142, 0.165, 0.169, 0.153, 0.145, 0.149, 0.154, 0.135, 0.136, 0.132, 0.17, 0.122, 0.135, 0.137, 0.138, 0.137, 0.138, 0.151, 0.146, 0.184, 0.15, 0.181, 0.153, 0.138, 0.124, 0.163, 0.136, 0.131, 0.149, 0.138, 0.14, 0.14, 0.129, 0.136, 0.158, 0.146, 0.163, 0.152, 0.133, 0.119, 0.131, 0.133, 0.136, 0.143, 0.14, 0.132, 0.144, 0.156, 0.133, 0.143, 0.169, 0.163, 0.145, 0.141, 0.137, 0.15, 0.119, 0.144, 0.143, 0.128, 0.132, 0.163, 0.155, 0.145, 0.16, 0.152, 0.152, 0.154, 0.142, 0.145, 0.131, 0.148, 0.131, 0.154, 0.151, 0.148, 0.162, 0.14, 0.136, 0.174, 0.144, 0.155, 0.167, 0.143, 0.146, 0.146, 0.177, 0.156, 0.16, 0.14, 0.159, 0.171, 0.137, 0.148, 0.165, 0.141, 0.154, 0.12, 0.112, 0.058, 0.051, 0.068, 0.073, 0.06, 0.054, 0.051, 0.058, 0.061, 0.057, 0.052, 0.061, 0.051, 0.056, 0.058
#             ],
#             [
#                 0.183, 0.19, 0.207, 0.183, 0.18, 0.224, 0.138, 0.197, 0.183, 0.184, 0.232, 0.179, 0.197, 0.19, 0.174, 0.186, 0.14, 0.184, 0.205, 0.198, 0.208, 0.132, 0.242, 0.194, 0.193, 0.214, 0.172, 0.187, 0.192, 0.176, 0.188, 0.151, 0.23, 0.213, 0.198, 0.249, 0.135, 0.199, 0.205, 0.181, 0.207, 0.176, 0.237, 0.179, 0.176, 0.181, 0.138, 0.205, 0.192, 0.204, 0.241, 0.142, 0.194, 0.157, 0.182, 0.242, 0.177, 0.191, 0.221, 0.193, 0.191, 0.139, 0.192, 0.184, 0.173, 0.256, 0.137, 0.199, 0.153, 0.173, 0.212, 0.184, 0.221, 0.215, 0.184, 0.232, 0.141, 0.186, 0.194, 0.187, 0.261, 0.144, 0.191, 0.164, 0.18, 0.204, 0.177, 0.214, 0.2, 0.175, 0.248, 0.147, 0.215, 0.216, 0.196, 0.257, 0.167, 0.199, 0.157, 0.198, 0.214, 0.186, 0.208, 0.221, 0.19, 0.081, 0.052, 0.087, 0.072, 0.07, 0.074, 0.062, 0.062, 0.061, 0.063, 0.072, 0.069, 0.069, 0.069, 0.067
#             ],
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 1.098, 1.086, 1.048, 1.102, 1.095, 1.058, 1.076, 1.037, 1.026, 1.063, 1.116, 1.11, 1.108, 1.094, 1.118, 1.091, 1.078, 1.057, 1.095, 1.088, 1.105, 1.086, 1.016, 1.023, 1.081, 1.082, 1.12, 1.092, 1.082, 1.098, 1.073, 1.07, 1.075, 1.104, 1.094, 1.081, 1.103, 1.037, 1.029, 1.081, 1.073, 1.101, 1.109, 1.094, 1.077, 1.093, 1.087, 1.06, 1.078, 1.082, 1.081, 1.085, 1.053, 1.036, 1.078, 1.063, 1.069, 1.093, 1.129, 1.064, 1.065, 1.065, 1.059, 1.025, 1.079, 1.065, 1.09, 1.044, 1.047, 1.074, 1.099, 1.108, 1.135, 1.127, 1.096, 1.07, 1.064, 1.067, 1.042, 1.109, 1.117, 1.085, 1.044, 1.075, 1.111, 1.068, 1.067, 1.079, 1.093, 1.078, 1.082, 1.07, 1.064, 1.051, 1.092, 1.082, 1.056, 1.026, 1.086, 1.098, 1.086, 1.079, 1.094, 1.091, 1.085, 1.094, 1.107, 1.057, 1.072, 1.11, 1.086, 1.044, 1.111, 1.107, 1.104, 1.091, 1.058, 1.083, 1.075, 1.093
#             ],
#             [
#                 3.322, 3.277, 3.265, 3.272, 3.351, 3.262, 3.2, 3.202, 3.215, 3.217, 3.262, 3.211, 3.177, 3.229, 3.335, 3.217, 3.224, 3.194, 3.061, 3.223, 3.16, 3.173, 3.192, 3.209, 3.198, 3.229, 3.223, 3.169, 3.21, 3.248, 3.213, 3.218, 3.228, 3.157, 3.265, 3.142, 3.19, 3.234, 3.211, 3.211, 3.263, 3.195, 3.286, 3.191, 3.242, 3.216, 3.194, 3.276, 3.188, 3.206, 3.184, 3.182, 3.162, 3.164, 3.177, 3.244, 3.232, 3.273, 3.224, 3.25, 3.209, 3.228, 3.237, 3.164, 3.204, 3.169, 3.224, 3.176, 3.204, 3.205, 3.285, 3.268, 3.249, 3.277, 3.261, 3.25, 3.25, 3.217, 3.167, 3.217, 3.276, 3.29, 3.229, 3.229, 3.221, 3.251, 3.231, 3.163, 3.645, 3.271, 3.194, 3.233, 3.233, 3.6, 3.186, 3.208, 3.238, 3.188, 3.234, 3.184, 3.287, 3.166, 3.144, 3.622, 3.226, 0.416, 0.422, 0.427, 0.405, 0.41, 0.418, 0.406, 0.409, 0.439, 0.418, 0.41, 0.412, 0.391, 0.433, 0.415
#             ],
#             [
#                 4.381, 4.367, 4.521, 4.423, 4.33, 4.516, 4.474, 4.315, 4.245, 4.286, 4.416, 4.444, 4.361, 4.561, 4.353, 4.407, 4.598, 4.424, 4.3, 4.353, 4.52, 4.22, 4.187, 4.249, 4.313, 4.373, 4.427, 4.38, 4.325, 4.303, 4.483, 4.392, 4.42, 4.267, 4.464, 4.499, 4.521, 4.151, 4.514, 4.327, 4.337, 4.019, 4.511, 4.167, 4.308, 4.319, 4.41, 4.421, 4.241, 4.371, 4.414, 4.15, 4.493, 4.266, 4.238, 4.452, 4.374, 4.365, 4.224, 4.33, 4.408, 4.215, 4.436, 4.429, 4.237, 4.357, 4.198, 4.416, 4.43, 4.401, 4.604, 4.088, 4.41, 4.28, 4.411, 4.373, 4.285, 4.482, 4.482, 4.264, 4.416, 4.313, 4.425, 4.269, 4.326, 4.36, 4.369, 4.376, 4.516, 4.321, 4.385, 4.524, 4.399, 4.337, 4.303, 4.359, 4.4, 4.455, 4.265, 4.358, 4.517, 4.43, 4.395, 4.21, 4.273, 4.405, 4.572, 4.527, 4.497, 4.318, 4.321, 4.287, 4.353, 4.294, 4.291, 4.51, 4.187, 4.329, 4.314, 4.279
#             ],
#             [
#                 12.328, 12.991, 11.46, 14.434, 12.84, 13.183, 13.013, 13.209, 12.989, 12.975, 12.995, 12.696, 13.242, 12.933, 12.978, 12.433, 13.196, 13.302, 14.369, 12.823, 13.071, 12.995, 13.309, 12.866, 13.182, 13.019, 12.996, 13.11, 13.068, 12.968, 13.2, 13.351, 13.184, 14.417, 12.773, 12.978, 12.774, 13.105, 12.921, 12.991, 13.091, 13.03, 13.05, 13.06, 12.838, 12.548, 13.165, 13.217, 14.294, 12.75, 12.966, 12.854, 13.11, 12.907, 13.003, 12.876, 12.938, 13.238, 13.134, 12.286, 13.049, 13.29, 13.154, 13.153, 12.732, 13.01, 12.945, 13.062, 12.995, 11.827, 12.955, 13.011, 13.153, 13.059, 12.941, 12.203, 13.314, 13.232, 13.104, 12.752, 12.164, 12.826, 12.98, 12.864, 12.998, 13.031, 13.019, 13.204, 12.945, 12.782, 12.048, 12.997, 13.15, 12.945, 12.763, 13.113, 12.997, 13.213, 13.034, 12.866, 12.794, 12.887, 13.01, 13.026, 12.754, 1.225, 1.339, 1.322, 1.483, 1.405, 1.305, 1.427, 1.317, 1.399, 1.407, 1.373, 1.359, 1.369, 1.358, 1.37
#             ],
#             [
#                 22.287, 22.609, 22.545, 21.656, 22.583, 22.578, 22.789, 22.74, 21.392, 21.733, 22.587, 22.71, 21.847, 21.572, 21.221, 22.348, 22.052, 22.307, 22.623, 22.193, 22.649, 22.643, 21.834, 22.552, 22.188, 21.76, 22.712, 21.526, 21.497, 21.5, 22.519, 22.628, 21.685, 21.452, 22.292, 22.718, 22.692, 22.275, 22.03, 21.346, 22.281, 22.715, 22.075, 22.749, 21.309, 22.656, 22.721, 22.057, 22.533, 22.27, 22.499, 21.877, 21.322, 20.577, 20.359, 21.665, 22.854, 22.067, 22.019, 22.051, 22.59, 21.811, 21.575, 20.406, 21.776, 22.45, 22.697, 22.534, 21.518, 20.957, 22.237, 22.678, 21.846, 21.562, 21.035, 22.422, 22.891, 22.076, 21.524, 21.515, 22.554, 22.67, 22.043, 22.488, 21.492, 22.345, 22.68, 21.991, 22.396, 21.497, 22.086, 22.858, 21.342, 21.059, 21.295, 22.289, 22.372, 21.58, 21.618, 22.647, 21.59, 22.938, 22.156, 20.842, 21.202, 22.704, 22.788, 21.741, 21.591, 21.453, 20.515, 22.591, 21.696, 21.919, 21.298, 22.478, 21.906, 21.355, 21.791, 21.085
#             ],
#         ],    
#         [
#             [
#                 0.278, 0.262, 0.269, 0.262, 0.264, 0.256, 0.258, 0.28, 0.255, 0.23, 0.204, 0.26, 0.279, 0.279, 0.307, 0.261, 0.285, 0.277, 0.273, 0.249, 0.284, 0.262, 0.296, 0.251, 0.291, 0.229, 0.25, 0.295, 0.291, 0.302, 0.274, 0.257, 0.273, 0.264, 0.233, 0.299, 0.258, 0.302, 0.257, 0.306, 0.241, 0.278, 0.292, 0.309, 0.312, 0.207, 0.216, 0.218, 0.207, 0.207, 0.19, 0.211, 0.249, 0.237, 0.254, 0.173, 0.227, 0.18, 0.254, 0.26
#             ],
#             [
#                 0.241, 0.318, 0.227, 0.354, 0.322, 0.3, 0.322, 0.276, 0.286, 0.322, 0.308, 0.345, 0.268, 0.321, 0.247, 0.242, 0.319, 0.231, 0.303, 0.342, 0.296, 0.328, 0.268, 0.287, 0.318, 0.325, 0.301, 0.278, 0.302, 0.238, 0.244, 0.322, 0.226, 0.283, 0.327, 0.31, 0.367, 0.262, 0.305, 0.336, 0.336, 0.305, 0.3, 0.319, 0.238, 0.19, 0.295, 0.215, 0.234, 0.273, 0.244, 0.274, 0.229, 0.25, 0.291, 0.263, 0.23, 0.225, 0.244, 0.182
#             ],
#             [
#                 0.435, 0.377, 0.394, 0.411, 0.314, 0.401, 0.402, 0.394, 0.419, 0.391, 0.397, 0.427, 0.388, 0.405, 0.418, 0.416, 0.388, 0.417, 0.41, 0.32, 0.424, 0.408, 0.394, 0.436, 0.417, 0.407, 0.468, 0.392, 0.395, 0.426, 0.393, 0.414, 0.396, 0.416, 0.39, 0.399, 0.417, 0.39, 0.396, 0.458, 0.417, 0.419, 0.401, 0.396, 0.428, 0.31, 0.317, 0.304, 0.361, 0.304, 0.318, 0.338, 0.305, 0.319, 0.335, 0.308, 0.331, 0.306, 0.314, 0.339
#             ],
#             [
#                 3.706, 3.746, 3.699, 3.695, 3.675, 3.66, 3.718, 3.761, 3.678, 3.658, 3.711, 3.72, 3.716, 3.695, 3.692, 3.701, 3.707, 3.701, 3.691, 3.726, 3.698, 3.72, 3.679, 3.668, 3.804, 3.708, 3.708, 3.696, 3.689, 3.715, 3.684, 3.625, 3.738, 3.655, 3.692, 3.752, 3.765, 3.732, 3.776, 3.819, 3.718, 3.774, 3.764, 3.731, 3.737, 3.733, 3.841, 3.752, 3.714, 3.748, 3.762, 3.733, 3.726, 3.733, 3.722, 3.685, 3.71, 3.684, 3.702, 3.694
#             ],
#             [
#                 10.681, 10.697, 10.735, 10.787, 10.707, 10.659, 10.728, 10.828, 10.685, 10.761, 10.709, 10.709, 10.665, 10.717, 10.704, 10.701, 10.725, 10.653, 10.712, 10.711, 10.663, 10.676, 10.778, 10.641, 10.699, 10.66, 10.737, 10.654, 10.643, 10.694, 10.653, 10.712, 10.607, 10.656, 10.64, 10.669, 10.833, 10.753, 10.744, 10.731, 10.722, 10.722, 10.779, 10.736, 10.754, 7.556, 7.64, 7.649, 7.551, 7.46, 7.288, 7.544, 7.545, 7.469, 7.394, 7.485, 7.556, 7.602, 7.528, 7.464
#             ],
#             [
#                 15.431, 15.503, 15.552, 15.518, 15.486, 15.468, 15.425, 15.371, 15.472, 15.34, 15.368, 15.517, 15.4, 15.569, 15.426, 15.439, 15.509, 15.408, 15.486, 15.523, 15.433, 15.257, 15.302, 15.333, 15.345, 15.451, 15.588, 15.432, 15.495, 15.484, 15.534, 15.36, 15.336, 15.25, 15.182, 15.405, 15.486, 15.605, 15.574, 15.463, 15.605, 15.461, 15.495, 15.505, 15.555, 15.567, 15.632, 15.557, 15.579, 15.725, 15.439, 15.519, 15.48, 15.578, 15.489, 15.547, 15.301, 15.214, 15.316, 15.263
#             ],
#             [
#                 38.064, 38.289, 37.597, 37.867, 38.093, 37.317, 38.038, 38.744, 38.504, 37.095, 38.463, 38.711, 37.436, 37.423, 37.959, 37.628, 37.838, 37.66, 37.71, 36.914, 37.806, 37.842, 38.801, 37.739, 37.784, 37.355, 37.574, 38.613, 37.367, 37.347, 38.068, 38.82, 38.575, 38.385, 37.296, 37.016, 37.411, 37.682, 37.319, 36.89, 37.992, 38.04, 37.488, 37.236, 37.169, 26.113, 27.08, 26.782, 27.336, 26.349, 26.962, 27.049, 27.399, 26.406, 27.187, 26.678, 26.255, 27.518, 26.071, 26.485
#             ],
#             [
#                 65.688, 66.429, 68.4, 67.286, 66.539, 64.662, 67.585, 67.363, 65.951, 67.635, 65.223, 66.51, 67.114, 68.04, 67.176, 65.696, 67.452, 67.966, 65.959, 65.335, 66.404, 66.166, 65.976, 65.594, 64.85, 67.197, 66.784, 68.341, 66.761, 65.138, 64.764, 64.905, 66.763, 66.141, 65.605, 65.344, 65.555, 67.748, 66.236, 67.231, 65.167, 66.383, 67.653, 66.864, 66.543, 67.613, 67.647, 67.923, 66.89, 66.579, 67.038, 66.098, 67.973, 67.01, 65.433, 65.915, 66.157, 66.999, 66.24, 65.681
#             ],
#         ],
#         [
#             [
#                 0.521, 0.588, 0.606, 0.586, 0.57, 0.61, 0.58, 0.439, 0.606, 0.576, 0.54, 0.589, 0.451, 0.641, 0.559, 0.559, 0.556, 0.398, 0.566, 0.524, 0.52, 0.546, 0.402, 0.561, 0.518, 0.491, 0.518, 0.567, 0.61, 0.527
#             ],
#             [
#                 0.663, 0.688, 0.553, 0.75, 0.665, 0.68, 0.686, 0.629, 0.705, 0.68, 0.656, 0.713, 0.627, 0.753, 0.717, 0.646, 0.687, 0.587, 0.717, 0.633, 0.676, 0.687, 0.615, 0.691, 0.632, 0.636, 0.682, 0.653, 0.712, 0.639
#             ],
#             [
#                 1.012, 1.071, 1.091, 1.116, 1.025, 1.048, 1.094, 1.042, 0.862, 1.034, 1.053, 1.021, 1.062, 0.849, 1.075, 0.971, 1.02, 0.937, 0.744, 0.921, 0.965, 1.035, 0.95, 0.782, 0.972, 0.985, 1.002, 0.93, 0.785, 0.965
#             ],
#             [
#                 14.017, 14.461, 14.391, 14.14, 14.164, 14.118, 14.199, 14.312, 14.129, 14.216, 15.083, 14.332, 14.358, 14.17, 14.203, 14.257, 14.307, 14.395, 14.212, 14.253, 14.327, 14.42, 14.452, 14.255, 14.357, 14.17, 14.428, 14.417, 14.241, 14.194
#             ],
#             [
#                 38.89, 39.249, 39.334, 38.97, 38.745, 39.204, 39.292, 39.356, 39.666, 39.412, 38.772, 39.143, 39.098, 39.412, 39.146, 35.409, 35.77, 36.136, 36.036, 35.316, 35.558, 35.584, 35.756, 35.698, 35.737, 35.398, 35.425, 35.962, 35.96, 35.503
#             ],
#             [
#                 58.895, 57.412, 58.035, 57.572, 57.647, 57.849, 57.396, 57.187, 57.753, 56.694, 57.472, 57.216, 57.993, 57.283, 56.706, 58.057, 57.689, 58.633, 57.4, 57.53, 56.905, 57.717, 57.526, 57.786, 57.741, 57.034, 57.719, 57.535, 57.024, 57.365
#             ],
#             [
#                 132.087, 132.367, 134.63, 133.618, 132.269, 132.156, 133.94, 135.68, 134.128, 131.84, 131.681, 132.241, 134.689, 132.37, 131.669, 120.242, 120.961, 124.395, 120.443, 120.314, 120.005, 119.831, 122.211, 120.66, 118.987, 120.506, 120.252, 121.239, 120.403, 120.651
#             ],
#             [
#                 232.282, 232.321, 232.542, 233.496, 231.954, 232.797, 233.229, 231.905, 230.397, 230.282, 231.831, 233.269, 233.291, 232.885, 230.353, 231.224, 231.556, 231.963, 230.481, 231.681, 230.094, 233.015, 234.409, 235.052, 231.671, 232.82, 230.776, 232.444, 230.225, 230.629
#             ],
#         ],
#         [
#             [
#                 1.116, 1.099, 1.145, 1.106, 1.267, 1.035, 1.638, 1.594, 1.302, 1.547, 1.057, 1.535, 1.639, 1.318, 1.614
#             ],
#             [
#                 1.628, 1.753, 1.944, 1.746, 1.935, 1.61, 1.785, 1.833, 1.851, 1.971, 1.622, 1.766, 1.76, 1.751, 1.917
#             ],
#             [
#                 2.998, 3.028, 3.315, 3.116, 3.303, 2.957, 3.066, 3.207, 3.238, 3.203, 2.904, 3.05, 3.256, 3.208, 3.187
#             ],
#             [
#                 53.933, 54.448, 54.158, 53.984, 54.035, 53.914, 54.299, 54.129, 54.109, 54.31, 53.883, 54.273, 54.086, 54.198, 54.073
#             ],
#             [
#                 145.263, 145.34, 146.337, 144.229, 144.529, 144.439, 145.235, 146.048, 143.908, 145.084, 145.488, 145.221, 146.02, 144.477, 144.498
#             ],
#             [
#                 219.871, 221.598, 220.384, 221.146, 220.838, 219.945, 222.077, 220.636, 221.284, 221.206, 219.656, 220.707, 220.454, 221.921, 219.983
#             ],
#             [
#                 478.666, 484.638, 483.839, 481.316, 480.119, 482.076, 480.894, 484.2, 479.742, 479.454, 478.566, 479.542, 484.842, 476.382, 474.346
#             ],
#             [
#                 872.889, 874.202, 846.84, 873.451, 871.592, 864.231, 887.441, 874.245, 872.806, 871.109, 865.572, 871.679, 876.482, 873.382, 872.448
#             ],
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0trainingtime_l)):
#         ys_array.append(np.mean(ys_d0trainingtime_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0trainingtime_l[m_i], axis=1)/np.sqrt(len(ys_d0trainingtime_l[m_i][0])))
#     for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v", "o", "s"]):
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Input Dimensions", fontsize=20)
#     ax.set_ylabel("Training Time(s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()


#     # # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/figs-1/'
#     filename = "trainlatency_by_input_size_with_rawinput_data_0_estimated"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[50, 100, 250, 6832, 18000, 27329, 60000, 109319]
#     labels = ("Observed", "Estimated")
#     ysestimate_l = [[871.2246/109319*50, 871.2246/109319*100, 871.2246/109319*250, 871.2246/16, 871.2246/109319*18000, 871.2246/4, 871.2246/109319*60000, 871.2246]]
#     ys_array = np.mean(ys_d0trainingtime_l[3], axis=(1))
#     ci_array = 1.96 * np.std(ys_d0trainingtime_l[3], axis=1)/np.sqrt(len(ys_d0trainingtime_l[3][0]))
#     ax.scatter(xs, ys_array, label=labels[0], marker="^")
#     ax.errorbar(xs, ys_array, yerr=ci_array, fmt='o', capsize=10)
#     ax.scatter(xs, ysestimate_l, label=labels[1], marker="*")
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Input Dimensions", fontsize=20)
#     ax.set_ylabel("Training Time(s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     filename = "trainlatency_by_labels_per_model_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[10, 20, 40, 80]
#     labels = ("50 dims", "100 dims", "250 dims", "6832 dims", "18000 dims", "27329 dims", "60000 dims", "109319 dims")
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0trainingtime_l)):
#         ys_array.append(np.mean(ys_d0trainingtime_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0trainingtime_l[m_i], axis=1)/np.sqrt(len(ys_d0trainingtime_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label in zip(ys_array[[3,5,7],:], ci_array[[3,5,7],:], np.array(labels)[[3,5,7]]):
#         ax.scatter(xs, ys, label=label)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10)
#     ysestimate_l = [[871.2246/(8*((1598.4+1598.4*math.log(1598.4))/(199.8+199.8*math.log(199.8)))), 871.2246/(4*((1598.4+1598.4*math.log(1598.4))/(399.6+399.6*math.log(399.6)))), 871.2246/(2*((1598.4+1598.4*math.log(1598.4))/(799.2+799.2*math.log(799.2)))), 871.2246]]
#     ysestimatenosorting_l = [[871.2246/(8*(1598.4/199.8)), 871.2246/(4*(1598.4/399.6)), 871.2246/(2*(1598.4/799.2)), 871.2246]]
#     ax.scatter(xs, ysestimate_l, marker="x", s=100, label="Estimated with 109319 dims \& 80 packages per model")
#     ax.scatter(xs, ysestimatenosorting_l, marker="+", s=100, label="Estimated with Linear Sorting Time")
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
#     ax.set_ylabel("Training Time(s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     # # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/figs-1/'
#     filename = "trainlatency_by_labels_per_model_with_rawinput_data_0_estimated"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[10, 20, 40, 80]
#     labels = ("Observed", "Estimated", "Estimated_Linear_Sorting")
#     ysestimate_l = [[871.2246/(8*((1598.4+1598.4*math.log(1598.4))/(199.8+199.8*math.log(199.8)))), 871.2246/(4*((1598.4+1598.4*math.log(1598.4))/(399.6+399.6*math.log(399.6)))), 871.2246/(2*((1598.4+1598.4*math.log(1598.4))/(799.2+799.2*math.log(799.2)))), 871.2246]]
#     ysestimatenosorting_l = [[871.2246/(8*(1598.4/199.8)), 871.2246/(4*(1598.4/399.6)), 871.2246/(2*(1598.4/799.2)), 871.2246]]
#     ys_array = ys_array[-1,:]
#     ci_array = ci_array[-1,:]
#     ax.scatter(xs, ys_array, label=labels[0])
#     ax.errorbar(xs, ys_array, yerr=ci_array, fmt='o', capsize=10)
#     ax.scatter(xs, ysestimate_l, label=labels[1])
#     ax.scatter(xs, ysestimatenosorting_l, label=labels[2])
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
#     ax.set_ylabel("Training Time(s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()








#     # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
#     filename = "testf1score_by_input_size_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[50, 100, 250, 6832, 18000, 27329, 60000, 109319]
#     labels = ("10 labels", "20 labels","40 labels","80 labels")
#     ys_d0f1score_l=[#models
#         [#dims
#             [
#                 0.363, 0.407, 0.42, 0.39, 0.43, 0.412, 0.391, 0.42, 0.362, 0.406, 0.378, 0.395, 0.411, 0.372, 0.405
#             ],
#             [
#                 0.525, 0.542, 0.541, 0.486, 0.548, 0.538, 0.536, 0.506, 0.47, 0.558, 0.492, 0.532, 0.495, 0.504, 0.534
#             ],
#             [
#                 0.67, 0.715, 0.716, 0.679, 0.71, 0.71, 0.644, 0.696, 0.721, 0.671, 0.654, 0.696, 0.669, 0.702, 0.666
#             ],
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.825, 0.81, 0.836, 0.849, 0.866, 0.88, 0.852, 0.88, 0.836, 0.914, 0.863, 0.814, 0.855, 0.856, 0.821
#             ],
#             [
#                 0.866, 0.851, 0.818, 0.859, 0.838, 0.863, 0.861, 0.86, 0.843, 0.856, 0.892, 0.871, 0.842, 0.875, 0.873
#             ],
#             [
#                 0.845, 0.807, 0.843, 0.867, 0.869, 0.877, 0.862, 0.874, 0.864, 0.902, 0.863, 0.809, 0.865, 0.859, 0.827
#             ],
#             [
#                 0.873, 0.863, 0.829, 0.856, 0.846, 0.87, 0.854, 0.863, 0.855, 0.857, 0.904, 0.869, 0.85, 0.862, 0.873
#             ],
#             [
#                 0.847, 0.82, 0.849, 0.867, 0.867, 0.87, 0.867, 0.893, 0.872, 0.902, 0.861, 0.816, 0.872, 0.858, 0.821
#             ],
#         ],    
#         [
#             [
#                 0.475, 0.447, 0.427, 0.482, 0.452, 0.42, 0.444, 0.439, 0.465, 0.478, 0.446, 0.446, 0.438, 0.468, 0.435
#             ],
#             [
#                 0.559, 0.597, 0.577, 0.616, 0.576, 0.544, 0.557, 0.601, 0.59, 0.578, 0.55, 0.557, 0.599, 0.57, 0.547
#             ],
#             [
#                 0.679, 0.68, 0.706, 0.715, 0.682, 0.734, 0.722, 0.692, 0.746, 0.727, 0.698, 0.722, 0.693, 0.685, 0.708
#             ],
#             [
#                 0.886, 0.92, 0.865, 0.877, 0.871, 0.877, 0.882, 0.891, 0.905, 0.845, 0.893, 0.85, 0.876, 0.888, 0.876
#             ],
#             [
#                 0.897, 0.903, 0.896, 0.893, 0.891, 0.919, 0.936, 0.89, 0.899, 0.884, 0.907, 0.921, 0.929, 0.883, 0.891
#             ],
#             [
#                 0.89, 0.892, 0.903, 0.877, 0.89, 0.902, 0.905, 0.889, 0.891, 0.879, 0.879, 0.901, 0.885, 0.907, 0.869
#             ],
#             [
#                 0.9, 0.895, 0.883, 0.877, 0.883, 0.912, 0.93, 0.913, 0.915, 0.901, 0.924, 0.917, 0.933, 0.88, 0.905
#             ],
#             [
#                 0.891, 0.897, 0.905, 0.893, 0.875, 0.888, 0.91, 0.881, 0.891, 0.889, 0.903, 0.909, 0.903, 0.894, 0.877
#             ],
#         ],
#         [
#             [
#                 0.429, 0.448, 0.44, 0.455, 0.432, 0.415, 0.418, 0.407, 0.419, 0.424, 0.405, 0.391, 0.415, 0.436, 0.428
#             ],
#             [
#                 0.594, 0.58, 0.585, 0.596, 0.589, 0.566, 0.557, 0.552, 0.565, 0.594, 0.525, 0.576, 0.601, 0.61, 0.578
#             ],
#             [
#                 0.708, 0.729, 0.695, 0.712, 0.712, 0.726, 0.72, 0.716, 0.705, 0.717, 0.691, 0.697, 0.717, 0.69, 0.701
#             ],
#             [
#                 0.897, 0.87, 0.896, 0.896, 0.905, 0.914, 0.932, 0.949, 0.913, 0.92, 0.915, 0.897, 0.896, 0.89, 0.903
#             ],
#             [
#                 0.926, 0.937, 0.917, 0.927, 0.912, 0.945, 0.915, 0.957, 0.947, 0.929, 0.945, 0.925, 0.899, 0.928, 0.941
#             ],
#             [
#                 0.905, 0.92, 0.924, 0.904, 0.905, 0.932, 0.934, 0.923, 0.956, 0.94, 0.925, 0.911, 0.926, 0.914, 0.923
#             ],
#             [
#                 0.923, 0.937, 0.944, 0.921, 0.924, 0.946, 0.935, 0.938, 0.948, 0.948, 0.932, 0.929, 0.931, 0.912, 0.917
#             ],
#             [
#                 0.915, 0.933, 0.916, 0.925, 0.912, 0.932, 0.932, 0.925, 0.944, 0.937, 0.942, 0.93, 0.918, 0.926, 0.907
#             ],
#         ],
#         [
#             [
#                 0.363, 0.365, 0.339, 0.317, 0.365, 0.363, 0.365, 0.339, 0.317, 0.365, 0.363, 0.365, 0.339, 0.317, 0.365
#             ],
#             [
#                 0.522, 0.527, 0.504, 0.48, 0.514, 0.522, 0.527, 0.504, 0.48, 0.514, 0.522, 0.527, 0.504, 0.48, 0.514
#             ],
#             [
#                 0.678, 0.688, 0.683, 0.662, 0.692, 0.678, 0.688, 0.683, 0.662, 0.692, 0.678, 0.688, 0.683, 0.662, 0.692
#             ],
#             [
#                 0.9, 0.908, 0.913, 0.91, 0.909, 0.9, 0.908, 0.913, 0.91, 0.909, 0.9, 0.908, 0.913, 0.91, 0.909
#             ],
#             [
#                 0.945, 0.943, 0.924, 0.929, 0.927, 0.945, 0.943, 0.924, 0.929, 0.927, 0.945, 0.943, 0.924, 0.929, 0.927
#             ],
#             [
#                 0.94, 0.937, 0.94, 0.942, 0.946, 0.94, 0.937, 0.94, 0.942, 0.946, 0.94, 0.937, 0.94, 0.942, 0.946
#             ],
#             [
#                 0.956, 0.937, 0.955, 0.949, 0.962, 0.956, 0.937, 0.955, 0.949, 0.962, 0.956, 0.937, 0.955, 0.949, 0.962
#             ],
#             [
#                 0.951, 0.952, 0.956, 0.955, 0.955, 0.951, 0.952, 0.956, 0.955, 0.955, 0.951, 0.952, 0.956, 0.955, 0.955
#             ],
#         ]
#     ]
#     ys_array = np.mean(ys_d0f1score_l, axis=(2))
#     ci_array = 1.96 * np.std(ys_d0f1score_l, axis=2)/np.sqrt(len(ys_d0f1score_l[0][0]))
#     for ys, ci, label in zip(ys_array, ci_array, labels):
#         ax.scatter(xs, ys, label=label)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10)
#     ax.set_xlim([0, 300])
#     ax.hlines(ys_array[0,3], xmin=0, xmax=7000, label="10 labels \&\& 6832 dims")
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Input Dimensions", fontsize=20)
#     ax.set_ylabel("F1-Scores", fontsize=20)
#     ax.grid()
#     plt.legend(loc="lower right", prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     filename = "testf1score_by_labels_per_model_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[10, 20, 40, 80]
#     labels = ("50 dims", "100 dims", "250 dims", "6832 dims", "18000 dims", "27329 dims", "60000 dims", "109319 dims")
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0f1score_l)):
#         ys_array.append(np.mean(ys_d0f1score_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0f1score_l[m_i], axis=1)/np.sqrt(len(ys_d0f1score_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label in zip(ys_array[[3,5,7],:], ci_array[[3,5,7],:], np.array(labels)[[3,5,7]]):
#         ax.scatter(xs, ys, label=label)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
#     ax.set_ylabel("F1-Scores", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()








#     # # # ###################### data3 ############################################
#     filename = "testf1score_by_labels_per_model_with_rawinput_data_3"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     # xs=[20, 50, 500]
#     xs=[10, 20, 50]
#     labels = ("500labels-F1-with-filter", "500labels-F1-no-filter")
#     ys_d3nonef1score_l=[#models
#         [
#             [
#                 0.88, 0.882, 0.881, 0.884, 0.881, 0.886, 0.887, 0.868, 0.885, 0.881, 0.88, 0.877, 0.867, 0.891, 0.884
#             ],
#             [
#                 0.598, 0.614, 0.579, 0.595, 0.618, 0.582, 0.598, 0.567, 0.606, 0.628, 0.587, 0.59, 0.602, 0.622, 0.618
#             ]
#         ],
#         [#filter or not
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.862, 0.875, 0.885, 0.882, 0.878, 0.881, 0.875, 0.885, 0.891, 0.88, 0.873, 0.878, 0.881, 0.888, 0.886
#             ],
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.65, 0.651, 0.615, 0.64, 0.634, 0.638, 0.643, 0.626, 0.654, 0.65, 0.64, 0.621, 0.636, 0.652, 0.631
#             ]
#         ],    
#         [
#             [
#                 0.874, 0.881, 0.883, 0.897, 0.887, 0.883, 0.876, 0.889, 0.889, 0.894, 0.878, 0.879, 0.882, 0.884, 0.891
#             ],
#             [
#                 0.69, 0.693, 0.679, 0.707, 0.685, 0.7, 0.698, 0.669, 0.718, 0.701, 0.704, 0.707, 0.683, 0.724, 0.697
#             ]
#         ],
#         # [
#         #     [
#         #         0.95, 0.952, 0.951, 0.951, 0.95, 0.95, 0.952, 0.951, 0.951, 0.95, 0.95, 0.952, 0.951, 0.951, 0.95
#         #     ],
#         #     [
#         #         0.915, 0.933, 0.916, 0.925, 0.912, 0.932, 0.932, 0.925, 0.944, 0.937, 0.942, 0.93, 0.918, 0.926, 0.907
#         #     ]
#         # ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d3nonef1score_l)):
#         ys_array.append(np.mean(ys_d3nonef1score_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d3nonef1score_l[m_i], axis=1)/np.sqrt(len(ys_d3nonef1score_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
#     xs=[10, 20, 40, 80]
#     labels = ("80labels-F1-no-filter",)
#     ys_d0nonef1score_l=[#models
#         [#dims
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.847, 0.82, 0.849, 0.867, 0.867, 0.87, 0.867, 0.893, 0.872, 0.902, 0.861, 0.816, 0.872, 0.858, 0.821
#             ]
#         ],    
#         [
#             [
#                 0.891, 0.897, 0.905, 0.893, 0.875, 0.888, 0.91, 0.881, 0.891, 0.889, 0.903, 0.909, 0.903, 0.894, 0.877
#             ]
#         ],
#         [
#             [
#                 0.915, 0.933, 0.916, 0.925, 0.912, 0.932, 0.932, 0.925, 0.944, 0.937, 0.942, 0.93, 0.918, 0.926, 0.907
#             ]
#         ],
#         [
#             [
#                 0.951, 0.952, 0.956, 0.955, 0.955, 0.951, 0.952, 0.956, 0.955, 0.955, 0.951, 0.952, 0.956, 0.955, 0.955
#             ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0nonef1score_l)):
#         ys_array.append(np.mean(ys_d0nonef1score_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0nonef1score_l[m_i], axis=1)/np.sqrt(len(ys_d0nonef1score_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label in zip(ys_array, ci_array, labels):
#         ax.scatter(xs, ys, label=label, color='#ff0067', marker="*")
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, color='#ff0067', marker="*")
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
#     ax.set_ylim(0.3,1)
#     ax.set_ylabel("F1-Score", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()


# # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! "500labels-F1-no-filter": missing partial CV results
#     filename = "trainlatency_by_labels_per_model_with_rawinput_data_3"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     # xs=[20, 50, 500]
#     xs=[10, 20, 50, 100, 500]
#     labels = ("500labels-F1-with-filter", "500labels-F1-no-filter")
#     ys_d3nonetrainlat_l=[#models
#         [
#             [
#                 0.146, 0.139, 0.129, 0.139, 0.143, 0.209, 0.153, 0.208, 0.276, 0.234, 0.378, 0.325, 0.421, 0.401, 0.416, 0.215, 0.212, 0.173, 0.141, 0.206, 0.148, 0.122, 0.156, 0.175, 0.191, 0.175, 0.127, 0.184, 0.194, 0.187, 0.145, 0.123, 0.125, 0.106, 0.133, 0.149, 0.126, 0.14, 0.149, 0.199, 0.166, 0.122, 0.156, 0.181, 0.187, 0.17, 0.16, 0.15, 0.119, 0.152, 0.211, 0.158, 0.195, 0.188, 0.244, 0.138, 0.1, 0.149, 0.161, 0.152, 0.192, 0.202, 0.154, 0.133, 0.184, 0.21, 0.144, 0.226, 0.168, 0.206, 0.158, 0.163, 0.172, 0.188, 0.159, 0.183, 0.167, 0.169, 0.129, 0.175, 0.326, 0.193, 0.345, 0.238, 0.27, 0.165, 0.133, 0.168, 0.198, 0.158, 0.289, 0.285, 0.255, 0.215, 0.269, 0.149, 0.144, 0.156, 0.138, 0.155, 0.16, 0.124, 0.16, 0.169, 0.147, 0.138, 0.159, 0.127, 0.128, 0.158, 0.232, 0.218, 0.255, 0.191, 0.207, 0.188, 0.156, 0.2, 0.183, 0.213, 0.233, 0.238, 0.191, 0.162, 0.211, 0.144, 0.149, 0.154, 0.143, 0.146, 0.159, 0.149, 0.196, 0.194, 0.189, 0.161, 0.173, 0.169, 0.131, 0.162, 0.151, 0.146, 0.151, 0.171, 0.181, 0.156, 0.171, 0.195, 0.163, 0.194, 0.133, 0.167, 0.163, 0.139, 0.149, 0.337, 0.391, 0.325, 0.334, 0.477, 0.185, 0.196, 0.213, 0.201, 0.211, 0.279, 0.292, 0.249, 0.245, 0.246, 0.133, 0.16, 0.144, 0.122, 0.131, 0.168, 0.17, 0.215, 0.183, 0.203, 0.182, 0.142, 0.132, 0.132, 0.162, 0.286, 0.25, 0.256, 0.263, 0.254, 0.204, 0.211, 0.234, 0.226, 0.218, 0.188, 0.163, 0.186, 0.176, 0.173, 0.144, 0.121, 0.149, 0.143, 0.152, 0.179, 0.18, 0.178, 0.16, 0.188, 0.331, 0.313, 0.331, 0.311, 0.349, 0.226, 0.181, 0.229, 0.245, 0.213, 0.162, 0.172, 0.158, 0.149, 0.164, 0.211, 0.201, 0.221, 0.231, 0.225, 0.219, 0.168, 0.197, 0.206, 0.234, 0.164, 0.197, 0.142, 0.217, 0.209, 0.147, 0.154, 0.161, 0.15, 0.165, 0.141, 0.145, 0.143, 0.156, 0.15, 0.275, 0.319, 0.226, 0.334, 0.263, 0.179, 0.15, 0.159, 0.163, 0.177, 0.146, 0.144, 0.176, 0.149, 0.167, 0.236, 0.308, 0.221, 0.281, 0.257, 0.219, 0.177, 0.19, 0.196, 0.214, 0.147, 0.15, 0.155, 0.207, 0.144, 0.248, 0.241, 0.169, 0.233, 0.238, 0.173, 0.107, 0.159, 0.167, 0.14, 0.156, 0.148, 0.154, 0.176, 0.166, 0.304, 0.317, 0.194, 0.308, 0.284, 0.302, 0.23, 0.29, 0.29, 0.278, 0.171, 0.167, 0.182, 0.169, 0.188, 0.178, 0.199, 0.127, 0.173, 0.161, 0.314, 0.248, 0.322, 0.289, 0.388, 0.181, 0.162, 0.19, 0.211, 0.184, 0.183, 0.135, 0.13, 0.181, 0.188, 0.38, 0.361, 0.371, 0.385, 0.38, 0.163, 0.16, 0.149, 0.166, 0.168, 0.173, 0.13, 0.133, 0.166, 0.162, 0.188, 0.146, 0.151, 0.186, 0.177, 0.132, 0.182, 0.136, 0.13, 0.141, 0.161, 0.127, 0.134, 0.166, 0.177, 0.176, 0.185, 0.154, 0.17, 0.175, 0.139, 0.154, 0.131, 0.139, 0.144, 0.159, 0.134, 0.143, 0.165, 0.16, 0.194, 0.158, 0.18, 0.209, 0.197, 0.203, 0.17, 0.187, 0.188, 0.199, 0.208, 0.178, 0.161, 0.21, 0.204, 0.288, 0.226, 0.277, 0.29, 0.274, 0.175, 0.196, 0.186, 0.182, 0.194, 0.331, 0.276, 0.229, 0.45, 0.335, 0.182, 0.153, 0.153, 0.149, 0.165, 0.271, 0.26, 0.267, 0.296, 0.278, 0.134, 0.137, 0.125, 0.176, 0.145, 0.238, 0.2, 0.191, 0.227, 0.228, 0.16, 0.156, 0.175, 0.173, 0.173, 0.173, 0.202, 0.164, 0.19, 0.193, 0.218, 0.19, 0.185, 0.18, 0.204, 0.266, 0.293, 0.258, 0.317, 0.267, 0.171, 0.16, 0.15, 0.159, 0.171, 0.135, 0.149, 0.165, 0.176, 0.166, 0.377, 0.363, 0.367, 0.415, 0.384, 0.18, 0.179, 0.168, 0.193, 0.189, 0.189, 0.225, 0.214, 0.194, 0.216, 0.151, 0.147, 0.141, 0.183, 0.177, 0.179, 0.179, 0.194, 0.191, 0.186, 0.209, 0.214, 0.188, 0.195, 0.22, 0.178, 0.188, 0.184, 0.23, 0.198, 0.154, 0.12, 0.137, 0.123, 0.157, 0.205, 0.198, 0.177, 0.19, 0.196, 0.296, 0.268, 0.279, 0.314, 0.281, 0.143, 0.135, 0.172, 0.119, 0.174, 0.171, 0.16, 0.18, 0.17, 0.207, 0.159, 0.161, 0.144, 0.159, 0.165, 0.192, 0.21, 0.227, 0.213, 0.236, 0.283, 0.215, 0.261, 0.22, 0.242, 0.184, 0.194, 0.174, 0.182, 0.18, 0.244, 0.293, 0.259, 0.26, 0.286, 0.241, 0.171, 0.224, 0.227, 0.251, 0.347, 0.384, 0.303, 0.293, 0.33, 0.218, 0.233, 0.217, 0.245, 0.228, 0.193, 0.15, 0.186, 0.214, 0.187, 0.295, 0.298, 0.305, 0.396, 0.342, 0.166, 0.173, 0.178, 0.185, 0.175, 0.137, 0.123, 0.13, 0.128, 0.147, 0.176, 0.139, 0.16, 0.163, 0.152, 0.345, 0.338, 0.353, 0.341, 0.341, 0.357, 0.336, 0.36, 0.349, 0.363, 0.466, 0.388, 0.449, 0.443, 0.444, 0.138, 0.128, 0.138, 0.15, 0.154, 0.316, 0.196, 0.288, 0.224, 0.306, 0.158, 0.17, 0.157, 0.152, 0.159, 0.2, 0.206, 0.205, 0.263, 0.202, 0.19, 0.129, 0.169, 0.176, 0.197, 0.266, 0.225, 0.26, 0.272, 0.231, 0.383, 0.291, 0.307, 0.3, 0.321, 0.139, 0.128, 0.172, 0.155, 0.146, 0.178, 0.121, 0.163, 0.179, 0.167, 0.196, 0.164, 0.171, 0.188, 0.172, 0.287, 0.252, 0.282, 0.222, 0.264, 0.23, 0.184, 0.263, 0.265, 0.231, 0.201, 0.175, 0.167, 0.181, 0.202, 0.154, 0.174, 0.169, 0.178, 0.21, 0.142, 0.131, 0.155, 0.154, 0.151, 0.272, 0.268, 0.277, 0.298, 0.284, 0.17, 0.174, 0.164, 0.186, 0.183, 0.163, 0.125, 0.174, 0.168, 0.195, 0.483, 0.449, 0.309, 0.347, 0.363, 0.169, 0.177, 0.176, 0.174, 0.167, 0.239, 0.15, 0.268, 0.239, 0.22, 0.189, 0.19, 0.186, 0.22, 0.19, 0.117, 0.097, 0.138, 0.153, 0.138, 0.071, 0.057, 0.075, 0.065, 0.076, 0.077, 0.069, 0.07, 0.071, 0.072
#             ],
#             [
#                 0.309, 0.254, 0.263, 0.354, 0.25, 0.24, 0.279, 0.282, 0.266, 0.212, 0.408, 0.419, 0.381, 0.462, 0.394, 0.497, 0.464, 0.503, 0.455, 0.442, 0.496, 0.506, 0.503, 0.494, 0.412, 0.367, 0.356, 0.345, 0.388, 0.383, 0.332, 0.294, 0.431, 0.312, 0.328, 0.526, 0.521, 0.552, 0.514, 0.457, 0.495, 0.514, 0.51, 0.498, 0.484, 0.444, 0.404, 0.448, 0.392, 0.42, 0.621, 0.633, 0.619, 0.637, 0.55, 0.203, 0.257, 0.246, 0.2, 0.258, 0.668, 0.603, 0.661, 0.639, 0.583, 0.499, 0.464, 0.49, 0.491, 0.468, 0.374, 0.31, 0.286, 0.227, 0.32, 0.644, 0.643, 0.643, 0.637, 0.579, 0.286, 0.26, 0.249, 0.262, 0.281, 0.247, 0.245, 0.244, 0.202, 0.287, 0.347, 0.351, 0.442, 0.351, 0.341, 0.421, 0.37, 0.409, 0.353, 0.414, 0.371, 0.381, 0.358, 0.317, 0.376, 0.386, 0.4, 0.381, 0.395, 0.408, 0.376, 0.362, 0.397, 0.386, 0.389, 0.337, 0.273, 0.272, 0.217, 0.26, 0.365, 0.351, 0.364, 0.37, 0.36, 0.424, 0.379, 0.341, 0.401, 0.403, 0.355, 0.359, 0.343, 0.324, 0.333, 0.395, 0.415, 0.355, 0.348, 0.338, 0.462, 0.451, 0.46, 0.439, 0.449, 0.416, 0.371, 0.347, 0.364, 0.337, 0.678, 0.711, 0.668, 0.69, 0.636, 0.245, 0.228, 0.248, 0.261, 0.257, 0.264, 0.247, 0.244, 0.248, 0.212, 0.261, 0.272, 0.283, 0.259, 0.31, 0.253, 0.274, 0.228, 0.239, 0.235, 0.463, 0.389, 0.337, 0.326, 0.348, 0.542, 0.557, 0.55, 0.534, 0.514, 0.453, 0.583, 0.457, 0.469, 0.617, 0.487, 0.501, 0.512, 0.506, 0.444, 0.411, 0.403, 0.397, 0.392, 0.397, 0.205, 0.236, 0.238, 0.207, 0.201, 0.511, 0.521, 0.511, 0.486, 0.491, 0.308, 0.318, 0.316, 0.284, 0.281, 0.597, 0.643, 0.639, 0.634, 0.578, 0.376, 0.374, 0.365, 0.36, 0.378, 0.375, 0.41, 0.356, 0.364, 0.417, 0.231, 0.273, 0.279, 0.26, 0.284, 0.523, 0.526, 0.54, 0.531, 0.503, 0.361, 0.393, 0.349, 0.33, 0.38, 0.368, 0.423, 0.363, 0.382, 0.357, 0.38, 0.353, 0.358, 0.372, 0.445, 0.386, 0.379, 0.402, 0.37, 0.378, 0.331, 0.378, 0.341, 0.383, 0.358, 0.423, 0.384, 0.419, 0.422, 0.376, 0.383, 0.411, 0.45, 0.452, 0.566, 0.323, 0.35, 0.336, 0.379, 0.362, 0.593, 0.615, 0.632, 0.601, 0.542, 0.345, 0.357, 0.382, 0.382, 0.373, 0.275, 0.269, 0.29, 0.269, 0.307, 0.392, 0.449, 0.395, 0.441, 0.428, 0.58, 0.589, 0.635, 0.585, 0.557, 0.366, 0.383, 0.358, 0.397, 0.348, 0.407, 0.438, 0.412, 0.412, 0.404, 0.381, 0.37, 0.395, 0.349, 0.37, 0.575, 0.583, 0.598, 0.61, 0.565, 0.405, 0.519, 0.464, 0.324, 0.477, 0.367, 0.392, 0.387, 0.365, 0.364, 0.913, 0.938, 0.966, 0.934, 0.908, 0.344, 0.403, 0.383, 0.412, 0.417, 0.459, 0.445, 0.427, 0.409, 0.397, 0.264, 0.285, 0.294, 0.263, 0.269, 0.452, 0.42, 0.392, 0.393, 0.487, 0.693, 0.691, 0.715, 0.711, 0.672, 0.266, 0.307, 0.312, 0.29, 0.307, 0.366, 0.37, 0.394, 0.363, 0.388, 0.416, 0.401, 0.409, 0.357, 0.399, 0.512, 0.517, 0.525, 0.528, 0.503, 0.434, 0.45, 0.448, 0.459, 0.445, 0.282, 0.239, 0.271, 0.265, 0.273, 0.334, 0.428, 0.329, 0.379, 0.302, 0.593, 0.611, 0.627, 0.608, 0.592, 0.592, 0.608, 0.592, 0.572, 0.571, 0.411, 0.388, 0.396, 0.366, 0.4, 0.348, 0.297, 0.29, 0.382, 0.288, 0.415, 0.43, 0.328, 0.378, 0.419, 0.293, 0.296, 0.324, 0.215, 0.306, 0.281, 0.362, 0.334, 0.336, 0.284, 0.258, 0.296, 0.167, 0.226, 0.253, 0.468, 0.364, 0.287, 0.298, 0.371, 0.292, 0.27, 0.288, 0.272, 0.28, 0.292, 0.315, 0.237, 0.367, 0.328, 0.226, 0.223, 0.174, 0.189, 0.236, 0.394, 0.345, 0.359, 0.381, 0.341, 0.386, 0.357, 0.276, 0.383, 0.38, 0.46, 0.416, 0.432, 0.429, 0.473, 0.453, 0.476, 0.501, 0.501, 0.474, 0.386, 0.402, 0.402, 0.387, 0.415, 0.359, 0.358, 0.364, 0.379, 0.408, 0.312, 0.278, 0.282, 0.365, 0.307, 0.337, 0.371, 0.313, 0.369, 0.426, 0.293, 0.26, 0.301, 0.29, 0.382, 0.292, 0.289, 0.266, 0.313, 0.323, 0.276, 0.265, 0.267, 0.334, 0.263, 0.44, 0.514, 0.475, 0.485, 0.469, 0.407, 0.351, 0.394, 0.393, 0.442, 0.309, 0.256, 0.245, 0.306, 0.271, 0.563, 0.437, 0.481, 0.44, 0.428, 0.903, 0.853, 0.862, 0.87, 0.794, 0.349, 0.352, 0.343, 0.388, 0.362, 0.411, 0.359, 0.388, 0.385, 0.386, 0.413, 0.363, 0.33, 0.383, 0.431, 0.245, 0.224, 0.228, 0.231, 0.233, 0.408, 0.372, 0.418, 0.401, 0.363, 0.634, 0.661, 0.662, 0.619, 0.611, 0.227, 0.207, 0.202, 0.172, 0.229, 1.098, 1.1, 1.196, 1.116, 1.059, 0.573, 0.582, 0.583, 0.576, 0.546, 0.298, 0.27, 0.231, 0.202, 0.269, 0.334, 0.281, 0.28, 0.275, 0.336, 0.388, 0.408, 0.397, 0.36, 0.354, 0.305, 0.291, 0.271, 0.236, 0.291, 0.568, 0.519, 0.541, 0.548, 0.531, 0.584, 0.579, 0.594, 0.599, 0.559, 0.482, 0.524, 0.496, 0.47, 0.484, 0.617, 0.427, 0.484, 0.577, 0.464, 0.351, 0.359, 0.32, 0.365, 0.359, 0.47, 0.477, 0.486, 0.492, 0.443, 0.348, 0.274, 0.301, 0.307, 0.32, 0.412, 0.448, 0.463, 0.444, 0.423, 0.434, 0.442, 0.406, 0.411, 0.372, 0.399, 0.403, 0.414, 0.397, 0.44, 0.288, 0.323, 0.283, 0.369, 0.297, 0.467, 0.495, 0.448, 0.477, 0.409, 0.231, 0.291, 0.25, 0.241, 0.288, 0.363, 0.347, 0.379, 0.369, 0.367, 0.133, 0.109, 0.106, 0.132, 0.093, 0.116, 0.143, 0.153, 0.148, 0.153, 0.217, 0.137, 0.231, 0.227, 0.212
#             ]
#         ],
#         [#filter or not
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.366, 0.367, 0.369, 0.376, 0.358, 0.468, 0.491, 0.427, 0.511, 0.487, 1.01, 1.064, 1.048, 1.066, 0.975, 0.218, 0.22, 0.345, 0.338, 0.26, 0.453, 0.471, 0.501, 0.51, 0.46, 0.319, 0.387, 0.322, 0.37, 0.342, 0.266, 0.306, 0.464, 0.457, 0.384, 0.647, 0.684, 0.662, 0.943, 0.648, 0.453, 0.478, 0.37, 0.408, 0.431, 0.467, 0.516, 0.68, 0.924, 0.569, 0.464, 0.496, 0.464, 0.464, 0.454, 0.379, 0.382, 0.331, 0.389, 0.422, 0.266, 0.433, 0.446, 0.474, 0.399, 0.333, 0.335, 0.365, 0.381, 0.35, 0.426, 0.39, 0.337, 0.427, 0.417, 0.321, 0.519, 0.556, 0.812, 0.472, 0.665, 1.081, 0.785, 0.863, 0.853, 0.508, 0.484, 0.394, 0.53, 0.486, 0.202, 0.343, 0.326, 0.358, 0.319, 0.604, 0.587, 0.534, 0.458, 0.577, 0.511, 0.493, 0.422, 0.634, 0.522, 0.401, 0.588, 0.589, 0.704, 0.589, 0.531, 0.574, 0.539, 0.537, 0.553, 0.441, 0.418, 0.401, 0.468, 0.455, 0.259, 0.364, 0.266, 0.358, 0.317, 0.316, 0.362, 0.326, 0.36, 0.349, 0.757, 0.647, 0.705, 0.766, 0.749, 0.348, 0.436, 0.443, 0.442, 0.385, 0.362, 0.375, 0.349, 0.42, 0.394, 0.773, 0.593, 0.556, 0.601, 0.558, 0.659, 0.725, 0.776, 0.739, 0.69, 0.472, 0.472, 0.449, 0.461, 0.44, 0.437, 0.448, 0.412, 0.441, 0.437, 0.945, 0.996, 0.993, 0.98, 0.948, 0.335, 0.356, 0.325, 0.475, 0.373, 0.365, 0.408, 0.337, 0.348, 0.385, 0.411, 0.385, 0.398, 0.405, 0.351, 0.332, 0.37, 0.353, 0.511, 0.369, 0.513, 0.384, 0.478, 0.441, 0.438, 0.603, 0.809, 0.605, 0.806, 0.555, 0.598, 0.866, 0.611, 0.715, 0.624, 0.679, 0.696, 0.681, 0.688, 0.699, 0.469, 0.485, 0.458, 0.491, 0.454, 0.57, 0.562, 0.622, 0.663, 0.661, 0.416, 0.426, 0.481, 0.457, 0.451, 0.408, 0.367, 0.465, 0.475, 0.395, 0.983, 1.013, 0.977, 1.009, 0.955, 0.414, 0.417, 0.43, 0.456, 0.466, 0.588, 0.506, 0.461, 0.465, 0.46, 0.712, 0.598, 0.589, 0.72, 0.675, 0.393, 0.348, 0.408, 0.381, 0.381, 0.54, 0.528, 0.718, 0.557, 0.552, 0.398, 0.385, 0.364, 0.402, 0.429, 0.626, 0.941, 0.759, 0.892, 0.653, 0.553, 0.5, 0.484, 0.766, 0.543, 0.677, 0.691, 0.673, 0.738, 0.637, 0.72, 0.533, 0.659, 0.635, 0.62, 0.882, 0.927, 0.918, 0.909, 0.872, 1.169, 1.191, 1.129, 1.185, 1.126, 0.881, 0.919, 0.915, 0.938, 0.855, 0.567, 0.574, 0.61, 0.903, 0.589, 0.68, 0.517, 0.464, 0.596, 0.548, 0.79, 0.568, 0.578, 0.62, 0.554, 0.482, 0.515, 0.496, 0.472, 0.485, 0.697, 0.517, 0.541, 0.53, 0.507, 0.432, 0.428, 0.5, 0.468, 0.453, 0.388, 0.392, 0.36, 0.496, 0.414, 0.387, 0.36, 0.363, 0.467, 0.391, 0.829, 0.734, 0.74, 0.798, 0.731, 0.467, 0.44, 0.474, 0.416, 0.474, 0.287, 0.333, 0.322, 0.379, 0.308, 0.286, 0.265, 0.28, 0.294, 0.30
#             ],
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 1.451, 1.387, 1.517, 1.477, 1.392, 1.042, 0.983, 0.939, 0.937, 0.947, 1.151, 1.107, 1.111, 1.168, 1.094, 0.794, 0.733, 0.861, 0.904, 0.864, 2.828, 2.759, 2.761, 2.771, 2.62, 1.308, 1.303, 1.275, 1.274, 1.192, 3.357, 3.331, 3.383, 3.365, 3.155, 1.282, 1.169, 1.217, 1.208, 1.122, 0.767, 0.752, 0.751, 0.716, 1.054, 0.749, 0.699, 1.14, 0.759, 1.113, 0.955, 0.848, 0.91, 0.876, 0.818, 0.885, 0.816, 0.808, 0.89, 0.777, 1.348, 1.384, 1.431, 1.348, 1.335, 1.172, 1.118, 1.156, 1.128, 1.018, 1.015, 0.926, 0.98, 1.037, 0.926, 1.921, 1.958, 2.07, 1.969, 1.784, 0.797, 0.732, 0.739, 0.793, 0.705, 0.65, 0.809, 0.747, 0.965, 0.648, 1.831, 1.861, 1.874, 1.835, 1.757, 0.765, 0.664, 0.721, 0.669, 0.683, 1.4, 1.385, 1.361, 1.385, 1.336, 0.766, 0.813, 1.117, 0.759, 0.753, 1.634, 1.658, 1.691, 1.736, 1.605, 1.716, 1.725, 1.7, 1.684, 1.575, 0.75, 0.953, 0.803, 1.061, 0.857, 0.919, 0.968, 0.855, 0.771, 0.905, 2.101, 2.024, 2.028, 2.02, 1.872, 1.095, 1.101, 1.122, 1.076, 1.087, 0.864, 0.895, 0.837, 0.869, 0.834, 1.642, 1.636, 1.66, 1.584, 1.584, 1.781, 1.85, 1.832, 1.83, 1.74, 1.004, 0.998, 0.954, 0.963, 0.972, 1.283, 1.293, 1.218, 1.189, 1.156, 0.864, 0.885, 0.911, 0.882, 0.869, 3.681, 3.724, 3.758, 3.717, 3.471, 1.062, 1.053, 1.045, 1.07, 0.947, 1.694, 1.624, 1.684, 1.68, 1.57, 0.806, 1.108, 0.732, 1.12, 1.127, 0.82, 0.88, 1.055, 0.851, 0.815, 1.612, 1.53, 1.599, 1.642, 1.487, 1.416, 1.386, 1.385, 1.398, 1.371, 2.181, 2.213, 2.26, 2.269, 2.094, 1.658, 1.587, 1.696, 1.672, 1.524, 1.003, 1.019, 0.999, 0.99, 0.937, 0.823, 0.892, 0.867, 1.293, 0.863, 0.956, 0.931, 1.001, 0.912, 0.915, 1.074, 0.721, 0.722, 0.75, 0.76, 0.605, 0.611, 0.618, 0.611, 0.601, 0.857, 0.872, 0.945, 0.921, 0.841, 1.358, 1.33, 1.315, 1.393, 1.27, 1.398, 1.41, 1.447, 1.394, 1.269, 1.103, 1.066, 1.104, 1.107, 1.04, 0.837, 1.016, 0.846, 0.843, 0.827, 0.71, 1.034, 0.737, 0.709, 0.694, 0.801, 0.702, 0.802, 1.165, 0.798, 1.583, 1.586, 1.638, 1.578, 1.463, 2.817, 2.837, 2.883, 2.877, 2.598, 0.812, 0.741, 0.942, 0.857, 0.81, 2.313, 2.293, 2.354, 2.307, 2.105, 1.799, 1.935, 1.809, 1.822, 1.755, 0.547, 0.529, 0.649, 0.512, 0.522, 1.9, 1.863, 1.886, 1.85, 1.671, 3.02, 3.03, 2.991, 3.12, 2.791, 1.326, 1.296, 1.354, 1.298, 1.289, 1.589, 1.539, 1.56, 1.629, 1.431, 0.72, 1.039, 0.673, 0.692, 0.738, 1.77, 1.821, 1.787, 1.721, 1.681, 0.909, 0.87, 1.418, 0.956, 0.952, 1.165, 0.93, 1.15, 0.916, 1.227, 0.852, 0.848, 0.799, 0.822, 0.803, 0.657, 0.666, 0.628, 0.665, 0.593, 0.902, 0.869, 0.846, 0.876, 0.817
#             ]
#         ],    
#         [
#             [
#                 1.806, 1.79, 1.956, 1.836, 1.841, 2.172, 2.173, 2.748, 1.818, 1.736, 4.609, 4.909, 4.643, 4.532, 4.369, 2.864, 3.0, 2.971, 2.955, 2.86, 2.044, 2.128, 2.056, 2.034, 2.035, 1.708, 1.691, 1.707, 1.579, 1.642, 2.438, 2.532, 2.442, 2.422, 2.338, 2.739, 2.859, 2.747, 2.762, 2.669, 1.945, 2.898, 1.996, 2.749, 2.321, 1.383, 2.061, 1.392, 1.695, 1.33, 1.335, 1.465, 1.363, 2.055, 2.152, 2.758, 2.927, 2.923, 2.789, 2.744, 5.853, 5.942, 5.801, 5.81, 5.521, 1.425, 1.591, 1.621, 1.464, 1.526, 1.906, 1.886, 1.892, 1.847, 2.742, 2.344, 2.498, 2.526, 2.386, 2.26, 2.609, 2.758, 2.647, 2.586, 2.516, 2.298, 2.425, 2.366, 2.283, 2.269, 1.821, 1.956, 1.864, 2.639, 2.617, 5.058, 5.018, 4.856, 4.891, 4.69, 2.248, 2.176, 2.326, 1.46, 1.53, 1.992, 2.131, 2.032, 1.933, 1.888, 2.981, 3.089, 2.991, 2.973, 2.837, 3.063, 3.087, 2.979, 3.025, 2.917, 4.389, 4.541, 4.453, 4.378, 4.014, 5.542, 5.629, 5.545, 5.513, 5.295, 4.91, 5.077, 4.801, 4.725, 4.671, 2.037, 2.181, 2.06, 2.054, 1.933, 2.403, 1.757, 1.761, 2.31, 1.682, 2.939, 2.947, 2.875, 2.911, 2.743
#             ],
#             [
#                 19.543, 18.144, 18.402, 18.576, 16.52, 24.082, 23.9, 23.984, 22.898, 20.422, 10.167, 10.219, 10.31, 10.061, 9.128, 14.531, 14.467, 14.574, 14.305, 12.938, 8.181, 8.208, 8.016, 8.146, 7.481, 5.899, 5.907, 5.908, 5.99, 5.748, 18.479, 18.361, 18.286, 18.263, 16.697, 3.816, 3.855, 3.949, 3.936, 3.667, 8.772, 8.627, 8.77, 8.811, 8.078, 6.906, 6.862, 6.859, 6.962, 6.293, 10.459, 10.608, 10.604, 10.585, 9.684, 24.906, 24.301, 23.681, 24.21, 21.413, 13.257, 13.205, 13.399, 13.214, 12.089, 26.096, 25.327, 26.212, 24.797, 22.786, 8.957, 8.932, 8.994, 9.013, 8.117, 22.624, 21.514, 20.882, 20.944, 19.215, 7.714, 7.636, 7.601, 7.702, 7.14, 13.641, 13.447, 13.803, 13.696, 12.595, 7.101, 6.961, 7.028, 6.917, 6.281, 9.755, 9.634, 9.635, 9.698, 8.818, 7.266, 7.408, 7.343, 7.359, 6.691, 7.28, 7.338, 7.255, 7.35, 6.672, 10.066, 10.04, 10.194, 10.013, 9.052, 23.654, 23.617, 23.573, 25.817, 21.009, 6.312, 6.36, 6.248, 6.249, 5.724, 25.205, 26.321, 27.852, 26.501, 23.067, 17.459, 17.017, 16.602, 16.948, 15.564, 8.571, 8.501, 8.479, 8.502, 7.791, 3.458, 3.438, 3.437, 3.502, 3.229, 4.735, 4.567, 4.539, 4.712, 4.475
#             ]
#         ],  
#         [
#             [
#                 14.348, 14.331, 14.478, 14.355, 13.676, 10.155, 9.981, 10.311, 10.065, 10.026, 19.345, 19.383, 19.364, 19.362, 18.348, 10.579, 10.461, 10.61, 10.299, 9.878, 11.613, 11.443, 11.433, 11.434, 10.902, 13.083, 12.976, 12.914, 13.046, 12.293, 28.064, 28.613, 28.2, 28.393, 27.119, 11.161, 11.288, 11.262, 11.1, 10.711, 10.877, 10.872, 10.875, 10.952, 10.532, 9.778, 9.582, 9.457, 9.701, 9.182, 26.583, 26.822, 26.879, 27.185, 25.392, 12.623, 12.535, 12.532, 12.479, 11.96, 19.336, 19.181, 19.368, 19.3, 18.184, 21.952, 21.942, 22.052, 23.126, 20.937, 25.275, 25.289, 25.871, 26.117, 23.99
#             ],
#             [
#                 122.545, 127.587, 122.861, 126.289, 111.18, 122.806, 118.088, 116.054, 119.474, 108.679, 65.84, 66.289, 66.68, 66.429, 56.346, 109.659, 111.891, 104.767, 131.898, 93.695, 61.53, 60.23, 65.285, 63.32, 48.981, 115.947, 112.436, 111.171, 99.94, 89.634, 136.606, 140.442, 135.875, 130.411, 129.993, 123.765, 122.309, 133.617, 124.448, 109.18, 114.516, 117.052, 114.766, 118.206, 96.567, 51.602, 49.3, 52.972, 47.543, 47.549, 84.523, 87.213, 92.689, 77.506, 74.011, 102.422, 97.899, 90.143, 102.285, 90.927, 71.739, 79.052, 80.888, 76.265, 72.293, 112.549, 109.328, 103.008, 114.478, 97.164, 120.754, 121.572, 111.36, 109.786, 99.919
#             ]
#         ],   
#         [
#             [
#                 1713.504, 1741.591, 1721.646, 1713.08, 1666.09, 1730.114, 1766.36, 1722.91, 1856.862, 1782.397, 1721.183, 1733.468, 1759.488, 1729.669, 1695.352
#             ],
#             [
#                 9894.905, 9899.71, 9906.249, 9969.281, 8907.607, 9902.359, 9892.856, 9907.377, 9963.56, 8906.326, 9890.464, 9897.454, 9901.675, 9970.215, 8901.829
#             ]
#         ],
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d3nonetrainlat_l)):
#         local_ys_array, local_ci_array = [], []
#         for f_i in range(len(ys_d3nonetrainlat_l[m_i])):
#             local_ys_array.append(np.mean(ys_d3nonetrainlat_l[m_i][f_i], axis=(0)))
#             local_ci_array.append(1.96 * np.std(ys_d3nonetrainlat_l[m_i][f_i], axis=0)/np.sqrt(len(ys_d3nonetrainlat_l[m_i][f_i])))
#         ys_array.append(local_ys_array)
#         ci_array.append(local_ci_array)
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
#     # ax.set_ylim(0.3,1)
#     ax.set_yscale("log")
#     ax.set_ylabel("Incremental Training Time (s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     filename = "testf1score_by_nestimator_with_rawinput_data_3"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 5))
#     xs=[20, 50]
#     labels = ("10 estimators without filter", "50 estimators without filter", "100 estimators without filter")
#     ys_d3nofilterscore_l=[#models
#         [#filter or not
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.641, 0.647, 0.63, 0.634, 0.636, 0.647, 0.642, 0.63, 0.638, 0.64, 0.657, 0.638, 0.61, 0.631, 0.635
#             ],
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.644, 0.651, 0.635, 0.637, 0.641, 0.655, 0.648, 0.639, 0.646, 0.649, 0.661, 0.643, 0.616, 0.635, 0.639
#             ],
#             [
#                 0.65, 0.651, 0.615, 0.64, 0.634, 0.638, 0.643, 0.626, 0.654, 0.65, 0.64, 0.621, 0.636, 0.652, 0.631
#             ]
#         ],    
#         [
#             [
#                 0.69, 0.697, 0.688, 0.676, 0.678, 0.684, 0.695, 0.68, 0.675, 0.665, 0.696, 0.699, 0.683, 0.676, 0.673
#             ],
#             [
#                 0.696, 0.702, 0.693, 0.682, 0.685, 0.697, 0.708, 0.693, 0.687, 0.677, 0.711, 0.713, 0.696, 0.692, 0.689
#             ],
#             [
#                 0.69, 0.693, 0.679, 0.707, 0.685, 0.7, 0.698, 0.669, 0.718, 0.701, 0.704, 0.707, 0.683, 0.724, 0.697
#             ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d3nofilterscore_l)):
#         ys_array.append(np.mean(ys_d3nofilterscore_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d3nofilterscore_l[m_i], axis=1)/np.sqrt(len(ys_d3nofilterscore_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for idx, (ys, ci, label, mark, c) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", "."], ['#ff0000', '#ff0067', '#ff00ff'])):
#         ax.scatter(xs, ys, label=label, color=c, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10+5*idx, color=c, marker=mark)
#     # xs=[20, 50]
#     # labels = ("10 estimators with filter", "50 estimators with filter", "100 estimators with filter")
#     # ys_d0withfilterf1score_l=[#models
#     #     [#dims
#     #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#     #             0.877, 0.869, 0.888, 0.887, 0.888, 0.882, 0.868, 0.878, 0.887, 0.884, 0.871, 0.871, 0.885, 0.875, 0.889
#     #         ],
#     #         [
#     #             0.88, 0.87, 0.89, 0.889, 0.891, 0.882, 0.868, 0.878, 0.887, 0.884, 0.871, 0.871, 0.885, 0.875, 0.889
#     #         ],
#     #         [
#     #             0.862, 0.875, 0.885, 0.882, 0.878, 0.881, 0.875, 0.885, 0.891, 0.88, 0.873, 0.878, 0.881, 0.888, 0.886
#     #         ]
#     #     ],    
#     #     [
#     #         [
#     #             0.88, 0.88, 0.888, 0.884, 0.893, 0.9, 0.874, 0.887, 0.902, 0.895, 0.892, 0.883, 0.894, 0.893, 0.89
#     #         ],
#     #         [
#     #             0.883, 0.883, 0.893, 0.888, 0.896, 0.903, 0.877, 0.889, 0.905, 0.897, 0.893, 0.884, 0.895, 0.894, 0.891
#     #         ],
#     #         [
#     #             0.874, 0.881, 0.883, 0.897, 0.887, 0.883, 0.876, 0.889, 0.889, 0.894, 0.878, 0.879, 0.882, 0.884, 0.891
#     #         ]
#     #     ]
#     # ]
#     # ys_array, ci_array = [], []
#     # for m_i in range(len(ys_d0withfilterf1score_l)):
#     #     ys_array.append(np.mean(ys_d0withfilterf1score_l[m_i], axis=(1)))
#     #     ci_array.append(1.96 * np.std(ys_d0withfilterf1score_l[m_i], axis=1)/np.sqrt(len(ys_d0withfilterf1score_l[m_i][0])))
#     # ys_array = np.array(ys_array).T
#     # ci_array = np.array(ci_array).T
#     # for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", "."])):
#     #     ax.scatter(xs, ys, label=label, color='#ff6700', marker=mark)
#     #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10+5*idx, color='#ff6700', marker=mark)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
#     # ax.set_ylim(0.3,1)
#     ax.set_ylabel("F1-Score", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()

#     filename = "testf1score_by_nestimator_with_500rawinput_data_3"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     xs=[10, 50, 100]
#     labels = ("20 Labels per Model", "50 Labels per Model")
#     ys_d3nofilterscore_l=[#models
#         [#filter or not
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.68, 0.677, 0.679, 0.692, 0.695, 0.709, 0.7, 0.71, 0.696, 0.695, 0.72, 0.727, 0.743, 0.72, 0.699
#             ],
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.823, 0.819, 0.842, 0.842, 0.832, 0.844, 0.836, 0.857, 0.833, 0.832, 0.842, 0.831, 0.844, 0.828, 0.825
#             ],
#             [
#                 0.826, 0.824, 0.822, 0.832, 0.833, 0.821, 0.837, 0.842, 0.854, 0.843, 0.83, 0.835, 0.829, 0.83, 0.82
#             ]
#         ],    
#         [
#             [
#                 0.562, 0.555, 0.544, 0.545, 0.561, 0.535, 0.564, 0.548, 0.535, 0.547, 0.54, 0.52, 0.535, 0.531, 0.546
#             ],
#             [
#                 0.753, 0.764, 0.752, 0.761, 0.763, 0.765, 0.796, 0.762, 0.765, 0.77, 0.771, 0.762, 0.76, 0.758, 0.764
#             ],
#             [
#                 0.8, 0.819, 0.806, 0.82, 0.81, 0.82, 0.817, 0.821, 0.818, 0.818, 0.806, 0.824, 0.814, 0.789, 0.798
#             ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d3nofilterscore_l)):
#         ys_array.append(np.mean(ys_d3nofilterscore_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d3nofilterscore_l[m_i], axis=1)/np.sqrt(len(ys_d3nofilterscore_l[m_i][0])))
#     # ys_array = np.array(ys_array).T
#     # ci_array = np.array(ci_array).T
#     for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", "."])): # ['#f00022', '#00f022', '#ff00ff']
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
#     # xs=[20, 50]
#     # labels = ("10 estimators with filter", "50 estimators with filter", "100 estimators with filter")
#     # ys_d0withfilterf1score_l=[#models
#     #     [#dims
#     #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#     #             0.877, 0.869, 0.888, 0.887, 0.888, 0.882, 0.868, 0.878, 0.887, 0.884, 0.871, 0.871, 0.885, 0.875, 0.889
#     #         ],
#     #         [
#     #             0.88, 0.87, 0.89, 0.889, 0.891, 0.882, 0.868, 0.878, 0.887, 0.884, 0.871, 0.871, 0.885, 0.875, 0.889
#     #         ],
#     #         [
#     #             0.862, 0.875, 0.885, 0.882, 0.878, 0.881, 0.875, 0.885, 0.891, 0.88, 0.873, 0.878, 0.881, 0.888, 0.886
#     #         ]
#     #     ],    
#     #     [
#     #         [
#     #             0.88, 0.88, 0.888, 0.884, 0.893, 0.9, 0.874, 0.887, 0.902, 0.895, 0.892, 0.883, 0.894, 0.893, 0.89
#     #         ],
#     #         [
#     #             0.883, 0.883, 0.893, 0.888, 0.896, 0.903, 0.877, 0.889, 0.905, 0.897, 0.893, 0.884, 0.895, 0.894, 0.891
#     #         ],
#     #         [
#     #             0.874, 0.881, 0.883, 0.897, 0.887, 0.883, 0.876, 0.889, 0.889, 0.894, 0.878, 0.879, 0.882, 0.884, 0.891
#     #         ]
#     #     ]
#     # ]
#     # ys_array, ci_array = [], []
#     # for m_i in range(len(ys_d0withfilterf1score_l)):
#     #     ys_array.append(np.mean(ys_d0withfilterf1score_l[m_i], axis=(1)))
#     #     ci_array.append(1.96 * np.std(ys_d0withfilterf1score_l[m_i], axis=1)/np.sqrt(len(ys_d0withfilterf1score_l[m_i][0])))
#     # ys_array = np.array(ys_array).T
#     # ci_array = np.array(ci_array).T
#     # for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", "."])):
#     #     ax.scatter(xs, ys, label=label, color='#ff6700', marker=mark)
#     #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10+5*idx, color='#ff6700', marker=mark)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Boosting Trees", fontsize=20)
#     # ax.set_ylim(0.3,1)
#     ax.set_ylabel("F1-Score", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     filename = "testf1score_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     # xs=[109319, 54659, 27329, 13664, 6832]
#     xs=[10, 20, 40, 80]
#     labels = ("Weighted F1 Scores for All Labels","Weighted Precision","Weighted Recall",)
#     ys_d0rawinputscores_l=[#models
#         [#dimensions
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 0.847, 0.82, 0.849, 0.867, 0.867, 0.87, 0.867, 0.893, 0.872, 0.902, 0.861, 0.816, 0.872, 0.858, 0.821
#             ],
#             [
#                 0.82, 0.789, 0.825, 0.841, 0.84, 0.832, 0.829, 0.87, 0.843, 0.871, 0.838, 0.787, 0.854, 0.834, 0.79
#             ],
#             [
#                 0.977, 0.958, 0.954, 0.969, 0.978, 0.989, 0.977, 0.97, 0.989, 0.99, 0.978, 0.942, 0.958, 0.965, 0.965
#             ]
#         ],
#         [
#             [
#                 0.891, 0.897, 0.905, 0.893, 0.875, 0.888, 0.91, 0.881, 0.891, 0.889, 0.903, 0.909, 0.903, 0.894, 0.877
#             ],
#             [
#                 0.857, 0.861, 0.87, 0.856, 0.834, 0.852, 0.888, 0.854, 0.861, 0.856, 0.886, 0.901, 0.901, 0.878, 0.848
#             ],
#             [
#                 0.99, 0.982, 0.99, 0.989, 0.99, 0.989, 0.97, 0.97, 0.988, 0.977, 0.977, 0.97, 0.956, 0.976, 0.978
#             ]
#         ],
#         [
#             [
#                 0.915, 0.933, 0.916, 0.925, 0.912, 0.932, 0.932, 0.925, 0.944, 0.937, 0.942, 0.93, 0.918, 0.926, 0.907
#             ],
#             [
#                 0.925, 0.951, 0.925, 0.933, 0.915, 0.909, 0.916, 0.9, 0.924, 0.913, 0.957, 0.946, 0.923, 0.935, 0.906
#             ],
#             [
#                 0.958, 0.958, 0.954, 0.965, 0.965, 0.989, 0.982, 0.988, 0.989, 0.988, 0.965, 0.958, 0.964, 0.965, 0.964
#             ]
#         ],
#         [
#             [
#                 0.951, 0.952, 0.956, 0.955, 0.955, 0.951, 0.952, 0.956, 0.955, 0.955, 0.951, 0.952, 0.956, 0.955, 0.955
#             ],
#             [
#                 0.997, 0.998, 0.995, 0.995, 0.993, 0.997, 0.998, 0.995, 0.995, 0.993, 0.997, 0.998, 0.995, 0.995, 0.993
#             ],
#             [
#                 0.945, 0.944, 0.952, 0.95, 0.953, 0.945, 0.944, 0.952, 0.95, 0.953, 0.945, 0.944, 0.952, 0.95, 0.953
#             ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0rawinputscores_l)):
#         ys_array.append(np.mean(ys_d0rawinputscores_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0rawinputscores_l[m_i], axis=1)/np.sqrt(len(ys_d0rawinputscores_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", ".", "*"])): # ['#f00022', '#00f022', '#ff00ff']
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
#     # ax.set_xlim(0,120000)
#     # ax.set_ylim(0.3,1)
#     ax.set_ylabel("Prediction Metrics", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()

#     filename = "inferencelatency_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 3))
#     # xs=[109319, 54659, 27329, 13664, 6832]
#     xs=[10, 20, 40, 80]
#     # labels = ("No Input Dimensions Collapsing", "Collapse to Total 109319 among all Submodels")
#     labels = ("Sum of Inference Times (s) among all Submodels",)
#     ys_d0infertime_l=[#models
#         [#dimensions
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 1.53, 1.48, 1.52, 1.51, 1.49, 1.52, 1.47, 1.5, 1.5, 1.5, 1.54, 1.49, 1.54, 1.52, 1.47
#             ],
#         ],
#         [
#             [
#                 1.53, 1.51, 1.61, 1.5, 1.46, 1.5, 1.47, 1.54, 1.51, 1.48, 1.52, 1.53, 1.54, 1.47, 1.49
#             ],
#         ],
#         [
#             [
#                 1.59, 1.53, 1.64, 1.56, 1.5, 1.51, 1.5, 1.62, 1.57, 1.57, 1.56, 1.51, 1.59, 1.62, 1.49
#             ],
#         ],
#         [
#             [
#                 2.03, 1.58, 1.78, 1.87, 1.6, 1.88, 1.59, 1.75, 1.93, 1.73, 1.83, 1.58, 1.75, 1.85, 1.63
#             ],
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0infertime_l)):
#         ys_array.append(np.mean(ys_d0infertime_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0infertime_l[m_i], axis=1)/np.sqrt(len(ys_d0infertime_l[m_i][0])))
#     ys_array = np.array(ys_array).T
#     ci_array = np.array(ci_array).T
#     for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", ".", "*"])): # ['#f00022', '#00f022', '#ff00ff']
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
#     # ax.set_xlim(0,120000)
#     # ax.set_ylim(0.3,1)
#     ax.set_ylabel("Inference Time (s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()



#     filename = "inferencelatency_by_input_size_with_rawinput_data_0"
#     fig, ax = plt.subplots(1, 1, figsize=(10, 7))
#     xs=[109319, 54659, 27329, 13664]
#     labels = ("10 labels per model", "20 labels per model","40 labels per model","80 labels per model")
#     ys_d0infertime_l=[#models
#         [#dimensions
#             [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#                 13.5, 13.8, 14.16, 13.75, 13.49, 13.54, 13.86, 13.55, 13.77, 13.48, 13.53, 13.82, 13.59, 13.61, 13.5
#             ],
#             [
#                 6.58, 6.61, 6.53, 6.58, 6.59, 6.54, 6.61, 6.68, 6.62, 6.58, 6.56, 6.59, 6.66, 6.58, 6.54
#             ],
#             [
#                 3.28, 3.31, 3.28, 3.29, 3.27, 3.32, 3.35, 3.29, 3.29, 3.27, 3.29, 3.32, 3.29, 3.3, 3.3
#             ],
#             [
#                 1.75, 1.74, 1.74, 1.76, 1.67, 1.75, 1.69, 1.74, 1.75, 1.69, 1.75, 1.72, 1.73, 1.75, 1.73
#             ],
#         ],    
#         [
#             [
#                 6.88, 7.0, 7.38, 7.86, 6.88, 6.87, 6.97, 7.16, 7.11, 6.9, 6.95, 6.89, 7.17, 7.26, 6.89
#             ],
#             [
#                 3.32, 3.48, 3.39, 3.42, 3.36, 3.34, 3.43, 3.43, 3.42, 3.42, 3.46, 3.36, 3.42, 3.42, 3.35
#             ],
#             [
#                 1.71, 1.73, 1.73, 1.71, 1.72, 1.71, 1.72, 1.72, 1.71, 1.7, 1.71, 1.73, 1.71, 1.71, 1.7
#             ],
#             [
#                 0.93, 0.92, 0.94, 0.92, 0.91, 0.92, 0.91, 0.92, 0.92, 0.91, 0.92, 0.92, 0.93, 0.92, 0.91
#             ],
#         ],    
#         [
#             [
#                 3.6, 3.55, 3.78, 3.93, 3.58, 3.6, 3.65, 3.78, 3.77, 3.6, 3.54, 3.6, 3.71, 4.01, 3.59
#             ],
#             [
#                 1.75, 1.76, 1.8, 1.84, 1.78, 1.76, 1.75, 1.82, 1.82, 1.76, 1.77, 1.76, 1.82, 1.82, 1.79
#             ],
#             [
#                 0.94, 0.93, 0.92, 0.93, 0.92, 0.94, 0.92, 0.94, 0.93, 0.93, 0.92, 0.92, 0.94, 0.94, 0.92
#             ],
#             [
#                 0.53, 0.52, 0.53, 0.54, 0.52, 0.54, 0.54, 0.54, 0.53, 0.52, 0.54, 0.53, 0.54, 0.54, 0.53
#             ],
#         ],    
#         [
#             [
#                 1.96, 1.93, 2.08, 2.15, 1.93, 1.96, 1.93, 2.06, 2.14, 1.99, 1.95, 1.98, 2.06, 2.15, 1.96
#             ],
#             [
#                 1.0, 0.98, 1.09, 0.98, 0.99, 0.99, 0.98, 1.03, 0.98, 1.0, 1.01, 0.99, 1.04, 1.04, 0.99
#             ],
#             [
#                 0.55, 0.55, 0.55, 0.56, 0.54, 0.55, 0.55, 0.56, 0.55, 0.55, 0.55, 0.54, 0.56, 0.54, 0.56
#             ],
#             [
#                 0.35, 0.33, 0.34, 0.35, 0.34, 0.35, 0.34, 0.34, 0.35, 0.34, 0.34, 0.34, 0.34, 0.34, 0.34
#             ],
#             # [
#             #     0.07, 0.07, 0.07, 0.06, 0.05, 0.05, 0.07, 0.07, 0.06, 0.07, 0.06, 0.06, 0.08, 0.08, 0.06
#             # ]
#         ]
#     ]
#     ys_array, ci_array = [], []
#     for m_i in range(len(ys_d0infertime_l)):
#         ys_array.append(np.mean(ys_d0infertime_l[m_i], axis=(1)))
#         ci_array.append(1.96 * np.std(ys_d0infertime_l[m_i], axis=1)/np.sqrt(len(ys_d0infertime_l[m_i][0])))
#     # ys_array = np.array(ys_array).T
#     # ci_array = np.array(ci_array).T
#     for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", ".", "*"])): # ['#f00022', '#00f022', '#ff00ff']
#         ax.scatter(xs, ys, label=label, marker=mark)
#         ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
#     # xs=[20, 50]
#     # labels = ("10 estimators with filter", "50 estimators with filter", "100 estimators with filter")
#     # ys_d0withfilterf1score_l=[#models
#     #     [#dims
#     #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
#     #             0.877, 0.869, 0.888, 0.887, 0.888, 0.882, 0.868, 0.878, 0.887, 0.884, 0.871, 0.871, 0.885, 0.875, 0.889
#     #         ],
#     #         [
#     #             0.88, 0.87, 0.89, 0.889, 0.891, 0.882, 0.868, 0.878, 0.887, 0.884, 0.871, 0.871, 0.885, 0.875, 0.889
#     #         ],
#     #         [
#     #             0.862, 0.875, 0.885, 0.882, 0.878, 0.881, 0.875, 0.885, 0.891, 0.88, 0.873, 0.878, 0.881, 0.888, 0.886
#     #         ]
#     #     ],    
#     #     [
#     #         [
#     #             0.88, 0.88, 0.888, 0.884, 0.893, 0.9, 0.874, 0.887, 0.902, 0.895, 0.892, 0.883, 0.894, 0.893, 0.89
#     #         ],
#     #         [
#     #             0.883, 0.883, 0.893, 0.888, 0.896, 0.903, 0.877, 0.889, 0.905, 0.897, 0.893, 0.884, 0.895, 0.894, 0.891
#     #         ],
#     #         [
#     #             0.874, 0.881, 0.883, 0.897, 0.887, 0.883, 0.876, 0.889, 0.889, 0.894, 0.878, 0.879, 0.882, 0.884, 0.891
#     #         ]
#     #     ]
#     # ]
#     # ys_array, ci_array = [], []
#     # for m_i in range(len(ys_d0withfilterf1score_l)):
#     #     ys_array.append(np.mean(ys_d0withfilterf1score_l[m_i], axis=(1)))
#     #     ci_array.append(1.96 * np.std(ys_d0withfilterf1score_l[m_i], axis=1)/np.sqrt(len(ys_d0withfilterf1score_l[m_i][0])))
#     # ys_array = np.array(ys_array).T
#     # ci_array = np.array(ci_array).T
#     # for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", "."])):
#     #     ax.scatter(xs, ys, label=label, color='#ff6700', marker=mark)
#     #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10+5*idx, color='#ff6700', marker=mark)
#     ax.hlines(y=0.39, xmin=0, xmax=120000, label="Decomposing an XGBoost Model")
#     ax.tick_params(axis='both', which='major', labelsize=20)
#     ax.tick_params(axis='both', which='minor', labelsize=18)
#     ax.set_xlabel("Input Feature Dimensions", fontsize=20)
#     ax.set_xlim(0,120000)
#     # ax.set_ylim(0.3,1)
#     ax.set_ylabel("Inference Time (s)", fontsize=20)
#     ax.grid()
#     plt.legend(prop={'size': 16})
#     # plt.show()
#     plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
#     plt.close()

#     # print(0)








    # # # ###################### data4 ############################################

    fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/'
    filename = "nerccostandtrainlatencysummodel_by_N_models_with_rawinput_data_4"
    # xs=[str(xlabel) for xlabel in [3000//50, 3000//25, 3000//10, 3000]]
    xs=["60", "120", "300", "3000\nDeltaSherlock"]
    # ys0_l=[[ys0/60/60*0.013*64 for ys0 in [20.14, 36.68, 51.58, 101.09, 249.6, 942.14, 9847.24]]]
    # ys_d4totaltraintime_l=[[sum([2.236, 4.209, 2.428, 2.51, 3.049, 3.11, 2.607, 2.533, 3.219, 3.938, 2.08, 6.05, 4.248, 12.301, 3.214, 2.71, 2.705, 8.022, 2.603, 1.915, 1.512, 1.806, 4.082, 4.392, 1.77, 2.01, 4.226, 2.933, 2.818, 1.923, 3.963, 3.588, 2.467, 2.011, 2.946, 6.876, 2.447, 2.532, 6.21, 2.114, 2.018, 2.968, 3.954, 3.589, 2.191, 2.925, 2.187, 2.762, 5.256, 2.73]), sum([2.234, 2.86, 4.443, 5.557, 3.663, 3.182, 2.515, 3.167, 3.608, 8.675, 1.584, 3.115, 2.161, 2.929, 2.93, 2.393, 3.052, 2.724, 2.692, 6.881, 2.583, 3.26, 2.743, 8.186, 2.19, 1.769, 5.494, 2.457, 2.925, 3.217, 2.459, 1.98, 1.939, 4.588, 2.421, 2.749, 3.017, 3.808, 3.288, 2.447, 3.125, 2.656, 2.631, 1.308, 2.299, 1.406, 4.316, 12.402, 4.02, 2.326]), sum([4.645, 2.372, 2.247, 2.234, 7.856, 3.166, 2.464, 2.423, 3.644, 2.517, 2.389, 2.851, 5.925, 1.914, 2.443, 2.13, 12.786, 2.294, 8.741, 2.384, 1.947, 5.934, 2.177, 2.603, 2.768, 4.504, 2.873, 2.375, 2.054, 3.018, 3.329, 2.804, 1.984, 1.965, 3.333, 2.178, 2.471, 1.786, 2.153, 1.861, 8.07, 1.919, 2.212, 2.479, 2.814, 2.522, 3.072, 3.619, 4.129, 2.732])],
    #                     [sum([12.156, 6.961, 11.058, 7.813, 9.737, 13.431, 27.468, 8.145, 18.968, 7.589, 5.238, 10.372, 3.881, 10.532, 5.821, 13.131, 3.743, 17.957, 9.06, 15.217, 8.647, 10.563, 5.785, 7.895, 13.402]), sum([5.677, 17.108, 7.737, 7.341, 22.429, 7.752, 4.823, 6.513, 10.254, 16.172, 7.265, 19.48, 6.355, 12.668, 8.653, 6.061, 10.186, 8.095, 12.045, 8.627, 9.406, 6.937, 6.506, 31.496, 11.758]), sum([12.591, 8.109, 20.071, 7.757, 11.948, 9.663, 14.374, 8.164, 28.058, 20.674, 14.071, 7.695, 11.86, 5.301, 7.704, 10.981, 5.641, 9.189, 6.641, 5.436, 17.11, 5.688, 8.005, 8.844, 9.692])],
    #                     [sum([49.414, 46.608, 101.057, 69.227, 40.1, 42.637, 48.874, 83.239, 45.403, 51.621]), sum([59.401, 73.899, 24.249, 67.144, 68.697, 49.869, 42.909, 52.019, 43.25, 101.657]), sum([72.174, 50.497, 58.942, 128.731, 53.453, 43.789, 45.134, 32.338, 60.207, 47.008])],
    #                     [5395.731, 5435.128, 5454.122]]
    ys_d4totaltraintime_l=[
        [
            sum([8.029897212982178, 1.8520338535308838, 2.9993555545806885, 4.317518949508667, 3.0020484924316406, 24.30865478515625, 1.543515920639038, 5.56501841545105, 2.1103663444519043, 2.5562400817871094, 1.8484623432159424, 3.4936327934265137, 2.448371171951294, 1.8872718811035156, 3.4887402057647705, 2.329653263092041, 2.762343645095825, 4.188585042953491, 2.166377067565918, 2.05721116065979, 1.7323427200317383, 1.7802622318267822, 1.6114583015441895, 10.166800498962402, 1.3878538608551025, 5.745956897735596, 3.366044044494629, 2.179743766784668, 5.492403030395508, 3.0637047290802, 3.8144330978393555, 1.8706269264221191, 2.7987864017486572, 3.4232969284057617, 2.350620746612549, 5.86482310295105, 2.204941749572754, 1.928124189376831, 25.03522562980652, 5.0886313915252686, 2.3949830532073975, 3.1468429565429688, 7.223953723907471, 3.5864460468292236, 1.8653831481933594, 1.7990589141845703, 1.5829079151153564, 1.6141078472137451, 1.7352488040924072, 3.7669928073883057]), 
            sum([3.216477394104004, 1.430241346359253, 1.3101491928100586, 6.470303535461426, 1.3478927612304688, 1.5927257537841797, 2.5660130977630615, 1.5203306674957275, 2.1664540767669678, 5.069245100021362, 10.37515115737915, 3.059972047805786, 3.2614665031433105, 9.983915567398071, 4.003943920135498, 2.2027041912078857, 5.335612535476685, 6.05609130859375, 1.6690750122070312, 2.839592456817627, 2.6677865982055664, 1.9599547386169434, 1.1530044078826904, 11.52375316619873, 1.404404640197754, 1.441281795501709, 2.1566853523254395, 4.429488897323608, 2.4609475135803223, 2.877492666244507, 1.567617654800415, 1.326289415359497, 1.3895792961120605, 1.6838321685791016, 7.172287464141846, 2.4687438011169434, 2.013502359390259, 1.7708337306976318, 3.1939568519592285, 2.580177068710327, 1.7158050537109375, 1.229781150817871, 2.613921642303467, 6.974794626235962, 1.5917649269104004, 5.160931587219238, 1.900024175643921, 19.46753215789795, 1.635099172592163, 4.251370906829834]),
            sum([2.6688177585601807, 1.7494125366210938, 2.5277106761932373, 3.1980795860290527, 1.3965787887573242, 1.7186872959136963, 5.67152738571167, 7.555086374282837, 1.168966293334961, 1.420475959777832, 3.6396477222442627, 3.6549320220947266, 4.078430891036987, 3.0651373863220215, 1.364961862564087, 9.887195348739624, 1.1240999698638916, 11.815392971038818, 2.178435802459717, 3.740210771560669, 1.3151092529296875, 4.6517791748046875, 2.5573337078094482, 1.9388880729675293, 1.8658714294433594, 2.3940534591674805, 1.7784230709075928, 2.1665525436401367, 6.451530694961548, 3.780392646789551, 1.1438837051391602, 5.304408550262451, 2.370227575302124, 4.3176867961883545, 2.684074878692627, 1.399301290512085, 2.0763766765594482, 1.3178224563598633, 1.7172164916992188, 2.3463408946990967, 2.026559591293335, 1.6395478248596191, 3.6522696018218994, 2.761030435562134, 3.6479129791259766, 12.4206862449646, 2.286123514175415, 22.083027362823486, 1.6587700843811035, 1.6161584854125977]),
            sum([3.0898900032043457, 2.1239173412323, 4.65432333946228, 10.29594612121582, 8.092661142349243, 4.5204973220825195, 1.7837650775909424, 2.4528894424438477, 2.2294819355010986, 2.0689730644226074, 1.8986601829528809, 2.6367452144622803, 1.5533020496368408, 24.563863039016724, 2.9435362815856934, 2.26489520072937, 2.452577590942383, 2.3989999294281006, 10.627686023712158, 2.7425687313079834, 1.9375488758087158, 8.03170895576477, 1.1269941329956055, 2.2656776905059814, 1.599402666091919, 1.7671597003936768, 1.4003808498382568, 2.4737491607666016, 3.662033796310425, 1.5424461364746094, 4.338785648345947, 1.4810278415679932, 1.6218407154083252, 1.532149076461792, 1.8729877471923828, 3.2219326496124268, 2.0163094997406006, 10.656807899475098, 2.086851119995117, 3.2151122093200684, 2.9912540912628174, 3.7224137783050537, 1.6295077800750732, 2.085989475250244, 3.909738063812256, 2.655244827270508, 3.4070539474487305, 7.222890615463257, 1.699054479598999, 1.3105967044830322]),
            sum([1.745192527770996, 1.356360912322998, 2.9354255199432373, 2.6630711555480957, 1.7665503025054932, 1.301314115524292, 4.236664295196533, 1.4465277194976807, 1.4753856658935547, 2.5660979747772217, 25.263699531555176, 9.10377025604248, 3.6376559734344482, 2.3944780826568604, 2.9652628898620605, 1.8953649997711182, 2.9823124408721924, 5.369048595428467, 1.3329124450683594, 1.887129306793213, 4.014279365539551, 3.1729013919830322, 1.8781147003173828, 11.500060796737671, 2.2453789710998535, 21.22187566757202, 2.41127872467041, 2.4608218669891357, 2.4877312183380127, 2.7677688598632812, 2.770029067993164, 3.1694750785827637, 1.5349533557891846, 2.9968252182006836, 1.5262537002563477, 1.63771390914917, 1.309401512145996, 5.464269638061523, 3.647977113723755, 1.4788908958435059, 1.3220984935760498, 3.0490427017211914, 7.691647052764893, 11.312275171279907, 1.1631267070770264, 1.146833896636963, 2.2484400272369385, 2.168473482131958, 2.76548433303833, 5.693224668502808]),
            sum([5.49184775352478, 3.2717180252075195, 1.5857253074645996, 2.6761319637298584, 1.6628589630126953, 1.6988422870635986, 2.19343900680542, 29.81986117362976, 3.46502947807312, 4.834465026855469, 1.8307440280914307, 1.8238985538482666, 2.778069496154785, 5.465042352676392, 1.529329538345337, 9.387434720993042, 2.9309237003326416, 2.711479425430298, 3.4741837978363037, 1.387272596359253, 2.478907585144043, 3.340143918991089, 1.8284506797790527, 2.001462936401367, 1.5948615074157715, 10.518564701080322, 2.769918918609619, 2.4559309482574463, 1.6506545543670654, 1.472743272781372, 1.977832555770874, 1.8241267204284668, 1.5341596603393555, 1.8340163230895996, 1.981715202331543, 5.863634347915649, 1.4078128337860107, 3.096395254135132, 5.852593183517456, 2.0218849182128906, 10.270245552062988, 6.371631383895874, 19.095728397369385, 3.0375590324401855, 2.3823983669281006, 1.5518813133239746, 7.522383451461792, 2.3336899280548096, 3.53759503364563, 3.4114651679992676]),
            sum([3.635679244995117, 2.862213611602783, 2.96767520904541, 2.3308441638946533, 6.237794637680054, 4.765473127365112, 2.085383653640747, 9.235119342803955, 3.060056686401367, 3.3023860454559326, 2.067816734313965, 4.202597379684448, 4.04735803604126, 2.2851321697235107, 2.3030331134796143, 3.5813546180725098, 1.9908230304718018, 2.6079909801483154, 20.655632972717285, 11.244138717651367, 11.319575786590576, 1.7166235446929932, 1.9869699478149414, 5.181312084197998, 2.373763084411621, 3.494164228439331, 6.741464853286743, 2.176649570465088, 2.296430826187134, 3.828728437423706, 3.066828966140747, 2.9470303058624268, 3.033853530883789, 1.7390413284301758, 6.359750747680664, 6.271398305892944, 2.399401903152466, 1.7561333179473877, 1.618661642074585, 2.8118152618408203, 3.0912954807281494, 1.3493566513061523, 1.8864893913269043, 1.5923662185668945, 2.27101469039917, 2.5717666149139404, 2.466367721557617, 9.452656984329224, 3.616274118423462, 2.903324842453003]),
            sum([5.592394590377808, 2.2671191692352295, 2.221144676208496, 2.431992769241333, 12.67451786994934, 3.0452308654785156, 2.4200527667999268, 2.176527738571167, 4.31308126449585, 3.024693489074707, 2.6994237899780273, 3.546691656112671, 7.816696882247925, 1.7417786121368408, 2.504668712615967, 2.0009267330169678, 22.713515996932983, 1.849358081817627, 13.131017208099365, 2.694868326187134, 1.6493914127349854, 8.04440689086914, 1.846400260925293, 2.6465139389038086, 2.4964141845703125, 5.606354475021362, 1.374962568283081, 2.4478044509887695, 1.7065563201904297, 3.20174241065979, 3.335329055786133, 3.1884353160858154, 1.761347770690918, 1.8728711605072021, 4.272232294082642, 1.878187656402588, 2.7297518253326416, 1.3073787689208984, 1.8305552005767822, 1.4419715404510498, 11.398545503616333, 1.5516881942749023, 2.0531225204467773, 1.7128283977508545, 2.940253257751465, 1.935607671737671, 3.1719861030578613, 2.8807215690612793, 6.517936944961548, 2.0086989402770996]),
            sum([1.4151079654693604, 1.7739901542663574, 6.574313402175903, 7.2341461181640625, 2.52790904045105, 1.6330852508544922, 2.4601688385009766, 2.594205141067505, 4.011118173599243, 12.476887226104736, 1.3071203231811523, 1.7192978858947754, 1.3867526054382324, 1.1940364837646484, 1.4321284294128418, 2.7555723190307617, 3.397642135620117, 3.07456374168396, 2.723553419113159, 12.072330951690674, 2.5957090854644775, 1.9653785228729248, 2.632096767425537, 16.58332133293152, 2.5625085830688477, 1.2746713161468506, 7.9742467403411865, 2.013183355331421, 2.822597026824951, 2.3698976039886475, 2.3928160667419434, 1.733212947845459, 1.9153573513031006, 5.855409145355225, 2.336411952972412, 2.9932925701141357, 3.297962188720703, 4.622767448425293, 3.920417547225952, 1.6661336421966553, 3.523688554763794, 2.380187511444092, 3.295067071914673, 1.60904860496521, 2.5821096897125244, 1.4745557308197021, 5.585092306137085, 20.97913670539856, 4.552108526229858, 2.0911858081817627]),
            # sum([2.2599546909332275, 5.860959053039551, 1.6872971057891846, 2.6122658252716064, 4.224048376083374, 3.1590418815612793, 2.907451868057251, 2.0609350204467773, 3.811128616333008, 2.843451976776123, 1.7924714088439941, 7.901972055435181, 2.549543619155884, 25.790019512176514, 2.4383609294891357, 2.5613629817962646, 2.9312632083892822, 11.067089080810547, 2.8109025955200195, 2.2598752975463867, 1.507671594619751, 1.8136401176452637, 4.9552130699157715, 2.7204174995422363, 1.191046953201294, 1.3465023040771484, 4.996950626373291, 2.223444938659668, 2.430529832839966, 1.9955921173095703, 5.195051670074463, 4.321598768234253, 1.450653314590454, 1.4451072216033936, 3.0488173961639404, 9.63210678100586, 3.1119027137756348, 3.0273654460906982, 8.725103378295898, 2.001119375228882, 1.987593173980713, 3.24078369140625, 4.490218162536621, 2.048307418823242, 1.7175371646881104, 1.6202187538146973, 1.9018332958221436, 3.0471739768981934, 7.027266263961792, 3.4920365810394287]),
        ],
        [
            sum([14.13504672050476, 6.643536806106567, 14.322987794876099, 8.727133750915527, 12.074774980545044, 17.016431093215942, 44.39469814300537, 8.43496561050415, 27.15203094482422, 8.397366285324097, 5.285809516906738, 13.988829135894775, 3.899996280670166, 13.238822937011719, 6.799224376678467, 17.039714336395264, 3.6864144802093506, 24.246922492980957, 10.468846321105957, 22.01151180267334, 9.954501867294312, 12.545536041259766, 5.470430135726929, 8.235721111297607, 19.940320014953613]), 
            sum([5.170547962188721, 24.292343854904175, 7.546392917633057, 8.034991025924683, 37.488040924072266, 4.406641483306885, 4.03205680847168, 7.204914808273315, 11.604877948760986, 22.19936966896057, 7.246811151504517, 32.23373460769653, 6.195426940917969, 16.955864906311035, 9.225871086120605, 5.638361930847168, 12.152792692184448, 8.373802900314331, 14.933627367019653, 9.702550411224365, 10.230079889297485, 8.107486724853516, 6.437952995300293, 52.44209122657776, 12.71657419204712]), 
            sum([14.45408320426941, 8.178836107254028, 29.807032823562622, 7.393904209136963, 14.076227903366089, 10.853855848312378, 18.87202286720276, 8.331816673278809, 47.13361597061157, 32.850250482559204, 19.14024043083191, 7.813594102859497, 15.411895036697388, 5.1977269649505615, 7.398233652114868, 12.166958093643188, 5.546251535415649, 10.18563985824585, 6.24114990234375, 4.451425790786743, 22.9970600605011, 5.281791925430298, 8.193644762039185, 9.788020133972168, 12.636177062988281]), 
            sum([9.77734375, 9.267190933227539, 15.348628282546997, 21.909423112869263, 11.393722772598267, 9.421780586242676, 10.656216144561768, 9.411010503768921, 5.46008038520813, 73.00767636299133, 23.062660694122314, 11.868800401687622, 9.133431434631348, 15.33626675605774, 9.43037223815918, 9.095588684082031, 7.356077671051025, 16.794620037078857, 7.5953686237335205, 7.45907998085022, 7.300816297531128, 5.719620943069458, 6.599687814712524, 22.10853862762451, 11.49854040145874]), 
            sum([15.143710613250732, 7.3828442096710205, 5.220373868942261, 41.24876952171326, 14.467401266098022, 6.005532264709473, 12.064475059509277, 18.088552713394165, 9.692595481872559, 8.227149248123169, 9.754254341125488, 6.275760173797607, 22.59534454345703, 8.577623128890991, 5.367448806762695, 4.945881366729736, 4.627644300460815, 14.638313055038452, 7.2214391231536865, 15.600471496582031, 26.41933822631836, 57.235706090927124, 6.402780055999756, 18.519588470458984, 11.474486351013184]), 
            sum([5.1155686378479, 9.90021276473999, 4.773776292800903, 9.50310206413269, 7.060441017150879, 65.42549681663513, 10.06359601020813, 7.651517868041992, 16.87304711341858, 4.0902605056762695, 12.722256183624268, 24.121120929718018, 60.06872224807739, 10.083392858505249, 9.487313270568848, 10.033523321151733, 6.466915607452393, 4.7743330001831055, 11.366303443908691, 7.5815112590789795, 8.06456971168518, 35.33736205101013, 3.46042799949646, 7.631725788116455, 24.312726736068726]), 
            sum([8.957527160644531, 43.30180525779724, 23.515421867370605, 7.723651170730591, 6.1501946449279785, 6.455656051635742, 55.793768644332886, 8.857685804367065, 8.353749990463257, 26.803433179855347, 31.9404239654541, 5.716303825378418, 5.723100900650024, 6.689754486083984, 9.11918592453003, 11.988826513290405, 5.636993646621704, 9.569688320159912, 24.79384732246399, 9.252457857131958, 11.81212592124939, 5.872482538223267, 12.100241422653198, 20.221774339675903, 4.912020444869995]), 
            sum([8.101531982421875, 10.46786642074585, 4.582698822021484, 31.278342723846436, 3.835265874862671, 15.77814507484436, 13.608526706695557, 22.646175384521484, 25.34614086151123, 12.149401426315308, 11.549139738082886, 8.579358577728271, 6.765780448913574, 6.201290845870972, 19.539942026138306, 11.650189399719238, 12.774480104446411, 6.994599342346191, 5.601522445678711, 9.785366773605347, 7.73382043838501, 12.03802752494812, 46.828033208847046, 55.428248167037964, 6.173834562301636]), 
            sum([9.130842685699463, 14.632440328598022, 4.338165760040283, 6.971630811691284, 13.199448585510254, 26.563375234603882, 26.401800870895386, 10.68200135231018, 22.554494619369507, 8.44787883758545, 8.626760482788086, 25.226454257965088, 3.9463956356048584, 11.61643362045288, 9.438043117523193, 3.69893479347229, 4.3438193798065186, 17.42571520805359, 6.252614259719849, 10.064390897750854, 4.219004154205322, 18.72703981399536, 12.895825862884521, 48.29000449180603, 10.612698793411255]), 
            # sum([18.007678031921387, 13.13792085647583, 43.98447227478027, 13.824566125869751, 8.409380912780762, 10.627373456954956, 6.762234926223755, 5.926272869110107, 10.184895038604736, 7.364484548568726, 8.508596420288086, 19.9880428314209, 12.262983322143555, 9.821865558624268, 15.575934171676636, 9.754586696624756, 10.76632809638977, 14.096184492111206, 6.940730094909668, 55.76835536956787, 9.805315732955933, 18.441522359848022, 5.908677339553833, 6.19050669670105, 9.465275526046753])
        ],
        [
            sum([112.09624099731445, 159.6753900051117, 51.45852327346802, 40.04783082008362, 59.180492639541626, 86.82043838500977, 53.088594913482666, 163.41428995132446, 69.6328444480896, 36.7096643447876]),
            sum([59.720964431762695, 52.06255626678467, 144.65125966072083, 79.39013910293579, 82.8301420211792, 55.201791286468506, 54.96039366722107, 51.418497800827026, 59.26886248588562, 158.68510818481445]),
            sum([43.75065994262695, 79.71525764465332, 90.08837532997131, 129.34906363487244, 48.897741079330444, 73.98879981040955, 71.18097043037415, 31.5597722530365, 59.01558041572571, 185.33672738075256]),
            sum([135.9530429840088, 46.74380683898926, 161.176029920578, 119.31006383895874, 67.77096152305603, 46.324801206588745, 42.44867658615112, 103.10152816772461, 59.84921360015869, 81.44150304794312]),
            sum([37.73823690414429, 38.2355899810791, 175.10894012451172, 50.09345030784607, 99.0332179069519, 147.25709128379822, 41.96045923233032, 51.99401116371155, 109.60917735099792, 62.10821580886841]),
            sum([57.488648414611816, 142.91337418556213, 45.093963384628296, 82.30222630500793, 42.758819818496704, 63.246208906173706, 25.782946825027466, 74.9639642238617, 168.66990685462952, 76.9375352859497]),
            sum([60.266440868377686, 99.96439027786255, 55.30855345726013, 177.19287204742432, 91.67611193656921, 74.26545071601868, 62.65848684310913, 45.95880389213562, 33.729467153549194, 83.36678385734558]),
            sum([106.72267460823059, 67.05953693389893, 81.23925185203552, 182.87208914756775, 68.88101077079773, 53.85119080543518, 57.34074640274048, 30.86008048057556, 78.27890586853027, 60.63566279411316]),
            sum([86.6029121875763, 103.58272242546082, 22.32465887069702, 88.85153031349182, 95.9472222328186, 65.36881303787231, 49.49083757400513, 70.07261943817139, 54.579429149627686, 153.26697731018066]), 
            # sum([67.31773042678833, 59.97956371307373, 160.1257803440094, 103.31810593605042, 49.250431537628174, 55.843337535858154, 64.43385028839111, 122.00954675674438, 56.71690225601196, 68.62684750556946])
        ],
        [
            8877.326451778412,
            9303.58086180687,
            7819.219457864761,
            8427.687427520752,
            9849.607594490051,
            9697.71790933609,
            10081.760856628418,
            9513.348496198654,
            9313.321469068527
        ]
    ]
    ys_d4totaltraintimemean_l = np.array(ys_d4totaltraintime_l).mean(axis=1).tolist()
    ys_d4totaltraintimestd_l  = np.array(ys_d4totaltraintime_l).std(axis=1).tolist()
    ys_d4nerccostmean_l = [ys0/60/60*0.013*64 for ys0 in ys_d4totaltraintimemean_l]
    ys_d4nerccoststd_l  = [ys0/60/60*0.013*64 for ys0 in ys_d4totaltraintimestd_l]
    ys_d4awscostmean_l = [ys0/60/60*2.448 for ys0 in ys_d4totaltraintimemean_l]
    ys_d4awscoststd_l  = [ys0/60/60*2.448 for ys0 in ys_d4totaltraintimestd_l]
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # bottom = np.zeros(len(xs))
    entry_count, width = 2, 0.4
    p = ax.bar([idx-width/entry_count+width/entry_count/2 for idx, _ in enumerate(ys_d4nerccostmean_l)], ys_d4nerccostmean_l, width/entry_count, yerr=ys_d4nerccoststd_l, color='#0067ff', edgecolor="black", hatch="x", label="NERC VM (\$)")
    p2 = ax.bar([idx-width/entry_count+(2+1)*width/entry_count/2 for idx, _ in enumerate(ys_d4awscostmean_l)], ys_d4awscostmean_l, width/entry_count, yerr=ys_d4awscoststd_l, color='#00ff67', edgecolor="black", hatch="|", label="AWS EC2 (\$)")
    # ax.bar_label(p)
    # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    ax.grid()
    ax.legend(loc="upper left", prop={'size': 16})
    ax.set_xticks(list(range(len(xs))))
    ax.set_xticklabels(xs)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    ax.set_ylabel("Resource Cost (\$)", fontsize=20)
    # plt.show()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/'
    # filename = "nerccostandtrainlatencysummodel_by_N_models_with_rawinput_data_4"
    # # xs=[str(xlabel) for xlabel in [3000//50, 3000//25, 3000//10, 3000]]
    # xs=["3", "6", "60", "120", "300", "3000\nDeltaSherlock"]
    # # ys0_l=[[ys0/60/60*0.013*64 for ys0 in [20.14, 36.68, 51.58, 101.09, 249.6, 942.14, 9847.24]]]
    # # ys_d4totaltraintime_l=[[sum([2.236, 4.209, 2.428, 2.51, 3.049, 3.11, 2.607, 2.533, 3.219, 3.938, 2.08, 6.05, 4.248, 12.301, 3.214, 2.71, 2.705, 8.022, 2.603, 1.915, 1.512, 1.806, 4.082, 4.392, 1.77, 2.01, 4.226, 2.933, 2.818, 1.923, 3.963, 3.588, 2.467, 2.011, 2.946, 6.876, 2.447, 2.532, 6.21, 2.114, 2.018, 2.968, 3.954, 3.589, 2.191, 2.925, 2.187, 2.762, 5.256, 2.73]), sum([2.234, 2.86, 4.443, 5.557, 3.663, 3.182, 2.515, 3.167, 3.608, 8.675, 1.584, 3.115, 2.161, 2.929, 2.93, 2.393, 3.052, 2.724, 2.692, 6.881, 2.583, 3.26, 2.743, 8.186, 2.19, 1.769, 5.494, 2.457, 2.925, 3.217, 2.459, 1.98, 1.939, 4.588, 2.421, 2.749, 3.017, 3.808, 3.288, 2.447, 3.125, 2.656, 2.631, 1.308, 2.299, 1.406, 4.316, 12.402, 4.02, 2.326]), sum([4.645, 2.372, 2.247, 2.234, 7.856, 3.166, 2.464, 2.423, 3.644, 2.517, 2.389, 2.851, 5.925, 1.914, 2.443, 2.13, 12.786, 2.294, 8.741, 2.384, 1.947, 5.934, 2.177, 2.603, 2.768, 4.504, 2.873, 2.375, 2.054, 3.018, 3.329, 2.804, 1.984, 1.965, 3.333, 2.178, 2.471, 1.786, 2.153, 1.861, 8.07, 1.919, 2.212, 2.479, 2.814, 2.522, 3.072, 3.619, 4.129, 2.732])],
    # #                     [sum([12.156, 6.961, 11.058, 7.813, 9.737, 13.431, 27.468, 8.145, 18.968, 7.589, 5.238, 10.372, 3.881, 10.532, 5.821, 13.131, 3.743, 17.957, 9.06, 15.217, 8.647, 10.563, 5.785, 7.895, 13.402]), sum([5.677, 17.108, 7.737, 7.341, 22.429, 7.752, 4.823, 6.513, 10.254, 16.172, 7.265, 19.48, 6.355, 12.668, 8.653, 6.061, 10.186, 8.095, 12.045, 8.627, 9.406, 6.937, 6.506, 31.496, 11.758]), sum([12.591, 8.109, 20.071, 7.757, 11.948, 9.663, 14.374, 8.164, 28.058, 20.674, 14.071, 7.695, 11.86, 5.301, 7.704, 10.981, 5.641, 9.189, 6.641, 5.436, 17.11, 5.688, 8.005, 8.844, 9.692])],
    # #                     [sum([49.414, 46.608, 101.057, 69.227, 40.1, 42.637, 48.874, 83.239, 45.403, 51.621]), sum([59.401, 73.899, 24.249, 67.144, 68.697, 49.869, 42.909, 52.019, 43.25, 101.657]), sum([72.174, 50.497, 58.942, 128.731, 53.453, 43.789, 45.134, 32.338, 60.207, 47.008])],
    # #                     [5395.731, 5435.128, 5454.122]]
    # ys_d4totaltraintime_l=[
    #     [sum([0.151, 0.101, 0.085, 0.061, 0.087, 0.068, 0.163, 0.079, 0.105, 0.077, 0.173, 0.122, 0.107, 0.135, 0.138, 0.081, 0.081, 0.083, 0.136, 0.087, 0.081, 0.104, 0.103, 0.095, 0.11, 0.09, 0.09, 0.817, 0.093, 0.074, 0.086, 0.104, 0.087, 0.143, 0.127, 0.081, 0.082, 0.082, 0.08, 0.108, 0.076, 0.102, 0.079, 0.124, 0.102, 0.095, 0.098, 0.095, 0.091, 0.095, 0.091, 0.089, 0.094, 0.129, 0.093, 0.079, 0.135, 0.116, 0.084, 0.082, 0.098, 0.116, 0.089, 0.134, 0.091, 0.101, 0.089, 0.093, 0.193, 0.081, 0.087, 0.147, 0.083, 0.078, 0.147, 0.097, 0.081, 0.088, 0.082, 0.092, 0.085, 0.084, 0.126, 0.091, 0.079, 0.092, 0.565, 0.075, 0.085, 0.097, 0.083, 0.108, 0.112, 0.083, 0.074, 0.119, 0.103, 0.073, 0.122, 0.087, 0.074, 0.064, 0.064, 0.07, 0.189, 0.099, 0.088, 0.102, 0.087, 0.093, 0.292, 0.085, 0.101, 0.113, 0.064, 0.07, 0.091, 0.095, 0.083, 0.058, 0.11, 0.126, 0.073, 0.102, 0.097, 0.101, 0.104, 0.084, 0.31, 0.075, 0.081, 0.074, 0.078, 0.106, 0.071, 0.075, 0.073, 0.085, 0.071, 0.09, 0.083, 0.079, 0.086, 0.125, 0.069, 0.082, 0.143, 0.094, 0.091, 0.081, 0.078, 0.078, 0.066, 0.065, 0.125, 0.068, 0.105, 0.066, 0.111, 0.072, 0.134, 0.114, 0.079, 0.113, 0.095, 0.26, 0.088, 0.078, 0.11, 0.117, 0.101, 0.165, 0.099, 0.103, 0.107, 0.078, 0.138, 0.066, 0.08, 0.109, 0.076, 0.072, 0.088, 0.114, 0.08, 0.103, 0.157, 0.082, 0.13, 0.085, 0.084, 0.088, 0.092, 0.085, 0.09, 0.084, 0.094, 0.075, 0.073, 0.285, 0.106, 0.109, 0.144, 0.111, 0.102, 0.085, 0.073, 0.088, 0.115, 0.077, 0.079, 0.077, 0.081, 0.1, 0.152, 0.08, 0.104, 0.126, 0.135, 0.084, 0.075, 0.087, 0.14, 0.096, 0.102, 0.165, 0.081, 0.077, 0.176, 0.106, 0.2, 0.106, 0.146, 0.076, 0.088, 0.783, 0.105, 0.074, 0.106, 0.135, 0.081, 0.1, 0.076, 0.077, 0.129, 0.127, 0.101, 0.184, 0.11, 0.105, 0.092, 0.128, 0.113, 0.12, 0.09, 0.099, 0.092, 0.072, 0.096, 0.082, 2.938, 0.092, 0.083, 0.086, 0.144, 0.101, 0.143, 0.084, 0.069, 0.074, 0.116, 0.102, 0.079, 0.093, 0.098, 0.08, 0.081, 0.11, 0.083, 0.088, 0.116, 0.087, 0.065, 0.079, 0.09, 0.085, 0.097, 0.087, 0.08, 0.26, 0.077, 0.098, 0.1, 0.087, 0.081, 0.1, 0.081, 0.114, 0.076, 0.122, 0.086, 0.085, 0.134, 0.077, 0.14, 0.149, 0.07, 0.065, 0.082, 0.119, 0.128, 0.076, 0.12, 0.075, 0.088, 0.085, 0.07, 0.138, 0.072, 0.11, 0.109, 0.097, 0.105, 0.082, 0.082, 0.154, 0.088, 0.078, 0.117, 0.108, 0.084, 0.1, 0.081, 0.076, 0.105, 0.088, 0.083, 0.078, 0.264, 0.088, 0.113, 0.092, 0.125, 0.068, 0.102, 0.083, 0.101, 0.143, 0.079, 0.108, 0.095, 0.097, 0.087, 0.135, 0.088, 0.08, 0.094, 0.086, 0.146, 1.463, 0.088, 0.082, 0.081, 0.085, 0.076, 0.07, 0.136, 0.139, 0.072, 0.076, 0.07, 0.131, 0.112, 0.098, 0.089, 0.216, 0.094, 0.074, 0.078, 0.082, 0.068, 0.093, 0.084, 0.073, 0.122, 0.232, 0.08, 0.084, 0.078, 0.092, 0.107, 0.09, 0.072, 0.089, 0.093, 0.057, 0.074, 0.108, 0.085, 0.119, 0.08, 0.069, 0.065, 0.079, 0.067, 0.101, 0.083, 0.081, 0.098, 0.092, 0.083, 0.084, 0.091, 0.081, 0.104, 0.109, 0.097, 0.099, 0.087, 0.066, 0.167, 0.074, 0.099, 0.074, 0.09, 0.08, 0.077, 0.068, 0.072, 0.071, 0.064, 0.071, 0.073, 0.064, 0.069, 0.114, 0.071, 0.084, 0.101, 0.076, 0.113, 0.094, 0.074, 0.132, 0.12, 0.115, 0.129, 0.084, 0.119, 0.092, 0.081, 0.09, 0.111, 0.084, 0.082, 0.063, 0.08, 0.073, 0.288, 0.11, 0.07, 0.197, 0.084, 0.073, 0.093, 0.143, 0.085, 0.08, 0.13, 0.143, 0.084, 0.108, 0.068, 0.075, 0.087, 0.083, 0.088, 0.13, 0.084, 0.08, 0.092, 0.088, 0.095, 0.078, 0.088, 0.114, 0.089, 0.111, 0.138, 0.074, 0.09, 0.096, 0.103, 0.071, 0.069, 0.097, 0.099, 0.082, 0.08, 0.093, 0.091, 0.084, 0.075, 0.082, 0.073, 0.093, 0.081, 0.109, 0.089, 0.094, 0.083, 0.113, 0.095, 0.08, 0.105, 0.145, 0.08, 0.081, 0.092, 0.079, 0.132, 0.086, 0.138, 0.095, 0.109, 0.089, 0.096, 0.307, 0.149, 0.079, 0.085, 0.103, 0.075, 0.076, 0.092, 0.096, 0.098, 0.085, 0.148, 0.397, 0.081, 0.081, 0.117, 0.08, 0.067, 0.095, 0.067, 0.122, 0.095, 0.075, 0.094, 0.074, 0.087, 0.076, 0.077, 0.078, 0.073, 0.191, 0.075, 0.082, 0.138, 0.131, 0.089, 0.091, 0.084, 0.084, 0.1, 0.069, 0.097, 0.097, 0.093, 0.08, 0.075, 0.108, 0.196, 0.061, 0.11, 0.108, 0.089, 0.119, 0.112, 0.084, 0.076, 0.101, 0.126, 0.115, 0.083, 0.105, 0.121, 0.078, 0.08, 0.145, 0.101, 0.102, 0.155, 0.122, 0.078, 0.075, 0.069, 0.092, 0.397, 0.09, 0.126, 0.086, 0.087, 0.081, 0.078, 0.088, 0.086, 0.143, 0.104, 0.093, 0.07, 0.093, 0.111, 0.137, 0.141, 0.173, 0.078, 0.154, 0.116, 0.063, 0.126, 0.077, 0.088, 0.104, 0.129, 0.077, 0.078, 0.088, 0.112, 0.081, 0.074, 0.134, 0.08, 0.307, 0.107, 0.111, 0.177, 0.091, 0.11, 0.076, 0.083, 0.075, 0.066, 0.099, 0.079, 0.073, 0.075, 0.086, 0.127, 0.132, 0.153, 0.071, 0.068, 0.079, 0.085, 0.11, 0.092, 0.11, 0.086, 0.089, 0.087, 0.108, 0.081, 0.077, 0.066, 0.072, 0.072, 0.087, 0.084, 0.093, 0.09, 0.077, 0.097, 0.074, 0.075, 0.088, 0.118, 0.09, 0.075, 0.078, 0.069, 0.108, 0.133, 0.133, 0.089, 0.093, 0.08, 0.077, 0.079, 0.084, 0.206, 0.084, 0.115, 0.084, 0.192, 0.068, 0.071, 0.09, 0.096, 0.083, 0.1, 0.077, 0.07, 0.075, 0.081, 0.072, 0.105, 0.09, 0.229, 0.091, 0.113, 0.061, 0.085, 0.078, 0.125, 0.085, 1.158, 0.089, 0.085, 0.069, 0.064, 0.104, 0.112, 0.079, 0.128, 0.086, 0.098, 0.078, 0.084, 0.104, 0.096, 0.086, 0.084, 0.209, 0.119, 0.089, 0.13, 0.14, 0.136, 0.066, 0.079, 0.087, 0.099, 0.077, 0.077, 0.083, 0.102, 0.292, 0.139, 0.077, 0.076, 0.081, 0.084, 0.107, 0.09, 0.132, 0.114, 0.095, 0.096, 0.139, 1.122, 0.07, 0.07, 0.077, 0.085, 0.079, 0.094, 0.077, 0.075, 0.122, 0.127, 0.079, 0.098, 0.106, 0.091, 0.088, 0.104, 0.084, 0.069, 0.122, 0.133, 0.107, 0.133, 0.082, 0.066, 0.071, 0.129, 0.093, 0.082, 0.127, 0.09, 0.123, 0.071, 0.112, 0.12, 0.109, 0.116, 0.09, 0.139, 0.082, 0.098, 0.087, 0.089, 0.084, 0.125, 0.102, 0.069, 0.107, 0.108, 0.073, 0.067, 0.148, 0.077, 0.112, 0.076, 0.086, 0.155, 0.115, 0.138, 0.095, 0.136, 0.087, 0.15, 0.088, 0.091, 0.096, 0.106, 0.086, 0.089, 0.105, 0.084, 0.105, 0.095, 0.109, 0.296, 0.153, 0.084, 0.091, 0.237, 0.09, 0.082, 0.197, 0.133, 0.122, 0.123, 0.113, 0.076, 0.078, 0.211, 0.067, 0.12, 0.121, 0.135, 0.086, 0.088, 0.087, 0.078, 0.097, 0.094, 0.119, 0.082, 0.085, 0.06, 0.068, 0.199, 0.102, 0.076, 0.09, 0.084, 0.124, 0.084, 0.138, 0.086, 0.103, 0.115, 0.101, 0.082, 0.105, 0.085, 0.091, 0.089, 0.11, 0.1, 0.123, 0.084, 0.168, 0.136, 0.102, 0.08, 0.108, 0.095, 0.123, 0.123, 0.148, 0.088, 0.089, 0.093, 0.097, 0.071, 0.098, 0.081, 0.064, 0.072, 0.085, 0.111, 0.087, 0.133, 0.079, 0.071, 0.089, 0.126, 0.075, 0.096, 0.105, 0.156, 0.091, 0.138, 0.066, 0.098, 0.101, 0.093, 0.09, 0.1, 0.112, 0.142, 0.076, 0.077, 0.072, 0.085, 0.124, 0.095, 0.125, 0.091, 0.113, 0.095, 0.109, 0.097, 0.084, 0.1, 0.085, 0.096, 0.088, 0.081, 0.082, 0.069, 0.077, 0.065, 0.189, 0.219, 0.085, 0.087, 0.087, 0.06, 0.085, 0.079, 0.102, 0.092, 0.086, 0.085, 0.077, 0.904, 0.072, 0.105, 0.112, 0.086, 0.125, 0.088, 0.097, 0.065, 0.122, 0.1, 0.122, 0.078, 0.105, 0.092, 0.133, 0.091, 0.061, 0.083, 0.063, 0.098, 0.114, 0.128, 0.133, 0.071, 0.36, 0.084, 0.088, 0.092, 0.094, 0.095, 0.092, 0.098, 0.093, 0.092, 0.091, 0.127, 0.086]), sum([0.084, 0.113, 0.084, 0.077, 0.086, 0.102, 0.084, 0.111, 0.078, 0.128, 0.097, 0.089, 0.091, 0.144, 0.082, 0.073, 0.052, 0.083, 0.082, 0.082, 0.076, 0.098, 0.084, 0.094, 0.121, 0.15, 0.1, 0.083, 0.122, 0.111, 0.09, 0.139, 0.119, 0.088, 0.114, 0.135, 0.078, 0.143, 0.091, 0.077, 0.082, 0.071, 0.09, 0.176, 0.088, 0.102, 0.09, 0.098, 0.082, 0.139, 0.08, 0.085, 0.08, 0.318, 0.122, 0.114, 0.424, 0.081, 0.104, 0.083, 0.727, 0.072, 0.339, 0.081, 0.076, 0.099, 0.105, 0.083, 0.088, 0.092, 0.096, 0.085, 0.104, 0.082, 0.154, 0.104, 0.084, 0.079, 0.088, 0.09, 0.21, 0.102, 0.078, 0.079, 0.138, 0.101, 0.116, 0.07, 0.095, 0.12, 0.082, 0.093, 0.069, 0.099, 0.111, 0.086, 0.098, 0.104, 0.112, 0.074, 0.079, 0.1, 0.087, 0.111, 0.108, 0.068, 0.128, 0.099, 0.092, 0.105, 0.089, 0.116, 0.106, 0.085, 0.071, 0.07, 0.092, 0.133, 0.119, 0.122, 0.075, 0.126, 0.091, 0.111, 0.1, 0.076, 0.118, 0.117, 0.093, 0.065, 0.074, 0.079, 0.123, 0.124, 0.143, 0.08, 0.061, 0.076, 0.087, 0.175, 0.127, 0.127, 0.071, 0.104, 0.089, 0.101, 0.09, 0.103, 0.068, 0.09, 0.062, 0.101, 0.09, 0.089, 0.099, 0.069, 0.092, 0.13, 0.075, 0.217, 0.388, 0.068, 0.096, 0.109, 0.091, 0.082, 0.141, 0.092, 0.146, 0.087, 0.088, 0.079, 0.084, 0.163, 0.107, 0.098, 0.083, 0.073, 0.072, 0.105, 0.076, 0.076, 0.08, 0.065, 0.12, 1.531, 0.091, 0.071, 0.127, 0.118, 0.1, 0.125, 0.08, 0.188, 0.096, 0.107, 0.094, 0.174, 0.163, 0.093, 0.079, 0.064, 0.121, 0.124, 0.126, 0.138, 0.104, 0.074, 0.088, 0.102, 0.076, 0.086, 0.07, 0.096, 0.103, 0.089, 0.105, 0.092, 0.09, 0.083, 0.095, 0.108, 0.089, 0.148, 0.095, 0.104, 0.09, 0.075, 0.099, 0.1, 0.094, 0.092, 0.1, 0.139, 0.084, 0.095, 0.08, 0.079, 0.109, 0.114, 0.083, 0.085, 0.167, 0.085, 0.078, 0.118, 0.093, 0.121, 0.1, 0.092, 0.079, 0.089, 0.079, 0.102, 0.084, 0.082, 0.086, 0.088, 0.087, 0.072, 0.09, 0.096, 0.075, 0.119, 0.118, 0.09, 0.076, 0.103, 0.083, 0.086, 0.092, 0.086, 0.085, 0.088, 0.079, 0.072, 0.118, 0.1, 0.075, 0.104, 0.092, 0.088, 0.131, 0.103, 0.089, 0.116, 0.115, 0.097, 0.098, 0.077, 0.091, 0.097, 0.086, 0.098, 0.099, 0.125, 0.076, 0.093, 0.087, 0.134, 0.08, 0.083, 0.087, 0.074, 0.081, 0.062, 0.095, 0.069, 0.11, 0.068, 0.08, 0.309, 0.087, 0.073, 0.091, 0.093, 0.094, 0.084, 0.092, 0.117, 0.094, 0.11, 0.074, 0.127, 0.071, 0.129, 0.08, 0.09, 0.091, 0.31, 0.093, 0.086, 0.101, 0.091, 0.103, 0.061, 0.135, 0.077, 0.086, 0.131, 0.134, 0.077, 0.126, 0.171, 0.063, 0.096, 0.083, 0.083, 0.104, 0.107, 0.097, 0.083, 0.084, 0.113, 0.083, 0.132, 0.129, 0.088, 0.119, 0.099, 0.085, 0.09, 0.095, 0.072, 0.078, 0.125, 0.128, 0.138, 0.15, 0.178, 0.095, 0.077, 0.09, 0.08, 0.091, 0.102, 0.104, 0.086, 0.111, 0.103, 0.085, 0.101, 0.101, 0.075, 0.088, 0.09, 0.093, 0.071, 0.062, 0.075, 0.078, 0.085, 0.091, 1.139, 0.066, 0.088, 0.091, 0.087, 0.088, 0.073, 0.08, 0.089, 0.087, 0.09, 0.08, 0.078, 0.241, 0.119, 0.085, 0.079, 0.1, 0.088, 0.128, 0.126, 0.1, 0.107, 0.082, 0.112, 0.093, 0.1, 0.111, 0.085, 0.111, 0.148, 0.099, 0.12, 0.09, 0.145, 0.092, 0.083, 0.084, 0.083, 0.129, 0.075, 0.089, 0.115, 0.076, 0.118, 0.122, 0.082, 0.095, 0.07, 0.094, 0.118, 0.114, 0.115, 0.2, 0.09, 0.084, 0.087, 0.079, 0.07, 0.059, 0.08, 0.098, 0.115, 0.1, 0.081, 0.06, 0.125, 0.099, 0.07, 0.081, 0.08, 0.072, 0.099, 0.087, 0.124, 0.506, 0.105, 0.095, 0.12, 0.09, 0.156, 0.081, 0.067, 1.278, 0.093, 0.083, 0.078, 0.082, 0.074, 0.089, 0.106, 0.083, 0.076, 0.077, 0.096, 0.07, 0.134, 0.078, 0.094, 0.086, 0.089, 0.25, 0.095, 0.08, 0.106, 0.086, 0.079, 0.076, 0.09, 0.082, 0.086, 0.103, 0.086, 0.065, 0.076, 0.075, 0.067, 0.095, 0.106, 0.079, 0.086, 0.079, 0.084, 0.092, 0.072, 0.084, 0.116, 0.081, 0.07, 0.072, 0.134, 0.065, 0.093, 0.099, 0.123, 0.084, 0.146, 0.066, 0.099, 0.079, 0.089, 0.847, 0.102, 0.084, 0.066, 0.069, 0.1, 0.075, 0.1, 0.108, 0.075, 0.196, 0.094, 0.088, 0.068, 0.079, 0.072, 0.08, 0.074, 0.103, 0.066, 0.082, 0.064, 0.069, 0.075, 0.069, 0.074, 0.082, 0.147, 0.096, 0.092, 0.083, 0.237, 0.076, 0.07, 0.118, 0.074, 0.083, 0.072, 0.075, 0.077, 0.067, 0.126, 0.091, 0.112, 0.087, 0.085, 0.085, 0.083, 0.09, 0.069, 0.091, 0.088, 0.118, 0.075, 0.101, 0.119, 0.209, 0.082, 0.11, 0.089, 0.09, 0.075, 0.081, 0.094, 0.08, 0.077, 0.072, 0.107, 0.18, 0.063, 0.093, 0.102, 0.092, 0.087, 0.073, 0.097, 0.15, 0.078, 0.072, 0.09, 0.085, 0.083, 0.089, 0.072, 0.107, 0.071, 0.068, 0.077, 0.089, 0.076, 0.079, 0.072, 0.08, 0.09, 0.064, 0.08, 0.117, 0.077, 0.082, 0.098, 0.086, 0.084, 0.085, 0.077, 0.082, 0.081, 0.087, 0.074, 0.073, 0.067, 0.119, 0.08, 0.069, 0.091, 0.078, 0.071, 0.088, 0.094, 0.09, 0.087, 0.081, 0.078, 0.117, 0.075, 0.067, 0.071, 0.095, 0.14, 0.1, 0.078, 0.07, 0.108, 0.279, 0.107, 0.097, 0.101, 0.083, 0.076, 0.106, 0.083, 0.111, 0.088, 0.092, 0.181, 0.066, 0.078, 0.071, 0.075, 0.081, 0.07, 0.063, 0.121, 0.082, 0.113, 0.08, 0.082, 0.08, 0.139, 0.069, 0.074, 0.067, 0.093, 0.07, 0.085, 0.074, 0.1, 0.079, 0.076, 0.103, 0.086, 0.123, 0.087, 0.12, 0.127, 0.124, 0.069, 0.105, 0.073, 0.108, 0.082, 0.102, 0.123, 0.219, 0.072, 0.131, 0.1, 0.087, 0.085, 0.063, 0.099, 0.085, 0.116, 0.07, 0.067, 0.082, 0.1, 0.278, 0.095, 0.132, 0.108, 0.083, 0.067, 0.07, 0.077, 0.077, 0.076, 0.09, 0.079, 0.098, 0.078, 0.08, 0.073, 0.104, 0.072, 0.079, 0.084, 0.678, 0.087, 0.083, 0.083, 0.088, 0.126, 0.082, 0.109, 0.106, 0.078, 0.074, 0.272, 0.086, 0.091, 0.081, 0.093, 0.094, 0.085, 0.086, 0.122, 0.062, 0.114, 0.064, 0.085, 0.085, 0.093, 0.134, 0.194, 0.084, 0.07, 0.068, 0.109, 0.092, 0.111, 0.07, 0.081, 0.071, 0.108, 0.11, 0.087, 0.105, 0.075, 0.072, 0.118, 0.085, 0.074, 0.065, 0.093, 0.067, 0.125, 0.083, 0.104, 0.069, 0.095, 0.098, 0.066, 0.1, 0.121, 0.274, 0.093, 0.075, 0.073, 0.069, 0.098, 0.085, 0.07, 0.092, 0.076, 0.088, 0.084, 0.079, 0.078, 0.093, 0.068, 0.134, 0.102, 0.071, 0.084, 0.072, 0.138, 0.095, 0.06, 0.073, 0.191, 0.077, 0.119, 0.09, 0.092, 0.1, 0.123, 0.082, 0.099, 0.098, 0.132, 0.077, 0.091, 0.115, 0.099, 0.082, 0.125, 0.267, 0.116, 0.129, 0.083, 0.088, 0.094, 0.128, 0.095, 0.084, 0.079, 0.069, 0.085, 0.067, 0.093, 0.086, 0.08, 0.076, 0.082, 0.094, 0.118, 0.111, 0.083, 0.099, 0.135, 0.087, 0.095, 0.086, 0.071, 0.072, 0.071, 0.071, 0.061, 0.069, 0.091, 0.069, 0.104, 0.078, 0.082, 0.098, 0.111, 0.077, 0.061, 0.075, 0.077, 0.083, 0.07, 0.095, 0.191, 0.186, 0.095, 0.117, 0.109, 0.105, 0.076, 0.091, 0.096, 0.1, 0.076, 0.087, 0.09, 0.077, 0.092, 0.078, 0.104, 0.066, 0.067, 0.087, 0.071, 0.065, 0.091, 0.102, 0.072, 0.072, 0.201, 0.074, 0.072, 0.113, 0.259, 0.073, 0.078, 0.078, 0.07, 0.073, 0.086, 0.23, 0.089, 0.065, 0.127, 0.098, 0.128, 0.145, 0.103, 0.097, 0.137, 0.086, 0.107, 0.113, 0.069, 0.091, 0.101, 0.078, 0.115, 0.14, 0.101, 0.125, 0.086, 0.067, 3.096, 0.085, 0.089, 0.086, 0.076, 0.09, 0.075, 0.104, 0.125, 0.157, 0.092, 0.22, 0.143, 0.107, 0.094, 0.102, 0.264, 0.152, 0.123, 0.081, 0.126, 0.091, 0.103, 0.096, 0.129, 0.099, 0.153, 0.139, 0.125, 0.088, 0.094, 0.148, 0.107, 0.087, 0.117, 0.097, 0.096, 0.082, 0.131, 0.13, 0.097, 0.122, 0.097])],
    #     [
    #         sum([0.206, 0.139, 0.151, 0.253, 0.213, 0.239, 0.23, 0.242, 0.135, 0.212, 0.154, 0.161, 0.174, 0.582, 0.142, 0.158, 0.175, 0.173, 0.161, 0.188, 0.156, 0.19, 0.176, 0.181, 0.178, 0.142, 0.207, 0.165, 0.189, 0.12, 0.247, 0.238, 0.176, 0.122, 0.281, 0.201, 0.164, 0.225, 0.148, 0.143, 0.131, 0.179, 0.137, 0.412, 0.149, 0.216, 0.185, 0.175, 0.222, 0.225, 0.152, 0.115, 0.235, 0.146, 0.165, 0.287, 0.195, 0.131, 0.137, 0.114, 0.198, 0.185, 0.236, 0.171, 0.367, 0.133, 0.157, 0.14, 0.184, 0.12, 0.156, 0.142, 0.125, 0.191, 0.17, 0.142, 0.145, 0.172, 0.149, 0.124, 0.126, 0.111, 0.251, 0.133, 0.164, 0.229, 0.186, 0.16, 0.222, 0.135, 0.129, 0.172, 0.173, 0.198, 0.149, 0.15, 0.162, 0.157, 0.23, 0.264, 0.225, 0.188, 0.226, 0.196, 0.16, 0.152, 0.148, 0.184, 0.162, 0.214, 0.164, 0.202, 0.236, 0.147, 0.199, 0.223, 0.17, 0.713, 0.148, 0.19, 0.137, 0.152, 0.189, 0.217, 0.155, 0.215, 0.193, 0.195, 0.144, 0.136, 2.191, 0.122, 0.206, 0.219, 0.136, 0.214, 0.134, 0.149, 0.186, 0.157, 0.189, 0.163, 0.18, 0.136, 0.276, 0.153, 0.112, 0.127, 0.179, 0.227, 0.147, 0.217, 0.249, 0.151, 0.252, 0.227, 0.177, 0.226, 0.184, 0.18, 0.211, 0.174, 0.261, 0.171, 0.208, 0.128, 0.151, 0.158, 0.157, 0.31, 0.193, 0.191, 0.16, 0.216, 0.229, 0.165, 0.241, 0.149, 0.146, 1.297, 0.176, 0.18, 0.139, 0.206, 0.132, 0.165, 0.148, 0.211, 0.141, 0.14, 0.171, 0.13, 0.305, 0.144, 0.163, 0.179, 0.15, 0.135, 0.139, 0.124, 0.105, 0.117, 0.155, 0.142, 0.158, 0.193, 0.202, 0.179, 0.139, 0.138, 0.216, 0.134, 0.157, 0.119, 0.127, 0.181, 0.115, 0.14, 0.154, 0.188, 0.137, 0.136, 0.128, 0.132, 0.206, 0.1, 0.188, 0.144, 0.141, 0.423, 0.23, 0.136, 0.207, 0.143, 0.202, 0.197, 0.135, 0.138, 0.271, 0.179, 0.182, 0.163, 0.245, 0.164, 0.162, 0.241, 0.165, 0.211, 0.146, 0.122, 0.164, 0.182, 0.174, 0.186, 0.15, 0.224, 0.141, 0.192, 0.115, 0.16, 0.206, 0.2, 0.177, 0.312, 0.249, 0.159, 0.133, 0.164, 0.166, 0.546, 0.145, 0.185, 0.152, 0.201, 0.234, 0.173, 0.112, 0.126, 0.238, 0.186, 0.185, 0.224, 0.154, 0.166, 0.161, 0.162, 0.227, 0.244, 0.159, 0.24, 0.214, 0.119, 0.119, 0.183, 0.162, 0.193, 0.151, 0.24, 0.088, 0.16, 0.494, 0.216, 0.144, 0.171, 0.156, 0.16, 0.129, 0.149, 0.167, 0.201, 0.204, 0.195, 0.199, 0.184, 0.172, 0.165, 0.223, 0.343, 0.168, 0.224, 0.172, 0.141, 0.169, 0.168, 0.155, 0.241, 0.207, 0.138, 0.194, 0.185, 0.125, 0.131, 0.113, 0.158, 0.119, 0.137, 0.166, 0.175, 0.166, 0.192, 0.14, 0.194, 0.223, 0.153, 0.152, 0.145, 0.222, 0.176, 0.233, 0.211, 0.149, 0.239, 0.144, 0.133, 0.173, 0.312, 0.22, 0.144, 0.186, 0.995, 0.145, 0.193, 0.146, 0.16, 0.16, 0.173, 0.167, 0.218, 0.185, 0.189, 0.239, 0.145, 0.147, 0.106, 0.295, 0.163, 0.155, 0.13, 0.148, 0.117, 0.137, 1.485, 0.145, 0.1, 0.167, 0.157, 0.213, 0.146, 0.12, 0.159, 0.197, 0.2, 0.225, 0.114, 0.25, 0.268, 0.169, 0.18, 0.215, 0.182, 0.217, 0.176, 0.142, 0.193, 0.193, 0.185, 0.219, 0.181, 0.129, 0.153, 0.155, 0.173, 0.155, 0.131, 0.168, 0.205, 0.166, 0.157, 0.366, 0.118, 0.345, 0.271, 0.228, 0.209, 0.148, 0.253, 0.167, 0.171, 0.12, 0.121, 0.157, 0.157, 0.192, 0.217, 0.132, 0.189, 0.167, 0.15, 0.194, 0.212, 0.169, 0.224, 0.194, 0.207, 0.178, 0.144, 0.194, 0.181, 0.195, 0.177, 0.15, 0.135, 0.106, 0.109, 0.137, 0.107, 0.159, 0.129, 0.146, 0.124, 0.119, 0.159, 0.201, 0.196, 0.165, 0.194, 0.199, 0.184, 0.173, 0.167, 0.155, 0.145, 0.157, 0.238, 0.266, 0.252, 0.144, 0.138, 0.18, 0.13, 0.117, 1.034, 0.201, 0.178, 0.151, 0.17, 0.19, 0.178, 0.188, 0.163, 0.135, 0.216, 0.219, 0.361, 0.137, 0.138, 0.14, 0.173, 0.154, 0.226]), 
    #         sum([0.189, 0.158, 0.178, 0.179, 0.175, 0.194, 0.208, 0.206, 0.156, 0.135, 0.156, 0.159, 0.167, 0.161, 0.213, 0.279, 0.162, 0.188, 0.214, 0.161, 0.138, 0.223, 0.138, 0.161, 0.162, 0.113, 0.353, 0.214, 0.401, 0.16, 0.591, 0.366, 0.159, 0.171, 0.19, 0.155, 0.174, 0.222, 0.148, 0.167, 0.259, 0.143, 0.193, 0.183, 0.193, 0.167, 0.14, 0.17, 0.162, 0.182, 0.18, 0.199, 0.154, 0.179, 0.19, 0.154, 0.16, 0.129, 0.17, 0.182, 0.166, 0.167, 0.175, 0.188, 0.136, 0.141, 0.224, 0.205, 0.09, 0.202, 0.237, 0.173, 0.145, 0.181, 0.161, 0.158, 0.18, 0.228, 0.236, 0.242, 0.594, 0.194, 0.147, 0.187, 0.234, 0.144, 0.224, 0.234, 0.163, 0.186, 0.154, 0.159, 1.267, 0.126, 0.161, 0.175, 0.22, 0.188, 0.222, 0.165, 0.113, 0.147, 0.155, 0.174, 0.194, 0.174, 0.169, 0.156, 0.149, 0.143, 0.181, 0.199, 0.196, 0.149, 0.228, 0.206, 0.219, 0.175, 0.182, 0.203, 0.181, 0.198, 0.233, 0.241, 0.227, 0.166, 0.145, 0.119, 0.109, 0.107, 0.182, 0.217, 0.254, 0.216, 0.177, 0.135, 0.162, 0.127, 0.162, 0.158, 0.183, 0.205, 0.235, 0.183, 0.201, 0.16, 0.139, 0.155, 0.148, 0.185, 0.158, 0.14, 0.151, 0.231, 0.175, 0.301, 0.145, 0.225, 0.203, 0.171, 0.141, 0.17, 0.217, 0.153, 0.318, 0.131, 0.183, 0.189, 0.202, 0.229, 0.183, 0.268, 0.12, 0.091, 0.137, 0.139, 0.177, 0.208, 0.199, 0.112, 0.094, 0.096, 0.114, 0.191, 0.243, 0.148, 0.145, 0.143, 0.149, 0.189, 0.166, 0.191, 0.168, 0.162, 0.147, 0.162, 0.989, 0.098, 0.109, 0.142, 0.144, 0.157, 0.166, 0.292, 0.129, 0.168, 0.19, 0.19, 0.204, 0.159, 0.161, 0.16, 0.187, 0.169, 0.16, 0.188, 0.196, 0.189, 0.19, 0.16, 0.151, 0.202, 0.176, 0.244, 0.165, 0.128, 0.13, 0.195, 0.146, 0.202, 0.15, 0.147, 0.17, 0.157, 0.421, 0.191, 0.188, 0.135, 1.005, 0.186, 0.183, 0.221, 0.173, 0.149, 0.179, 0.156, 0.136, 0.274, 0.151, 0.158, 0.134, 0.138, 0.143, 0.119, 0.14, 0.176, 0.169, 0.139, 0.153, 0.216, 0.146, 0.18, 0.166, 0.226, 0.171, 0.161, 0.195, 1.174, 0.148, 0.182, 0.189, 0.203, 0.223, 0.187, 0.154, 0.119, 0.174, 0.144, 0.131, 0.18, 0.192, 0.137, 0.307, 0.113, 0.171, 0.168, 0.157, 0.174, 0.194, 0.145, 0.145, 0.13, 0.168, 0.174, 0.205, 0.281, 0.172, 0.147, 0.151, 0.153, 0.177, 0.196, 0.141, 0.134, 0.115, 0.13, 0.106, 0.164, 0.109, 0.177, 0.129, 0.172, 0.135, 0.196, 0.157, 0.183, 0.175, 0.165, 0.18, 0.173, 0.159, 0.132, 0.194, 0.14, 0.119, 0.184, 0.161, 0.105, 0.159, 0.117, 0.148, 0.18, 0.176, 0.458, 0.213, 0.168, 0.214, 0.204, 0.308, 0.209, 0.162, 0.169, 0.197, 0.19, 0.127, 0.203, 0.145, 0.201, 0.156, 0.169, 0.13, 0.166, 0.183, 0.172, 0.151, 0.186, 0.173, 0.182, 0.24, 0.198, 0.177, 0.209, 0.219, 0.176, 0.215, 0.282, 0.155, 0.116, 0.124, 0.148, 0.125, 0.126, 0.127, 0.16, 0.144, 0.784, 0.141, 0.234, 0.184, 0.192, 0.282, 0.213, 0.167, 0.163, 0.197, 0.191, 0.157, 0.142, 0.245, 0.116, 0.136, 0.146, 0.135, 0.188, 0.183, 0.198, 0.165, 0.15, 0.199, 0.23, 0.179, 0.182, 0.191, 0.203, 0.321, 0.119, 0.145, 0.138, 0.192, 0.182, 0.174, 0.158, 0.21, 0.141, 0.192, 0.204, 0.254, 0.198, 0.142, 0.197, 0.188, 0.219, 0.198, 0.208, 0.206, 0.319, 0.193, 0.158, 0.135, 0.114, 0.155, 0.14, 0.138, 0.132, 0.179, 0.165, 0.194, 0.157, 0.115, 0.119, 0.142, 0.13, 0.179, 0.126, 0.154, 0.121, 0.171, 0.145, 0.245, 0.215, 0.16, 0.17, 0.137, 0.155, 0.131, 0.148, 0.16, 0.143, 0.15, 0.134, 0.198, 0.225, 0.136, 0.299, 0.187, 0.147, 0.179, 0.325, 0.212, 0.219, 0.185, 0.199, 0.155, 0.184, 0.17, 0.203, 0.213, 0.187, 2.187, 0.142, 0.111, 0.116, 0.207, 0.174, 0.361, 0.16, 0.297, 0.276, 0.183, 0.133, 0.166, 0.195, 0.21, 0.114, 0.144, 0.127, 0.109, 0.194, 0.154, 0.152])],
    #     [sum([3.732, 6.956, 2.661, 4.144, 8.312, 6.578, 6.191, 3.614, 8.927, 5.16, 3.447, 10.002, 4.014, 25.411, 4.581, 8.635, 5.95, 19.499, 4.922, 3.172, 2.375, 2.715, 10.492, 13.346, 4.257, 4.972, 9.5, 4.183, 3.647, 2.971, 8.03, 8.89, 2.213, 2.73, 5.569, 11.039, 7.405, 7.856, 10.59, 3.143, 2.851, 9.699, 8.615, 3.277, 3.942, 2.893, 3.379, 4.342, 10.463, 5.298]), sum([2.712, 3.321, 12.619, 15.376, 5.145, 3.315, 4.404, 8.218, 20.964, 32.07, 2.807, 3.367, 2.623, 2.62, 3.79, 4.108, 6.413, 5.741, 4.275, 21.896, 8.563, 3.323, 4.82, 18.497, 4.214, 1.722, 14.493, 3.63, 4.89, 3.612, 3.006, 2.365, 2.062, 7.498, 3.37, 4.83, 4.269, 5.863, 4.796, 2.99, 5.631, 3.503, 4.99, 1.869, 3.844, 2.378, 6.51, 29.027, 6.616, 3.295])],
    #     [sum([22.174, 11.216, 19.947, 17.87, 16.275, 23.255, 89.372, 11.384, 48.279, 13.587, 8.171, 21.217, 8.879, 27.455, 13.331, 35.09, 5.384, 40.399, 21.216, 43.755, 13.998, 23.449, 7.979, 12.028, 24.483]), sum([9.841, 50.011, 18.667, 29.306, 63.957, 8.925, 8.148, 10.66, 36.816, 40.153, 12.376, 42.923, 8.803, 25.933, 14.411, 9.548, 17.995, 12.988, 21.031, 14.198, 16.339, 12.52, 10.014, 72.303, 21.754])],
    #     [sum([137.52, 108.837, 246.572, 154.826, 72.207, 91.959, 100.265, 194.845, 110.499, 105.434]), sum([200.806, 230.496, 54.144, 169.071, 182.641, 132.875, 100.119, 105.447, 100.602, 255.987])],
    #     [12346.28, 12422.935]]
    # ys_d4totaltraintimemean_l = np.array(ys_d4totaltraintime_l).mean(axis=1).tolist()
    # ys_d4totaltraintimestd_l  = np.array(ys_d4totaltraintime_l).std(axis=1).tolist()
    # ys_d4nerccostmean_l = [ys0/60/60*0.013*64 for ys0 in ys_d4totaltraintimemean_l]
    # ys_d4nerccoststd_l  = [ys0/60/60*0.013*64 for ys0 in ys_d4totaltraintimestd_l]
    # ys_d4awscostmean_l = [ys0/60/60*2.448 for ys0 in ys_d4totaltraintimemean_l]
    # ys_d4awscoststd_l  = [ys0/60/60*2.448 for ys0 in ys_d4totaltraintimestd_l]
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 2, 0.4
    # p = ax.bar([idx-width/entry_count+width/entry_count/2 for idx, _ in enumerate(ys_d4nerccostmean_l)], ys_d4nerccostmean_l, width/entry_count, yerr=ys_d4nerccoststd_l, color='#0067ff', edgecolor="black", hatch="x", label="NERC VM (\$)")
    # p2 = ax.bar([idx-width/entry_count+(2+1)*width/entry_count/2 for idx, _ in enumerate(ys_d4awscostmean_l)], ys_d4awscostmean_l, width/entry_count, yerr=ys_d4awscoststd_l, color='#00ff67', edgecolor="black", hatch="|", label="AWS EC2 (\$)")
    # # ax.bar_label(p)
    # # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    # ax.grid()
    # ax.legend(loc="upper left", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # ax.set_ylabel("Resource Cost (\$)", fontsize=20)
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()


    fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/'
    filename = "F1_score_incremental_praxi_SL_OAA"
    # xs=[str(xlabel) for xlabel in [3000//50, 3000//25, 3000//10, 3000]]
    xs=["30", "60", "90", "93", "120", "150"]
    ys_d4noreplay_f1score_l=[
        [1,1,1],
        [1,1,1],
        [0.860, 0.866, 0.865],
        [0.845, 0.845, 0.845],
        [0.618, 0.628, 0.606],
        [0.487, 0.474, 0.482]]
    ys_d4noreplay_f1scoremean_l = np.array(ys_d4noreplay_f1score_l).mean(axis=1).tolist()
    ys_d4noreplay_f1scorestd_l  = np.array(ys_d4noreplay_f1score_l).std(axis=1).tolist()
    ys_d4replay_f1score_l=[
        [1, 0.917, 1],
        [1, 0.958, 1],
        [1, 0.972, 1],
        [0.959, 0.957, 0.958],
        [0.717, 0.682, 0.723],
        [0.556, 0.516, 0.546]]
    ys_d4replay_f1scoremean_l = np.array(ys_d4replay_f1score_l).mean(axis=1).tolist()
    ys_d4replay_f1scorestd_l  = np.array(ys_d4replay_f1score_l).std(axis=1).tolist()
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # bottom = np.zeros(len(xs))
    entry_count, width = 2, 0.4
    p = ax.bar([idx-width/entry_count+width/entry_count/2 for idx, _ in enumerate(ys_d4noreplay_f1scoremean_l)], ys_d4noreplay_f1scoremean_l, width/entry_count, yerr=ys_d4noreplay_f1scorestd_l, color='#0067ff', edgecolor="black", hatch="x", label="-oaa 80")
    p2 = ax.bar([idx-width/entry_count+(2+1)*width/entry_count/2 for idx, _ in enumerate(ys_d4replay_f1scoremean_l)], ys_d4replay_f1scoremean_l, width/entry_count, yerr=ys_d4replay_f1scorestd_l, color='#00ff67', edgecolor="black", hatch="|", label="-oaa 90")
    # ax.bar_label(p)
    # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    ax.grid()
    ax.legend(loc="upper left", prop={'size': 16})
    ax.set_xticks(list(range(len(xs))))
    ax.set_xticklabels(xs)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.set_xlabel("Number of Labels Trained after Incremental Training", fontsize=20)
    ax.set_ylabel("F1 Score", fontsize=20)
    # plt.show()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()


    fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/'
    filename = "F1_score_incremental_praxi_SL_CSOAA"
    # xs=[str(xlabel) for xlabel in [3000//50, 3000//25, 3000//10, 3000]]
    xs=["6", "12", "18", "24", "30", "60", "90", "93", "120", "150"]
    ys_d4noreplay_f1score_l=[
        [1],
        [1],
        [0.541],
        [0.183],
        [0.317],
        [0.390],
        [0.192],
        [0.194],
        [0.186]]
    ys_d4noreplay_f1scoremean_l = np.array(ys_d4noreplay_f1score_l).mean(axis=1).tolist()
    ys_d4noreplay_f1scorestd_l  = np.array(ys_d4noreplay_f1score_l).std(axis=1).tolist()
    ys_d4replay_f1score_l=[
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [0.461],
        [0.183],
        [0.363],]
    ys_d4replay_f1scoremean_l = np.array(ys_d4replay_f1score_l).mean(axis=1).tolist()
    ys_d4replay_f1scorestd_l  = np.array(ys_d4replay_f1score_l).std(axis=1).tolist()
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # bottom = np.zeros(len(xs))
    entry_count, width = 2, 0.4
    p = ax.bar([idx-width/entry_count+width/entry_count/2 for idx, _ in enumerate(ys_d4noreplay_f1scoremean_l)], ys_d4noreplay_f1scoremean_l, width/entry_count, yerr=ys_d4noreplay_f1scorestd_l, color='#0067ff', edgecolor="black", hatch="x", label="Incrementally Build Classifiers")
    p2 = ax.bar([idx-width/entry_count+(2+1)*width/entry_count/2 for idx, _ in enumerate(ys_d4replay_f1scoremean_l)], ys_d4replay_f1scoremean_l, width/entry_count, yerr=ys_d4replay_f1scorestd_l, color='#00ff67', edgecolor="black", hatch="|", label="Pro-actively Build 90 Classifiers")
    # ax.bar_label(p)
    # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    ax.grid()
    ax.legend(loc="upper left", prop={'size': 16})
    ax.set_xticks(list(range(len(xs))))
    ax.set_xticklabels(xs)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.set_xlabel("Number of Labels Trained after Incremental Training", fontsize=20)
    ax.set_ylabel("F1 Score", fontsize=20)
    # plt.show()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/'
    # filename = "F1_score_incremental_praxi_ML"
    # # xs=[str(xlabel) for xlabel in [3000//50, 3000//25, 3000//10, 3000]]
    # xs=["8", "16", "18", "25", "37", "167", "188"]
    # ys_d4noreplay_f1score_l=[
    #     [1, 1, 1],
    #     [0.384, 0.560, 0.762],
    #     [0.444, 0.520, 0.444],
    #     [0.711, 0.491, 0.711],
    #     [0.502, 0.538, 0.252],
    #     [0.595, 0.436, 0.514],
    #     [0.569, 0.389, 0.468]]
    # # ys_d4noreplay_f1score_l=[
    # #     [0.390, 0.572, 0.254],
    # #     [0.618, 0.511, 0.629],
    # #     [0.550, 0.375]]
    # ys_d4noreplay_f1scoremean_l = np.array(ys_d4noreplay_f1score_l).mean(axis=1).tolist()
    # ys_d4noreplay_f1scorestd_l  = np.array(ys_d4noreplay_f1score_l).std(axis=1).tolist()
    # ys_d4replay_f1score_l=[
    #     [1, 1, 1],
    #     [0.890, 0.932, 0.963],
    #     [0.745, 0.887, 0.965],
    #     [0.747, 0.895, 0.929],
    #     [0.743, 0.890, 0.819],
    #     [0.694, 0.864, 0.760],
    #     [0.728, 0.861, 0.762]]
    # # ys_d4replay_f1score_l=[
    # #     [0.852, 0.907, 0.806],
    # #     [0.758, 0.869],
    # #     [1]]
    # ys_d4replay_f1scoremean_l = np.array(ys_d4replay_f1score_l).mean(axis=1).tolist()
    # ys_d4replay_f1scorestd_l  = np.array(ys_d4replay_f1score_l).std(axis=1).tolist()
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 2, 0.4
    # p = ax.bar([idx-width/entry_count+width/entry_count/2 for idx, _ in enumerate(ys_d4noreplay_f1scoremean_l)], ys_d4noreplay_f1scoremean_l, width/entry_count, yerr=ys_d4noreplay_f1scorestd_l, color='#0067ff', edgecolor="black", hatch="x", label="no data replay")
    # p2 = ax.bar([idx-width/entry_count+(2+1)*width/entry_count/2 for idx, _ in enumerate(ys_d4replay_f1scoremean_l)], ys_d4replay_f1scoremean_l, width/entry_count, yerr=ys_d4replay_f1scorestd_l, color='#00ff67', edgecolor="black", hatch="|", label="with data replay")
    # # ax.bar_label(p)
    # # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    # ax.grid()
    # ax.legend(loc="upper left", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Package for Discovery after Incremental Training", fontsize=20)
    # ax.set_ylabel("F1 Score", fontsize=20)
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()



    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/figs/'
    # filename = "F1_score_incremental_praxi_ML_conf"
    # # xs=[str(xlabel) for xlabel in [3000//50, 3000//25, 3000//10, 3000]]
    # xs=["5", "10", "15"]
    # ys_d4noreplay_f1score_l=[
    #     [0.502, 0.538, 0.252],
    #     [0.595, 0.436, 0.514],
    #     [0.569, 0.389, 0.468]]
    # ys_d4noreplay_f1scoremean_l = np.array(ys_d4noreplay_f1score_l).mean(axis=1).tolist()
    # ys_d4noreplay_f1scorestd_l  = np.array(ys_d4noreplay_f1score_l).std(axis=1).tolist()
    # ys_d4replay_f1score_l=[
    #     [0.743, 0.890, 0.819],
    #     [0.694, 0.864, 0.760],
    #     [0.728, 0.861, 0.762]]
    # ys_d4replay_f1scoremean_l = np.array(ys_d4replay_f1score_l).mean(axis=1).tolist()
    # ys_d4replay_f1scorestd_l  = np.array(ys_d4replay_f1score_l).std(axis=1).tolist()
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 2, 0.4
    # p = ax.bar([idx-width/entry_count+width/entry_count/2 for idx, _ in enumerate(ys_d4noreplay_f1scoremean_l)], ys_d4noreplay_f1scoremean_l, width/entry_count, yerr=ys_d4noreplay_f1scorestd_l, color='#0067ff', edgecolor="black", hatch="x", label="no data replay")
    # p2 = ax.bar([idx-width/entry_count+(2+1)*width/entry_count/2 for idx, _ in enumerate(ys_d4replay_f1scoremean_l)], ys_d4replay_f1scoremean_l, width/entry_count, yerr=ys_d4replay_f1scorestd_l, color='#00ff67', edgecolor="black", hatch="|", label="with data replay")
    # # ax.bar_label(p)
    # # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    # ax.grid()
    # ax.legend(loc="upper left", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Package for Discovery after Incremental Training", fontsize=20)
    # ax.set_ylabel("F1 Score", fontsize=20)
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()




    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs_label = [3, 6, 60, 120, 300, "3000 (DeltaSherlock)"]
    # xs = list(range(len(xs_label)))
    # labels = ["No Filter"]
    # ys_d4trainingtimerawinput_l=[#models
    #     [#dims
    #         [
    #             [0.151, 0.101, 0.085, 0.061, 0.087, 0.068, 0.163, 0.079, 0.105, 0.077, 0.173, 0.122, 0.107, 0.135, 0.138, 0.081, 0.081, 0.083, 0.136, 0.087, 0.081, 0.104, 0.103, 0.095, 0.11, 0.09, 0.09, 0.817, 0.093, 0.074, 0.086, 0.104, 0.087, 0.143, 0.127, 0.081, 0.082, 0.082, 0.08, 0.108, 0.076, 0.102, 0.079, 0.124, 0.102, 0.095, 0.098, 0.095, 0.091, 0.095, 0.091, 0.089, 0.094, 0.129, 0.093, 0.079, 0.135, 0.116, 0.084, 0.082, 0.098, 0.116, 0.089, 0.134, 0.091, 0.101, 0.089, 0.093, 0.193, 0.081, 0.087, 0.147, 0.083, 0.078, 0.147, 0.097, 0.081, 0.088, 0.082, 0.092, 0.085, 0.084, 0.126, 0.091, 0.079, 0.092, 0.565, 0.075, 0.085, 0.097, 0.083, 0.108, 0.112, 0.083, 0.074, 0.119, 0.103, 0.073, 0.122, 0.087, 0.074, 0.064, 0.064, 0.07, 0.189, 0.099, 0.088, 0.102, 0.087, 0.093, 0.292, 0.085, 0.101, 0.113, 0.064, 0.07, 0.091, 0.095, 0.083, 0.058, 0.11, 0.126, 0.073, 0.102, 0.097, 0.101, 0.104, 0.084, 0.31, 0.075, 0.081, 0.074, 0.078, 0.106, 0.071, 0.075, 0.073, 0.085, 0.071, 0.09, 0.083, 0.079, 0.086, 0.125, 0.069, 0.082, 0.143, 0.094, 0.091, 0.081, 0.078, 0.078, 0.066, 0.065, 0.125, 0.068, 0.105, 0.066, 0.111, 0.072, 0.134, 0.114, 0.079, 0.113, 0.095, 0.26, 0.088, 0.078, 0.11, 0.117, 0.101, 0.165, 0.099, 0.103, 0.107, 0.078, 0.138, 0.066, 0.08, 0.109, 0.076, 0.072, 0.088, 0.114, 0.08, 0.103, 0.157, 0.082, 0.13, 0.085, 0.084, 0.088, 0.092, 0.085, 0.09, 0.084, 0.094, 0.075, 0.073, 0.285, 0.106, 0.109, 0.144, 0.111, 0.102, 0.085, 0.073, 0.088, 0.115, 0.077, 0.079, 0.077, 0.081, 0.1, 0.152, 0.08, 0.104, 0.126, 0.135, 0.084, 0.075, 0.087, 0.14, 0.096, 0.102, 0.165, 0.081, 0.077, 0.176, 0.106, 0.2, 0.106, 0.146, 0.076, 0.088, 0.783, 0.105, 0.074, 0.106, 0.135, 0.081, 0.1, 0.076, 0.077, 0.129, 0.127, 0.101, 0.184, 0.11, 0.105, 0.092, 0.128, 0.113, 0.12, 0.09, 0.099, 0.092, 0.072, 0.096, 0.082, 2.938, 0.092, 0.083, 0.086, 0.144, 0.101, 0.143, 0.084, 0.069, 0.074, 0.116, 0.102, 0.079, 0.093, 0.098, 0.08, 0.081, 0.11, 0.083, 0.088, 0.116, 0.087, 0.065, 0.079, 0.09, 0.085, 0.097, 0.087, 0.08, 0.26, 0.077, 0.098, 0.1, 0.087, 0.081, 0.1, 0.081, 0.114, 0.076, 0.122, 0.086, 0.085, 0.134, 0.077, 0.14, 0.149, 0.07, 0.065, 0.082, 0.119, 0.128, 0.076, 0.12, 0.075, 0.088, 0.085, 0.07, 0.138, 0.072, 0.11, 0.109, 0.097, 0.105, 0.082, 0.082, 0.154, 0.088, 0.078, 0.117, 0.108, 0.084, 0.1, 0.081, 0.076, 0.105, 0.088, 0.083, 0.078, 0.264, 0.088, 0.113, 0.092, 0.125, 0.068, 0.102, 0.083, 0.101, 0.143, 0.079, 0.108, 0.095, 0.097, 0.087, 0.135, 0.088, 0.08, 0.094, 0.086, 0.146, 1.463, 0.088, 0.082, 0.081, 0.085, 0.076, 0.07, 0.136, 0.139, 0.072, 0.076, 0.07, 0.131, 0.112, 0.098, 0.089, 0.216, 0.094, 0.074, 0.078, 0.082, 0.068, 0.093, 0.084, 0.073, 0.122, 0.232, 0.08, 0.084, 0.078, 0.092, 0.107, 0.09, 0.072, 0.089, 0.093, 0.057, 0.074, 0.108, 0.085, 0.119, 0.08, 0.069, 0.065, 0.079, 0.067, 0.101, 0.083, 0.081, 0.098, 0.092, 0.083, 0.084, 0.091, 0.081, 0.104, 0.109, 0.097, 0.099, 0.087, 0.066, 0.167, 0.074, 0.099, 0.074, 0.09, 0.08, 0.077, 0.068, 0.072, 0.071, 0.064, 0.071, 0.073, 0.064, 0.069, 0.114, 0.071, 0.084, 0.101, 0.076, 0.113, 0.094, 0.074, 0.132, 0.12, 0.115, 0.129, 0.084, 0.119, 0.092, 0.081, 0.09, 0.111, 0.084, 0.082, 0.063, 0.08, 0.073, 0.288, 0.11, 0.07, 0.197, 0.084, 0.073, 0.093, 0.143, 0.085, 0.08, 0.13, 0.143, 0.084, 0.108, 0.068, 0.075, 0.087, 0.083, 0.088, 0.13, 0.084, 0.08, 0.092, 0.088, 0.095, 0.078, 0.088, 0.114, 0.089, 0.111, 0.138, 0.074, 0.09, 0.096, 0.103, 0.071, 0.069, 0.097, 0.099, 0.082, 0.08, 0.093, 0.091, 0.084, 0.075, 0.082, 0.073, 0.093, 0.081, 0.109, 0.089, 0.094, 0.083, 0.113, 0.095, 0.08, 0.105, 0.145, 0.08, 0.081, 0.092, 0.079, 0.132, 0.086, 0.138, 0.095, 0.109, 0.089, 0.096, 0.307, 0.149, 0.079, 0.085, 0.103, 0.075, 0.076, 0.092, 0.096, 0.098, 0.085, 0.148, 0.397, 0.081, 0.081, 0.117, 0.08, 0.067, 0.095, 0.067, 0.122, 0.095, 0.075, 0.094, 0.074, 0.087, 0.076, 0.077, 0.078, 0.073, 0.191, 0.075, 0.082, 0.138, 0.131, 0.089, 0.091, 0.084, 0.084, 0.1, 0.069, 0.097, 0.097, 0.093, 0.08, 0.075, 0.108, 0.196, 0.061, 0.11, 0.108, 0.089, 0.119, 0.112, 0.084, 0.076, 0.101, 0.126, 0.115, 0.083, 0.105, 0.121, 0.078, 0.08, 0.145, 0.101, 0.102, 0.155, 0.122, 0.078, 0.075, 0.069, 0.092, 0.397, 0.09, 0.126, 0.086, 0.087, 0.081, 0.078, 0.088, 0.086, 0.143, 0.104, 0.093, 0.07, 0.093, 0.111, 0.137, 0.141, 0.173, 0.078, 0.154, 0.116, 0.063, 0.126, 0.077, 0.088, 0.104, 0.129, 0.077, 0.078, 0.088, 0.112, 0.081, 0.074, 0.134, 0.08, 0.307, 0.107, 0.111, 0.177, 0.091, 0.11, 0.076, 0.083, 0.075, 0.066, 0.099, 0.079, 0.073, 0.075, 0.086, 0.127, 0.132, 0.153, 0.071, 0.068, 0.079, 0.085, 0.11, 0.092, 0.11, 0.086, 0.089, 0.087, 0.108, 0.081, 0.077, 0.066, 0.072, 0.072, 0.087, 0.084, 0.093, 0.09, 0.077, 0.097, 0.074, 0.075, 0.088, 0.118, 0.09, 0.075, 0.078, 0.069, 0.108, 0.133, 0.133, 0.089, 0.093, 0.08, 0.077, 0.079, 0.084, 0.206, 0.084, 0.115, 0.084, 0.192, 0.068, 0.071, 0.09, 0.096, 0.083, 0.1, 0.077, 0.07, 0.075, 0.081, 0.072, 0.105, 0.09, 0.229, 0.091, 0.113, 0.061, 0.085, 0.078, 0.125, 0.085, 1.158, 0.089, 0.085, 0.069, 0.064, 0.104, 0.112, 0.079, 0.128, 0.086, 0.098, 0.078, 0.084, 0.104, 0.096, 0.086, 0.084, 0.209, 0.119, 0.089, 0.13, 0.14, 0.136, 0.066, 0.079, 0.087, 0.099, 0.077, 0.077, 0.083, 0.102, 0.292, 0.139, 0.077, 0.076, 0.081, 0.084, 0.107, 0.09, 0.132, 0.114, 0.095, 0.096, 0.139, 1.122, 0.07, 0.07, 0.077, 0.085, 0.079, 0.094, 0.077, 0.075, 0.122, 0.127, 0.079, 0.098, 0.106, 0.091, 0.088, 0.104, 0.084, 0.069, 0.122, 0.133, 0.107, 0.133, 0.082, 0.066, 0.071, 0.129, 0.093, 0.082, 0.127, 0.09, 0.123, 0.071, 0.112, 0.12, 0.109, 0.116, 0.09, 0.139, 0.082, 0.098, 0.087, 0.089, 0.084, 0.125, 0.102, 0.069, 0.107, 0.108, 0.073, 0.067, 0.148, 0.077, 0.112, 0.076, 0.086, 0.155, 0.115, 0.138, 0.095, 0.136, 0.087, 0.15, 0.088, 0.091, 0.096, 0.106, 0.086, 0.089, 0.105, 0.084, 0.105, 0.095, 0.109, 0.296, 0.153, 0.084, 0.091, 0.237, 0.09, 0.082, 0.197, 0.133, 0.122, 0.123, 0.113, 0.076, 0.078, 0.211, 0.067, 0.12, 0.121, 0.135, 0.086, 0.088, 0.087, 0.078, 0.097, 0.094, 0.119, 0.082, 0.085, 0.06, 0.068, 0.199, 0.102, 0.076, 0.09, 0.084, 0.124, 0.084, 0.138, 0.086, 0.103, 0.115, 0.101, 0.082, 0.105, 0.085, 0.091, 0.089, 0.11, 0.1, 0.123, 0.084, 0.168, 0.136, 0.102, 0.08, 0.108, 0.095, 0.123, 0.123, 0.148, 0.088, 0.089, 0.093, 0.097, 0.071, 0.098, 0.081, 0.064, 0.072, 0.085, 0.111, 0.087, 0.133, 0.079, 0.071, 0.089, 0.126, 0.075, 0.096, 0.105, 0.156, 0.091, 0.138, 0.066, 0.098, 0.101, 0.093, 0.09, 0.1, 0.112, 0.142, 0.076, 0.077, 0.072, 0.085, 0.124, 0.095, 0.125, 0.091, 0.113, 0.095, 0.109, 0.097, 0.084, 0.1, 0.085, 0.096, 0.088, 0.081, 0.082, 0.069, 0.077, 0.065, 0.189, 0.219, 0.085, 0.087, 0.087, 0.06, 0.085, 0.079, 0.102, 0.092, 0.086, 0.085, 0.077, 0.904, 0.072, 0.105, 0.112, 0.086, 0.125, 0.088, 0.097, 0.065, 0.122, 0.1, 0.122, 0.078, 0.105, 0.092, 0.133, 0.091, 0.061, 0.083, 0.063, 0.098, 0.114, 0.128, 0.133, 0.071, 0.36, 0.084, 0.088, 0.092, 0.094, 0.095, 0.092, 0.098, 0.093, 0.092, 0.091, 0.127, 0.086], [0.084, 0.113, 0.084, 0.077, 0.086, 0.102, 0.084, 0.111, 0.078, 0.128, 0.097, 0.089, 0.091, 0.144, 0.082, 0.073, 0.052, 0.083, 0.082, 0.082, 0.076, 0.098, 0.084, 0.094, 0.121, 0.15, 0.1, 0.083, 0.122, 0.111, 0.09, 0.139, 0.119, 0.088, 0.114, 0.135, 0.078, 0.143, 0.091, 0.077, 0.082, 0.071, 0.09, 0.176, 0.088, 0.102, 0.09, 0.098, 0.082, 0.139, 0.08, 0.085, 0.08, 0.318, 0.122, 0.114, 0.424, 0.081, 0.104, 0.083, 0.727, 0.072, 0.339, 0.081, 0.076, 0.099, 0.105, 0.083, 0.088, 0.092, 0.096, 0.085, 0.104, 0.082, 0.154, 0.104, 0.084, 0.079, 0.088, 0.09, 0.21, 0.102, 0.078, 0.079, 0.138, 0.101, 0.116, 0.07, 0.095, 0.12, 0.082, 0.093, 0.069, 0.099, 0.111, 0.086, 0.098, 0.104, 0.112, 0.074, 0.079, 0.1, 0.087, 0.111, 0.108, 0.068, 0.128, 0.099, 0.092, 0.105, 0.089, 0.116, 0.106, 0.085, 0.071, 0.07, 0.092, 0.133, 0.119, 0.122, 0.075, 0.126, 0.091, 0.111, 0.1, 0.076, 0.118, 0.117, 0.093, 0.065, 0.074, 0.079, 0.123, 0.124, 0.143, 0.08, 0.061, 0.076, 0.087, 0.175, 0.127, 0.127, 0.071, 0.104, 0.089, 0.101, 0.09, 0.103, 0.068, 0.09, 0.062, 0.101, 0.09, 0.089, 0.099, 0.069, 0.092, 0.13, 0.075, 0.217, 0.388, 0.068, 0.096, 0.109, 0.091, 0.082, 0.141, 0.092, 0.146, 0.087, 0.088, 0.079, 0.084, 0.163, 0.107, 0.098, 0.083, 0.073, 0.072, 0.105, 0.076, 0.076, 0.08, 0.065, 0.12, 1.531, 0.091, 0.071, 0.127, 0.118, 0.1, 0.125, 0.08, 0.188, 0.096, 0.107, 0.094, 0.174, 0.163, 0.093, 0.079, 0.064, 0.121, 0.124, 0.126, 0.138, 0.104, 0.074, 0.088, 0.102, 0.076, 0.086, 0.07, 0.096, 0.103, 0.089, 0.105, 0.092, 0.09, 0.083, 0.095, 0.108, 0.089, 0.148, 0.095, 0.104, 0.09, 0.075, 0.099, 0.1, 0.094, 0.092, 0.1, 0.139, 0.084, 0.095, 0.08, 0.079, 0.109, 0.114, 0.083, 0.085, 0.167, 0.085, 0.078, 0.118, 0.093, 0.121, 0.1, 0.092, 0.079, 0.089, 0.079, 0.102, 0.084, 0.082, 0.086, 0.088, 0.087, 0.072, 0.09, 0.096, 0.075, 0.119, 0.118, 0.09, 0.076, 0.103, 0.083, 0.086, 0.092, 0.086, 0.085, 0.088, 0.079, 0.072, 0.118, 0.1, 0.075, 0.104, 0.092, 0.088, 0.131, 0.103, 0.089, 0.116, 0.115, 0.097, 0.098, 0.077, 0.091, 0.097, 0.086, 0.098, 0.099, 0.125, 0.076, 0.093, 0.087, 0.134, 0.08, 0.083, 0.087, 0.074, 0.081, 0.062, 0.095, 0.069, 0.11, 0.068, 0.08, 0.309, 0.087, 0.073, 0.091, 0.093, 0.094, 0.084, 0.092, 0.117, 0.094, 0.11, 0.074, 0.127, 0.071, 0.129, 0.08, 0.09, 0.091, 0.31, 0.093, 0.086, 0.101, 0.091, 0.103, 0.061, 0.135, 0.077, 0.086, 0.131, 0.134, 0.077, 0.126, 0.171, 0.063, 0.096, 0.083, 0.083, 0.104, 0.107, 0.097, 0.083, 0.084, 0.113, 0.083, 0.132, 0.129, 0.088, 0.119, 0.099, 0.085, 0.09, 0.095, 0.072, 0.078, 0.125, 0.128, 0.138, 0.15, 0.178, 0.095, 0.077, 0.09, 0.08, 0.091, 0.102, 0.104, 0.086, 0.111, 0.103, 0.085, 0.101, 0.101, 0.075, 0.088, 0.09, 0.093, 0.071, 0.062, 0.075, 0.078, 0.085, 0.091, 1.139, 0.066, 0.088, 0.091, 0.087, 0.088, 0.073, 0.08, 0.089, 0.087, 0.09, 0.08, 0.078, 0.241, 0.119, 0.085, 0.079, 0.1, 0.088, 0.128, 0.126, 0.1, 0.107, 0.082, 0.112, 0.093, 0.1, 0.111, 0.085, 0.111, 0.148, 0.099, 0.12, 0.09, 0.145, 0.092, 0.083, 0.084, 0.083, 0.129, 0.075, 0.089, 0.115, 0.076, 0.118, 0.122, 0.082, 0.095, 0.07, 0.094, 0.118, 0.114, 0.115, 0.2, 0.09, 0.084, 0.087, 0.079, 0.07, 0.059, 0.08, 0.098, 0.115, 0.1, 0.081, 0.06, 0.125, 0.099, 0.07, 0.081, 0.08, 0.072, 0.099, 0.087, 0.124, 0.506, 0.105, 0.095, 0.12, 0.09, 0.156, 0.081, 0.067, 1.278, 0.093, 0.083, 0.078, 0.082, 0.074, 0.089, 0.106, 0.083, 0.076, 0.077, 0.096, 0.07, 0.134, 0.078, 0.094, 0.086, 0.089, 0.25, 0.095, 0.08, 0.106, 0.086, 0.079, 0.076, 0.09, 0.082, 0.086, 0.103, 0.086, 0.065, 0.076, 0.075, 0.067, 0.095, 0.106, 0.079, 0.086, 0.079, 0.084, 0.092, 0.072, 0.084, 0.116, 0.081, 0.07, 0.072, 0.134, 0.065, 0.093, 0.099, 0.123, 0.084, 0.146, 0.066, 0.099, 0.079, 0.089, 0.847, 0.102, 0.084, 0.066, 0.069, 0.1, 0.075, 0.1, 0.108, 0.075, 0.196, 0.094, 0.088, 0.068, 0.079, 0.072, 0.08, 0.074, 0.103, 0.066, 0.082, 0.064, 0.069, 0.075, 0.069, 0.074, 0.082, 0.147, 0.096, 0.092, 0.083, 0.237, 0.076, 0.07, 0.118, 0.074, 0.083, 0.072, 0.075, 0.077, 0.067, 0.126, 0.091, 0.112, 0.087, 0.085, 0.085, 0.083, 0.09, 0.069, 0.091, 0.088, 0.118, 0.075, 0.101, 0.119, 0.209, 0.082, 0.11, 0.089, 0.09, 0.075, 0.081, 0.094, 0.08, 0.077, 0.072, 0.107, 0.18, 0.063, 0.093, 0.102, 0.092, 0.087, 0.073, 0.097, 0.15, 0.078, 0.072, 0.09, 0.085, 0.083, 0.089, 0.072, 0.107, 0.071, 0.068, 0.077, 0.089, 0.076, 0.079, 0.072, 0.08, 0.09, 0.064, 0.08, 0.117, 0.077, 0.082, 0.098, 0.086, 0.084, 0.085, 0.077, 0.082, 0.081, 0.087, 0.074, 0.073, 0.067, 0.119, 0.08, 0.069, 0.091, 0.078, 0.071, 0.088, 0.094, 0.09, 0.087, 0.081, 0.078, 0.117, 0.075, 0.067, 0.071, 0.095, 0.14, 0.1, 0.078, 0.07, 0.108, 0.279, 0.107, 0.097, 0.101, 0.083, 0.076, 0.106, 0.083, 0.111, 0.088, 0.092, 0.181, 0.066, 0.078, 0.071, 0.075, 0.081, 0.07, 0.063, 0.121, 0.082, 0.113, 0.08, 0.082, 0.08, 0.139, 0.069, 0.074, 0.067, 0.093, 0.07, 0.085, 0.074, 0.1, 0.079, 0.076, 0.103, 0.086, 0.123, 0.087, 0.12, 0.127, 0.124, 0.069, 0.105, 0.073, 0.108, 0.082, 0.102, 0.123, 0.219, 0.072, 0.131, 0.1, 0.087, 0.085, 0.063, 0.099, 0.085, 0.116, 0.07, 0.067, 0.082, 0.1, 0.278, 0.095, 0.132, 0.108, 0.083, 0.067, 0.07, 0.077, 0.077, 0.076, 0.09, 0.079, 0.098, 0.078, 0.08, 0.073, 0.104, 0.072, 0.079, 0.084, 0.678, 0.087, 0.083, 0.083, 0.088, 0.126, 0.082, 0.109, 0.106, 0.078, 0.074, 0.272, 0.086, 0.091, 0.081, 0.093, 0.094, 0.085, 0.086, 0.122, 0.062, 0.114, 0.064, 0.085, 0.085, 0.093, 0.134, 0.194, 0.084, 0.07, 0.068, 0.109, 0.092, 0.111, 0.07, 0.081, 0.071, 0.108, 0.11, 0.087, 0.105, 0.075, 0.072, 0.118, 0.085, 0.074, 0.065, 0.093, 0.067, 0.125, 0.083, 0.104, 0.069, 0.095, 0.098, 0.066, 0.1, 0.121, 0.274, 0.093, 0.075, 0.073, 0.069, 0.098, 0.085, 0.07, 0.092, 0.076, 0.088, 0.084, 0.079, 0.078, 0.093, 0.068, 0.134, 0.102, 0.071, 0.084, 0.072, 0.138, 0.095, 0.06, 0.073, 0.191, 0.077, 0.119, 0.09, 0.092, 0.1, 0.123, 0.082, 0.099, 0.098, 0.132, 0.077, 0.091, 0.115, 0.099, 0.082, 0.125, 0.267, 0.116, 0.129, 0.083, 0.088, 0.094, 0.128, 0.095, 0.084, 0.079, 0.069, 0.085, 0.067, 0.093, 0.086, 0.08, 0.076, 0.082, 0.094, 0.118, 0.111, 0.083, 0.099, 0.135, 0.087, 0.095, 0.086, 0.071, 0.072, 0.071, 0.071, 0.061, 0.069, 0.091, 0.069, 0.104, 0.078, 0.082, 0.098, 0.111, 0.077, 0.061, 0.075, 0.077, 0.083, 0.07, 0.095, 0.191, 0.186, 0.095, 0.117, 0.109, 0.105, 0.076, 0.091, 0.096, 0.1, 0.076, 0.087, 0.09, 0.077, 0.092, 0.078, 0.104, 0.066, 0.067, 0.087, 0.071, 0.065, 0.091, 0.102, 0.072, 0.072, 0.201, 0.074, 0.072, 0.113, 0.259, 0.073, 0.078, 0.078, 0.07, 0.073, 0.086, 0.23, 0.089, 0.065, 0.127, 0.098, 0.128, 0.145, 0.103, 0.097, 0.137, 0.086, 0.107, 0.113, 0.069, 0.091, 0.101, 0.078, 0.115, 0.14, 0.101, 0.125, 0.086, 0.067, 3.096, 0.085, 0.089, 0.086, 0.076, 0.09, 0.075, 0.104, 0.125, 0.157, 0.092, 0.22, 0.143, 0.107, 0.094, 0.102, 0.264, 0.152, 0.123, 0.081, 0.126, 0.091, 0.103, 0.096, 0.129, 0.099, 0.153, 0.139, 0.125, 0.088, 0.094, 0.148, 0.107, 0.087, 0.117, 0.097, 0.096, 0.082, 0.131, 0.13, 0.097, 0.122, 0.097], [0.12, 0.081, 0.101, 0.082, 0.632, 0.075, 0.121, 0.105, 0.105, 0.079, 0.081, 0.126, 0.091, 0.15, 0.134, 0.114, 0.175, 0.102, 0.092, 0.092, 0.087, 0.157, 0.092, 0.09, 0.086, 0.078, 0.108, 0.067, 0.094, 0.087, 0.087, 0.092, 0.099, 0.103, 0.192, 0.12, 0.118, 0.08, 0.091, 0.104, 0.083, 0.082, 0.09, 0.083, 0.082, 0.1, 0.137, 0.099, 0.125, 0.085, 0.18, 0.091, 0.1, 0.09, 0.123, 0.089, 0.104, 0.13, 0.082, 0.089, 0.098, 0.071, 0.071, 0.1, 0.086, 0.086, 0.162, 0.083, 0.084, 0.113, 0.101, 0.122, 0.094, 0.156, 0.098, 0.135, 0.177, 0.088, 0.093, 0.088, 0.074, 0.081, 0.075, 0.083, 0.167, 0.064, 0.107, 0.097, 0.138, 0.087, 0.121, 0.2, 0.092, 0.135, 0.121, 0.132, 1.336, 0.129, 0.088, 0.09, 0.16, 0.108, 0.09, 0.249, 0.115, 0.089, 0.134, 0.08, 0.087, 0.195, 0.097, 0.129, 0.091, 0.096, 0.147, 0.098, 0.086, 0.091, 0.088, 0.101, 0.134, 0.138, 0.09, 0.103, 0.096, 0.084, 0.1, 0.089, 0.084, 0.102, 0.105, 0.123, 0.149, 0.112, 0.091, 0.206, 0.101, 0.109, 0.086, 0.079, 0.084, 0.206, 0.081, 0.137, 0.104, 0.105, 0.092, 0.09, 0.088, 0.114, 0.106, 0.082, 0.127, 0.138, 0.141, 0.078, 0.078, 0.123, 0.11, 0.098, 0.116, 0.091, 0.147, 0.106, 0.21, 0.086, 0.128, 0.104, 0.106, 0.1, 0.08, 0.335, 0.09, 0.084, 0.134, 0.152, 0.112, 0.115, 0.105, 0.142, 0.1, 0.089, 0.09, 0.094, 0.107, 0.093, 0.133, 0.102, 0.308, 0.092, 0.097, 0.139, 0.1, 0.089, 0.112, 0.1, 0.089, 0.085, 0.096, 0.108, 0.091, 0.097, 0.09, 0.145, 0.089, 0.091, 0.098, 0.083, 0.15, 0.154, 0.091, 0.287, 0.088, 0.086, 0.104, 0.096, 0.087, 0.101, 0.091, 0.088, 0.09, 0.091, 0.091, 0.085, 0.088, 0.087, 0.351, 0.088, 0.075, 0.094, 0.147, 0.146, 0.084, 0.156, 0.081, 0.091, 0.089, 0.094, 0.098, 0.146, 0.129, 0.163, 0.087, 0.136, 0.161, 0.109, 0.098, 0.108, 0.107, 0.093, 0.166, 0.086, 0.117, 0.135, 0.093, 0.087, 0.089, 0.899, 0.079, 0.146, 0.092, 0.083, 0.155, 0.092, 0.095, 0.084, 0.078, 0.088, 0.08, 0.088, 0.082, 0.093, 0.095, 0.126, 0.124, 0.102, 0.098, 0.135, 0.124, 0.083, 0.079, 0.084, 0.076, 0.122, 0.088, 0.137, 0.102, 0.221, 0.087, 0.098, 0.091, 0.093, 0.084, 0.087, 0.146, 0.095, 0.084, 0.107, 0.117, 0.093, 0.116, 0.099, 0.094, 0.097, 0.075, 0.091, 0.072, 0.065, 0.112, 0.072, 0.105, 0.112, 0.077, 0.104, 0.073, 0.124, 0.166, 0.093, 0.08, 0.079, 0.123, 0.108, 0.085, 0.125, 0.087, 0.094, 0.097, 0.088, 0.092, 0.077, 0.096, 3.321, 0.136, 0.086, 0.116, 0.112, 0.153, 0.102, 0.097, 0.089, 0.129, 0.106, 0.083, 0.082, 0.069, 0.07, 0.161, 0.09, 0.096, 0.164, 0.083, 0.092, 0.08, 0.087, 0.081, 0.123, 0.092, 0.078, 0.081, 0.084, 0.105, 0.104, 0.203, 0.079, 0.085, 0.08, 0.091, 0.09, 0.08, 0.138, 0.117, 0.089, 1.429, 0.146, 0.093, 0.117, 0.098, 0.128, 0.098, 0.214, 0.121, 0.148, 0.122, 0.084, 0.072, 0.275, 0.093, 0.07, 0.065, 0.075, 0.095, 0.085, 0.071, 0.087, 0.085, 0.083, 0.09, 0.09, 0.074, 0.113, 0.118, 0.079, 0.1, 0.088, 0.095, 0.087, 0.136, 0.118, 0.108, 0.096, 0.097, 0.09, 0.076, 0.088, 0.075, 0.078, 0.099, 0.076, 0.08, 0.063, 0.759, 0.099, 0.09, 0.117, 0.112, 0.081, 0.108, 0.077, 0.079, 0.104, 0.118, 0.09, 0.075, 0.08, 0.073, 0.256, 0.238, 0.085, 0.096, 0.084, 0.095, 0.12, 0.076, 0.115, 0.081, 0.097, 0.125, 0.099, 0.095, 0.086, 0.132, 0.091, 0.106, 0.093, 0.076, 0.087, 0.094, 0.092, 0.116, 0.09, 0.084, 0.096, 0.084, 0.328, 0.078, 0.076, 0.086, 0.088, 0.087, 0.091, 0.075, 0.091, 0.089, 0.081, 0.082, 0.089, 0.093, 0.091, 0.081, 0.112, 0.103, 0.088, 0.086, 0.069, 0.097, 0.111, 0.079, 0.082, 0.127, 0.08, 0.111, 0.069, 0.142, 0.073, 0.087, 0.1, 0.082, 0.09, 0.128, 0.171, 0.083, 0.111, 0.1, 0.292, 0.122, 0.078, 0.086, 0.095, 0.097, 0.084, 0.11, 0.079, 0.285, 0.092, 0.1, 0.091, 0.089, 0.094, 0.089, 0.102, 0.07, 0.071, 0.072, 0.095, 0.116, 0.069, 0.084, 0.075, 0.119, 0.08, 0.096, 0.116, 0.092, 0.082, 0.073, 0.089, 0.084, 0.09, 0.081, 0.101, 0.106, 0.103, 0.097, 0.097, 0.082, 0.093, 0.077, 0.089, 0.08, 0.068, 0.088, 0.081, 0.119, 0.086, 0.115, 0.106, 0.123, 0.071, 0.093, 0.171, 0.083, 0.094, 0.081, 0.084, 0.111, 0.097, 0.106, 0.086, 0.089, 0.082, 0.104, 0.116, 0.12, 0.083, 0.114, 0.079, 0.083, 0.096, 0.096, 0.085, 0.171, 0.085, 0.217, 0.085, 0.085, 0.126, 0.145, 0.096, 0.094, 0.098, 0.08, 0.089, 0.097, 0.082, 0.111, 0.096, 0.074, 0.068, 0.085, 0.091, 0.095, 0.085, 0.093, 0.092, 0.084, 0.082, 0.084, 0.304, 0.08, 0.081, 0.09, 0.13, 0.166, 0.098, 0.129, 0.079, 0.063, 0.103, 0.094, 0.07, 0.127, 0.076, 0.081, 0.087, 0.082, 0.109, 0.067, 0.078, 0.086, 0.079, 0.081, 0.083, 0.09, 0.079, 0.11, 0.092, 0.221, 0.207, 0.125, 0.07, 0.063, 0.076, 0.082, 0.071, 0.082, 0.126, 0.117, 0.095, 0.089, 0.082, 0.12, 0.093, 0.11, 0.082, 0.128, 0.079, 0.122, 0.096, 0.116, 0.129, 0.116, 0.078, 0.085, 0.083, 0.098, 0.089, 0.119, 0.109, 0.089, 0.095, 0.137, 0.105, 0.095, 0.132, 0.096, 0.085, 0.112, 0.113, 0.106, 0.1, 0.114, 0.075, 0.082, 0.073, 0.07, 0.082, 0.134, 0.107, 0.104, 0.41, 0.071, 0.09, 0.097, 0.067, 0.097, 0.076, 0.068, 0.061, 0.069, 0.105, 0.107, 0.093, 0.122, 0.101, 0.069, 0.113, 0.104, 0.075, 0.104, 0.142, 0.097, 0.096, 0.082, 0.086, 0.069, 0.079, 0.106, 0.088, 0.113, 0.113, 0.106, 0.129, 0.097, 0.103, 0.068, 0.163, 0.143, 0.079, 0.1, 0.091, 0.071, 0.068, 0.139, 0.151, 0.089, 0.113, 0.081, 0.085, 0.096, 0.082, 0.091, 0.095, 0.1, 0.083, 0.088, 0.077, 0.118, 0.097, 0.08, 0.09, 0.101, 0.087, 0.098, 0.126, 0.092, 0.078, 0.096, 0.091, 0.097, 0.088, 0.109, 0.082, 0.095, 0.089, 0.097, 0.08, 0.09, 0.116, 0.09, 0.168, 0.123, 0.148, 0.099, 0.102, 0.088, 0.094, 0.108, 0.083, 0.134, 0.087, 0.091, 0.083, 0.092, 0.078, 0.104, 0.094, 0.084, 0.122, 0.122, 0.11, 0.099, 0.097, 0.101, 0.101, 0.083, 0.071, 0.097, 0.066, 0.069, 0.094, 0.081, 0.063, 0.123, 0.091, 0.102, 0.107, 0.128, 0.097, 1.129, 0.079, 0.088, 0.069, 0.092, 0.092, 0.105, 0.124, 0.09, 0.433, 0.119, 0.099, 0.1, 0.095, 0.096, 0.083, 0.106, 0.093, 0.117, 0.107, 0.096, 0.077, 0.083, 0.08, 0.092, 0.102, 0.099, 0.078, 0.072, 0.107, 0.088, 0.139, 0.08, 0.11, 0.091, 0.082, 0.097, 0.084, 0.135, 0.093, 0.086, 0.14, 0.09, 0.096, 0.148, 0.12, 0.085, 0.098, 0.114, 0.101, 0.087, 0.147, 0.087, 0.079, 0.069, 0.073, 0.07, 0.088, 0.127, 0.092, 0.078, 0.082, 0.083, 0.088, 0.106, 0.078, 0.061, 0.073, 0.076, 0.085, 0.07, 0.076, 0.091, 0.091, 0.075, 0.103, 0.177, 0.18, 0.141, 0.085, 0.107, 0.098, 0.081, 0.095, 0.086, 0.084, 0.125, 0.101, 0.091, 0.084, 0.083, 0.078, 0.079, 0.079, 0.081, 0.098, 0.09, 0.124, 0.09, 0.128, 0.106, 0.128, 0.089, 0.096, 0.071, 0.077, 0.136, 0.114, 0.084, 0.085, 0.089, 0.09, 0.103, 0.073, 0.075, 0.104, 0.078, 0.091, 0.13, 0.07, 0.099, 0.098, 0.083, 0.086, 0.105, 0.309, 0.094, 0.086, 0.088, 0.087, 0.086, 0.117, 0.116, 0.095, 0.098, 0.106, 0.109, 0.098, 0.095, 0.093, 0.238, 0.113, 0.129, 0.083, 0.095, 0.127, 0.134, 0.08, 0.096, 0.088, 0.085, 0.096, 0.089, 0.064, 0.09, 0.126, 0.091, 0.075, 0.103, 0.09, 0.141, 0.124, 0.116, 0.09, 0.527, 0.068, 0.207, 0.089, 0.086, 0.081, 0.105, 0.105, 0.079, 0.095, 0.092, 0.108, 0.102, 0.102, 0.137, 0.128, 0.09, 0.077, 0.093, 0.086, 0.079, 0.095, 0.091, 0.075, 0.077, 0.119, 0.089, 0.145], [0.099, 0.064, 0.098, 0.08, 0.088, 0.092, 0.08, 0.078, 0.066, 0.067, 0.063, 0.183, 0.089, 0.084, 0.185, 0.081, 0.069, 0.102, 0.074, 0.065, 0.086, 0.095, 0.073, 0.125, 0.086, 0.091, 0.158, 0.135, 0.094, 0.117, 0.095, 0.108, 0.093, 0.104, 0.084, 0.103, 0.129, 0.116, 0.099, 0.084, 0.083, 0.098, 0.101, 0.109, 0.304, 0.084, 0.07, 0.085, 0.105, 0.1, 0.074, 0.077, 0.079, 0.12, 0.077, 0.09, 0.09, 0.093, 0.108, 0.088, 0.116, 0.09, 0.084, 0.154, 0.13, 0.082, 0.067, 0.068, 0.114, 0.072, 0.099, 0.079, 0.105, 0.079, 0.075, 0.097, 0.145, 0.135, 0.067, 0.068, 0.081, 0.079, 0.073, 0.084, 0.102, 0.072, 0.089, 0.095, 0.378, 0.105, 0.112, 0.096, 0.081, 0.083, 0.081, 0.073, 0.074, 0.075, 0.108, 0.105, 0.091, 0.074, 0.076, 0.112, 0.215, 0.093, 0.122, 0.077, 0.11, 0.077, 0.096, 0.129, 0.102, 0.084, 0.088, 0.083, 0.07, 0.099, 0.067, 0.323, 0.085, 0.071, 0.083, 0.075, 0.141, 0.084, 0.145, 0.104, 0.116, 0.098, 0.07, 0.073, 0.093, 0.076, 0.072, 0.094, 0.061, 0.116, 0.068, 0.061, 0.08, 0.839, 0.129, 0.085, 0.316, 0.097, 0.088, 0.071, 0.125, 0.07, 0.084, 0.099, 0.111, 0.164, 0.071, 0.127, 0.096, 0.1, 0.093, 0.094, 0.073, 0.112, 0.112, 0.22, 0.089, 0.093, 0.09, 0.129, 0.112, 0.113, 0.089, 0.072, 0.088, 0.151, 0.075, 0.079, 0.11, 0.083, 0.137, 0.091, 0.08, 0.086, 0.126, 0.122, 0.099, 0.102, 0.084, 0.114, 0.098, 0.156, 0.079, 0.073, 0.083, 0.09, 0.114, 0.134, 0.137, 0.067, 0.111, 0.099, 0.07, 0.079, 0.128, 0.068, 0.08, 0.071, 0.077, 0.093, 0.084, 0.114, 0.07, 0.09, 0.083, 0.077, 0.067, 0.069, 0.076, 0.082, 0.117, 0.09, 0.1, 0.096, 0.074, 0.076, 0.079, 0.118, 0.083, 0.112, 0.109, 0.083, 0.077, 0.075, 0.104, 0.098, 0.272, 0.214, 0.069, 0.119, 0.09, 0.079, 0.071, 0.075, 0.105, 0.089, 0.086, 0.092, 0.082, 0.097, 0.07, 0.103, 0.102, 0.07, 0.08, 0.072, 0.069, 0.089, 0.064, 0.502, 0.091, 0.127, 0.075, 0.089, 0.099, 0.139, 0.11, 0.093, 0.087, 0.073, 0.065, 0.136, 0.063, 0.082, 0.072, 0.064, 0.079, 0.074, 0.069, 0.108, 0.107, 0.109, 0.123, 0.061, 0.079, 0.07, 0.071, 0.11, 0.076, 0.07, 0.126, 0.098, 0.091, 0.07, 0.089, 0.092, 0.086, 0.093, 0.187, 0.073, 0.098, 0.085, 0.2, 0.097, 0.15, 0.074, 0.097, 0.142, 0.081, 0.101, 0.204, 0.092, 0.085, 0.159, 0.087, 0.085, 0.089, 0.083, 0.097, 0.091, 0.068, 0.088, 0.096, 0.071, 0.071, 0.089, 0.074, 0.091, 0.094, 0.09, 0.074, 0.1, 0.129, 0.074, 0.083, 0.092, 0.087, 0.07, 0.101, 0.068, 0.079, 0.085, 0.105, 0.087, 0.08, 0.067, 0.08, 0.072, 0.087, 0.09, 0.218, 0.076, 0.076, 0.079, 0.065, 0.068, 0.163, 0.068, 0.068, 0.088, 0.098, 0.083, 0.089, 0.072, 0.099, 3.036, 0.061, 0.104, 0.065, 0.076, 0.07, 0.118, 0.083, 0.082, 0.095, 0.125, 0.092, 0.086, 0.091, 0.108, 0.08, 0.156, 0.068, 0.103, 0.326, 0.079, 0.096, 0.069, 0.094, 0.16, 0.074, 0.063, 0.112, 0.073, 0.085, 0.076, 0.084, 0.077, 0.078, 0.099, 0.065, 1.296, 0.109, 0.071, 0.112, 1.457, 0.077, 0.135, 0.084, 0.067, 0.094, 0.155, 0.071, 0.141, 0.07, 0.082, 0.076, 0.124, 0.127, 0.08, 0.092, 0.07, 0.078, 0.079, 0.08, 0.062, 0.078, 0.122, 0.083, 0.083, 0.069, 0.074, 0.074, 0.072, 0.079, 0.075, 0.083, 0.089, 0.099, 0.083, 0.095, 0.116, 0.081, 0.085, 0.081, 0.095, 0.121, 0.113, 0.089, 0.105, 0.084, 0.091, 0.115, 0.077, 0.072, 0.069, 0.106, 0.129, 0.107, 0.112, 0.11, 0.08, 0.083, 0.069, 0.1, 0.111, 0.079, 0.103, 0.272, 0.079, 0.114, 0.083, 0.103, 0.119, 0.088, 0.113, 0.068, 0.135, 0.144, 0.146, 0.074, 0.102, 0.067, 0.065, 0.164, 0.08, 0.08, 0.11, 0.066, 0.19, 0.076, 0.076, 0.093, 0.065, 0.077, 0.09, 0.074, 0.067, 0.093, 0.096, 0.098, 0.074, 0.106, 0.085, 0.106, 0.085, 0.076, 0.108, 0.117, 0.14, 0.085, 0.084, 0.127, 0.07, 0.071, 0.078, 0.096, 0.101, 0.108, 0.07, 0.261, 0.074, 0.076, 0.066, 0.587, 0.148, 0.086, 0.14, 0.128, 0.07, 0.075, 0.086, 0.094, 0.087, 0.284, 0.088, 0.101, 0.088, 0.098, 0.093, 0.098, 0.092, 0.08, 0.079, 0.093, 0.088, 0.102, 0.08, 0.07, 0.082, 0.079, 0.126, 0.066, 0.076, 0.07, 0.168, 0.076, 0.097, 0.091, 0.077, 0.069, 0.1, 0.083, 0.078, 0.081, 0.091, 0.06, 0.077, 0.104, 0.096, 0.088, 0.091, 0.085, 0.103, 0.073, 0.064, 0.074, 0.076, 0.111, 0.078, 0.216, 0.076, 0.109, 0.228, 0.075, 0.131, 0.129, 0.226, 0.09, 0.072, 0.09, 0.065, 0.085, 0.065, 0.07, 0.081, 0.087, 0.076, 0.107, 0.068, 0.077, 0.075, 0.138, 0.082, 0.08, 0.101, 0.203, 0.087, 0.086, 0.066, 0.069, 0.073, 0.126, 0.08, 0.153, 0.09, 0.083, 0.086, 0.077, 0.075, 0.09, 0.133, 0.067, 0.119, 0.134, 0.089, 0.075, 0.128, 0.086, 0.081, 0.084, 0.069, 0.106, 0.067, 0.061, 0.16, 0.066, 0.093, 0.082, 0.076, 0.168, 0.087, 0.084, 0.1, 0.074, 0.131, 0.074, 0.077, 0.096, 0.09, 0.098, 0.166, 0.082, 0.081, 0.124, 0.25, 0.095, 0.07, 0.064, 0.065, 0.128, 0.084, 0.083, 0.079, 0.105, 0.07, 0.065, 0.121, 0.104, 0.079, 0.149, 0.096, 0.093, 0.091, 0.094, 0.099, 0.068, 0.066, 0.09, 0.083, 0.07, 0.083, 0.103, 0.091, 0.681, 0.079, 0.073, 0.1, 0.069, 0.101, 0.074, 0.089, 0.091, 0.075, 0.11, 0.07, 0.1, 0.082, 0.086, 0.092, 0.086, 0.111, 0.072, 0.132, 0.109, 0.075, 0.093, 0.093, 0.076, 0.093, 0.076, 0.074, 0.1, 0.084, 0.076, 0.156, 0.087, 0.414, 0.078, 0.105, 0.094, 0.066, 0.071, 0.099, 0.105, 0.083, 0.071, 0.128, 0.065, 0.18, 0.16, 0.082, 0.078, 0.066, 0.066, 0.076, 0.067, 0.103, 0.087, 0.079, 0.075, 0.091, 0.105, 0.074, 0.095, 0.098, 0.082, 0.079, 0.069, 0.08, 0.062, 0.074, 0.1, 0.083, 0.078, 0.068, 0.095, 0.075, 0.105, 0.131, 0.099, 0.074, 0.073, 0.062, 0.063, 0.104, 0.08, 0.1, 0.089, 0.075, 0.102, 0.107, 0.093, 0.067, 0.085, 0.063, 0.118, 0.112, 0.068, 0.085, 0.088, 0.065, 0.073, 0.067, 0.064, 0.067, 0.081, 0.271, 0.118, 0.099, 0.077, 0.117, 0.091, 0.07, 0.061, 0.068, 0.073, 0.07, 0.09, 0.096, 0.105, 0.106, 0.09, 0.078, 0.074, 0.083, 0.124, 0.075, 0.093, 0.068, 0.105, 0.076, 0.071, 0.076, 0.066, 0.276, 0.088, 0.065, 0.074, 0.082, 0.063, 0.104, 0.095, 0.091, 0.086, 0.078, 0.059, 0.084, 0.074, 0.069, 0.069, 0.087, 0.096, 0.074, 0.094, 0.066, 0.07, 0.09, 0.097, 0.087, 0.065, 0.09, 0.067, 0.098, 0.078, 0.087, 0.064, 0.096, 0.105, 0.071, 0.078, 0.096, 0.126, 0.089, 0.116, 0.099, 0.084, 0.069, 0.071, 0.096, 0.06, 0.071, 0.082, 0.126, 0.081, 0.074, 0.096, 0.085, 0.073, 0.148, 0.081, 0.074, 0.079, 0.073, 0.091, 0.089, 0.095, 0.089, 0.069, 0.075, 0.093, 0.082, 0.084, 0.071, 0.072, 0.171, 0.069, 0.103, 0.101, 0.088, 0.126, 0.1, 0.087, 0.083, 0.063, 0.093, 0.094, 0.069, 0.093, 0.074, 0.062, 0.096, 0.094, 0.102, 0.132, 0.073, 0.071, 0.06, 0.065, 0.121, 0.105, 0.084, 0.062, 0.094, 0.109, 0.066, 0.117, 0.085, 0.083, 0.07, 0.072, 0.069, 0.083, 0.104, 0.068, 0.077, 0.08, 0.084, 0.073, 0.076, 0.065, 0.102, 0.069, 0.105, 0.119, 0.152, 0.082, 0.081, 0.078, 0.088, 0.069, 0.086, 0.075, 0.067, 0.094, 0.082, 0.073, 0.086, 0.188, 0.08, 0.072, 0.079, 0.09, 0.088, 0.066, 1.078, 0.082, 0.104, 0.142, 0.12, 0.13, 0.104, 0.082, 0.125, 0.094, 0.114, 0.073, 0.088, 0.071, 0.097, 0.079, 0.07, 0.066, 0.293, 0.086, 0.116, 0.122, 0.085, 0.08, 0.156, 0.109, 0.075, 0.104, 0.102, 0.141, 0.075, 0.087, 0.068, 0.119, 0.083, 0.076, 0.098, 0.113, 0.09, 0.207, 0.112, 0.07, 0.089, 0.077, 0.084, 0.092, 0.077], [0.074, 0.081, 0.082, 0.094, 0.074, 0.078, 0.133, 0.084, 0.097, 0.207, 0.085, 0.09, 0.078, 0.135, 0.081, 0.357, 0.089, 0.238, 0.102, 0.068, 0.124, 0.091, 0.083, 0.063, 0.084, 0.087, 0.073, 0.075, 0.07, 0.084, 0.125, 0.068, 0.066, 0.077, 0.087, 0.066, 0.068, 0.096, 0.094, 0.208, 0.115, 0.126, 0.096, 0.125, 0.095, 0.074, 0.109, 0.058, 0.061, 0.072, 0.06, 0.063, 0.058, 0.077, 0.068, 0.08, 0.078, 0.116, 0.126, 0.089, 0.082, 0.108, 0.128, 0.127, 0.105, 0.109, 0.07, 0.139, 0.09, 0.131, 0.143, 0.144, 0.076, 0.084, 0.097, 0.144, 0.094, 0.136, 0.081, 0.083, 0.084, 0.111, 0.092, 0.083, 0.099, 0.11, 0.074, 0.092, 0.073, 0.074, 0.095, 0.083, 0.078, 0.084, 0.074, 0.092, 0.121, 0.077, 0.115, 0.078, 0.103, 0.135, 0.101, 0.099, 0.084, 0.08, 0.107, 0.093, 0.11, 0.082, 0.137, 0.08, 0.094, 0.069, 0.114, 0.09, 0.083, 0.083, 0.12, 0.163, 0.097, 0.132, 0.096, 0.076, 0.059, 0.069, 0.095, 0.092, 0.108, 0.086, 0.083, 0.146, 0.085, 0.11, 0.082, 0.081, 0.15, 0.145, 0.08, 0.09, 0.105, 0.086, 0.072, 0.058, 0.091, 0.074, 0.105, 0.134, 0.11, 0.086, 0.105, 0.134, 0.111, 0.077, 2.943, 0.084, 0.093, 0.085, 0.086, 0.085, 0.082, 0.074, 0.091, 0.103, 0.067, 0.089, 0.084, 0.078, 0.072, 0.298, 0.08, 0.064, 0.07, 0.068, 0.081, 0.089, 0.06, 0.063, 0.075, 0.143, 0.086, 0.077, 0.081, 0.09, 0.133, 0.138, 0.089, 0.287, 0.098, 0.085, 0.137, 0.095, 0.078, 0.084, 0.102, 0.096, 0.07, 0.213, 0.174, 0.068, 0.121, 0.129, 0.1, 0.088, 0.134, 0.108, 0.086, 0.097, 0.082, 0.084, 0.075, 0.085, 0.08, 0.073, 0.117, 0.085, 0.063, 0.071, 0.069, 0.101, 0.071, 0.106, 0.091, 0.093, 0.077, 0.121, 0.082, 0.107, 0.08, 0.079, 0.074, 0.144, 0.088, 0.072, 0.134, 0.104, 0.113, 0.086, 0.13, 0.13, 0.207, 0.095, 0.074, 0.081, 0.1, 0.099, 0.108, 0.092, 0.074, 0.071, 0.086, 0.088, 0.088, 0.082, 0.092, 0.093, 0.136, 0.109, 0.075, 0.103, 0.077, 0.087, 0.08, 0.102, 0.065, 0.086, 0.096, 0.087, 0.086, 0.088, 0.1, 0.071, 0.101, 0.102, 0.102, 0.084, 0.075, 0.088, 0.661, 0.116, 0.091, 0.121, 0.081, 0.136, 0.112, 0.084, 0.077, 0.1, 0.092, 0.13, 0.087, 0.09, 0.094, 0.075, 0.123, 0.091, 0.089, 0.082, 0.077, 0.083, 0.079, 0.065, 0.118, 0.079, 1.189, 0.094, 0.07, 0.067, 0.071, 0.075, 0.085, 0.088, 0.078, 0.094, 0.074, 0.08, 0.064, 0.068, 0.067, 0.078, 0.077, 0.068, 0.121, 0.069, 0.088, 0.082, 0.088, 0.13, 0.098, 0.08, 0.142, 0.12, 0.07, 0.153, 0.078, 0.15, 0.075, 0.076, 0.081, 0.103, 0.079, 0.072, 0.154, 0.111, 0.089, 0.157, 0.115, 0.104, 0.11, 0.171, 0.104, 0.118, 0.088, 0.095, 0.095, 0.084, 0.103, 0.069, 0.073, 0.116, 0.075, 0.066, 0.085, 0.082, 0.112, 0.108, 0.121, 0.089, 0.165, 0.091, 0.103, 0.064, 0.073, 0.074, 0.06, 0.173, 0.082, 0.096, 0.221, 0.086, 0.073, 0.088, 0.09, 0.136, 0.097, 0.085, 0.122, 0.086, 0.08, 0.081, 0.09, 0.08, 0.095, 0.076, 0.113, 0.093, 0.073, 0.073, 0.064, 0.063, 0.072, 0.079, 0.069, 0.093, 0.074, 0.081, 0.105, 0.087, 0.097, 0.093, 0.072, 0.213, 0.079, 0.081, 0.104, 0.082, 0.104, 0.073, 0.071, 0.075, 0.09, 0.096, 0.069, 0.105, 0.074, 0.062, 0.096, 0.084, 0.081, 0.127, 0.105, 0.084, 0.075, 0.2, 0.106, 0.201, 0.101, 0.061, 0.08, 0.084, 0.081, 0.081, 0.076, 0.095, 0.085, 0.099, 0.086, 0.09, 0.093, 0.08, 0.104, 0.089, 0.134, 0.089, 0.087, 0.102, 0.089, 0.089, 0.092, 0.11, 0.094, 0.091, 0.114, 0.093, 0.09, 0.111, 0.213, 0.095, 0.067, 0.078, 0.098, 0.077, 0.087, 0.104, 0.092, 0.084, 0.086, 0.072, 0.085, 0.084, 0.106, 0.077, 0.104, 0.123, 0.093, 0.081, 0.085, 0.085, 0.097, 0.102, 0.071, 0.071, 0.08, 0.068, 0.086, 0.12, 0.144, 0.08, 0.067, 0.075, 0.107, 0.085, 0.079, 0.082, 0.067, 0.073, 0.201, 0.077, 0.071, 0.086, 0.074, 0.387, 0.082, 0.124, 0.109, 0.084, 0.294, 0.403, 0.073, 0.084, 0.075, 0.067, 0.074, 0.084, 0.13, 0.112, 0.076, 0.115, 0.083, 0.072, 0.072, 0.098, 0.067, 0.106, 0.104, 0.082, 0.105, 0.165, 0.087, 0.078, 0.114, 0.132, 0.067, 0.067, 0.069, 0.057, 0.084, 0.074, 0.102, 0.09, 0.087, 0.151, 0.096, 0.089, 0.071, 0.078, 0.077, 0.093, 0.086, 0.081, 0.079, 0.128, 0.088, 0.069, 0.077, 0.073, 0.081, 0.084, 0.083, 0.147, 0.081, 0.078, 0.093, 0.078, 0.077, 0.081, 0.089, 0.087, 0.086, 0.083, 0.064, 0.069, 0.062, 0.09, 0.078, 0.099, 0.114, 0.108, 0.076, 0.084, 0.082, 0.076, 0.062, 0.063, 0.069, 0.08, 0.093, 0.091, 0.1, 0.091, 0.074, 0.081, 0.084, 0.138, 0.09, 0.093, 0.073, 0.079, 0.086, 0.092, 0.094, 0.096, 0.101, 0.074, 0.086, 0.073, 0.081, 0.069, 0.079, 0.113, 0.128, 0.072, 0.098, 0.093, 0.078, 0.065, 0.079, 0.082, 0.1, 0.084, 0.077, 0.073, 0.106, 0.09, 0.09, 0.112, 0.08, 0.083, 0.09, 0.097, 0.075, 0.077, 0.085, 0.083, 0.077, 0.073, 0.083, 0.094, 0.079, 0.077, 0.094, 0.134, 0.068, 0.069, 0.066, 0.091, 0.084, 0.095, 0.086, 0.068, 0.072, 0.071, 0.07, 0.071, 0.061, 0.089, 0.124, 0.117, 0.093, 0.063, 0.103, 0.111, 0.095, 0.128, 0.101, 0.081, 0.079, 0.107, 0.086, 0.099, 0.079, 0.084, 0.071, 0.102, 0.073, 0.098, 0.095, 0.078, 0.068, 0.068, 0.084, 0.064, 0.072, 0.075, 0.082, 0.081, 0.063, 0.16, 0.079, 0.109, 0.08, 0.071, 0.085, 0.448, 0.086, 0.08, 0.098, 0.107, 0.095, 0.08, 0.09, 0.089, 0.098, 0.129, 0.09, 0.086, 0.12, 0.073, 0.275, 0.132, 0.083, 0.088, 0.139, 0.097, 0.095, 0.08, 0.07, 0.107, 0.1, 0.096, 0.101, 0.088, 0.072, 0.079, 0.066, 0.085, 0.082, 0.103, 0.078, 0.07, 0.09, 0.088, 0.085, 0.081, 0.088, 0.085, 0.075, 0.062, 0.125, 0.081, 0.093, 0.108, 0.08, 0.08, 0.069, 0.087, 0.066, 0.28, 0.079, 0.078, 0.264, 0.084, 0.071, 0.185, 0.084, 0.101, 0.06, 0.071, 0.111, 0.073, 0.274, 0.075, 0.076, 0.08, 0.062, 0.079, 0.082, 0.097, 0.081, 0.086, 0.1, 0.095, 0.079, 0.104, 0.076, 0.076, 0.13, 0.084, 0.093, 0.092, 0.101, 0.204, 0.086, 0.079, 0.061, 0.123, 0.092, 0.101, 0.096, 0.098, 0.094, 0.095, 0.084, 0.093, 0.147, 0.094, 0.098, 0.066, 0.111, 0.131, 0.086, 0.098, 0.103, 0.133, 0.093, 0.098, 0.116, 1.033, 0.078, 0.079, 0.135, 0.15, 0.081, 0.086, 0.089, 0.169, 0.102, 0.086, 0.097, 0.102, 0.172, 0.161, 0.061, 0.065, 0.083, 0.079, 0.081, 0.062, 0.102, 0.162, 0.088, 0.064, 0.107, 0.115, 0.084, 0.127, 0.096, 0.238, 1.517, 0.072, 0.083, 0.093, 0.065, 0.085, 0.083, 0.077, 0.106, 0.093, 0.82, 0.139, 0.087, 0.107, 0.093, 0.111, 0.121, 0.124, 0.104, 0.092, 0.083, 0.088, 0.128, 0.085, 0.077, 0.087, 0.094, 0.076, 0.301, 0.073, 0.07, 0.072, 0.113, 0.088, 0.075, 0.083, 0.075, 0.078, 0.085, 0.084, 0.082, 0.154, 0.112, 0.085, 0.095, 0.081, 0.088, 0.154, 0.098, 0.083, 0.095, 0.09, 0.072, 0.083, 0.101, 0.068, 0.071, 0.077, 0.081, 0.072, 0.096, 0.086, 0.107, 0.073, 0.095, 0.092, 0.086, 0.086, 0.075, 0.069, 0.088, 0.13, 0.122, 0.085, 0.077, 0.067, 0.084, 0.08, 0.067, 0.082, 0.076, 0.112, 0.337, 0.137, 0.075, 0.085, 0.079, 0.093, 0.75, 0.114, 0.084, 0.083, 0.084, 0.121, 0.11, 0.09, 0.074, 0.089, 0.102, 0.197, 0.112, 0.091, 0.09, 0.068, 0.073, 0.076, 0.086, 0.124, 0.093, 0.095, 0.076, 0.087, 0.086, 0.098, 0.089, 0.081, 0.104, 0.073, 0.078, 0.228, 0.087, 0.185, 0.087, 0.081, 0.095, 0.088, 0.104, 0.093, 0.111, 0.098, 0.078, 0.101, 0.094, 0.125, 0.085, 0.122, 0.095, 0.242, 0.075, 0.09, 0.08, 0.087, 0.097, 0.096, 0.103, 0.098, 0.124, 0.085, 0.068, 0.085, 0.095, 0.136], [0.06, 0.068, 0.123, 0.084, 0.167, 0.097, 0.089, 0.073, 0.1, 0.109, 0.09, 0.089, 0.075, 0.104, 0.121, 0.089, 0.104, 0.085, 0.096, 0.085, 0.082, 0.09, 0.089, 0.102, 0.098, 0.091, 0.093, 0.096, 0.083, 0.066, 0.108, 0.079, 0.111, 0.094, 0.079, 0.083, 0.084, 0.088, 0.102, 0.12, 0.078, 0.109, 0.088, 0.182, 0.083, 0.088, 0.077, 0.072, 0.11, 0.071, 0.081, 0.074, 0.093, 0.104, 0.109, 0.068, 0.065, 0.063, 0.078, 0.245, 0.071, 0.075, 0.088, 0.082, 0.092, 0.082, 0.087, 0.088, 0.124, 0.118, 0.239, 0.084, 0.13, 0.125, 0.061, 0.103, 0.089, 0.115, 0.083, 0.082, 0.098, 0.114, 0.073, 0.077, 0.08, 0.079, 0.097, 0.08, 0.117, 0.113, 0.094, 0.071, 0.089, 0.071, 0.072, 0.069, 0.117, 0.133, 0.085, 0.076, 0.085, 0.076, 0.101, 0.082, 0.09, 0.089, 0.066, 0.086, 0.123, 0.073, 0.077, 0.072, 0.083, 0.093, 0.085, 0.076, 0.072, 0.088, 0.075, 0.066, 0.079, 0.077, 0.095, 0.074, 0.228, 0.082, 0.116, 0.078, 0.19, 0.069, 0.081, 0.083, 0.106, 0.082, 0.1, 0.152, 0.105, 0.216, 0.082, 0.072, 0.09, 0.092, 0.085, 0.062, 0.073, 0.124, 0.096, 0.093, 0.097, 0.076, 0.102, 0.134, 0.073, 0.109, 0.084, 0.079, 0.082, 0.098, 0.113, 0.097, 0.139, 0.086, 0.088, 0.082, 0.115, 0.089, 0.108, 0.083, 0.098, 0.077, 0.085, 0.075, 0.101, 0.134, 0.09, 0.079, 0.086, 0.111, 0.102, 0.087, 0.116, 0.129, 0.115, 0.091, 0.074, 0.091, 0.135, 0.097, 0.117, 0.128, 0.16, 0.119, 0.093, 0.141, 0.144, 0.123, 0.12, 0.122, 0.099, 0.077, 0.081, 0.084]
    #         ]
    #     ],
    #     [#dims
    #         [
    #             [0.206, 0.139, 0.151, 0.253, 0.213, 0.239, 0.23, 0.242, 0.135, 0.212, 0.154, 0.161, 0.174, 0.582, 0.142, 0.158, 0.175, 0.173, 0.161, 0.188, 0.156, 0.19, 0.176, 0.181, 0.178, 0.142, 0.207, 0.165, 0.189, 0.12, 0.247, 0.238, 0.176, 0.122, 0.281, 0.201, 0.164, 0.225, 0.148, 0.143, 0.131, 0.179, 0.137, 0.412, 0.149, 0.216, 0.185, 0.175, 0.222, 0.225, 0.152, 0.115, 0.235, 0.146, 0.165, 0.287, 0.195, 0.131, 0.137, 0.114, 0.198, 0.185, 0.236, 0.171, 0.367, 0.133, 0.157, 0.14, 0.184, 0.12, 0.156, 0.142, 0.125, 0.191, 0.17, 0.142, 0.145, 0.172, 0.149, 0.124, 0.126, 0.111, 0.251, 0.133, 0.164, 0.229, 0.186, 0.16, 0.222, 0.135, 0.129, 0.172, 0.173, 0.198, 0.149, 0.15, 0.162, 0.157, 0.23, 0.264, 0.225, 0.188, 0.226, 0.196, 0.16, 0.152, 0.148, 0.184, 0.162, 0.214, 0.164, 0.202, 0.236, 0.147, 0.199, 0.223, 0.17, 0.713, 0.148, 0.19, 0.137, 0.152, 0.189, 0.217, 0.155, 0.215, 0.193, 0.195, 0.144, 0.136, 2.191, 0.122, 0.206, 0.219, 0.136, 0.214, 0.134, 0.149, 0.186, 0.157, 0.189, 0.163, 0.18, 0.136, 0.276, 0.153, 0.112, 0.127, 0.179, 0.227, 0.147, 0.217, 0.249, 0.151, 0.252, 0.227, 0.177, 0.226, 0.184, 0.18, 0.211, 0.174, 0.261, 0.171, 0.208, 0.128, 0.151, 0.158, 0.157, 0.31, 0.193, 0.191, 0.16, 0.216, 0.229, 0.165, 0.241, 0.149, 0.146, 1.297, 0.176, 0.18, 0.139, 0.206, 0.132, 0.165, 0.148, 0.211, 0.141, 0.14, 0.171, 0.13, 0.305, 0.144, 0.163, 0.179, 0.15, 0.135, 0.139, 0.124, 0.105, 0.117, 0.155, 0.142, 0.158, 0.193, 0.202, 0.179, 0.139, 0.138, 0.216, 0.134, 0.157, 0.119, 0.127, 0.181, 0.115, 0.14, 0.154, 0.188, 0.137, 0.136, 0.128, 0.132, 0.206, 0.1, 0.188, 0.144, 0.141, 0.423, 0.23, 0.136, 0.207, 0.143, 0.202, 0.197, 0.135, 0.138, 0.271, 0.179, 0.182, 0.163, 0.245, 0.164, 0.162, 0.241, 0.165, 0.211, 0.146, 0.122, 0.164, 0.182, 0.174, 0.186, 0.15, 0.224, 0.141, 0.192, 0.115, 0.16, 0.206, 0.2, 0.177, 0.312, 0.249, 0.159, 0.133, 0.164, 0.166, 0.546, 0.145, 0.185, 0.152, 0.201, 0.234, 0.173, 0.112, 0.126, 0.238, 0.186, 0.185, 0.224, 0.154, 0.166, 0.161, 0.162, 0.227, 0.244, 0.159, 0.24, 0.214, 0.119, 0.119, 0.183, 0.162, 0.193, 0.151, 0.24, 0.088, 0.16, 0.494, 0.216, 0.144, 0.171, 0.156, 0.16, 0.129, 0.149, 0.167, 0.201, 0.204, 0.195, 0.199, 0.184, 0.172, 0.165, 0.223, 0.343, 0.168, 0.224, 0.172, 0.141, 0.169, 0.168, 0.155, 0.241, 0.207, 0.138, 0.194, 0.185, 0.125, 0.131, 0.113, 0.158, 0.119, 0.137, 0.166, 0.175, 0.166, 0.192, 0.14, 0.194, 0.223, 0.153, 0.152, 0.145, 0.222, 0.176, 0.233, 0.211, 0.149, 0.239, 0.144, 0.133, 0.173, 0.312, 0.22, 0.144, 0.186, 0.995, 0.145, 0.193, 0.146, 0.16, 0.16, 0.173, 0.167, 0.218, 0.185, 0.189, 0.239, 0.145, 0.147, 0.106, 0.295, 0.163, 0.155, 0.13, 0.148, 0.117, 0.137, 1.485, 0.145, 0.1, 0.167, 0.157, 0.213, 0.146, 0.12, 0.159, 0.197, 0.2, 0.225, 0.114, 0.25, 0.268, 0.169, 0.18, 0.215, 0.182, 0.217, 0.176, 0.142, 0.193, 0.193, 0.185, 0.219, 0.181, 0.129, 0.153, 0.155, 0.173, 0.155, 0.131, 0.168, 0.205, 0.166, 0.157, 0.366, 0.118, 0.345, 0.271, 0.228, 0.209, 0.148, 0.253, 0.167, 0.171, 0.12, 0.121, 0.157, 0.157, 0.192, 0.217, 0.132, 0.189, 0.167, 0.15, 0.194, 0.212, 0.169, 0.224, 0.194, 0.207, 0.178, 0.144, 0.194, 0.181, 0.195, 0.177, 0.15, 0.135, 0.106, 0.109, 0.137, 0.107, 0.159, 0.129, 0.146, 0.124, 0.119, 0.159, 0.201, 0.196, 0.165, 0.194, 0.199, 0.184, 0.173, 0.167, 0.155, 0.145, 0.157, 0.238, 0.266, 0.252, 0.144, 0.138, 0.18, 0.13, 0.117, 1.034, 0.201, 0.178, 0.151, 0.17, 0.19, 0.178, 0.188, 0.163, 0.135, 0.216, 0.219, 0.361, 0.137, 0.138, 0.14, 0.173, 0.154, 0.226], [0.189, 0.158, 0.178, 0.179, 0.175, 0.194, 0.208, 0.206, 0.156, 0.135, 0.156, 0.159, 0.167, 0.161, 0.213, 0.279, 0.162, 0.188, 0.214, 0.161, 0.138, 0.223, 0.138, 0.161, 0.162, 0.113, 0.353, 0.214, 0.401, 0.16, 0.591, 0.366, 0.159, 0.171, 0.19, 0.155, 0.174, 0.222, 0.148, 0.167, 0.259, 0.143, 0.193, 0.183, 0.193, 0.167, 0.14, 0.17, 0.162, 0.182, 0.18, 0.199, 0.154, 0.179, 0.19, 0.154, 0.16, 0.129, 0.17, 0.182, 0.166, 0.167, 0.175, 0.188, 0.136, 0.141, 0.224, 0.205, 0.09, 0.202, 0.237, 0.173, 0.145, 0.181, 0.161, 0.158, 0.18, 0.228, 0.236, 0.242, 0.594, 0.194, 0.147, 0.187, 0.234, 0.144, 0.224, 0.234, 0.163, 0.186, 0.154, 0.159, 1.267, 0.126, 0.161, 0.175, 0.22, 0.188, 0.222, 0.165, 0.113, 0.147, 0.155, 0.174, 0.194, 0.174, 0.169, 0.156, 0.149, 0.143, 0.181, 0.199, 0.196, 0.149, 0.228, 0.206, 0.219, 0.175, 0.182, 0.203, 0.181, 0.198, 0.233, 0.241, 0.227, 0.166, 0.145, 0.119, 0.109, 0.107, 0.182, 0.217, 0.254, 0.216, 0.177, 0.135, 0.162, 0.127, 0.162, 0.158, 0.183, 0.205, 0.235, 0.183, 0.201, 0.16, 0.139, 0.155, 0.148, 0.185, 0.158, 0.14, 0.151, 0.231, 0.175, 0.301, 0.145, 0.225, 0.203, 0.171, 0.141, 0.17, 0.217, 0.153, 0.318, 0.131, 0.183, 0.189, 0.202, 0.229, 0.183, 0.268, 0.12, 0.091, 0.137, 0.139, 0.177, 0.208, 0.199, 0.112, 0.094, 0.096, 0.114, 0.191, 0.243, 0.148, 0.145, 0.143, 0.149, 0.189, 0.166, 0.191, 0.168, 0.162, 0.147, 0.162, 0.989, 0.098, 0.109, 0.142, 0.144, 0.157, 0.166, 0.292, 0.129, 0.168, 0.19, 0.19, 0.204, 0.159, 0.161, 0.16, 0.187, 0.169, 0.16, 0.188, 0.196, 0.189, 0.19, 0.16, 0.151, 0.202, 0.176, 0.244, 0.165, 0.128, 0.13, 0.195, 0.146, 0.202, 0.15, 0.147, 0.17, 0.157, 0.421, 0.191, 0.188, 0.135, 1.005, 0.186, 0.183, 0.221, 0.173, 0.149, 0.179, 0.156, 0.136, 0.274, 0.151, 0.158, 0.134, 0.138, 0.143, 0.119, 0.14, 0.176, 0.169, 0.139, 0.153, 0.216, 0.146, 0.18, 0.166, 0.226, 0.171, 0.161, 0.195, 1.174, 0.148, 0.182, 0.189, 0.203, 0.223, 0.187, 0.154, 0.119, 0.174, 0.144, 0.131, 0.18, 0.192, 0.137, 0.307, 0.113, 0.171, 0.168, 0.157, 0.174, 0.194, 0.145, 0.145, 0.13, 0.168, 0.174, 0.205, 0.281, 0.172, 0.147, 0.151, 0.153, 0.177, 0.196, 0.141, 0.134, 0.115, 0.13, 0.106, 0.164, 0.109, 0.177, 0.129, 0.172, 0.135, 0.196, 0.157, 0.183, 0.175, 0.165, 0.18, 0.173, 0.159, 0.132, 0.194, 0.14, 0.119, 0.184, 0.161, 0.105, 0.159, 0.117, 0.148, 0.18, 0.176, 0.458, 0.213, 0.168, 0.214, 0.204, 0.308, 0.209, 0.162, 0.169, 0.197, 0.19, 0.127, 0.203, 0.145, 0.201, 0.156, 0.169, 0.13, 0.166, 0.183, 0.172, 0.151, 0.186, 0.173, 0.182, 0.24, 0.198, 0.177, 0.209, 0.219, 0.176, 0.215, 0.282, 0.155, 0.116, 0.124, 0.148, 0.125, 0.126, 0.127, 0.16, 0.144, 0.784, 0.141, 0.234, 0.184, 0.192, 0.282, 0.213, 0.167, 0.163, 0.197, 0.191, 0.157, 0.142, 0.245, 0.116, 0.136, 0.146, 0.135, 0.188, 0.183, 0.198, 0.165, 0.15, 0.199, 0.23, 0.179, 0.182, 0.191, 0.203, 0.321, 0.119, 0.145, 0.138, 0.192, 0.182, 0.174, 0.158, 0.21, 0.141, 0.192, 0.204, 0.254, 0.198, 0.142, 0.197, 0.188, 0.219, 0.198, 0.208, 0.206, 0.319, 0.193, 0.158, 0.135, 0.114, 0.155, 0.14, 0.138, 0.132, 0.179, 0.165, 0.194, 0.157, 0.115, 0.119, 0.142, 0.13, 0.179, 0.126, 0.154, 0.121, 0.171, 0.145, 0.245, 0.215, 0.16, 0.17, 0.137, 0.155, 0.131, 0.148, 0.16, 0.143, 0.15, 0.134, 0.198, 0.225, 0.136, 0.299, 0.187, 0.147, 0.179, 0.325, 0.212, 0.219, 0.185, 0.199, 0.155, 0.184, 0.17, 0.203, 0.213, 0.187, 2.187, 0.142, 0.111, 0.116, 0.207, 0.174, 0.361, 0.16, 0.297, 0.276, 0.183, 0.133, 0.166, 0.195, 0.21, 0.114, 0.144, 0.127, 0.109, 0.194, 0.154, 0.152], [0.158, 0.121, 0.663, 0.229, 0.188, 0.155, 0.178, 0.211, 0.234, 0.152, 0.207, 0.157, 0.157, 0.224, 0.154, 0.151, 0.206, 0.298, 0.211, 0.212, 0.147, 0.166, 0.168, 0.224, 0.209, 0.249, 0.126, 0.159, 0.183, 0.221, 0.185, 0.161, 0.131, 0.18, 0.167, 0.126, 0.142, 0.158, 0.186, 0.098, 0.155, 0.166, 0.193, 0.21, 0.224, 0.233, 0.22, 0.217, 1.579, 0.153, 0.221, 0.281, 0.158, 0.172, 0.217, 0.174, 0.138, 0.23, 0.139, 0.151, 0.217, 0.151, 0.156, 0.176, 0.162, 0.181, 0.199, 0.27, 0.183, 0.119, 0.236, 0.22, 0.193, 0.141, 0.148, 0.144, 0.186, 0.188, 0.165, 0.157, 0.18, 0.209, 0.254, 0.236, 0.196, 0.34, 0.142, 0.228, 0.215, 0.18, 0.11, 0.121, 0.135, 0.221, 0.334, 0.208, 0.167, 0.18, 0.141, 0.159, 0.145, 0.193, 0.143, 0.165, 0.19, 0.301, 0.142, 0.173, 0.159, 0.127, 0.114, 0.113, 0.127, 0.34, 0.123, 0.213, 0.216, 0.148, 0.152, 0.171, 0.192, 0.175, 0.175, 0.179, 0.155, 0.182, 0.206, 0.152, 1.042, 0.213, 0.112, 0.202, 0.132, 0.127, 0.107, 0.138, 0.193, 0.177, 0.194, 0.174, 0.124, 0.216, 0.223, 0.317, 0.134, 0.176, 0.14, 0.166, 0.189, 0.195, 0.18, 0.232, 0.184, 0.159, 0.203, 0.233, 0.187, 0.159, 0.237, 0.157, 0.194, 0.245, 0.146, 0.162, 0.156, 2.25, 0.212, 0.27, 0.228, 0.152, 0.21, 0.148, 0.141, 0.254, 0.246, 0.14, 0.18, 0.197, 0.135, 0.135, 0.181, 0.253, 0.126, 0.181, 0.208, 0.191, 1.29, 0.183, 0.214, 0.297, 0.231, 0.225, 0.32, 0.144, 0.152, 0.192, 0.137, 0.17, 0.159, 0.211, 0.227, 0.169, 0.161, 0.171, 0.235, 0.164, 0.146, 0.135, 0.195, 0.176, 0.594, 0.2, 0.207, 0.2, 0.212, 0.171, 0.15, 0.256, 0.262, 0.152, 0.19, 0.184, 0.123, 0.216, 0.144, 0.194, 0.208, 0.134, 0.237, 0.223, 0.166, 0.329, 0.146, 0.144, 0.163, 0.15, 0.138, 0.156, 0.158, 0.214, 0.196, 0.151, 0.177, 0.145, 0.206, 0.191, 0.201, 0.211, 0.153, 0.25, 0.194, 0.479, 0.177, 0.15, 0.16, 0.178, 0.305, 0.204, 0.143, 0.182, 0.131, 0.143, 0.232, 0.177, 0.205, 0.234, 0.124, 0.122, 0.137, 0.125, 0.126, 0.144, 0.124, 0.122, 0.162, 0.149, 0.211, 0.207, 0.182, 0.184, 0.165, 0.182, 0.18, 0.183, 0.189, 0.171, 0.172, 0.157, 0.148, 0.159, 0.244, 0.307, 0.213, 0.177, 0.148, 0.14, 0.15, 0.196, 0.156, 0.139, 0.158, 0.141, 0.139, 0.323, 0.143, 0.208, 0.183, 0.191, 0.237, 0.215, 0.23, 0.146, 0.165, 0.147, 0.16, 0.12, 0.175, 0.206, 0.499, 0.149, 0.15, 0.165, 0.203, 0.259, 0.144, 0.17, 0.21, 0.197, 0.223, 0.2, 0.192, 0.121, 0.114, 0.174, 0.134, 0.194, 0.21, 0.171, 0.19, 0.185, 0.206, 0.15, 0.168, 0.147, 0.568, 0.206, 0.235, 0.168, 0.141, 0.159, 0.179, 0.186, 0.224, 0.199, 0.209, 0.128, 0.172, 0.171, 0.188, 0.2, 0.183, 0.176, 0.245, 0.2, 0.189, 0.132, 0.207, 0.203, 0.139, 0.172, 0.164, 0.138, 0.128, 0.18, 0.158, 0.177, 0.16, 0.155, 0.17, 0.132, 0.133, 0.133, 0.157, 0.183, 0.182, 0.205, 0.192, 0.149, 0.188, 0.203, 0.137, 0.147, 0.191, 0.188, 0.171, 0.178, 0.189, 0.156, 0.185, 0.148, 0.134, 0.153, 0.191, 0.205, 1.022, 0.108, 0.15, 0.212, 0.517, 0.222, 0.173, 0.148, 0.159, 0.174, 0.144, 0.139, 0.188, 0.155, 0.185, 0.194, 0.177, 0.165, 0.155, 0.197, 0.216, 0.167, 0.251, 0.125, 0.191, 0.234, 0.129, 0.143, 0.188, 0.203, 0.113, 0.117, 0.162, 0.113, 0.153, 0.127, 0.209, 0.185, 0.262, 0.151, 0.135, 0.126, 0.178, 0.181, 0.161, 0.144, 0.135, 0.138, 0.221, 0.192, 0.202, 0.167, 0.131, 0.244, 0.159, 0.171, 0.173, 0.218, 0.236, 0.24, 0.183, 0.141, 0.336, 0.168, 0.165, 0.217, 0.205, 0.173, 0.185, 0.135, 0.296, 0.165, 0.169, 0.141, 0.139, 0.132, 0.18, 0.224, 0.132, 0.152, 0.163, 0.174, 0.428, 0.226, 0.157, 0.224, 0.157, 0.225, 0.188, 0.196, 0.133, 0.142, 0.146, 0.154, 0.188, 0.214], [0.125, 0.123, 0.137, 0.101, 0.096, 0.264, 0.147, 0.218, 0.182, 0.137, 0.178, 0.177, 0.139, 0.231, 0.214, 0.215, 0.163, 0.204, 0.224, 0.233, 0.142, 0.208, 0.324, 0.113, 0.182, 0.125, 0.193, 0.109, 0.197, 0.129, 0.18, 0.166, 0.199, 0.132, 0.155, 0.209, 0.191, 0.247, 0.233, 0.096, 0.101, 0.1, 0.117, 0.171, 0.507, 0.146, 0.127, 0.148, 0.162, 0.175, 0.118, 0.184, 0.221, 0.209, 0.186, 0.172, 0.195, 0.15, 0.179, 0.333, 0.139, 0.152, 0.202, 0.201, 0.188, 0.186, 0.17, 0.208, 0.192, 0.127, 1.054, 0.217, 0.337, 0.152, 0.14, 0.119, 0.195, 0.186, 0.146, 0.207, 0.221, 0.332, 0.208, 0.191, 0.177, 0.129, 0.202, 0.147, 0.194, 0.247, 0.178, 0.211, 0.24, 0.227, 0.252, 0.123, 0.29, 0.26, 0.225, 0.224, 0.167, 0.251, 0.169, 0.223, 0.24, 0.16, 0.181, 0.15, 0.192, 0.236, 0.191, 0.19, 0.169, 0.171, 0.132, 0.109, 0.166, 0.367, 0.173, 0.13, 0.158, 0.163, 0.137, 0.184, 0.206, 0.174, 0.159, 0.172, 0.422, 0.169, 0.21, 0.192, 0.199, 0.12, 0.172, 0.164, 0.148, 0.19, 0.176, 0.197, 0.205, 0.168, 0.188, 0.168, 0.187, 0.128, 0.14, 0.149, 0.216, 0.181, 0.257, 0.182, 0.223, 0.132, 0.232, 0.143, 0.117, 0.16, 0.155, 0.146, 0.152, 0.165, 0.156, 0.146, 0.13, 0.158, 0.114, 0.121, 0.213, 0.183, 0.219, 0.159, 0.221, 0.142, 0.333, 0.138, 0.126, 0.184, 0.144, 0.209, 0.192, 2.172, 0.204, 0.159, 0.186, 0.151, 0.202, 0.163, 0.191, 0.213, 0.211, 0.3, 0.16, 0.22, 0.114, 0.176, 0.213, 0.135, 0.15, 0.994, 0.251, 1.184, 0.198, 0.13, 0.23, 0.222, 0.195, 0.202, 0.214, 0.207, 0.165, 0.163, 0.214, 0.179, 0.14, 0.129, 0.166, 0.18, 0.141, 0.18, 0.171, 0.205, 0.192, 0.16, 0.126, 0.137, 0.154, 0.204, 0.179, 0.18, 0.137, 0.208, 0.206, 0.426, 0.21, 0.201, 0.193, 0.238, 0.193, 0.2, 0.143, 0.238, 0.251, 0.254, 0.161, 0.15, 0.157, 0.108, 0.143, 0.147, 0.218, 0.22, 0.206, 0.181, 0.199, 0.231, 0.159, 0.193, 0.224, 0.317, 0.151, 0.833, 0.297, 0.239, 0.157, 0.223, 0.308, 0.147, 0.186, 0.215, 0.163, 0.177, 0.224, 0.146, 0.189, 0.116, 0.186, 0.12, 0.142, 0.12, 0.138, 0.157, 0.109, 0.181, 0.133, 0.179, 0.124, 0.154, 0.274, 0.252, 0.231, 0.193, 0.304, 0.209, 0.14, 0.182, 0.162, 0.169, 0.185, 0.155, 0.236, 0.203, 0.26, 0.141, 0.146, 0.182, 0.204, 0.157, 0.17, 0.164, 0.205, 0.163, 0.199, 0.121, 0.175, 0.147, 0.201, 0.169, 0.16, 0.194, 0.163, 0.204, 0.136, 0.182, 0.192, 0.147, 0.255, 0.16, 0.144, 0.2, 0.146, 0.189, 0.202, 0.218, 0.212, 0.2, 0.197, 0.161, 0.181, 0.169, 0.215, 0.631, 0.21, 0.21, 0.159, 0.174, 0.22, 0.175, 0.144, 0.186, 0.174, 0.202, 0.174, 0.176, 0.178, 0.164, 0.215, 0.43, 0.169, 0.19, 0.211, 0.152, 0.236, 0.251, 0.242, 0.151, 0.146, 0.222, 0.191, 0.156, 0.167, 0.186, 0.187, 0.173, 0.169, 0.255, 0.192, 0.264, 0.231, 0.164, 0.154, 0.207, 0.284, 0.217, 0.213, 0.167, 0.248, 0.216, 0.171, 0.213, 0.159, 0.134, 0.308, 0.235, 0.193, 0.201, 0.147, 0.161, 0.22, 0.176, 0.168, 0.161, 0.179, 0.176, 0.201, 0.2, 0.316, 0.169, 0.169, 0.201, 0.201, 0.173, 0.181, 0.154, 0.173, 0.185, 0.226, 0.199, 0.189, 0.18, 0.267, 0.239, 0.213, 0.215, 0.194, 0.216, 0.212, 0.199, 0.217, 0.168, 0.194, 0.157, 0.145, 0.217, 0.141, 0.165, 0.175, 0.151, 0.165, 0.157, 0.211, 0.219, 0.21, 0.164, 0.211, 0.155, 0.158, 0.133, 0.133, 0.184, 0.143, 0.19, 0.133, 0.218, 0.194, 0.163, 0.197, 0.203, 0.195, 0.191, 0.206, 0.187, 0.203, 0.213, 0.182, 0.233, 0.304, 0.16, 0.183, 0.168, 0.113, 0.22, 0.14, 0.215, 0.148, 0.138, 1.021, 0.207, 0.204, 0.169, 0.202, 0.192, 0.144, 0.21, 0.128, 0.329, 0.199, 0.176, 0.189, 0.179, 0.147, 0.206, 0.153, 0.171, 0.179, 0.198, 0.291, 0.175, 0.199, 0.224], [0.165, 0.121, 0.153, 0.162, 0.24, 0.149, 0.215, 0.344, 0.298, 0.224, 0.246, 0.158, 0.226, 0.14, 0.15, 0.206, 0.15, 0.192, 0.241, 0.275, 0.221, 0.217, 0.166, 0.168, 0.15, 0.154, 0.116, 0.118, 0.184, 0.213, 0.21, 0.235, 0.21, 0.199, 0.235, 0.238, 0.147, 0.207, 0.174, 0.123, 0.209, 0.131, 0.203, 0.204, 0.149, 0.193, 0.125, 0.156, 0.201, 0.192, 0.201, 0.19, 0.124, 0.164, 0.153, 0.203, 0.178, 0.179, 0.158, 0.18, 0.183, 0.126, 0.149, 0.207, 0.168, 0.206, 0.201, 0.146, 0.204, 0.115, 0.178, 0.173, 0.203, 0.218, 0.22, 0.217, 0.168, 2.235, 0.141, 0.116, 0.137, 0.156, 0.245, 0.196, 0.343, 0.14, 0.135, 0.171, 0.137, 0.209, 0.145, 0.144, 0.229, 0.307, 0.136, 0.167, 0.152, 0.213, 0.246, 0.258, 0.242, 0.194, 0.189, 0.158, 0.186, 0.158, 0.126, 0.21, 0.142, 0.181, 0.197, 0.121, 0.164, 0.146, 0.144, 0.174, 0.118, 0.193, 0.181, 0.187, 0.277, 0.141, 0.177, 0.19, 0.144, 0.14, 0.17, 0.158, 0.149, 0.147, 0.135, 0.188, 0.15, 0.197, 0.175, 0.171, 0.184, 0.144, 0.145, 0.809, 0.186, 0.165, 0.174, 0.14, 0.222, 0.172, 0.195, 0.228, 0.151, 0.134, 0.164, 0.2, 1.513, 0.148, 0.145, 0.144, 0.176, 0.161, 0.138, 0.157, 0.171, 0.193, 0.171, 0.227, 0.166, 0.166, 0.246, 0.2, 0.141, 0.203, 0.134, 0.193, 0.22, 0.223, 0.251, 0.158, 0.157, 0.141, 0.157, 0.194, 0.133, 0.133, 0.203, 0.19, 0.263, 0.194, 0.14, 0.201, 0.139, 0.267, 0.13, 0.143, 0.135, 0.138, 0.109, 0.133, 0.17, 0.146, 0.169, 0.14, 0.156, 0.173, 0.142, 0.183, 0.186, 0.302, 0.132, 0.152, 0.146, 0.098, 0.201, 0.189, 0.1, 0.17, 0.167, 0.155, 0.278, 0.217, 0.128, 0.128, 0.158, 0.222, 0.193, 0.217, 0.152, 0.184, 0.2, 0.172, 0.173, 0.198, 0.142, 0.23, 0.177, 0.255, 0.131, 0.192, 0.167, 0.206, 0.179, 0.164, 0.175, 0.193, 0.186, 0.192, 0.197, 0.138, 0.14, 0.221, 0.192, 0.164, 0.211, 0.182, 0.135, 0.215, 0.131, 0.534, 0.157, 0.182, 0.878, 0.165, 0.173, 0.149, 0.194, 0.219, 0.21, 0.184, 0.214, 0.192, 0.181, 0.179, 0.194, 0.161, 0.164, 0.165, 0.22, 0.223, 0.237, 0.137, 0.151, 0.197, 0.185, 0.153, 0.148, 0.168, 0.203, 0.138, 0.202, 0.132, 0.141, 0.156, 0.148, 0.194, 0.208, 0.156, 0.147, 0.171, 0.135, 0.133, 0.167, 0.205, 0.14, 0.164, 0.132, 0.123, 0.193, 0.158, 0.151, 0.117, 0.138, 0.178, 0.201, 0.224, 0.15, 0.164, 0.181, 0.201, 0.174, 0.211, 0.151, 0.17, 0.148, 0.18, 0.139, 0.161, 0.134, 0.187, 0.143, 0.19, 0.184, 0.196, 0.154, 0.137, 0.164, 0.173, 0.136, 0.16, 0.174, 0.158, 0.147, 0.193, 0.144, 0.17, 0.201, 0.208, 0.14, 0.142, 0.137, 0.22, 0.245, 0.176, 0.124, 0.452, 0.159, 0.197, 0.165, 0.154, 0.214, 0.184, 0.217, 0.347, 0.15, 0.172, 0.14, 0.167, 0.176, 0.162, 0.147, 0.151, 0.173, 0.134, 0.177, 0.145, 0.146, 0.138, 0.205, 0.155, 0.174, 0.175, 0.296, 0.181, 0.303, 0.227, 0.22, 0.149, 0.199, 0.46, 0.169, 0.165, 0.148, 0.138, 0.156, 0.187, 0.145, 0.163, 0.19, 0.284, 0.158, 0.217, 0.169, 0.187, 0.194, 0.165, 0.215, 0.2, 0.22, 0.153, 0.207, 0.182, 1.04, 0.159, 0.24, 0.242, 0.217, 0.222, 0.203, 0.307, 0.142, 0.149, 0.154, 0.218, 0.12, 0.195, 0.231, 0.282, 1.187, 0.186, 0.159, 0.141, 0.219, 0.827, 0.147, 0.154, 0.233, 0.154, 0.203, 0.208, 0.16, 0.161, 0.346, 0.161, 0.213, 0.179, 0.156, 0.165, 0.233, 0.2, 0.197, 0.229, 0.2, 0.158, 0.156, 0.182, 0.155, 0.151, 0.162, 0.194, 0.166, 0.13, 0.11, 0.187, 0.168, 0.121, 0.147, 0.137, 0.234, 0.373, 0.143, 0.186, 0.673, 0.21, 0.195, 0.195, 0.196, 0.296, 0.174, 0.163, 0.147, 0.165, 0.151, 0.143, 0.156, 0.175, 0.203, 0.339, 0.223, 0.196, 0.169, 0.17, 0.194, 0.171, 0.186, 0.193, 0.275, 0.197, 0.129, 0.234, 0.244, 0.221, 0.135, 0.227], [0.094, 0.123, 0.197, 0.097, 0.136, 0.092, 0.163, 0.173, 0.13, 0.101, 0.12, 0.134, 0.162, 0.129, 0.102, 0.157, 0.164, 0.099, 0.152, 0.143, 0.143, 0.207, 0.103, 0.134, 0.151, 0.13, 0.156, 0.142, 0.118, 0.27, 0.112, 0.11, 0.113, 0.117, 0.123, 0.256, 0.184, 0.158, 0.125, 0.114, 0.16, 0.128, 0.127, 0.135, 0.142, 0.132, 0.096, 0.125, 0.186, 0.123, 0.12, 0.187, 0.149, 0.127, 0.191, 0.142, 0.155, 0.13, 0.129, 0.155, 0.128, 0.166, 0.309, 0.173, 0.229, 0.115, 0.176, 0.207, 0.299, 0.141, 0.138, 0.124, 0.168, 0.169, 0.184, 0.197, 0.208, 0.116, 0.18, 0.183, 0.173, 0.127, 0.15, 0.139, 0.137, 0.122, 0.158, 0.121, 0.152, 0.136, 0.149, 0.193, 0.116, 0.18, 0.156, 0.19, 0.143, 0.14, 0.131, 0.157, 0.137, 2.169, 0.131, 0.181, 0.104, 0.125, 0.199, 0.213, 0.155, 0.171, 1.113, 0.181, 0.31, 0.167, 0.169, 0.222, 0.215, 0.16, 0.121, 0.109, 0.117, 0.194, 0.202, 0.521, 0.157, 0.11, 0.131, 0.152, 0.176, 0.146, 0.169, 0.164, 0.192, 0.161, 0.188, 0.132, 0.182, 0.152, 0.167, 0.145, 0.232, 0.169, 0.118, 0.281, 0.148, 0.156, 0.222, 0.144, 0.125, 0.166, 0.192, 0.15, 0.184, 0.147, 0.11, 0.139, 0.156, 0.128, 0.152, 0.106, 0.185, 0.176, 0.228, 0.19, 0.221, 0.111, 0.199, 0.128, 0.177, 0.193, 0.189, 0.167, 0.191, 0.119, 0.12, 0.201, 0.147, 0.729, 0.125, 0.122, 0.136, 0.14, 0.098, 0.145, 0.109, 0.166, 0.195, 0.168, 0.147, 0.189, 0.152, 0.143, 0.216, 0.208, 0.139, 0.244, 0.164, 0.166, 0.133, 0.194, 0.162, 0.204, 0.104, 0.22, 0.294, 0.172, 0.227, 0.135, 0.146, 0.224, 0.204, 0.162, 0.17, 0.172, 0.13, 0.1, 0.127, 0.286, 0.168, 0.184, 0.159, 0.186, 0.14, 0.118, 0.197, 0.113, 0.116, 0.166, 0.163, 0.227, 0.187, 0.19, 0.973, 0.129, 0.15, 0.188, 0.179, 0.186, 0.199, 0.212, 0.209, 0.161, 0.136, 0.214, 0.169, 0.157, 0.14, 0.23, 0.197, 0.14, 0.348, 0.615, 0.189, 0.172, 0.23, 0.192, 0.179, 0.196, 0.138, 1.168, 0.179, 0.17, 0.148, 0.149, 0.185, 0.182, 0.22, 0.183, 0.158, 0.134, 0.134, 0.148, 0.204, 0.11, 0.171, 0.169, 0.199, 0.288, 0.18, 0.175, 0.232, 0.184, 0.283, 0.213, 0.191, 0.157, 0.151, 0.125, 0.118, 0.109, 0.125, 0.115, 0.212, 0.139, 0.146, 0.147, 0.165, 0.164, 0.139, 0.125, 0.109, 0.108, 0.204, 0.178, 0.206, 0.149, 0.15, 0.199, 0.276, 0.178, 0.128, 0.147, 0.157, 0.232, 0.15, 0.146, 0.205, 0.202, 0.176, 0.109, 0.154, 0.105, 0.186, 0.115, 0.115, 0.144, 0.159, 0.157, 0.123, 0.169, 0.128, 0.143, 0.178, 0.159, 0.299, 0.174, 0.171, 0.145, 0.157, 0.114, 0.122, 0.19, 0.123, 0.148, 0.12, 0.185, 0.125, 0.134, 0.112, 0.178, 0.16, 0.136, 0.123, 0.141, 0.111, 0.172, 0.138, 0.165, 0.126, 0.148, 0.191, 0.188, 0.129, 0.208, 0.113, 0.14, 0.196, 0.126, 0.111, 0.181, 0.227, 0.164, 0.15, 0.372, 0.162, 0.17, 0.14, 0.119, 0.465, 0.152, 0.164, 0.172, 0.122, 0.175, 0.171, 0.161, 0.143, 0.106, 0.284, 0.175, 0.123, 0.195, 0.147, 0.109, 0.152, 0.195, 0.182, 0.16, 0.151, 0.126, 0.159, 0.128, 0.162, 0.152, 0.118, 0.143, 0.203, 0.217, 0.126, 0.123, 0.108, 0.109, 0.137, 0.149, 0.141, 0.162, 0.302, 0.165, 0.111, 0.201, 0.145, 0.181, 0.426, 0.12, 0.129, 0.146, 0.164, 0.287, 0.399, 0.164, 0.184, 0.995, 0.187, 0.12, 0.126, 0.112, 0.153, 0.318, 0.238, 0.197, 0.144, 0.161, 0.123, 0.166, 0.192, 0.224, 0.149, 0.149, 0.192, 0.145, 0.108, 0.108, 0.113, 0.126, 0.14, 0.134, 0.162, 0.138, 0.101, 0.115, 0.132, 0.179, 0.126, 0.139, 0.152, 0.153, 0.152, 0.174, 0.22, 0.121, 0.155, 0.094, 0.121, 0.103, 0.212, 0.087, 0.093, 0.13, 0.122, 0.179, 0.157, 0.162, 0.15, 0.157, 0.146, 0.141, 0.219, 0.187, 0.191, 0.183, 0.207, 0.119, 0.274, 0.214, 0.198, 0.181, 0.128, 0.335, 0.251, 0.208], [0.108, 0.144, 0.149, 0.155, 0.274, 0.124, 0.103, 0.146, 0.119, 0.201, 0.189, 0.224, 0.11, 0.162, 0.163, 0.2, 0.181, 0.204, 0.096, 0.096, 0.117, 0.236, 0.18, 0.152, 0.178, 0.166, 0.187, 0.248, 0.25, 0.165, 0.143, 0.148, 0.169, 0.113, 0.187, 1.001, 0.154, 0.214, 0.221, 0.216, 0.343, 0.111, 0.724, 0.148, 0.191, 0.133, 0.266, 0.147, 0.143, 0.105, 0.116, 0.126, 0.476, 0.2, 0.126, 0.165, 0.164, 0.19, 0.132, 0.163, 0.201, 0.123, 0.147, 0.107, 0.194, 0.182, 0.151, 0.154, 0.121, 0.156, 0.194, 0.137, 0.21, 0.193, 0.137, 0.156, 0.204, 0.197, 0.209, 0.155, 0.148, 0.141, 0.168, 0.131, 0.175, 0.204, 0.218, 0.241, 0.15, 0.21, 0.168, 0.214, 0.148, 0.209, 0.167, 0.172, 0.175, 0.134, 0.175, 0.161, 0.21, 0.192, 0.162, 0.183, 0.115, 0.19, 0.165, 0.128, 0.111, 0.089, 0.103, 0.09, 0.221, 0.19, 0.17, 0.111, 0.111, 0.135, 0.117, 0.144, 0.123, 0.139, 0.161, 0.121, 0.136, 0.121, 0.11, 0.139, 0.161, 0.153, 0.128, 0.15, 0.152, 0.117, 0.256, 0.787, 0.145, 0.172, 0.175, 2.362, 0.145, 0.115, 0.145, 0.156, 0.122, 0.145, 0.187, 0.318, 0.142, 0.125, 0.108, 0.141, 0.177, 0.201, 0.16, 0.171, 0.128, 0.115, 0.137, 0.115, 0.155, 0.153, 0.141, 0.204, 0.142, 0.206, 0.114, 0.156, 0.124, 0.102, 0.14, 0.173, 0.165, 0.19, 0.173, 0.18, 0.112, 0.137, 0.114, 0.337, 1.006, 0.179, 0.136, 0.211, 0.187, 0.175, 0.192, 0.284, 0.171, 0.211, 0.23, 0.268, 0.186, 0.201, 0.167, 0.199, 0.15, 0.252, 0.204, 0.244, 0.206, 0.274, 0.187, 0.207, 0.247, 0.17, 0.179, 0.13, 0.153, 0.155, 0.187, 0.252, 0.345, 0.236, 0.213, 0.446, 0.179, 0.204, 0.159, 0.364, 0.209, 0.231, 0.168, 0.215, 0.227, 0.263, 0.214, 0.21, 0.124, 0.127, 0.157, 0.201, 0.131, 0.163, 0.171, 0.356, 0.151, 0.16, 0.169, 0.213, 0.166, 0.241, 0.199, 0.223, 0.141, 0.182, 0.191, 0.164, 0.169, 0.14, 0.19, 0.226, 0.221, 0.224, 0.177, 0.201, 0.192, 0.158, 0.192, 0.127, 0.124, 0.177, 0.141, 0.123, 0.188, 0.147, 0.202, 0.217, 0.198, 0.17, 0.204, 0.157, 0.167, 0.181, 0.145, 0.267, 0.169, 0.208, 0.233, 0.219, 0.207, 0.216, 0.184, 0.152, 0.209, 0.226, 0.454, 0.121, 0.196, 0.169, 0.143, 0.183, 0.226, 0.153, 0.218, 0.196, 0.19, 0.146, 0.148, 0.154, 0.225, 0.21, 0.196, 0.152, 0.19, 0.2, 0.168, 0.246, 0.245, 0.17, 0.226, 0.218, 0.189, 0.23, 0.129, 0.168, 0.167, 0.119, 0.113, 0.146, 0.18, 0.158, 0.197, 0.209, 0.216, 0.142, 0.17, 0.147, 0.194, 0.182, 0.184, 0.238, 0.238, 0.23, 0.237, 0.227, 0.138, 0.195, 0.209, 0.174, 0.161, 0.19, 0.211, 0.145, 0.134, 0.159, 0.194, 0.173, 0.257, 0.146, 0.334, 0.136, 0.149, 0.097, 0.117, 0.146, 0.144, 0.174, 0.154, 0.141, 0.163, 0.182, 0.187, 0.135, 0.155, 0.222, 0.18, 0.156, 0.228, 0.15, 0.222, 0.237, 0.146, 0.19, 0.162, 0.152, 0.241, 0.174, 0.168, 1.202, 0.195, 0.134, 0.227, 0.169, 0.227, 0.113, 0.17, 0.222, 0.138, 0.19, 0.185, 0.218, 0.243, 0.142, 0.157, 0.113, 0.263, 0.175, 0.171, 0.252, 0.226, 0.196, 0.143, 0.179, 0.327, 0.176, 0.138, 0.173, 0.138, 0.193, 0.164, 0.175, 0.299, 0.221, 0.205, 0.233, 0.124, 0.191, 0.211, 0.213, 0.136, 0.153, 0.141, 0.15, 0.188, 0.186, 0.176, 0.175, 0.22, 0.197, 0.212, 0.195, 0.2, 0.179, 0.154, 0.221, 0.189, 0.156, 0.243, 0.151, 0.206, 0.342, 0.208, 0.225, 0.152, 0.205, 0.246, 0.221, 0.23, 0.161, 0.154, 0.225, 0.234, 0.199, 0.153, 0.194, 0.134, 0.155, 0.16, 0.305, 0.12, 0.193, 0.208, 0.154, 0.217, 0.551, 0.151, 0.205, 0.2, 0.157, 0.214, 0.193, 0.219, 0.218, 0.229, 0.201, 0.195, 0.202, 0.204, 1.104, 0.288, 0.184, 0.152, 0.158, 0.187, 0.199, 0.215, 0.208, 0.204, 0.206, 0.225, 0.173, 0.155, 0.182, 0.153, 0.14, 0.216, 0.197, 0.246, 0.144], [0.114, 0.1, 0.149, 0.123, 0.119, 0.18, 0.12, 0.289, 0.159, 0.167, 0.184, 0.157, 0.129, 0.123, 0.122, 0.119, 0.148, 0.139, 0.151, 0.133, 0.176, 0.198, 0.176, 0.155, 0.158, 0.158, 0.19, 0.246, 0.122, 0.167, 0.145, 0.157, 0.36, 0.107, 0.143, 0.12, 0.134, 0.142, 0.179, 0.188, 0.155, 0.175, 0.161, 0.122, 0.147, 0.204, 0.114, 0.182, 0.166, 0.15, 0.122, 0.121, 0.141, 0.098, 0.218, 0.13, 0.114, 0.114, 0.122, 0.104, 0.096, 0.135, 0.12, 0.205, 0.322, 0.116, 0.13, 0.575, 0.139, 0.148, 0.196, 0.16, 0.14, 0.106, 1.077, 0.173, 0.108, 0.101, 0.142, 0.133, 0.125, 0.132, 0.165, 0.093, 0.123, 0.133, 0.169, 0.131, 0.169, 0.13, 0.131, 0.186, 0.134, 0.156, 0.224, 0.115, 0.151, 0.132, 0.171, 0.112, 0.156, 0.13, 0.173, 0.094, 0.146, 0.119, 0.149, 0.128, 0.171, 0.321, 0.142, 0.174, 0.162, 0.132, 0.155, 0.153, 0.289, 0.197, 0.178, 0.165, 0.168, 0.112, 0.154, 0.165, 0.107, 0.099, 0.445, 0.158, 0.116, 0.137, 0.178, 0.224, 0.152, 0.173, 0.124, 0.205, 0.139, 0.109, 0.191, 0.159, 0.148, 0.108, 0.156, 0.119, 0.123, 0.117, 0.181, 0.11, 0.165, 0.141, 0.157, 0.149, 0.159, 0.288, 0.154, 1.048, 0.122, 0.169, 0.2, 0.117, 0.19, 0.15, 0.097, 0.142, 0.145, 0.106, 0.166, 0.189, 0.168, 0.145, 0.139, 0.117, 0.156, 0.157, 0.132, 0.546, 0.161, 1.017, 0.203, 0.147, 0.147, 0.176, 0.132, 0.192, 0.144, 0.296, 0.176, 0.169, 0.196, 0.154, 0.125, 0.271, 0.096, 0.198, 0.137, 0.152, 0.172, 0.115, 0.128, 0.279, 0.11, 0.154, 0.137, 0.113, 0.137, 0.158, 0.133, 0.125, 0.129, 0.141, 0.116, 0.15, 0.123, 0.123, 0.263, 0.344, 0.166, 0.119, 0.115, 0.213, 0.212, 0.178, 0.108, 0.126, 0.115, 0.184, 0.148, 0.14, 0.15, 0.173, 0.133, 0.153, 0.17, 0.195, 0.154, 0.182, 0.189, 0.174, 0.206, 0.279, 0.218, 0.15, 0.155, 0.174, 0.214, 0.157, 0.246, 0.203, 0.171, 0.141, 0.207, 0.231, 0.204, 0.222, 0.194, 0.242, 0.142, 0.208, 0.218, 0.131, 0.115, 0.163, 0.145, 0.165, 0.126, 0.115, 0.149, 0.169, 0.199, 0.177, 0.144, 0.201, 0.148, 0.137, 0.138, 0.22, 0.154, 0.158, 0.161, 0.319, 0.582, 0.18, 0.143, 0.157, 0.178, 0.203, 0.121, 0.179, 0.154, 0.177, 0.155, 0.154, 0.273, 0.157, 0.184, 0.118, 0.191, 0.159, 0.159, 0.582, 0.131, 0.158, 0.127, 0.128, 0.111, 0.219, 0.192, 0.152, 0.208, 0.157, 0.256, 0.143, 0.518, 0.147, 0.162, 0.193, 0.208, 0.179, 0.117, 0.13, 0.152, 0.176, 0.248, 0.198, 0.221, 0.218, 0.183, 0.176, 0.182, 0.281, 0.141, 0.283, 0.291, 0.144, 0.243, 0.173, 0.123, 0.109, 0.104, 0.174, 0.179, 0.24, 0.163, 0.211, 0.171, 0.235, 0.226, 0.163, 0.136, 0.251, 0.157, 0.128, 0.118, 0.15, 0.147, 0.135, 0.132, 0.153, 0.219, 0.176, 0.173, 0.168, 0.206, 0.227, 0.173, 0.165, 0.211, 0.122, 0.187, 0.236, 0.176, 0.134, 0.149, 0.123, 0.13, 0.173, 0.175, 0.154, 0.225, 0.16, 0.215, 0.24, 0.153, 0.186, 0.22, 0.123, 0.2, 0.259, 0.169, 0.181, 0.246, 0.136, 0.181, 0.226, 0.214, 0.201, 0.145, 0.186, 0.193, 0.152, 0.127, 0.123, 0.206, 0.207, 0.136, 0.194, 0.217, 0.175, 0.18, 0.272, 0.211, 0.208, 0.165, 0.227, 0.15, 0.11, 0.184, 0.156, 0.166, 0.171, 0.288, 0.202, 0.211, 0.217, 0.269, 0.116, 0.162, 0.137, 0.167, 0.21, 0.177, 0.209, 0.119, 0.129, 0.186, 0.163, 0.151, 0.15, 0.159, 0.293, 0.166, 0.169, 0.141, 0.196, 0.14, 0.289, 0.225, 0.319, 0.149, 0.191, 0.153, 0.144, 0.226, 0.237, 0.137, 0.14, 0.166, 1.2, 0.301, 0.183, 0.18, 0.158, 0.18, 0.267, 0.131, 0.167, 0.149, 0.211, 0.13, 0.216, 0.266, 0.181, 0.216, 0.14, 2.137, 0.203, 0.275, 0.231, 0.139, 0.184, 0.205, 0.202, 0.265, 0.145, 0.13, 0.187, 0.214, 0.183, 0.205, 0.206, 0.125, 0.179, 0.192, 0.19, 0.131, 0.172, 0.234, 0.28, 0.182, 0.19], [0.177, 0.195, 0.131, 0.165, 0.171, 0.155, 0.287, 0.227, 0.183, 0.172, 0.253, 0.158, 0.155, 0.204, 0.185, 0.148, 0.152, 0.248, 0.149, 0.184, 0.211, 0.22, 0.19, 0.16, 0.197, 0.169, 0.195, 0.125, 0.223, 0.153, 0.598, 0.233, 0.206, 0.153, 0.238, 0.186, 0.322, 0.259, 0.189, 0.212, 0.212, 0.147, 0.157, 0.086, 0.164, 0.15, 0.174, 0.164, 0.214, 0.117, 0.206, 0.176, 0.221, 0.129, 0.15, 0.191, 0.217, 0.15, 0.185, 0.152, 0.158, 0.149, 0.27, 0.096, 0.095, 0.126, 0.093, 0.151, 0.137, 0.188, 0.184, 0.15, 0.163, 0.165, 0.252, 0.201, 0.208, 0.149, 0.2, 0.157, 0.205, 0.202, 0.27, 0.194, 0.258, 0.214, 0.146, 0.142, 0.238, 0.175, 0.239, 0.188, 0.213, 0.217, 0.272, 0.253, 0.304, 0.253, 0.194, 0.149, 0.298, 0.179, 0.178, 0.139, 0.212, 0.212, 0.246, 0.97, 0.178, 0.263, 0.163, 0.145, 0.215, 0.203, 0.194, 0.137, 0.175, 0.12, 0.302, 0.187, 0.129, 0.325, 0.15, 0.115, 0.174, 0.117, 0.173, 0.171, 0.154, 0.144, 0.284, 0.178, 0.136, 1.001, 0.197, 0.252, 0.148, 0.202, 0.169, 0.224, 0.53, 0.118, 0.111, 0.182, 0.193, 0.169, 0.126, 0.157, 0.142, 0.218, 0.184, 0.163, 0.175, 0.192, 0.139, 0.277, 0.12, 0.202, 0.193, 0.147, 0.197, 0.189, 0.568, 0.228, 0.145, 0.236, 0.181, 0.195, 0.23, 0.208, 0.147, 0.351, 0.15, 0.135, 0.204, 0.193, 0.239, 0.362, 0.385, 0.155, 0.142, 0.121, 0.204, 0.214, 0.195, 0.181, 0.197, 0.211, 0.15, 0.151, 0.192, 0.137, 0.224, 0.137, 0.198, 0.145, 0.231, 0.227, 0.181, 0.216, 0.16, 0.194, 0.197, 0.187, 0.145, 0.324, 0.109, 0.118, 0.141, 0.109, 0.14, 0.207, 0.114, 0.19, 0.132, 0.209, 0.213, 0.163, 0.177, 0.193, 0.164, 0.141, 0.21, 0.17, 0.144, 0.138, 0.164, 0.135, 0.14, 0.14, 0.193, 0.18, 0.188, 0.196, 0.191, 0.115, 0.2, 1.264, 0.2, 0.235, 0.238, 0.24, 0.23, 0.156, 0.154, 0.15, 0.143, 0.165, 0.125, 0.141, 0.136, 0.132, 0.153, 0.211, 0.192, 0.251, 0.195, 0.147, 0.155, 0.198, 0.149, 0.253, 0.174, 0.275, 0.156, 0.117, 0.152, 0.188, 0.166, 0.218, 0.185, 0.145, 0.168, 0.212, 0.483, 0.209, 0.146, 0.146, 0.161, 0.228, 0.24, 0.207, 0.175, 0.127, 0.291, 0.179, 0.148, 0.159, 0.15, 0.161, 0.173, 0.354, 0.154, 0.179, 0.21, 0.133, 0.125, 0.17, 0.154, 0.208, 0.147, 0.175, 0.212, 0.214, 0.127, 0.224, 0.15, 0.155, 0.154, 0.143, 0.141, 0.212, 0.171, 0.157, 0.158, 0.164, 0.191, 0.152, 0.243, 0.149, 0.22, 0.127, 0.224, 0.128, 0.188, 0.156, 0.135, 0.163, 0.159, 0.132, 0.176, 0.197, 0.178, 0.19, 0.188, 0.228, 0.148, 0.152, 0.141, 0.184, 1.08, 0.146, 0.223, 0.226, 0.196, 0.173, 0.17, 0.169, 0.171, 0.149, 0.214, 0.208, 0.138, 0.158, 0.159, 0.124, 0.189, 0.138, 0.144, 0.223, 0.245, 0.229, 0.129, 0.267, 0.174, 0.152, 0.147, 0.206, 0.228, 0.213, 0.208, 0.21, 0.164, 0.15, 0.192, 0.183, 0.129, 0.172, 0.149, 0.156, 0.165, 0.192, 0.192, 0.21, 0.224, 0.138, 0.223, 0.186, 0.217, 0.181, 0.133, 0.183, 0.147, 0.113, 0.202, 0.218, 0.28, 0.159, 0.169, 0.149, 0.123, 0.095, 0.166, 0.171, 0.136, 0.157, 0.146, 0.147, 0.137, 0.201, 0.12, 0.208, 0.169, 0.155, 0.202, 0.227, 0.178, 0.194, 0.165, 0.176, 0.21, 0.124, 0.196, 0.43, 0.172, 0.164, 0.106, 0.115, 0.149, 0.152, 0.138, 0.136, 0.295, 0.133, 0.148, 0.728, 0.22, 0.244, 0.193, 0.218, 0.129, 0.143, 0.133, 0.146, 0.136, 0.151, 0.194, 0.147, 0.151, 0.144, 0.15, 0.204, 0.196, 0.162, 0.166, 0.184, 0.184, 0.162, 0.182, 0.785, 0.144, 0.167, 0.169, 0.138, 0.138, 0.202, 0.234, 0.218, 0.233, 0.248, 0.158, 0.164, 0.267, 0.239, 0.155, 0.218, 4.321, 0.125, 0.158, 0.189, 0.16, 0.163, 0.124, 0.17, 0.224, 0.142, 0.185, 0.204, 0.14, 0.213, 0.153, 0.189, 0.142, 0.43, 0.138, 0.2, 0.16, 0.14, 0.183, 0.14]
    #         ]
    #     ],
    #     [#dims
    #         [
    #             [3.732, 6.956, 2.661, 4.144, 8.312, 6.578, 6.191, 3.614, 8.927, 5.16, 3.447, 10.002, 4.014, 25.411, 4.581, 8.635, 5.95, 19.499, 4.922, 3.172, 2.375, 2.715, 10.492, 13.346, 4.257, 4.972, 9.5, 4.183, 3.647, 2.971, 8.03, 8.89, 2.213, 2.73, 5.569, 11.039, 7.405, 7.856, 10.59, 3.143, 2.851, 9.699, 8.615, 3.277, 3.942, 2.893, 3.379, 4.342, 10.463, 5.298], [2.712, 3.321, 12.619, 15.376, 5.145, 3.315, 4.404, 8.218, 20.964, 32.07, 2.807, 3.367, 2.623, 2.62, 3.79, 4.108, 6.413, 5.741, 4.275, 21.896, 8.563, 3.323, 4.82, 18.497, 4.214, 1.722, 14.493, 3.63, 4.89, 3.612, 3.006, 2.365, 2.062, 7.498, 3.37, 4.83, 4.269, 5.863, 4.796, 2.99, 5.631, 3.503, 4.99, 1.869, 3.844, 2.378, 6.51, 29.027, 6.616, 3.295], [11.748, 3.867, 4.396, 3.927, 19.239, 4.996, 3.876, 4.049, 7.851, 6.613, 4.113, 5.0, 14.934, 2.97, 4.736, 3.423, 34.848, 3.249, 30.293, 4.711, 9.741, 13.079, 3.302, 4.614, 4.161, 8.778, 1.737, 3.618, 2.07, 14.139, 6.045, 4.991, 2.887, 2.174, 5.255, 3.29, 4.348, 1.93, 3.366, 1.997, 15.43, 2.031, 2.451, 1.809, 3.593, 2.742, 3.658, 3.373, 6.012, 2.546], [5.497, 3.883, 5.276, 4.61, 7.009, 7.476, 2.815, 21.149, 7.299, 8.359, 3.542, 13.03, 10.285, 4.044, 3.684, 7.3, 6.843, 6.407, 50.788, 18.271, 19.806, 2.866, 2.843, 8.278, 4.227, 5.432, 10.718, 3.389, 3.555, 5.833, 4.567, 4.848, 4.717, 2.815, 8.644, 5.758, 3.996, 3.303, 2.825, 4.779, 5.169, 2.735, 3.577, 2.625, 3.421, 3.414, 3.856, 15.102, 5.794, 5.041], [9.971, 3.92, 2.125, 5.377, 3.336, 3.128, 3.664, 34.078, 5.026, 7.18, 3.666, 3.455, 3.416, 7.005, 1.957, 14.892, 5.007, 4.667, 5.985, 1.81, 3.272, 5.588, 3.312, 3.693, 2.967, 15.425, 4.247, 3.759, 2.48, 2.186, 2.705, 2.859, 2.213, 2.439, 3.232, 11.764, 2.43, 5.219, 10.089, 3.777, 14.31, 8.314, 54.291, 5.74, 4.919, 2.695, 13.661, 3.765, 5.871, 5.669], [3.236, 2.671, 5.814, 4.976, 3.457, 2.603, 6.468, 1.89, 1.846, 3.116, 37.668, 13.995, 5.501, 3.566, 4.076, 2.984, 3.793, 7.644, 1.897, 2.728, 10.438, 7.138, 3.374, 30.661, 3.228, 41.132, 2.567, 4.39, 4.178, 4.756, 5.136, 8.164, 1.736, 3.198, 2.975, 2.654, 1.494, 7.331, 4.488, 2.354, 1.94, 3.983, 10.947, 17.268, 2.572, 2.017, 3.808, 3.851, 4.15, 6.961], [7.537, 4.983, 7.16, 17.68, 9.787, 7.225, 4.545, 6.58, 3.237, 2.971, 1.654, 4.238, 2.256, 50.829, 4.308, 3.868, 4.408, 4.114, 29.766, 5.424, 3.148, 14.322, 3.373, 4.311, 2.098, 2.973, 1.982, 4.345, 8.322, 2.071, 6.698, 2.359, 2.119, 2.521, 2.453, 4.665, 3.399, 17.712, 3.512, 4.725, 5.85, 7.162, 4.688, 3.229, 5.02, 3.172, 5.507, 10.644, 2.715, 1.952], [3.49, 2.529, 3.641, 3.858, 1.466, 2.19, 6.459, 8.42, 1.487, 1.66, 4.821, 4.622, 5.609, 5.571, 2.879, 13.992, 2.303, 15.998, 4.643, 6.912, 2.316, 7.127, 4.993, 3.414, 3.07, 3.632, 2.377, 2.449, 11.217, 5.651, 2.16, 6.776, 3.799, 7.354, 4.803, 1.788, 4.166, 2.194, 3.128, 3.218, 3.029, 2.989, 5.056, 3.872, 4.959, 22.097, 4.166, 33.978, 2.565, 2.474], [4.336, 2.451, 1.85, 7.969, 1.962, 2.147, 3.131, 2.254, 2.741, 6.553, 14.917, 3.884, 4.148, 13.072, 4.716, 2.889, 6.683, 7.537, 2.387, 3.994, 3.353, 2.999, 1.806, 14.828, 2.04, 2.589, 2.7, 4.874, 3.071, 3.554, 1.887, 1.56, 1.504, 1.997, 8.004, 3.075, 3.127, 3.051, 4.555, 3.734, 2.353, 1.942, 3.676, 9.337, 2.511, 7.58, 2.793, 21.907, 1.97, 4.825]
    #         ]
    #     ],    
    #     [
    #         [
    #             [22.174, 11.216, 19.947, 17.87, 16.275, 23.255, 89.372, 11.384, 48.279, 13.587, 8.171, 21.217, 8.879, 27.455, 13.331, 35.09, 5.384, 40.399, 21.216, 43.755, 13.998, 23.449, 7.979, 12.028, 24.483], [9.841, 50.011, 18.667, 29.306, 63.957, 8.925, 8.148, 10.66, 36.816, 40.153, 12.376, 42.923, 8.803, 25.933, 14.411, 9.548, 17.995, 12.988, 21.031, 14.198, 16.339, 12.52, 10.014, 72.303, 21.754], [24.707, 13.314, 36.728, 11.408, 23.66, 20.209, 38.798, 13.554, 72.144, 50.169, 33.363, 13.411, 27.698, 19.078, 14.828, 28.281, 10.377, 18.118, 13.444, 7.83, 47.984, 8.147, 13.416, 14.169, 19.175], [14.801, 16.762, 25.255, 36.961, 21.271, 18.361, 20.811, 18.805, 10.548, 100.591, 43.61, 26.447, 19.854, 28.924, 17.922, 17.964, 14.313, 54.139, 13.654, 19.879, 15.395, 10.564, 11.967, 47.312, 33.505], [25.654, 13.237, 9.745, 145.075, 65.357, 62.178, 66.173, 67.421, 79.35, 23.917, 29.43, 13.6, 38.394, 15.902, 9.14, 10.926, 10.898, 27.438, 13.218, 28.75, 62.509, 70.508, 11.024, 34.541, 19.194], [10.817, 19.442, 11.032, 15.166, 9.682, 140.208, 25.428, 14.96, 30.77, 11.393, 34.491, 44.498, 67.044, 12.175, 14.531, 15.851, 14.736, 8.519, 18.857, 12.895, 13.053, 57.008, 6.689, 13.754, 30.256], [17.03, 52.323, 33.511, 10.526, 10.24, 9.643, 94.064, 23.349, 13.942, 65.536, 27.439, 12.929, 12.68, 19.586, 15.239, 20.577, 7.495, 11.895, 27.882, 18.007, 17.831, 14.709, 19.352, 32.425, 6.547], [14.85, 18.678, 9.584, 39.883, 7.94, 26.978, 18.485, 39.028, 43.304, 18.948, 12.676, 23.691, 12.484, 11.514, 32.996, 15.22, 29.752, 18.635, 8.742, 8.937, 11.952, 33.072, 50.096, 85.796, 8.85], [13.845, 25.947, 8.676, 9.507, 28.179, 41.059, 52.486, 22.9, 44.401, 15.235, 16.084, 43.017, 8.793, 23.497, 20.347, 8.742, 7.656, 29.065, 16.353, 21.15, 9.433, 32.137, 33.291, 61.35, 16.359]
    #         ]
    #     ],
    #     [
    #         [
    #             [137.52, 108.837, 246.572, 154.826, 72.207, 91.959, 100.265, 194.845, 110.499, 105.434], [200.806, 230.496, 54.144, 169.071, 182.641, 132.875, 100.119, 105.447, 100.602, 255.987], [205.14, 147.829, 134.508, 239.642, 115.852, 74.865, 86.575, 51.963, 145.612, 135.914], [141.868, 246.479, 107.631, 290.425, 170.007, 138.145, 135.179, 192.867, 185.605, 258.184], [123.862, 212.337, 81.014, 131.813, 70.9, 103.839, 45.547, 138.468, 337.39, 151.631], [74.157, 75.901, 258.526, 85.102, 163.956, 215.382, 69.61, 112.424, 194.122, 119.476], [165.655, 63.929, 208.652, 148.711, 103.568, 87.623, 88.546, 158.681, 133.89, 127.948], [71.644, 128.312, 102.619, 177.731, 96.87, 137.776, 132.611, 71.119, 125.586, 311.709], [100.045, 77.098, 180.829, 110.486, 116.486, 96.684, 66.725, 86.089, 90.376, 214.9]
    #         ]
    #     ],
    #     [
    #         [
    #             [12346.28], [12422.935]
    #         ]
    #     ]
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4trainingtimerawinput_l)):
    #     # Summing the innermost lists for each configuration within a model
    #     model_sums = [[sum(inner) for inner in dim] for dim in ys_d4trainingtimerawinput_l[m_i]]
        
    #     # Calculating the mean for each configuration
    #     model_means = [np.mean(dim_sums) for dim_sums in model_sums]
    #     ys_array.append(model_means)
        
    #     # Calculating the standard deviation for each configuration
    #     model_stds = [np.std(dim_sums) / np.sqrt(len(dim_sums)) for dim_sums in model_sums]
    #     ci_array.append([1.96 * std for std in model_stds])

    # # Convert to numpy arrays for plotting
    # ys_array = np.array(ys_array).T  # Transpose to match the expected shape for plotting
    # ci_array = np.array(ci_array).T

    # for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v", "o", "s"]):
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='^', capsize=10)
    # ax.set_xticks(xs)
    # ax.set_xticklabels(xs_label, fontsize=18)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # # ax.set_xscale('log')
    # ax.set_ylabel("Resource Cost (\$)", fontsize=20)
    # ax.grid()
    # # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()



    # filename = "testf1score_with_rawinput_300filter_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs=[60, 120, 300, 3000]
    # labels = ("Weighted F1 Scores for All Labels","Weighted Precision","Weighted Recall",)
    # ys_d4rawinputscores_l=[#models
    #     [#dimensions
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             0.824, 0.832, 0.84
    #         ],
    #         [
    #             0.798, 0.807, 0.815
    #         ],
    #         [
    #             0.989, 0.989, 0.988
    #         ]
    #     ],
    #     [
    #         [
    #             0.826, 0.843, 0.829
    #         ],
    #         [
    #             0.822, 0.818, 0.811
    #         ],
    #         [
    #             0.973, 0.988, 0.976
    #         ]
    #     ],
    #     [
    #         [
    #             0.822, 0.802, 0.821
    #         ],
    #         [
    #             0.831, 0.796, 0.805
    #         ],
    #         [
    #             0.955, 0.937, 0.952
    #         ]
    #     ],
    #     [
    #         [
    #             0.822, 0.822, 0.822
    #         ],
    #         [
    #             0.808, 0.808, 0.808
    #         ],
    #         [
    #             0.928, 0.928, 0.928
    #         ]
    #     ]
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4rawinputscores_l)):
    #     ys_array.append(np.mean(ys_d4rawinputscores_l[m_i], axis=(1)))
    #     ci_array.append(1.96 * np.std(ys_d4rawinputscores_l[m_i], axis=1)/np.sqrt(len(ys_d4rawinputscores_l[m_i][0])))
    # ys_array = np.array(ys_array).T
    # ci_array = np.array(ci_array).T
    # for idx, (ys, ci, label, mark) in enumerate(zip(ys_array, ci_array, labels, ["^", "v", ".", "*"])): # ['#f00022', '#00f022', '#ff00ff']
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # # ax.set_xscale('log')
    # # ax.set_xlim(0,120000)
    # # ax.set_ylim(0.3,1)
    # ax.set_ylabel("Prediction Metrics", fontsize=20)
    # ax.grid()
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()



    # filename = "testf1score_by_labels_per_model_with_rawinput_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs=[60, 120, 300, 3000]
    # labels = ("Filter=300", "Filter=100")
    # ys_d4nonef1score_l=[#models
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             0.824, 0.832, 0.84
    #         ],
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             0,0,0
    #         ]
    #     ],    
    #     [
    #         [
    #             0.826, 0.843, 0.829
    #         ],
    #         [
    #             0,0,0
    #         ]
    #     ],
    #     [
    #         [
    #             0.822, 0.802, 0.821
    #         ],
    #         [
    #             0,0,0
    #         ]
    #     ],
    #     [
    #         [
    #             0.822, 0.822, 0.822
    #         ],
    #         [
    #             0,0,0
    #         ]
    #     ]
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4nonef1score_l)):
    #     ys_array.append(np.mean(ys_d4nonef1score_l[m_i], axis=(1)))
    #     ci_array.append(1.96 * np.std(ys_d4nonef1score_l[m_i], axis=1)/np.sqrt(len(ys_d4nonef1score_l[m_i][0])))
    # ys_array = np.array(ys_array).T
    # ci_array = np.array(ci_array).T
    # for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
    # ax.set_xscale('log')
    # ax.set_ylim(0.3,1)
    # ax.set_ylabel("F1-Score", fontsize=20)
    # ax.grid()
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()




    filename = "test_f1score_model_token_share_by_cos_sim_with_rawinput_False100filter_data_4"
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    xs_label = [0.6, 0.7, 0.8, 0.9, 0.98]
    xs = list(range(len(xs_label)))
    f1_score_label = "F1-Score"
    precision_label = "Precision"
    # token_share_label = "\% of Token Considered by Multiple Sub-Model"
    token_share_label = "\% of Duplicate Features"

    # Data for F1-Score
    ys_d4f1scorebycosinesim_l = [
        [[0.864]],
        [[0.856, 0.846]],
        [[0.85, 0.856, 0.845]],
        [[0.815, 0.792, 0.816]],
        [[0.733, 0.743, 0.706]],
    ]

    # Data for Precision
    ys_d4f1precisonbycosinesim_l = [
        [[0.848]],
        [[0.832, 0.826]],
        [[0.823, 0.831, 0.816]],
        [[0.784, 0.761, 0.781]],
        [[0.688, 0.7, 0.661]],
    ]

    # Data for Token Share
    ys_d4modelsharedtokenbycosinesim_l = [
        [[0.03720166231376994]],
        [[0.07461357775259121]],
        [[0.07368660238615396]],
        [[0.07786976351998774]],
        [[0.16024135306646517]],
    ]

    # Calculate means and confidence intervals for F1-Score
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1scorebycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1scorebycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1scorebycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1scorebycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot F1-Score
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=f1_score_label, marker="^", markersize=10)

    # Calculate means and confidence intervals for Precision
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1precisonbycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1precisonbycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1precisonbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1precisonbycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot Precision
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=precision_label, marker="*", markersize=10)

    # Calculate means and confidence intervals for Token Share
    ys_array_ts, ci_array_ts = [], []
    for m_i in range(len(ys_d4modelsharedtokenbycosinesim_l)):
        ys_array_ts.append(np.mean(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=(1)))
        ci_array_ts.append(1.96 * np.std(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4modelsharedtokenbycosinesim_l[m_i][0])))
    ys_array_ts = np.array(ys_array_ts).T
    ci_array_ts = np.array(ci_array_ts).T

    # Plot Token Share on secondary y-axis
    ax2 = ax.twinx()
    for ys, ci in zip(ys_array_ts, ci_array_ts):
        ax2.errorbar(xs, [ele*100 for ele in ys], yerr=ci, fmt='o', capsize=10, label=token_share_label, marker="v", markersize=10, color='r')

    # Styling and labeling
    ax.set_xlabel(r"Cosine Similarity Threshold $\tau$", fontsize=20)
    ax.set_xticks(xs)
    ax.set_xticklabels(xs_label)
    ax.set_ylabel("Model Metrics", fontsize=20, color='b')
    ax.tick_params(axis='y', labelcolor='b', which='major', labelsize=20)
    ax.tick_params(axis='y', labelcolor='b', which='minor', labelsize=18)
    ax2.set_ylabel("\%", fontsize=20, color='r')
    ax2.tick_params(axis='y', labelcolor='r', which='major', labelsize=20)
    ax2.tick_params(axis='y', labelcolor='r', which='minor', labelsize=18)
    ax.grid(True)
    # ax2.grid(True)

    # Adding legends
    ax.legend(title="Metric", fontsize=18, loc="center left")
    ax2.legend(fontsize=18, loc="lower right", bbox_to_anchor=(0.9, 0))

    fig.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter as needed

    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()




    filename = "incremental_training_time_of_sub_models_with_rawinput_False100filter_data_4"

    # Sample data
    sub_models = list(range(25))
    times_impl1 = [0.857, 0.742, 5.32, 0.377, 0.485, 5924.644, 0.473, 2.236, 0.683, 0.399, 3.567, 0.334, 9.734, 0.993, 8.885, 0.278, 0.407, 2.902, 0.621, 13.718, 0.407, 0.659, 0.321, 0.745, 0.733]  # Training times for implementation 1
    times_impl2 = [5.351, 6.768, 1.877, 4.296, 15.209, 259.11, 24.289, 5.531, 4.42, 6.084, 25.962, 6.382, 14.499, 18.264, 2.3, 4.775, 3.671, 45.586, 793.254, 3.49, 5.866, 4.268, 24.232, 4.125, 2.174]  # Training times for implementation 2
    # times_impl1 = [0.857, 5924.644, 0.742, 5.32, 0.377, 0.485, 0.473, 2.236, 0.683, 0.399, 3.567, 0.334, 9.734, 0.993, 8.885, 0.278, 0.407, 2.902, 0.621, 0.407, 0.659, 0.321, 0.745, 13.718, 0.733]  # Training times for implementation 1
    # times_impl2 = [5.351, 259.11, 6.768, 1.877, 4.296, 15.209, 24.289, 5.531, 4.42, 6.084, 25.962, 6.382, 14.499, 18.264, 2.3, 4.775, 3.671, 45.586, 3.49, 5.866, 4.268, 24.232, 4.125, 793.254, 2.174]  # Training times for implementation 2

    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()

    # Assuming num_labels for each τ
    num_labels_tau_06 = [28, 23, 14, 16, 22, 2265, 25, 57, 34, 18, 35, 21, 75, 26, 37, 13, 18, 15, 133, 18, 19, 39, 13, 15, 21]  # For τ = 0.6
    num_labels_tau_07 = [65, 68, 60, 78, 72, 414, 55, 154, 88, 66, 79, 70, 60, 92, 62, 62, 57, 111, 874, 92, 61, 47, 111, 51, 51]  # For τ = 0.7
    # num_labels_tau_06 = [28, 2265, 23, 14, 16, 22, 25, 57, 34, 18, 35, 21, 75, 26, 37, 13, 18, 15, 18, 19, 39, 13, 15, 133, 21]  # For τ = 0.6
    # num_labels_tau_07 = [65, 414, 68, 60, 78, 72, 55, 154, 88, 66, 79, 70, 60, 92, 62, 62, 57, 111, 92, 61, 47, 111, 51, 874, 51]  # For τ = 0.7

    # Create the plot
    fig, ax1 = plt.subplots(figsize=(10, 3))

    ind = np.arange(len(sub_models))  # the x locations for the groups
    width = 0.35  # the width of the bars

    # Plotting training times
    bars_impl1 = ax1.bar(ind - width/2, times_impl1, width, color='blue', label=r'$\tau = 0.6$')
    bars_impl2 = ax1.bar(ind + width/2, times_impl2, width, color='orange', label=r'$\tau = 0.7$')

    ax1.set_xlabel('Sub-Models', fontsize=20)
    ax1.set_ylabel('Training Time (s)', color='black', fontsize=20)
    ax1.set_xticks(ind)
    ax1.set_xticklabels(sub_models, fontsize=18, rotation=45)
    ax1.tick_params(axis='y', labelcolor='black', labelsize=20)
    ax1.legend(loc='upper left', title='Training Time', fontsize=18, title_fontsize=18)

    # Secondary y-axis for num_labels
    ax2 = ax1.twinx()
    ax2.plot(ind - width/2, num_labels_tau_06, color='green', marker='o', linestyle='--', label=r'$\tau = 0.6$')
    ax2.plot(ind + width/2, num_labels_tau_07, color='red', marker='x', linestyle='--', label=r'$\tau = 0.7$')
    ax2.set_ylabel('Number of Labels', color='green', fontsize=20)
    ax2.tick_params(axis='y', labelcolor='green', labelsize=20)
    ax2.legend(loc='upper right', title='Num Labels', fontsize=18, title_fontsize=18)

    plt.tight_layout()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()




    filename = "trainlatency_by_labels_per_model_with_rawinput_data_4"
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    xs_label = [3, 6, 60, 120, 300, "3000\n(DeltaSherlock)\n(XGBoost)", "3000\n(Praxi)\n(VW)"]
    xs = list(range(len(xs_label)))
    labels = ["Filter=25", "No Filter"]
    ys_d4trainingtimerawinput_l=[#models
        [#dims
            [
                [0.123, 0.1, 0.1, 0.1, 0.095, 0.078, 0.15, 0.085, 0.085, 0.077, 0.117, 0.123, 0.072, 0.105, 0.095, 0.075, 0.08, 0.077, 0.128, 0.068, 0.079, 0.094, 0.085, 0.089, 0.095, 0.07, 0.079, 0.682, 0.088, 0.091, 0.084, 0.091, 0.099, 0.122, 0.131, 0.078, 0.071, 0.09, 0.076, 0.114, 0.08, 0.09, 0.084, 0.133, 0.088, 0.094, 0.103, 0.086, 0.091, 0.104, 0.08, 0.087, 0.094, 0.145, 0.092, 0.096, 0.14, 0.086, 0.093, 0.082, 0.095, 0.108, 0.093, 0.115, 0.084, 0.086, 0.08, 0.093, 0.189, 0.072, 0.081, 0.148, 0.093, 0.079, 0.135, 0.07, 0.083, 0.076, 0.08, 0.074, 0.073, 0.074, 0.116, 0.082, 0.078, 0.083, 0.509, 0.078, 0.085, 0.1, 0.085, 0.126, 0.088, 0.072, 0.071, 0.096, 0.117, 0.076, 0.092, 0.096, 0.088, 0.075, 0.088, 0.065, 0.183, 0.091, 0.103, 0.072, 0.066, 0.07, 0.244, 0.096, 0.086, 0.116, 0.088, 0.082, 0.061, 0.069, 0.077, 0.079, 0.087, 0.096, 0.07, 0.069, 0.086, 0.093, 0.082, 0.071, 0.289, 0.067, 0.066, 0.078, 0.071, 0.082, 0.068, 0.085, 0.073, 0.08, 0.076, 0.069, 0.088, 0.088, 0.075, 0.08, 0.069, 0.07, 0.117, 0.082, 0.08, 0.074, 0.084, 0.077, 0.075, 0.086, 0.14, 0.08, 0.141, 0.099, 0.116, 0.094, 0.127, 0.128, 0.085, 0.133, 0.08, 0.259, 0.076, 0.073, 0.098, 0.057, 0.072, 0.159, 0.112, 0.106, 0.075, 0.068, 0.103, 0.075, 0.081, 0.089, 0.075, 0.083, 0.07, 0.084, 0.079, 0.075, 0.115, 0.089, 0.11, 0.07, 0.068, 0.062, 0.074, 0.086, 0.087, 0.078, 0.132, 0.055, 0.074, 0.227, 0.093, 0.092, 0.133, 0.106, 0.09, 0.098, 0.072, 0.091, 0.089, 0.067, 0.072, 0.106, 0.082, 0.093, 0.136, 0.061, 0.094, 0.101, 0.11, 0.079, 0.076, 0.093, 0.131, 0.088, 0.083, 0.154, 0.081, 0.076, 0.164, 0.087, 0.157, 0.084, 0.125, 0.081, 0.067, 0.699, 0.138, 0.093, 0.104, 0.129, 0.084, 0.077, 0.082, 0.088, 0.134, 0.156, 0.085, 0.156, 0.088, 0.079, 0.085, 0.12, 0.134, 0.164, 0.094, 0.081, 0.072, 0.081, 0.096, 0.11, 2.949, 0.095, 0.071, 0.087, 0.118, 0.091, 0.131, 0.074, 0.083, 0.065, 0.093, 0.077, 0.083, 0.077, 0.069, 0.09, 0.076, 0.121, 0.087, 0.105, 0.08, 0.07, 0.075, 0.07, 0.09, 0.083, 0.088, 0.085, 0.079, 0.244, 0.09, 0.084, 0.08, 0.078, 0.074, 0.075, 0.08, 0.134, 0.071, 0.107, 0.065, 0.067, 0.113, 0.072, 0.154, 0.16, 0.088, 0.089, 0.102, 0.078, 0.126, 0.078, 0.14, 0.07, 0.075, 0.096, 0.072, 0.145, 0.074, 0.089, 0.099, 0.126, 0.089, 0.081, 0.075, 0.145, 0.098, 0.095, 0.133, 0.097, 0.081, 0.088, 0.082, 0.084, 0.107, 0.08, 0.086, 0.083, 0.274, 0.092, 0.109, 0.091, 0.119, 0.082, 0.108, 0.084, 0.089, 0.129, 0.072, 0.091, 0.071, 0.068, 0.076, 0.105, 0.075, 0.067, 0.09, 0.074, 0.135, 1.473, 0.091, 0.087, 0.07, 0.096, 0.079, 0.084, 0.149, 0.107, 0.076, 0.08, 0.071, 0.1, 0.126, 0.098, 0.073, 0.182, 0.077, 0.072, 0.065, 0.082, 0.086, 0.092, 0.084, 0.074, 0.121, 0.21, 0.073, 0.11, 0.078, 0.111, 0.067, 0.074, 0.086, 0.083, 0.084, 0.075, 0.08, 0.093, 0.066, 0.082, 0.066, 0.076, 0.08, 0.074, 0.087, 0.109, 0.092, 0.089, 0.104, 0.113, 0.093, 0.089, 0.124, 0.077, 0.083, 0.11, 0.083, 0.096, 0.08, 0.071, 0.148, 0.086, 0.138, 0.078, 0.084, 0.076, 0.072, 0.079, 0.064, 0.069, 0.067, 0.082, 0.086, 0.079, 0.081, 0.097, 0.076, 0.071, 0.085, 0.071, 0.136, 0.068, 0.075, 0.128, 0.104, 0.091, 0.132, 0.083, 0.131, 0.088, 0.072, 0.07, 0.08, 0.064, 0.068, 0.078, 0.072, 0.07, 0.281, 0.141, 0.069, 0.186, 0.069, 0.08, 0.089, 0.108, 0.07, 0.083, 0.149, 0.142, 0.083, 0.093, 0.075, 0.068, 0.087, 0.076, 0.076, 0.112, 0.083, 0.089, 0.094, 0.075, 0.083, 0.084, 0.076, 0.135, 0.07, 0.086, 0.144, 0.09, 0.091, 0.093, 0.089, 0.073, 0.091, 0.089, 0.079, 0.08, 0.087, 0.091, 0.077, 0.08, 0.09, 0.095, 0.086, 0.073, 0.069, 0.108, 0.072, 0.082, 0.081, 0.12, 0.077, 0.081, 0.097, 0.115, 0.069, 0.072, 0.071, 0.096, 0.079, 0.058, 0.09, 0.058, 0.1, 0.072, 0.079, 0.285, 0.089, 0.067, 0.07, 0.084, 0.068, 0.078, 0.083, 0.081, 0.084, 0.084, 0.098, 0.37, 0.068, 0.094, 0.101, 0.068, 0.082, 0.093, 0.085, 0.127, 0.093, 0.084, 0.119, 0.092, 0.075, 0.084, 0.084, 0.082, 0.091, 0.193, 0.117, 0.083, 0.159, 0.104, 0.07, 0.096, 0.066, 0.082, 0.084, 0.081, 0.08, 0.076, 0.089, 0.076, 0.071, 0.116, 0.162, 0.078, 0.103, 0.095, 0.093, 0.121, 0.117, 0.081, 0.08, 0.097, 0.14, 0.095, 0.078, 0.091, 0.099, 0.072, 0.085, 0.111, 0.091, 0.083, 0.164, 0.112, 0.08, 0.088, 0.078, 0.071, 0.379, 0.086, 0.09, 0.085, 0.065, 0.092, 0.093, 0.068, 0.085, 0.129, 0.071, 0.071, 0.078, 0.101, 0.099, 0.142, 0.119, 0.094, 0.09, 0.155, 0.086, 0.058, 0.11, 0.067, 0.063, 0.092, 0.122, 0.077, 0.086, 0.079, 0.109, 0.084, 0.08, 0.111, 0.066, 0.266, 0.077, 0.09, 0.15, 0.087, 0.084, 0.082, 0.097, 0.082, 0.071, 0.074, 0.071, 0.08, 0.059, 0.069, 0.099, 0.112, 0.123, 0.064, 0.059, 0.075, 0.072, 0.134, 0.103, 0.091, 0.093, 0.08, 0.086, 0.078, 0.081, 0.08, 0.079, 0.098, 0.103, 0.091, 0.083, 0.086, 0.114, 0.081, 0.122, 0.08, 0.077, 0.084, 0.088, 0.073, 0.074, 0.078, 0.081, 0.092, 0.15, 0.11, 0.075, 0.084, 0.077, 0.064, 0.07, 0.079, 0.19, 0.087, 0.134, 0.08, 0.19, 0.074, 0.072, 0.103, 0.098, 0.102, 0.167, 0.072, 0.079, 0.088, 0.087, 0.085, 0.15, 0.089, 0.2, 0.096, 0.101, 0.08, 0.083, 0.088, 0.14, 0.089, 1.257, 0.073, 0.067, 0.067, 0.073, 0.076, 0.084, 0.071, 0.122, 0.082, 0.083, 0.081, 0.068, 0.094, 0.091, 0.077, 0.079, 0.189, 0.097, 0.093, 0.135, 0.13, 0.102, 0.074, 0.086, 0.089, 0.09, 0.075, 0.074, 0.085, 0.097, 0.279, 0.151, 0.08, 0.078, 0.069, 0.071, 0.088, 0.093, 0.111, 0.116, 0.083, 0.101, 0.118, 1.188, 0.089, 0.085, 0.083, 0.077, 0.076, 0.132, 0.072, 0.087, 0.084, 0.08, 0.064, 0.084, 0.077, 0.079, 0.088, 0.099, 0.072, 0.072, 0.115, 0.107, 0.103, 0.125, 0.084, 0.063, 0.086, 0.12, 0.101, 0.066, 0.137, 0.078, 0.143, 0.063, 0.098, 0.081, 0.092, 0.103, 0.078, 0.136, 0.082, 0.091, 0.076, 0.091, 0.084, 0.128, 0.08, 0.077, 0.094, 0.07, 0.073, 0.066, 0.144, 0.084, 0.13, 0.085, 0.069, 0.083, 0.116, 0.083, 0.088, 0.137, 0.082, 0.133, 0.091, 0.08, 0.084, 0.084, 0.078, 0.067, 0.101, 0.068, 0.063, 0.066, 0.084, 0.259, 0.105, 0.074, 0.068, 0.206, 0.07, 0.072, 0.175, 0.117, 0.088, 0.085, 0.061, 0.071, 0.062, 0.187, 0.065, 0.117, 0.087, 0.129, 0.076, 0.074, 0.073, 0.089, 0.085, 0.07, 0.081, 0.099, 0.122, 0.072, 0.097, 0.128, 0.091, 0.075, 0.079, 0.074, 0.12, 0.076, 0.09, 0.078, 0.077, 0.085, 0.076, 0.071, 0.117, 0.072, 0.098, 0.099, 0.098, 0.068, 0.079, 0.07, 0.12, 0.103, 0.061, 0.079, 0.074, 0.072, 0.119, 0.099, 0.141, 0.086, 0.082, 0.073, 0.086, 0.076, 0.075, 0.077, 0.071, 0.069, 0.081, 0.076, 0.072, 0.106, 0.077, 0.077, 0.078, 0.128, 0.072, 0.101, 0.102, 0.119, 0.09, 0.133, 0.096, 0.087, 0.08, 0.077, 0.081, 0.118, 0.102, 0.144, 0.099, 0.105, 0.081, 0.081, 0.112, 0.097, 0.132, 0.083, 0.097, 0.089, 0.132, 0.092, 0.079, 0.079, 0.092, 0.07, 0.072, 0.082, 0.069, 0.091, 0.093, 0.078, 0.168, 0.226, 0.075, 0.083, 0.094, 0.089, 0.088, 0.078, 0.094, 0.09, 0.083, 0.087, 0.081, 0.838, 0.082, 0.082, 0.084, 0.08, 0.083, 0.076, 0.072, 0.071, 0.147, 0.085, 0.107, 0.084, 0.089, 0.085, 0.126, 0.102, 0.073, 0.077, 0.078, 0.092, 0.117, 0.104, 0.127, 0.076, 0.328, 0.073, 0.08, 0.081, 0.081, 0.075, 0.07, 0.08, 0.072, 0.075, 0.08, 0.119, 0.083], [0.077, 0.109, 0.08, 0.069, 0.082, 0.102, 0.063, 0.091, 0.09, 0.127, 0.097, 0.093, 0.086, 0.148, 0.136, 0.089, 0.078, 0.102, 0.09, 0.072, 0.073, 0.083, 0.07, 0.094, 0.128, 0.107, 0.08, 0.081, 0.114, 0.097, 0.095, 0.103, 0.076, 0.07, 0.097, 0.112, 0.089, 0.146, 0.095, 0.089, 0.083, 0.075, 0.092, 0.164, 0.075, 0.076, 0.074, 0.066, 0.077, 0.135, 0.074, 0.08, 0.077, 0.299, 0.108, 0.081, 0.368, 0.065, 0.069, 0.08, 0.836, 0.06, 0.302, 0.066, 0.066, 0.073, 0.077, 0.083, 0.084, 0.07, 0.096, 0.074, 0.094, 0.078, 0.148, 0.103, 0.087, 0.085, 0.074, 0.08, 0.181, 0.122, 0.072, 0.074, 0.117, 0.107, 0.137, 0.072, 0.095, 0.102, 0.087, 0.091, 0.088, 0.082, 0.102, 0.069, 0.072, 0.067, 0.09, 0.074, 0.082, 0.138, 0.079, 0.091, 0.088, 0.084, 0.145, 0.095, 0.09, 0.102, 0.091, 0.11, 0.09, 0.09, 0.073, 0.088, 0.102, 0.109, 0.102, 0.142, 0.076, 0.094, 0.087, 0.086, 0.101, 0.068, 0.12, 0.091, 0.069, 0.075, 0.091, 0.087, 0.131, 0.139, 0.126, 0.089, 0.067, 0.077, 0.079, 0.168, 0.139, 0.118, 0.073, 0.124, 0.071, 0.094, 0.081, 0.088, 0.079, 0.107, 0.079, 0.078, 0.065, 0.064, 0.083, 0.075, 0.074, 0.095, 0.081, 0.178, 0.411, 0.067, 0.094, 0.097, 0.087, 0.076, 0.113, 0.083, 0.12, 0.08, 0.087, 0.078, 0.074, 0.148, 0.136, 0.088, 0.095, 0.089, 0.066, 0.134, 0.079, 0.071, 0.096, 0.073, 0.124, 1.486, 0.076, 0.078, 0.131, 0.094, 0.086, 0.156, 0.086, 0.195, 0.08, 0.109, 0.099, 0.136, 0.135, 0.098, 0.081, 0.081, 0.094, 0.114, 0.079, 0.084, 0.081, 0.071, 0.078, 0.124, 0.075, 0.102, 0.078, 0.101, 0.106, 0.074, 0.088, 0.074, 0.084, 0.078, 0.103, 0.099, 0.082, 0.143, 0.083, 0.102, 0.083, 0.078, 0.077, 0.077, 0.088, 0.078, 0.077, 0.139, 0.079, 0.075, 0.077, 0.074, 0.078, 0.115, 0.079, 0.083, 0.149, 0.083, 0.085, 0.105, 0.103, 0.105, 0.141, 0.083, 0.082, 0.112, 0.087, 0.093, 0.077, 0.098, 0.086, 0.089, 0.084, 0.086, 0.09, 0.132, 0.08, 0.099, 0.11, 0.087, 0.061, 0.102, 0.071, 0.077, 0.068, 0.076, 0.068, 0.09, 0.07, 0.09, 0.1, 0.084, 0.085, 0.089, 0.095, 0.092, 0.121, 0.094, 0.088, 0.108, 0.098, 0.126, 0.153, 0.064, 0.078, 0.081, 0.083, 0.089, 0.072, 0.084, 0.089, 0.078, 0.07, 0.111, 0.084, 0.088, 0.074, 0.072, 0.076, 0.077, 0.095, 0.08, 0.08, 0.081, 0.087, 0.286, 0.078, 0.086, 0.112, 0.091, 0.088, 0.084, 0.077, 0.098, 0.084, 0.121, 0.066, 0.137, 0.076, 0.082, 0.076, 0.079, 0.08, 0.297, 0.076, 0.066, 0.087, 0.082, 0.094, 0.077, 0.126, 0.078, 0.07, 0.134, 0.156, 0.072, 0.127, 0.17, 0.1, 0.087, 0.085, 0.077, 0.076, 0.11, 0.072, 0.09, 0.078, 0.112, 0.068, 0.155, 0.092, 0.079, 0.077, 0.084, 0.078, 0.078, 0.093, 0.092, 0.07, 0.096, 0.124, 0.126, 0.171, 0.168, 0.099, 0.075, 0.095, 0.061, 0.078, 0.098, 0.098, 0.088, 0.091, 0.085, 0.077, 0.08, 0.123, 0.082, 0.076, 0.081, 0.092, 0.087, 0.081, 0.066, 0.083, 0.067, 0.066, 1.014, 0.068, 0.073, 0.079, 0.07, 0.073, 0.072, 0.08, 0.076, 0.088, 0.081, 0.084, 0.079, 0.241, 0.102, 0.073, 0.085, 0.072, 0.072, 0.124, 0.126, 0.08, 0.086, 0.072, 0.102, 0.078, 0.086, 0.101, 0.093, 0.095, 0.118, 0.101, 0.093, 0.08, 0.132, 0.069, 0.125, 0.107, 0.087, 0.137, 0.085, 0.08, 0.109, 0.066, 0.097, 0.111, 0.08, 0.087, 0.086, 0.093, 0.132, 0.112, 0.127, 0.185, 0.087, 0.079, 0.087, 0.083, 0.06, 0.073, 0.08, 0.095, 0.082, 0.082, 0.09, 0.09, 0.131, 0.095, 0.103, 0.076, 0.081, 0.075, 0.107, 0.078, 0.114, 0.471, 0.079, 0.087, 0.1, 0.107, 0.154, 0.098, 0.075, 1.219, 0.077, 0.091, 0.095, 0.078, 0.079, 0.096, 0.117, 0.085, 0.078, 0.076, 0.081, 0.078, 0.115, 0.071, 0.086, 0.072, 0.08, 0.274, 0.076, 0.084, 0.098, 0.092, 0.073, 0.082, 0.084, 0.081, 0.087, 0.091, 0.087, 0.085, 0.092, 0.082, 0.082, 0.066, 0.117, 0.078, 0.101, 0.08, 0.088, 0.089, 0.068, 0.08, 0.115, 0.088, 0.086, 0.082, 0.137, 0.082, 0.09, 0.081, 0.129, 0.067, 0.139, 0.069, 0.086, 0.09, 0.087, 0.874, 0.1, 0.082, 0.085, 0.076, 0.071, 0.07, 0.108, 0.12, 0.092, 0.183, 0.074, 0.085, 0.085, 0.081, 0.092, 0.091, 0.091, 0.114, 0.062, 0.089, 0.076, 0.07, 0.08, 0.09, 0.089, 0.08, 0.177, 0.099, 0.097, 0.072, 0.208, 0.089, 0.089, 0.108, 0.083, 0.102, 0.093, 0.082, 0.078, 0.079, 0.125, 0.082, 0.069, 0.084, 0.067, 0.075, 0.072, 0.094, 0.08, 0.084, 0.089, 0.122, 0.071, 0.072, 0.106, 0.198, 0.081, 0.089, 0.078, 0.082, 0.083, 0.081, 0.081, 0.082, 0.09, 0.085, 0.11, 0.167, 0.082, 0.077, 0.099, 0.084, 0.085, 0.081, 0.073, 0.136, 0.082, 0.074, 0.085, 0.095, 0.095, 0.065, 0.071, 0.138, 0.099, 0.086, 0.062, 0.084, 0.084, 0.084, 0.073, 0.096, 0.107, 0.079, 0.092, 0.13, 0.079, 0.067, 0.088, 0.083, 0.064, 0.079, 0.081, 0.061, 0.077, 0.102, 0.095, 0.085, 0.067, 0.113, 0.098, 0.094, 0.084, 0.084, 0.082, 0.085, 0.101, 0.097, 0.081, 0.103, 0.077, 0.113, 0.076, 0.091, 0.091, 0.07, 0.125, 0.092, 0.071, 0.083, 0.125, 0.284, 0.105, 0.086, 0.094, 0.071, 0.086, 0.122, 0.077, 0.138, 0.081, 0.109, 0.21, 0.082, 0.135, 0.089, 0.082, 0.089, 0.08, 0.067, 0.144, 0.085, 0.121, 0.073, 0.069, 0.079, 0.116, 0.067, 0.067, 0.064, 0.073, 0.07, 0.125, 0.073, 0.106, 0.08, 0.075, 0.088, 0.077, 0.094, 0.092, 0.125, 0.123, 0.081, 0.078, 0.099, 0.065, 0.101, 0.087, 0.09, 0.088, 0.21, 0.084, 0.145, 0.074, 0.102, 0.101, 0.069, 0.085, 0.088, 0.114, 0.087, 0.073, 0.084, 0.13, 0.285, 0.084, 0.111, 0.133, 0.092, 0.094, 0.082, 0.08, 0.084, 0.081, 0.083, 0.083, 0.089, 0.076, 0.059, 0.07, 0.089, 0.063, 0.074, 0.083, 0.51, 0.075, 0.066, 0.081, 0.077, 0.113, 0.073, 0.114, 0.09, 0.085, 0.07, 0.246, 0.064, 0.095, 0.074, 0.081, 0.088, 0.09, 0.08, 0.116, 0.075, 0.128, 0.071, 0.103, 0.063, 0.078, 0.126, 0.178, 0.079, 0.075, 0.072, 0.086, 0.093, 0.115, 0.075, 0.061, 0.068, 0.106, 0.089, 0.079, 0.106, 0.088, 0.098, 0.129, 0.094, 0.096, 0.08, 0.084, 0.07, 0.13, 0.075, 0.126, 0.076, 0.102, 0.08, 0.059, 0.102, 0.149, 0.289, 0.078, 0.058, 0.073, 0.081, 0.068, 0.077, 0.075, 0.107, 0.071, 0.072, 0.072, 0.086, 0.079, 0.081, 0.059, 0.119, 0.092, 0.074, 0.072, 0.061, 0.091, 0.091, 0.062, 0.079, 0.173, 0.067, 0.115, 0.081, 0.088, 0.095, 0.128, 0.088, 0.11, 0.098, 0.13, 0.086, 0.08, 0.089, 0.088, 0.088, 0.115, 0.248, 0.075, 0.078, 0.07, 0.07, 0.061, 0.094, 0.093, 0.078, 0.072, 0.07, 0.096, 0.082, 0.086, 0.082, 0.062, 0.091, 0.074, 0.088, 0.098, 0.086, 0.08, 0.092, 0.141, 0.069, 0.119, 0.061, 0.091, 0.063, 0.083, 0.08, 0.073, 0.083, 0.086, 0.079, 0.102, 0.07, 0.058, 0.089, 0.115, 0.075, 0.085, 0.081, 0.089, 0.089, 0.088, 0.073, 0.13, 0.172, 0.077, 0.111, 0.119, 0.129, 0.082, 0.086, 0.103, 0.106, 0.072, 0.097, 0.086, 0.095, 0.097, 0.07, 0.134, 0.071, 0.096, 0.081, 0.062, 0.075, 0.083, 0.12, 0.092, 0.098, 0.188, 0.082, 0.078, 0.126, 0.269, 0.065, 0.086, 0.075, 0.065, 0.074, 0.089, 0.217, 0.094, 0.071, 0.131, 0.087, 0.124, 0.139, 0.092, 0.088, 0.139, 0.083, 0.084, 0.109, 0.081, 0.097, 0.079, 0.083, 0.095, 0.109, 0.092, 0.143, 0.076, 0.075, 3.058, 0.082, 0.073, 0.089, 0.085, 0.076, 0.08, 0.094, 0.129, 0.174, 0.1, 0.214, 0.155, 0.085, 0.078, 0.087, 0.235, 0.165, 0.112, 0.08, 0.111, 0.08, 0.075, 0.07, 0.097, 0.074, 0.146, 0.149, 0.093, 0.073, 0.075, 0.119, 0.086, 0.078, 0.067, 0.067, 0.097, 0.07, 0.141, 0.121, 0.079, 0.076, 0.07]
            ],
            [
                [0.151, 0.101, 0.085, 0.061, 0.087, 0.068, 0.163, 0.079, 0.105, 0.077, 0.173, 0.122, 0.107, 0.135, 0.138, 0.081, 0.081, 0.083, 0.136, 0.087, 0.081, 0.104, 0.103, 0.095, 0.11, 0.09, 0.09, 0.817, 0.093, 0.074, 0.086, 0.104, 0.087, 0.143, 0.127, 0.081, 0.082, 0.082, 0.08, 0.108, 0.076, 0.102, 0.079, 0.124, 0.102, 0.095, 0.098, 0.095, 0.091, 0.095, 0.091, 0.089, 0.094, 0.129, 0.093, 0.079, 0.135, 0.116, 0.084, 0.082, 0.098, 0.116, 0.089, 0.134, 0.091, 0.101, 0.089, 0.093, 0.193, 0.081, 0.087, 0.147, 0.083, 0.078, 0.147, 0.097, 0.081, 0.088, 0.082, 0.092, 0.085, 0.084, 0.126, 0.091, 0.079, 0.092, 0.565, 0.075, 0.085, 0.097, 0.083, 0.108, 0.112, 0.083, 0.074, 0.119, 0.103, 0.073, 0.122, 0.087, 0.074, 0.064, 0.064, 0.07, 0.189, 0.099, 0.088, 0.102, 0.087, 0.093, 0.292, 0.085, 0.101, 0.113, 0.064, 0.07, 0.091, 0.095, 0.083, 0.058, 0.11, 0.126, 0.073, 0.102, 0.097, 0.101, 0.104, 0.084, 0.31, 0.075, 0.081, 0.074, 0.078, 0.106, 0.071, 0.075, 0.073, 0.085, 0.071, 0.09, 0.083, 0.079, 0.086, 0.125, 0.069, 0.082, 0.143, 0.094, 0.091, 0.081, 0.078, 0.078, 0.066, 0.065, 0.125, 0.068, 0.105, 0.066, 0.111, 0.072, 0.134, 0.114, 0.079, 0.113, 0.095, 0.26, 0.088, 0.078, 0.11, 0.117, 0.101, 0.165, 0.099, 0.103, 0.107, 0.078, 0.138, 0.066, 0.08, 0.109, 0.076, 0.072, 0.088, 0.114, 0.08, 0.103, 0.157, 0.082, 0.13, 0.085, 0.084, 0.088, 0.092, 0.085, 0.09, 0.084, 0.094, 0.075, 0.073, 0.285, 0.106, 0.109, 0.144, 0.111, 0.102, 0.085, 0.073, 0.088, 0.115, 0.077, 0.079, 0.077, 0.081, 0.1, 0.152, 0.08, 0.104, 0.126, 0.135, 0.084, 0.075, 0.087, 0.14, 0.096, 0.102, 0.165, 0.081, 0.077, 0.176, 0.106, 0.2, 0.106, 0.146, 0.076, 0.088, 0.783, 0.105, 0.074, 0.106, 0.135, 0.081, 0.1, 0.076, 0.077, 0.129, 0.127, 0.101, 0.184, 0.11, 0.105, 0.092, 0.128, 0.113, 0.12, 0.09, 0.099, 0.092, 0.072, 0.096, 0.082, 2.938, 0.092, 0.083, 0.086, 0.144, 0.101, 0.143, 0.084, 0.069, 0.074, 0.116, 0.102, 0.079, 0.093, 0.098, 0.08, 0.081, 0.11, 0.083, 0.088, 0.116, 0.087, 0.065, 0.079, 0.09, 0.085, 0.097, 0.087, 0.08, 0.26, 0.077, 0.098, 0.1, 0.087, 0.081, 0.1, 0.081, 0.114, 0.076, 0.122, 0.086, 0.085, 0.134, 0.077, 0.14, 0.149, 0.07, 0.065, 0.082, 0.119, 0.128, 0.076, 0.12, 0.075, 0.088, 0.085, 0.07, 0.138, 0.072, 0.11, 0.109, 0.097, 0.105, 0.082, 0.082, 0.154, 0.088, 0.078, 0.117, 0.108, 0.084, 0.1, 0.081, 0.076, 0.105, 0.088, 0.083, 0.078, 0.264, 0.088, 0.113, 0.092, 0.125, 0.068, 0.102, 0.083, 0.101, 0.143, 0.079, 0.108, 0.095, 0.097, 0.087, 0.135, 0.088, 0.08, 0.094, 0.086, 0.146, 1.463, 0.088, 0.082, 0.081, 0.085, 0.076, 0.07, 0.136, 0.139, 0.072, 0.076, 0.07, 0.131, 0.112, 0.098, 0.089, 0.216, 0.094, 0.074, 0.078, 0.082, 0.068, 0.093, 0.084, 0.073, 0.122, 0.232, 0.08, 0.084, 0.078, 0.092, 0.107, 0.09, 0.072, 0.089, 0.093, 0.057, 0.074, 0.108, 0.085, 0.119, 0.08, 0.069, 0.065, 0.079, 0.067, 0.101, 0.083, 0.081, 0.098, 0.092, 0.083, 0.084, 0.091, 0.081, 0.104, 0.109, 0.097, 0.099, 0.087, 0.066, 0.167, 0.074, 0.099, 0.074, 0.09, 0.08, 0.077, 0.068, 0.072, 0.071, 0.064, 0.071, 0.073, 0.064, 0.069, 0.114, 0.071, 0.084, 0.101, 0.076, 0.113, 0.094, 0.074, 0.132, 0.12, 0.115, 0.129, 0.084, 0.119, 0.092, 0.081, 0.09, 0.111, 0.084, 0.082, 0.063, 0.08, 0.073, 0.288, 0.11, 0.07, 0.197, 0.084, 0.073, 0.093, 0.143, 0.085, 0.08, 0.13, 0.143, 0.084, 0.108, 0.068, 0.075, 0.087, 0.083, 0.088, 0.13, 0.084, 0.08, 0.092, 0.088, 0.095, 0.078, 0.088, 0.114, 0.089, 0.111, 0.138, 0.074, 0.09, 0.096, 0.103, 0.071, 0.069, 0.097, 0.099, 0.082, 0.08, 0.093, 0.091, 0.084, 0.075, 0.082, 0.073, 0.093, 0.081, 0.109, 0.089, 0.094, 0.083, 0.113, 0.095, 0.08, 0.105, 0.145, 0.08, 0.081, 0.092, 0.079, 0.132, 0.086, 0.138, 0.095, 0.109, 0.089, 0.096, 0.307, 0.149, 0.079, 0.085, 0.103, 0.075, 0.076, 0.092, 0.096, 0.098, 0.085, 0.148, 0.397, 0.081, 0.081, 0.117, 0.08, 0.067, 0.095, 0.067, 0.122, 0.095, 0.075, 0.094, 0.074, 0.087, 0.076, 0.077, 0.078, 0.073, 0.191, 0.075, 0.082, 0.138, 0.131, 0.089, 0.091, 0.084, 0.084, 0.1, 0.069, 0.097, 0.097, 0.093, 0.08, 0.075, 0.108, 0.196, 0.061, 0.11, 0.108, 0.089, 0.119, 0.112, 0.084, 0.076, 0.101, 0.126, 0.115, 0.083, 0.105, 0.121, 0.078, 0.08, 0.145, 0.101, 0.102, 0.155, 0.122, 0.078, 0.075, 0.069, 0.092, 0.397, 0.09, 0.126, 0.086, 0.087, 0.081, 0.078, 0.088, 0.086, 0.143, 0.104, 0.093, 0.07, 0.093, 0.111, 0.137, 0.141, 0.173, 0.078, 0.154, 0.116, 0.063, 0.126, 0.077, 0.088, 0.104, 0.129, 0.077, 0.078, 0.088, 0.112, 0.081, 0.074, 0.134, 0.08, 0.307, 0.107, 0.111, 0.177, 0.091, 0.11, 0.076, 0.083, 0.075, 0.066, 0.099, 0.079, 0.073, 0.075, 0.086, 0.127, 0.132, 0.153, 0.071, 0.068, 0.079, 0.085, 0.11, 0.092, 0.11, 0.086, 0.089, 0.087, 0.108, 0.081, 0.077, 0.066, 0.072, 0.072, 0.087, 0.084, 0.093, 0.09, 0.077, 0.097, 0.074, 0.075, 0.088, 0.118, 0.09, 0.075, 0.078, 0.069, 0.108, 0.133, 0.133, 0.089, 0.093, 0.08, 0.077, 0.079, 0.084, 0.206, 0.084, 0.115, 0.084, 0.192, 0.068, 0.071, 0.09, 0.096, 0.083, 0.1, 0.077, 0.07, 0.075, 0.081, 0.072, 0.105, 0.09, 0.229, 0.091, 0.113, 0.061, 0.085, 0.078, 0.125, 0.085, 1.158, 0.089, 0.085, 0.069, 0.064, 0.104, 0.112, 0.079, 0.128, 0.086, 0.098, 0.078, 0.084, 0.104, 0.096, 0.086, 0.084, 0.209, 0.119, 0.089, 0.13, 0.14, 0.136, 0.066, 0.079, 0.087, 0.099, 0.077, 0.077, 0.083, 0.102, 0.292, 0.139, 0.077, 0.076, 0.081, 0.084, 0.107, 0.09, 0.132, 0.114, 0.095, 0.096, 0.139, 1.122, 0.07, 0.07, 0.077, 0.085, 0.079, 0.094, 0.077, 0.075, 0.122, 0.127, 0.079, 0.098, 0.106, 0.091, 0.088, 0.104, 0.084, 0.069, 0.122, 0.133, 0.107, 0.133, 0.082, 0.066, 0.071, 0.129, 0.093, 0.082, 0.127, 0.09, 0.123, 0.071, 0.112, 0.12, 0.109, 0.116, 0.09, 0.139, 0.082, 0.098, 0.087, 0.089, 0.084, 0.125, 0.102, 0.069, 0.107, 0.108, 0.073, 0.067, 0.148, 0.077, 0.112, 0.076, 0.086, 0.155, 0.115, 0.138, 0.095, 0.136, 0.087, 0.15, 0.088, 0.091, 0.096, 0.106, 0.086, 0.089, 0.105, 0.084, 0.105, 0.095, 0.109, 0.296, 0.153, 0.084, 0.091, 0.237, 0.09, 0.082, 0.197, 0.133, 0.122, 0.123, 0.113, 0.076, 0.078, 0.211, 0.067, 0.12, 0.121, 0.135, 0.086, 0.088, 0.087, 0.078, 0.097, 0.094, 0.119, 0.082, 0.085, 0.06, 0.068, 0.199, 0.102, 0.076, 0.09, 0.084, 0.124, 0.084, 0.138, 0.086, 0.103, 0.115, 0.101, 0.082, 0.105, 0.085, 0.091, 0.089, 0.11, 0.1, 0.123, 0.084, 0.168, 0.136, 0.102, 0.08, 0.108, 0.095, 0.123, 0.123, 0.148, 0.088, 0.089, 0.093, 0.097, 0.071, 0.098, 0.081, 0.064, 0.072, 0.085, 0.111, 0.087, 0.133, 0.079, 0.071, 0.089, 0.126, 0.075, 0.096, 0.105, 0.156, 0.091, 0.138, 0.066, 0.098, 0.101, 0.093, 0.09, 0.1, 0.112, 0.142, 0.076, 0.077, 0.072, 0.085, 0.124, 0.095, 0.125, 0.091, 0.113, 0.095, 0.109, 0.097, 0.084, 0.1, 0.085, 0.096, 0.088, 0.081, 0.082, 0.069, 0.077, 0.065, 0.189, 0.219, 0.085, 0.087, 0.087, 0.06, 0.085, 0.079, 0.102, 0.092, 0.086, 0.085, 0.077, 0.904, 0.072, 0.105, 0.112, 0.086, 0.125, 0.088, 0.097, 0.065, 0.122, 0.1, 0.122, 0.078, 0.105, 0.092, 0.133, 0.091, 0.061, 0.083, 0.063, 0.098, 0.114, 0.128, 0.133, 0.071, 0.36, 0.084, 0.088, 0.092, 0.094, 0.095, 0.092, 0.098, 0.093, 0.092, 0.091, 0.127, 0.086], [0.084, 0.113, 0.084, 0.077, 0.086, 0.102, 0.084, 0.111, 0.078, 0.128, 0.097, 0.089, 0.091, 0.144, 0.082, 0.073, 0.052, 0.083, 0.082, 0.082, 0.076, 0.098, 0.084, 0.094, 0.121, 0.15, 0.1, 0.083, 0.122, 0.111, 0.09, 0.139, 0.119, 0.088, 0.114, 0.135, 0.078, 0.143, 0.091, 0.077, 0.082, 0.071, 0.09, 0.176, 0.088, 0.102, 0.09, 0.098, 0.082, 0.139, 0.08, 0.085, 0.08, 0.318, 0.122, 0.114, 0.424, 0.081, 0.104, 0.083, 0.727, 0.072, 0.339, 0.081, 0.076, 0.099, 0.105, 0.083, 0.088, 0.092, 0.096, 0.085, 0.104, 0.082, 0.154, 0.104, 0.084, 0.079, 0.088, 0.09, 0.21, 0.102, 0.078, 0.079, 0.138, 0.101, 0.116, 0.07, 0.095, 0.12, 0.082, 0.093, 0.069, 0.099, 0.111, 0.086, 0.098, 0.104, 0.112, 0.074, 0.079, 0.1, 0.087, 0.111, 0.108, 0.068, 0.128, 0.099, 0.092, 0.105, 0.089, 0.116, 0.106, 0.085, 0.071, 0.07, 0.092, 0.133, 0.119, 0.122, 0.075, 0.126, 0.091, 0.111, 0.1, 0.076, 0.118, 0.117, 0.093, 0.065, 0.074, 0.079, 0.123, 0.124, 0.143, 0.08, 0.061, 0.076, 0.087, 0.175, 0.127, 0.127, 0.071, 0.104, 0.089, 0.101, 0.09, 0.103, 0.068, 0.09, 0.062, 0.101, 0.09, 0.089, 0.099, 0.069, 0.092, 0.13, 0.075, 0.217, 0.388, 0.068, 0.096, 0.109, 0.091, 0.082, 0.141, 0.092, 0.146, 0.087, 0.088, 0.079, 0.084, 0.163, 0.107, 0.098, 0.083, 0.073, 0.072, 0.105, 0.076, 0.076, 0.08, 0.065, 0.12, 1.531, 0.091, 0.071, 0.127, 0.118, 0.1, 0.125, 0.08, 0.188, 0.096, 0.107, 0.094, 0.174, 0.163, 0.093, 0.079, 0.064, 0.121, 0.124, 0.126, 0.138, 0.104, 0.074, 0.088, 0.102, 0.076, 0.086, 0.07, 0.096, 0.103, 0.089, 0.105, 0.092, 0.09, 0.083, 0.095, 0.108, 0.089, 0.148, 0.095, 0.104, 0.09, 0.075, 0.099, 0.1, 0.094, 0.092, 0.1, 0.139, 0.084, 0.095, 0.08, 0.079, 0.109, 0.114, 0.083, 0.085, 0.167, 0.085, 0.078, 0.118, 0.093, 0.121, 0.1, 0.092, 0.079, 0.089, 0.079, 0.102, 0.084, 0.082, 0.086, 0.088, 0.087, 0.072, 0.09, 0.096, 0.075, 0.119, 0.118, 0.09, 0.076, 0.103, 0.083, 0.086, 0.092, 0.086, 0.085, 0.088, 0.079, 0.072, 0.118, 0.1, 0.075, 0.104, 0.092, 0.088, 0.131, 0.103, 0.089, 0.116, 0.115, 0.097, 0.098, 0.077, 0.091, 0.097, 0.086, 0.098, 0.099, 0.125, 0.076, 0.093, 0.087, 0.134, 0.08, 0.083, 0.087, 0.074, 0.081, 0.062, 0.095, 0.069, 0.11, 0.068, 0.08, 0.309, 0.087, 0.073, 0.091, 0.093, 0.094, 0.084, 0.092, 0.117, 0.094, 0.11, 0.074, 0.127, 0.071, 0.129, 0.08, 0.09, 0.091, 0.31, 0.093, 0.086, 0.101, 0.091, 0.103, 0.061, 0.135, 0.077, 0.086, 0.131, 0.134, 0.077, 0.126, 0.171, 0.063, 0.096, 0.083, 0.083, 0.104, 0.107, 0.097, 0.083, 0.084, 0.113, 0.083, 0.132, 0.129, 0.088, 0.119, 0.099, 0.085, 0.09, 0.095, 0.072, 0.078, 0.125, 0.128, 0.138, 0.15, 0.178, 0.095, 0.077, 0.09, 0.08, 0.091, 0.102, 0.104, 0.086, 0.111, 0.103, 0.085, 0.101, 0.101, 0.075, 0.088, 0.09, 0.093, 0.071, 0.062, 0.075, 0.078, 0.085, 0.091, 1.139, 0.066, 0.088, 0.091, 0.087, 0.088, 0.073, 0.08, 0.089, 0.087, 0.09, 0.08, 0.078, 0.241, 0.119, 0.085, 0.079, 0.1, 0.088, 0.128, 0.126, 0.1, 0.107, 0.082, 0.112, 0.093, 0.1, 0.111, 0.085, 0.111, 0.148, 0.099, 0.12, 0.09, 0.145, 0.092, 0.083, 0.084, 0.083, 0.129, 0.075, 0.089, 0.115, 0.076, 0.118, 0.122, 0.082, 0.095, 0.07, 0.094, 0.118, 0.114, 0.115, 0.2, 0.09, 0.084, 0.087, 0.079, 0.07, 0.059, 0.08, 0.098, 0.115, 0.1, 0.081, 0.06, 0.125, 0.099, 0.07, 0.081, 0.08, 0.072, 0.099, 0.087, 0.124, 0.506, 0.105, 0.095, 0.12, 0.09, 0.156, 0.081, 0.067, 1.278, 0.093, 0.083, 0.078, 0.082, 0.074, 0.089, 0.106, 0.083, 0.076, 0.077, 0.096, 0.07, 0.134, 0.078, 0.094, 0.086, 0.089, 0.25, 0.095, 0.08, 0.106, 0.086, 0.079, 0.076, 0.09, 0.082, 0.086, 0.103, 0.086, 0.065, 0.076, 0.075, 0.067, 0.095, 0.106, 0.079, 0.086, 0.079, 0.084, 0.092, 0.072, 0.084, 0.116, 0.081, 0.07, 0.072, 0.134, 0.065, 0.093, 0.099, 0.123, 0.084, 0.146, 0.066, 0.099, 0.079, 0.089, 0.847, 0.102, 0.084, 0.066, 0.069, 0.1, 0.075, 0.1, 0.108, 0.075, 0.196, 0.094, 0.088, 0.068, 0.079, 0.072, 0.08, 0.074, 0.103, 0.066, 0.082, 0.064, 0.069, 0.075, 0.069, 0.074, 0.082, 0.147, 0.096, 0.092, 0.083, 0.237, 0.076, 0.07, 0.118, 0.074, 0.083, 0.072, 0.075, 0.077, 0.067, 0.126, 0.091, 0.112, 0.087, 0.085, 0.085, 0.083, 0.09, 0.069, 0.091, 0.088, 0.118, 0.075, 0.101, 0.119, 0.209, 0.082, 0.11, 0.089, 0.09, 0.075, 0.081, 0.094, 0.08, 0.077, 0.072, 0.107, 0.18, 0.063, 0.093, 0.102, 0.092, 0.087, 0.073, 0.097, 0.15, 0.078, 0.072, 0.09, 0.085, 0.083, 0.089, 0.072, 0.107, 0.071, 0.068, 0.077, 0.089, 0.076, 0.079, 0.072, 0.08, 0.09, 0.064, 0.08, 0.117, 0.077, 0.082, 0.098, 0.086, 0.084, 0.085, 0.077, 0.082, 0.081, 0.087, 0.074, 0.073, 0.067, 0.119, 0.08, 0.069, 0.091, 0.078, 0.071, 0.088, 0.094, 0.09, 0.087, 0.081, 0.078, 0.117, 0.075, 0.067, 0.071, 0.095, 0.14, 0.1, 0.078, 0.07, 0.108, 0.279, 0.107, 0.097, 0.101, 0.083, 0.076, 0.106, 0.083, 0.111, 0.088, 0.092, 0.181, 0.066, 0.078, 0.071, 0.075, 0.081, 0.07, 0.063, 0.121, 0.082, 0.113, 0.08, 0.082, 0.08, 0.139, 0.069, 0.074, 0.067, 0.093, 0.07, 0.085, 0.074, 0.1, 0.079, 0.076, 0.103, 0.086, 0.123, 0.087, 0.12, 0.127, 0.124, 0.069, 0.105, 0.073, 0.108, 0.082, 0.102, 0.123, 0.219, 0.072, 0.131, 0.1, 0.087, 0.085, 0.063, 0.099, 0.085, 0.116, 0.07, 0.067, 0.082, 0.1, 0.278, 0.095, 0.132, 0.108, 0.083, 0.067, 0.07, 0.077, 0.077, 0.076, 0.09, 0.079, 0.098, 0.078, 0.08, 0.073, 0.104, 0.072, 0.079, 0.084, 0.678, 0.087, 0.083, 0.083, 0.088, 0.126, 0.082, 0.109, 0.106, 0.078, 0.074, 0.272, 0.086, 0.091, 0.081, 0.093, 0.094, 0.085, 0.086, 0.122, 0.062, 0.114, 0.064, 0.085, 0.085, 0.093, 0.134, 0.194, 0.084, 0.07, 0.068, 0.109, 0.092, 0.111, 0.07, 0.081, 0.071, 0.108, 0.11, 0.087, 0.105, 0.075, 0.072, 0.118, 0.085, 0.074, 0.065, 0.093, 0.067, 0.125, 0.083, 0.104, 0.069, 0.095, 0.098, 0.066, 0.1, 0.121, 0.274, 0.093, 0.075, 0.073, 0.069, 0.098, 0.085, 0.07, 0.092, 0.076, 0.088, 0.084, 0.079, 0.078, 0.093, 0.068, 0.134, 0.102, 0.071, 0.084, 0.072, 0.138, 0.095, 0.06, 0.073, 0.191, 0.077, 0.119, 0.09, 0.092, 0.1, 0.123, 0.082, 0.099, 0.098, 0.132, 0.077, 0.091, 0.115, 0.099, 0.082, 0.125, 0.267, 0.116, 0.129, 0.083, 0.088, 0.094, 0.128, 0.095, 0.084, 0.079, 0.069, 0.085, 0.067, 0.093, 0.086, 0.08, 0.076, 0.082, 0.094, 0.118, 0.111, 0.083, 0.099, 0.135, 0.087, 0.095, 0.086, 0.071, 0.072, 0.071, 0.071, 0.061, 0.069, 0.091, 0.069, 0.104, 0.078, 0.082, 0.098, 0.111, 0.077, 0.061, 0.075, 0.077, 0.083, 0.07, 0.095, 0.191, 0.186, 0.095, 0.117, 0.109, 0.105, 0.076, 0.091, 0.096, 0.1, 0.076, 0.087, 0.09, 0.077, 0.092, 0.078, 0.104, 0.066, 0.067, 0.087, 0.071, 0.065, 0.091, 0.102, 0.072, 0.072, 0.201, 0.074, 0.072, 0.113, 0.259, 0.073, 0.078, 0.078, 0.07, 0.073, 0.086, 0.23, 0.089, 0.065, 0.127, 0.098, 0.128, 0.145, 0.103, 0.097, 0.137, 0.086, 0.107, 0.113, 0.069, 0.091, 0.101, 0.078, 0.115, 0.14, 0.101, 0.125, 0.086, 0.067, 3.096, 0.085, 0.089, 0.086, 0.076, 0.09, 0.075, 0.104, 0.125, 0.157, 0.092, 0.22, 0.143, 0.107, 0.094, 0.102, 0.264, 0.152, 0.123, 0.081, 0.126, 0.091, 0.103, 0.096, 0.129, 0.099, 0.153, 0.139, 0.125, 0.088, 0.094, 0.148, 0.107, 0.087, 0.117, 0.097, 0.096, 0.082, 0.131, 0.13, 0.097, 0.122, 0.097], [0.12, 0.081, 0.101, 0.082, 0.632, 0.075, 0.121, 0.105, 0.105, 0.079, 0.081, 0.126, 0.091, 0.15, 0.134, 0.114, 0.175, 0.102, 0.092, 0.092, 0.087, 0.157, 0.092, 0.09, 0.086, 0.078, 0.108, 0.067, 0.094, 0.087, 0.087, 0.092, 0.099, 0.103, 0.192, 0.12, 0.118, 0.08, 0.091, 0.104, 0.083, 0.082, 0.09, 0.083, 0.082, 0.1, 0.137, 0.099, 0.125, 0.085, 0.18, 0.091, 0.1, 0.09, 0.123, 0.089, 0.104, 0.13, 0.082, 0.089, 0.098, 0.071, 0.071, 0.1, 0.086, 0.086, 0.162, 0.083, 0.084, 0.113, 0.101, 0.122, 0.094, 0.156, 0.098, 0.135, 0.177, 0.088, 0.093, 0.088, 0.074, 0.081, 0.075, 0.083, 0.167, 0.064, 0.107, 0.097, 0.138, 0.087, 0.121, 0.2, 0.092, 0.135, 0.121, 0.132, 1.336, 0.129, 0.088, 0.09, 0.16, 0.108, 0.09, 0.249, 0.115, 0.089, 0.134, 0.08, 0.087, 0.195, 0.097, 0.129, 0.091, 0.096, 0.147, 0.098, 0.086, 0.091, 0.088, 0.101, 0.134, 0.138, 0.09, 0.103, 0.096, 0.084, 0.1, 0.089, 0.084, 0.102, 0.105, 0.123, 0.149, 0.112, 0.091, 0.206, 0.101, 0.109, 0.086, 0.079, 0.084, 0.206, 0.081, 0.137, 0.104, 0.105, 0.092, 0.09, 0.088, 0.114, 0.106, 0.082, 0.127, 0.138, 0.141, 0.078, 0.078, 0.123, 0.11, 0.098, 0.116, 0.091, 0.147, 0.106, 0.21, 0.086, 0.128, 0.104, 0.106, 0.1, 0.08, 0.335, 0.09, 0.084, 0.134, 0.152, 0.112, 0.115, 0.105, 0.142, 0.1, 0.089, 0.09, 0.094, 0.107, 0.093, 0.133, 0.102, 0.308, 0.092, 0.097, 0.139, 0.1, 0.089, 0.112, 0.1, 0.089, 0.085, 0.096, 0.108, 0.091, 0.097, 0.09, 0.145, 0.089, 0.091, 0.098, 0.083, 0.15, 0.154, 0.091, 0.287, 0.088, 0.086, 0.104, 0.096, 0.087, 0.101, 0.091, 0.088, 0.09, 0.091, 0.091, 0.085, 0.088, 0.087, 0.351, 0.088, 0.075, 0.094, 0.147, 0.146, 0.084, 0.156, 0.081, 0.091, 0.089, 0.094, 0.098, 0.146, 0.129, 0.163, 0.087, 0.136, 0.161, 0.109, 0.098, 0.108, 0.107, 0.093, 0.166, 0.086, 0.117, 0.135, 0.093, 0.087, 0.089, 0.899, 0.079, 0.146, 0.092, 0.083, 0.155, 0.092, 0.095, 0.084, 0.078, 0.088, 0.08, 0.088, 0.082, 0.093, 0.095, 0.126, 0.124, 0.102, 0.098, 0.135, 0.124, 0.083, 0.079, 0.084, 0.076, 0.122, 0.088, 0.137, 0.102, 0.221, 0.087, 0.098, 0.091, 0.093, 0.084, 0.087, 0.146, 0.095, 0.084, 0.107, 0.117, 0.093, 0.116, 0.099, 0.094, 0.097, 0.075, 0.091, 0.072, 0.065, 0.112, 0.072, 0.105, 0.112, 0.077, 0.104, 0.073, 0.124, 0.166, 0.093, 0.08, 0.079, 0.123, 0.108, 0.085, 0.125, 0.087, 0.094, 0.097, 0.088, 0.092, 0.077, 0.096, 3.321, 0.136, 0.086, 0.116, 0.112, 0.153, 0.102, 0.097, 0.089, 0.129, 0.106, 0.083, 0.082, 0.069, 0.07, 0.161, 0.09, 0.096, 0.164, 0.083, 0.092, 0.08, 0.087, 0.081, 0.123, 0.092, 0.078, 0.081, 0.084, 0.105, 0.104, 0.203, 0.079, 0.085, 0.08, 0.091, 0.09, 0.08, 0.138, 0.117, 0.089, 1.429, 0.146, 0.093, 0.117, 0.098, 0.128, 0.098, 0.214, 0.121, 0.148, 0.122, 0.084, 0.072, 0.275, 0.093, 0.07, 0.065, 0.075, 0.095, 0.085, 0.071, 0.087, 0.085, 0.083, 0.09, 0.09, 0.074, 0.113, 0.118, 0.079, 0.1, 0.088, 0.095, 0.087, 0.136, 0.118, 0.108, 0.096, 0.097, 0.09, 0.076, 0.088, 0.075, 0.078, 0.099, 0.076, 0.08, 0.063, 0.759, 0.099, 0.09, 0.117, 0.112, 0.081, 0.108, 0.077, 0.079, 0.104, 0.118, 0.09, 0.075, 0.08, 0.073, 0.256, 0.238, 0.085, 0.096, 0.084, 0.095, 0.12, 0.076, 0.115, 0.081, 0.097, 0.125, 0.099, 0.095, 0.086, 0.132, 0.091, 0.106, 0.093, 0.076, 0.087, 0.094, 0.092, 0.116, 0.09, 0.084, 0.096, 0.084, 0.328, 0.078, 0.076, 0.086, 0.088, 0.087, 0.091, 0.075, 0.091, 0.089, 0.081, 0.082, 0.089, 0.093, 0.091, 0.081, 0.112, 0.103, 0.088, 0.086, 0.069, 0.097, 0.111, 0.079, 0.082, 0.127, 0.08, 0.111, 0.069, 0.142, 0.073, 0.087, 0.1, 0.082, 0.09, 0.128, 0.171, 0.083, 0.111, 0.1, 0.292, 0.122, 0.078, 0.086, 0.095, 0.097, 0.084, 0.11, 0.079, 0.285, 0.092, 0.1, 0.091, 0.089, 0.094, 0.089, 0.102, 0.07, 0.071, 0.072, 0.095, 0.116, 0.069, 0.084, 0.075, 0.119, 0.08, 0.096, 0.116, 0.092, 0.082, 0.073, 0.089, 0.084, 0.09, 0.081, 0.101, 0.106, 0.103, 0.097, 0.097, 0.082, 0.093, 0.077, 0.089, 0.08, 0.068, 0.088, 0.081, 0.119, 0.086, 0.115, 0.106, 0.123, 0.071, 0.093, 0.171, 0.083, 0.094, 0.081, 0.084, 0.111, 0.097, 0.106, 0.086, 0.089, 0.082, 0.104, 0.116, 0.12, 0.083, 0.114, 0.079, 0.083, 0.096, 0.096, 0.085, 0.171, 0.085, 0.217, 0.085, 0.085, 0.126, 0.145, 0.096, 0.094, 0.098, 0.08, 0.089, 0.097, 0.082, 0.111, 0.096, 0.074, 0.068, 0.085, 0.091, 0.095, 0.085, 0.093, 0.092, 0.084, 0.082, 0.084, 0.304, 0.08, 0.081, 0.09, 0.13, 0.166, 0.098, 0.129, 0.079, 0.063, 0.103, 0.094, 0.07, 0.127, 0.076, 0.081, 0.087, 0.082, 0.109, 0.067, 0.078, 0.086, 0.079, 0.081, 0.083, 0.09, 0.079, 0.11, 0.092, 0.221, 0.207, 0.125, 0.07, 0.063, 0.076, 0.082, 0.071, 0.082, 0.126, 0.117, 0.095, 0.089, 0.082, 0.12, 0.093, 0.11, 0.082, 0.128, 0.079, 0.122, 0.096, 0.116, 0.129, 0.116, 0.078, 0.085, 0.083, 0.098, 0.089, 0.119, 0.109, 0.089, 0.095, 0.137, 0.105, 0.095, 0.132, 0.096, 0.085, 0.112, 0.113, 0.106, 0.1, 0.114, 0.075, 0.082, 0.073, 0.07, 0.082, 0.134, 0.107, 0.104, 0.41, 0.071, 0.09, 0.097, 0.067, 0.097, 0.076, 0.068, 0.061, 0.069, 0.105, 0.107, 0.093, 0.122, 0.101, 0.069, 0.113, 0.104, 0.075, 0.104, 0.142, 0.097, 0.096, 0.082, 0.086, 0.069, 0.079, 0.106, 0.088, 0.113, 0.113, 0.106, 0.129, 0.097, 0.103, 0.068, 0.163, 0.143, 0.079, 0.1, 0.091, 0.071, 0.068, 0.139, 0.151, 0.089, 0.113, 0.081, 0.085, 0.096, 0.082, 0.091, 0.095, 0.1, 0.083, 0.088, 0.077, 0.118, 0.097, 0.08, 0.09, 0.101, 0.087, 0.098, 0.126, 0.092, 0.078, 0.096, 0.091, 0.097, 0.088, 0.109, 0.082, 0.095, 0.089, 0.097, 0.08, 0.09, 0.116, 0.09, 0.168, 0.123, 0.148, 0.099, 0.102, 0.088, 0.094, 0.108, 0.083, 0.134, 0.087, 0.091, 0.083, 0.092, 0.078, 0.104, 0.094, 0.084, 0.122, 0.122, 0.11, 0.099, 0.097, 0.101, 0.101, 0.083, 0.071, 0.097, 0.066, 0.069, 0.094, 0.081, 0.063, 0.123, 0.091, 0.102, 0.107, 0.128, 0.097, 1.129, 0.079, 0.088, 0.069, 0.092, 0.092, 0.105, 0.124, 0.09, 0.433, 0.119, 0.099, 0.1, 0.095, 0.096, 0.083, 0.106, 0.093, 0.117, 0.107, 0.096, 0.077, 0.083, 0.08, 0.092, 0.102, 0.099, 0.078, 0.072, 0.107, 0.088, 0.139, 0.08, 0.11, 0.091, 0.082, 0.097, 0.084, 0.135, 0.093, 0.086, 0.14, 0.09, 0.096, 0.148, 0.12, 0.085, 0.098, 0.114, 0.101, 0.087, 0.147, 0.087, 0.079, 0.069, 0.073, 0.07, 0.088, 0.127, 0.092, 0.078, 0.082, 0.083, 0.088, 0.106, 0.078, 0.061, 0.073, 0.076, 0.085, 0.07, 0.076, 0.091, 0.091, 0.075, 0.103, 0.177, 0.18, 0.141, 0.085, 0.107, 0.098, 0.081, 0.095, 0.086, 0.084, 0.125, 0.101, 0.091, 0.084, 0.083, 0.078, 0.079, 0.079, 0.081, 0.098, 0.09, 0.124, 0.09, 0.128, 0.106, 0.128, 0.089, 0.096, 0.071, 0.077, 0.136, 0.114, 0.084, 0.085, 0.089, 0.09, 0.103, 0.073, 0.075, 0.104, 0.078, 0.091, 0.13, 0.07, 0.099, 0.098, 0.083, 0.086, 0.105, 0.309, 0.094, 0.086, 0.088, 0.087, 0.086, 0.117, 0.116, 0.095, 0.098, 0.106, 0.109, 0.098, 0.095, 0.093, 0.238, 0.113, 0.129, 0.083, 0.095, 0.127, 0.134, 0.08, 0.096, 0.088, 0.085, 0.096, 0.089, 0.064, 0.09, 0.126, 0.091, 0.075, 0.103, 0.09, 0.141, 0.124, 0.116, 0.09, 0.527, 0.068, 0.207, 0.089, 0.086, 0.081, 0.105, 0.105, 0.079, 0.095, 0.092, 0.108, 0.102, 0.102, 0.137, 0.128, 0.09, 0.077, 0.093, 0.086, 0.079, 0.095, 0.091, 0.075, 0.077, 0.119, 0.089, 0.145], [0.099, 0.064, 0.098, 0.08, 0.088, 0.092, 0.08, 0.078, 0.066, 0.067, 0.063, 0.183, 0.089, 0.084, 0.185, 0.081, 0.069, 0.102, 0.074, 0.065, 0.086, 0.095, 0.073, 0.125, 0.086, 0.091, 0.158, 0.135, 0.094, 0.117, 0.095, 0.108, 0.093, 0.104, 0.084, 0.103, 0.129, 0.116, 0.099, 0.084, 0.083, 0.098, 0.101, 0.109, 0.304, 0.084, 0.07, 0.085, 0.105, 0.1, 0.074, 0.077, 0.079, 0.12, 0.077, 0.09, 0.09, 0.093, 0.108, 0.088, 0.116, 0.09, 0.084, 0.154, 0.13, 0.082, 0.067, 0.068, 0.114, 0.072, 0.099, 0.079, 0.105, 0.079, 0.075, 0.097, 0.145, 0.135, 0.067, 0.068, 0.081, 0.079, 0.073, 0.084, 0.102, 0.072, 0.089, 0.095, 0.378, 0.105, 0.112, 0.096, 0.081, 0.083, 0.081, 0.073, 0.074, 0.075, 0.108, 0.105, 0.091, 0.074, 0.076, 0.112, 0.215, 0.093, 0.122, 0.077, 0.11, 0.077, 0.096, 0.129, 0.102, 0.084, 0.088, 0.083, 0.07, 0.099, 0.067, 0.323, 0.085, 0.071, 0.083, 0.075, 0.141, 0.084, 0.145, 0.104, 0.116, 0.098, 0.07, 0.073, 0.093, 0.076, 0.072, 0.094, 0.061, 0.116, 0.068, 0.061, 0.08, 0.839, 0.129, 0.085, 0.316, 0.097, 0.088, 0.071, 0.125, 0.07, 0.084, 0.099, 0.111, 0.164, 0.071, 0.127, 0.096, 0.1, 0.093, 0.094, 0.073, 0.112, 0.112, 0.22, 0.089, 0.093, 0.09, 0.129, 0.112, 0.113, 0.089, 0.072, 0.088, 0.151, 0.075, 0.079, 0.11, 0.083, 0.137, 0.091, 0.08, 0.086, 0.126, 0.122, 0.099, 0.102, 0.084, 0.114, 0.098, 0.156, 0.079, 0.073, 0.083, 0.09, 0.114, 0.134, 0.137, 0.067, 0.111, 0.099, 0.07, 0.079, 0.128, 0.068, 0.08, 0.071, 0.077, 0.093, 0.084, 0.114, 0.07, 0.09, 0.083, 0.077, 0.067, 0.069, 0.076, 0.082, 0.117, 0.09, 0.1, 0.096, 0.074, 0.076, 0.079, 0.118, 0.083, 0.112, 0.109, 0.083, 0.077, 0.075, 0.104, 0.098, 0.272, 0.214, 0.069, 0.119, 0.09, 0.079, 0.071, 0.075, 0.105, 0.089, 0.086, 0.092, 0.082, 0.097, 0.07, 0.103, 0.102, 0.07, 0.08, 0.072, 0.069, 0.089, 0.064, 0.502, 0.091, 0.127, 0.075, 0.089, 0.099, 0.139, 0.11, 0.093, 0.087, 0.073, 0.065, 0.136, 0.063, 0.082, 0.072, 0.064, 0.079, 0.074, 0.069, 0.108, 0.107, 0.109, 0.123, 0.061, 0.079, 0.07, 0.071, 0.11, 0.076, 0.07, 0.126, 0.098, 0.091, 0.07, 0.089, 0.092, 0.086, 0.093, 0.187, 0.073, 0.098, 0.085, 0.2, 0.097, 0.15, 0.074, 0.097, 0.142, 0.081, 0.101, 0.204, 0.092, 0.085, 0.159, 0.087, 0.085, 0.089, 0.083, 0.097, 0.091, 0.068, 0.088, 0.096, 0.071, 0.071, 0.089, 0.074, 0.091, 0.094, 0.09, 0.074, 0.1, 0.129, 0.074, 0.083, 0.092, 0.087, 0.07, 0.101, 0.068, 0.079, 0.085, 0.105, 0.087, 0.08, 0.067, 0.08, 0.072, 0.087, 0.09, 0.218, 0.076, 0.076, 0.079, 0.065, 0.068, 0.163, 0.068, 0.068, 0.088, 0.098, 0.083, 0.089, 0.072, 0.099, 3.036, 0.061, 0.104, 0.065, 0.076, 0.07, 0.118, 0.083, 0.082, 0.095, 0.125, 0.092, 0.086, 0.091, 0.108, 0.08, 0.156, 0.068, 0.103, 0.326, 0.079, 0.096, 0.069, 0.094, 0.16, 0.074, 0.063, 0.112, 0.073, 0.085, 0.076, 0.084, 0.077, 0.078, 0.099, 0.065, 1.296, 0.109, 0.071, 0.112, 1.457, 0.077, 0.135, 0.084, 0.067, 0.094, 0.155, 0.071, 0.141, 0.07, 0.082, 0.076, 0.124, 0.127, 0.08, 0.092, 0.07, 0.078, 0.079, 0.08, 0.062, 0.078, 0.122, 0.083, 0.083, 0.069, 0.074, 0.074, 0.072, 0.079, 0.075, 0.083, 0.089, 0.099, 0.083, 0.095, 0.116, 0.081, 0.085, 0.081, 0.095, 0.121, 0.113, 0.089, 0.105, 0.084, 0.091, 0.115, 0.077, 0.072, 0.069, 0.106, 0.129, 0.107, 0.112, 0.11, 0.08, 0.083, 0.069, 0.1, 0.111, 0.079, 0.103, 0.272, 0.079, 0.114, 0.083, 0.103, 0.119, 0.088, 0.113, 0.068, 0.135, 0.144, 0.146, 0.074, 0.102, 0.067, 0.065, 0.164, 0.08, 0.08, 0.11, 0.066, 0.19, 0.076, 0.076, 0.093, 0.065, 0.077, 0.09, 0.074, 0.067, 0.093, 0.096, 0.098, 0.074, 0.106, 0.085, 0.106, 0.085, 0.076, 0.108, 0.117, 0.14, 0.085, 0.084, 0.127, 0.07, 0.071, 0.078, 0.096, 0.101, 0.108, 0.07, 0.261, 0.074, 0.076, 0.066, 0.587, 0.148, 0.086, 0.14, 0.128, 0.07, 0.075, 0.086, 0.094, 0.087, 0.284, 0.088, 0.101, 0.088, 0.098, 0.093, 0.098, 0.092, 0.08, 0.079, 0.093, 0.088, 0.102, 0.08, 0.07, 0.082, 0.079, 0.126, 0.066, 0.076, 0.07, 0.168, 0.076, 0.097, 0.091, 0.077, 0.069, 0.1, 0.083, 0.078, 0.081, 0.091, 0.06, 0.077, 0.104, 0.096, 0.088, 0.091, 0.085, 0.103, 0.073, 0.064, 0.074, 0.076, 0.111, 0.078, 0.216, 0.076, 0.109, 0.228, 0.075, 0.131, 0.129, 0.226, 0.09, 0.072, 0.09, 0.065, 0.085, 0.065, 0.07, 0.081, 0.087, 0.076, 0.107, 0.068, 0.077, 0.075, 0.138, 0.082, 0.08, 0.101, 0.203, 0.087, 0.086, 0.066, 0.069, 0.073, 0.126, 0.08, 0.153, 0.09, 0.083, 0.086, 0.077, 0.075, 0.09, 0.133, 0.067, 0.119, 0.134, 0.089, 0.075, 0.128, 0.086, 0.081, 0.084, 0.069, 0.106, 0.067, 0.061, 0.16, 0.066, 0.093, 0.082, 0.076, 0.168, 0.087, 0.084, 0.1, 0.074, 0.131, 0.074, 0.077, 0.096, 0.09, 0.098, 0.166, 0.082, 0.081, 0.124, 0.25, 0.095, 0.07, 0.064, 0.065, 0.128, 0.084, 0.083, 0.079, 0.105, 0.07, 0.065, 0.121, 0.104, 0.079, 0.149, 0.096, 0.093, 0.091, 0.094, 0.099, 0.068, 0.066, 0.09, 0.083, 0.07, 0.083, 0.103, 0.091, 0.681, 0.079, 0.073, 0.1, 0.069, 0.101, 0.074, 0.089, 0.091, 0.075, 0.11, 0.07, 0.1, 0.082, 0.086, 0.092, 0.086, 0.111, 0.072, 0.132, 0.109, 0.075, 0.093, 0.093, 0.076, 0.093, 0.076, 0.074, 0.1, 0.084, 0.076, 0.156, 0.087, 0.414, 0.078, 0.105, 0.094, 0.066, 0.071, 0.099, 0.105, 0.083, 0.071, 0.128, 0.065, 0.18, 0.16, 0.082, 0.078, 0.066, 0.066, 0.076, 0.067, 0.103, 0.087, 0.079, 0.075, 0.091, 0.105, 0.074, 0.095, 0.098, 0.082, 0.079, 0.069, 0.08, 0.062, 0.074, 0.1, 0.083, 0.078, 0.068, 0.095, 0.075, 0.105, 0.131, 0.099, 0.074, 0.073, 0.062, 0.063, 0.104, 0.08, 0.1, 0.089, 0.075, 0.102, 0.107, 0.093, 0.067, 0.085, 0.063, 0.118, 0.112, 0.068, 0.085, 0.088, 0.065, 0.073, 0.067, 0.064, 0.067, 0.081, 0.271, 0.118, 0.099, 0.077, 0.117, 0.091, 0.07, 0.061, 0.068, 0.073, 0.07, 0.09, 0.096, 0.105, 0.106, 0.09, 0.078, 0.074, 0.083, 0.124, 0.075, 0.093, 0.068, 0.105, 0.076, 0.071, 0.076, 0.066, 0.276, 0.088, 0.065, 0.074, 0.082, 0.063, 0.104, 0.095, 0.091, 0.086, 0.078, 0.059, 0.084, 0.074, 0.069, 0.069, 0.087, 0.096, 0.074, 0.094, 0.066, 0.07, 0.09, 0.097, 0.087, 0.065, 0.09, 0.067, 0.098, 0.078, 0.087, 0.064, 0.096, 0.105, 0.071, 0.078, 0.096, 0.126, 0.089, 0.116, 0.099, 0.084, 0.069, 0.071, 0.096, 0.06, 0.071, 0.082, 0.126, 0.081, 0.074, 0.096, 0.085, 0.073, 0.148, 0.081, 0.074, 0.079, 0.073, 0.091, 0.089, 0.095, 0.089, 0.069, 0.075, 0.093, 0.082, 0.084, 0.071, 0.072, 0.171, 0.069, 0.103, 0.101, 0.088, 0.126, 0.1, 0.087, 0.083, 0.063, 0.093, 0.094, 0.069, 0.093, 0.074, 0.062, 0.096, 0.094, 0.102, 0.132, 0.073, 0.071, 0.06, 0.065, 0.121, 0.105, 0.084, 0.062, 0.094, 0.109, 0.066, 0.117, 0.085, 0.083, 0.07, 0.072, 0.069, 0.083, 0.104, 0.068, 0.077, 0.08, 0.084, 0.073, 0.076, 0.065, 0.102, 0.069, 0.105, 0.119, 0.152, 0.082, 0.081, 0.078, 0.088, 0.069, 0.086, 0.075, 0.067, 0.094, 0.082, 0.073, 0.086, 0.188, 0.08, 0.072, 0.079, 0.09, 0.088, 0.066, 1.078, 0.082, 0.104, 0.142, 0.12, 0.13, 0.104, 0.082, 0.125, 0.094, 0.114, 0.073, 0.088, 0.071, 0.097, 0.079, 0.07, 0.066, 0.293, 0.086, 0.116, 0.122, 0.085, 0.08, 0.156, 0.109, 0.075, 0.104, 0.102, 0.141, 0.075, 0.087, 0.068, 0.119, 0.083, 0.076, 0.098, 0.113, 0.09, 0.207, 0.112, 0.07, 0.089, 0.077, 0.084, 0.092, 0.077], [0.074, 0.081, 0.082, 0.094, 0.074, 0.078, 0.133, 0.084, 0.097, 0.207, 0.085, 0.09, 0.078, 0.135, 0.081, 0.357, 0.089, 0.238, 0.102, 0.068, 0.124, 0.091, 0.083, 0.063, 0.084, 0.087, 0.073, 0.075, 0.07, 0.084, 0.125, 0.068, 0.066, 0.077, 0.087, 0.066, 0.068, 0.096, 0.094, 0.208, 0.115, 0.126, 0.096, 0.125, 0.095, 0.074, 0.109, 0.058, 0.061, 0.072, 0.06, 0.063, 0.058, 0.077, 0.068, 0.08, 0.078, 0.116, 0.126, 0.089, 0.082, 0.108, 0.128, 0.127, 0.105, 0.109, 0.07, 0.139, 0.09, 0.131, 0.143, 0.144, 0.076, 0.084, 0.097, 0.144, 0.094, 0.136, 0.081, 0.083, 0.084, 0.111, 0.092, 0.083, 0.099, 0.11, 0.074, 0.092, 0.073, 0.074, 0.095, 0.083, 0.078, 0.084, 0.074, 0.092, 0.121, 0.077, 0.115, 0.078, 0.103, 0.135, 0.101, 0.099, 0.084, 0.08, 0.107, 0.093, 0.11, 0.082, 0.137, 0.08, 0.094, 0.069, 0.114, 0.09, 0.083, 0.083, 0.12, 0.163, 0.097, 0.132, 0.096, 0.076, 0.059, 0.069, 0.095, 0.092, 0.108, 0.086, 0.083, 0.146, 0.085, 0.11, 0.082, 0.081, 0.15, 0.145, 0.08, 0.09, 0.105, 0.086, 0.072, 0.058, 0.091, 0.074, 0.105, 0.134, 0.11, 0.086, 0.105, 0.134, 0.111, 0.077, 2.943, 0.084, 0.093, 0.085, 0.086, 0.085, 0.082, 0.074, 0.091, 0.103, 0.067, 0.089, 0.084, 0.078, 0.072, 0.298, 0.08, 0.064, 0.07, 0.068, 0.081, 0.089, 0.06, 0.063, 0.075, 0.143, 0.086, 0.077, 0.081, 0.09, 0.133, 0.138, 0.089, 0.287, 0.098, 0.085, 0.137, 0.095, 0.078, 0.084, 0.102, 0.096, 0.07, 0.213, 0.174, 0.068, 0.121, 0.129, 0.1, 0.088, 0.134, 0.108, 0.086, 0.097, 0.082, 0.084, 0.075, 0.085, 0.08, 0.073, 0.117, 0.085, 0.063, 0.071, 0.069, 0.101, 0.071, 0.106, 0.091, 0.093, 0.077, 0.121, 0.082, 0.107, 0.08, 0.079, 0.074, 0.144, 0.088, 0.072, 0.134, 0.104, 0.113, 0.086, 0.13, 0.13, 0.207, 0.095, 0.074, 0.081, 0.1, 0.099, 0.108, 0.092, 0.074, 0.071, 0.086, 0.088, 0.088, 0.082, 0.092, 0.093, 0.136, 0.109, 0.075, 0.103, 0.077, 0.087, 0.08, 0.102, 0.065, 0.086, 0.096, 0.087, 0.086, 0.088, 0.1, 0.071, 0.101, 0.102, 0.102, 0.084, 0.075, 0.088, 0.661, 0.116, 0.091, 0.121, 0.081, 0.136, 0.112, 0.084, 0.077, 0.1, 0.092, 0.13, 0.087, 0.09, 0.094, 0.075, 0.123, 0.091, 0.089, 0.082, 0.077, 0.083, 0.079, 0.065, 0.118, 0.079, 1.189, 0.094, 0.07, 0.067, 0.071, 0.075, 0.085, 0.088, 0.078, 0.094, 0.074, 0.08, 0.064, 0.068, 0.067, 0.078, 0.077, 0.068, 0.121, 0.069, 0.088, 0.082, 0.088, 0.13, 0.098, 0.08, 0.142, 0.12, 0.07, 0.153, 0.078, 0.15, 0.075, 0.076, 0.081, 0.103, 0.079, 0.072, 0.154, 0.111, 0.089, 0.157, 0.115, 0.104, 0.11, 0.171, 0.104, 0.118, 0.088, 0.095, 0.095, 0.084, 0.103, 0.069, 0.073, 0.116, 0.075, 0.066, 0.085, 0.082, 0.112, 0.108, 0.121, 0.089, 0.165, 0.091, 0.103, 0.064, 0.073, 0.074, 0.06, 0.173, 0.082, 0.096, 0.221, 0.086, 0.073, 0.088, 0.09, 0.136, 0.097, 0.085, 0.122, 0.086, 0.08, 0.081, 0.09, 0.08, 0.095, 0.076, 0.113, 0.093, 0.073, 0.073, 0.064, 0.063, 0.072, 0.079, 0.069, 0.093, 0.074, 0.081, 0.105, 0.087, 0.097, 0.093, 0.072, 0.213, 0.079, 0.081, 0.104, 0.082, 0.104, 0.073, 0.071, 0.075, 0.09, 0.096, 0.069, 0.105, 0.074, 0.062, 0.096, 0.084, 0.081, 0.127, 0.105, 0.084, 0.075, 0.2, 0.106, 0.201, 0.101, 0.061, 0.08, 0.084, 0.081, 0.081, 0.076, 0.095, 0.085, 0.099, 0.086, 0.09, 0.093, 0.08, 0.104, 0.089, 0.134, 0.089, 0.087, 0.102, 0.089, 0.089, 0.092, 0.11, 0.094, 0.091, 0.114, 0.093, 0.09, 0.111, 0.213, 0.095, 0.067, 0.078, 0.098, 0.077, 0.087, 0.104, 0.092, 0.084, 0.086, 0.072, 0.085, 0.084, 0.106, 0.077, 0.104, 0.123, 0.093, 0.081, 0.085, 0.085, 0.097, 0.102, 0.071, 0.071, 0.08, 0.068, 0.086, 0.12, 0.144, 0.08, 0.067, 0.075, 0.107, 0.085, 0.079, 0.082, 0.067, 0.073, 0.201, 0.077, 0.071, 0.086, 0.074, 0.387, 0.082, 0.124, 0.109, 0.084, 0.294, 0.403, 0.073, 0.084, 0.075, 0.067, 0.074, 0.084, 0.13, 0.112, 0.076, 0.115, 0.083, 0.072, 0.072, 0.098, 0.067, 0.106, 0.104, 0.082, 0.105, 0.165, 0.087, 0.078, 0.114, 0.132, 0.067, 0.067, 0.069, 0.057, 0.084, 0.074, 0.102, 0.09, 0.087, 0.151, 0.096, 0.089, 0.071, 0.078, 0.077, 0.093, 0.086, 0.081, 0.079, 0.128, 0.088, 0.069, 0.077, 0.073, 0.081, 0.084, 0.083, 0.147, 0.081, 0.078, 0.093, 0.078, 0.077, 0.081, 0.089, 0.087, 0.086, 0.083, 0.064, 0.069, 0.062, 0.09, 0.078, 0.099, 0.114, 0.108, 0.076, 0.084, 0.082, 0.076, 0.062, 0.063, 0.069, 0.08, 0.093, 0.091, 0.1, 0.091, 0.074, 0.081, 0.084, 0.138, 0.09, 0.093, 0.073, 0.079, 0.086, 0.092, 0.094, 0.096, 0.101, 0.074, 0.086, 0.073, 0.081, 0.069, 0.079, 0.113, 0.128, 0.072, 0.098, 0.093, 0.078, 0.065, 0.079, 0.082, 0.1, 0.084, 0.077, 0.073, 0.106, 0.09, 0.09, 0.112, 0.08, 0.083, 0.09, 0.097, 0.075, 0.077, 0.085, 0.083, 0.077, 0.073, 0.083, 0.094, 0.079, 0.077, 0.094, 0.134, 0.068, 0.069, 0.066, 0.091, 0.084, 0.095, 0.086, 0.068, 0.072, 0.071, 0.07, 0.071, 0.061, 0.089, 0.124, 0.117, 0.093, 0.063, 0.103, 0.111, 0.095, 0.128, 0.101, 0.081, 0.079, 0.107, 0.086, 0.099, 0.079, 0.084, 0.071, 0.102, 0.073, 0.098, 0.095, 0.078, 0.068, 0.068, 0.084, 0.064, 0.072, 0.075, 0.082, 0.081, 0.063, 0.16, 0.079, 0.109, 0.08, 0.071, 0.085, 0.448, 0.086, 0.08, 0.098, 0.107, 0.095, 0.08, 0.09, 0.089, 0.098, 0.129, 0.09, 0.086, 0.12, 0.073, 0.275, 0.132, 0.083, 0.088, 0.139, 0.097, 0.095, 0.08, 0.07, 0.107, 0.1, 0.096, 0.101, 0.088, 0.072, 0.079, 0.066, 0.085, 0.082, 0.103, 0.078, 0.07, 0.09, 0.088, 0.085, 0.081, 0.088, 0.085, 0.075, 0.062, 0.125, 0.081, 0.093, 0.108, 0.08, 0.08, 0.069, 0.087, 0.066, 0.28, 0.079, 0.078, 0.264, 0.084, 0.071, 0.185, 0.084, 0.101, 0.06, 0.071, 0.111, 0.073, 0.274, 0.075, 0.076, 0.08, 0.062, 0.079, 0.082, 0.097, 0.081, 0.086, 0.1, 0.095, 0.079, 0.104, 0.076, 0.076, 0.13, 0.084, 0.093, 0.092, 0.101, 0.204, 0.086, 0.079, 0.061, 0.123, 0.092, 0.101, 0.096, 0.098, 0.094, 0.095, 0.084, 0.093, 0.147, 0.094, 0.098, 0.066, 0.111, 0.131, 0.086, 0.098, 0.103, 0.133, 0.093, 0.098, 0.116, 1.033, 0.078, 0.079, 0.135, 0.15, 0.081, 0.086, 0.089, 0.169, 0.102, 0.086, 0.097, 0.102, 0.172, 0.161, 0.061, 0.065, 0.083, 0.079, 0.081, 0.062, 0.102, 0.162, 0.088, 0.064, 0.107, 0.115, 0.084, 0.127, 0.096, 0.238, 1.517, 0.072, 0.083, 0.093, 0.065, 0.085, 0.083, 0.077, 0.106, 0.093, 0.82, 0.139, 0.087, 0.107, 0.093, 0.111, 0.121, 0.124, 0.104, 0.092, 0.083, 0.088, 0.128, 0.085, 0.077, 0.087, 0.094, 0.076, 0.301, 0.073, 0.07, 0.072, 0.113, 0.088, 0.075, 0.083, 0.075, 0.078, 0.085, 0.084, 0.082, 0.154, 0.112, 0.085, 0.095, 0.081, 0.088, 0.154, 0.098, 0.083, 0.095, 0.09, 0.072, 0.083, 0.101, 0.068, 0.071, 0.077, 0.081, 0.072, 0.096, 0.086, 0.107, 0.073, 0.095, 0.092, 0.086, 0.086, 0.075, 0.069, 0.088, 0.13, 0.122, 0.085, 0.077, 0.067, 0.084, 0.08, 0.067, 0.082, 0.076, 0.112, 0.337, 0.137, 0.075, 0.085, 0.079, 0.093, 0.75, 0.114, 0.084, 0.083, 0.084, 0.121, 0.11, 0.09, 0.074, 0.089, 0.102, 0.197, 0.112, 0.091, 0.09, 0.068, 0.073, 0.076, 0.086, 0.124, 0.093, 0.095, 0.076, 0.087, 0.086, 0.098, 0.089, 0.081, 0.104, 0.073, 0.078, 0.228, 0.087, 0.185, 0.087, 0.081, 0.095, 0.088, 0.104, 0.093, 0.111, 0.098, 0.078, 0.101, 0.094, 0.125, 0.085, 0.122, 0.095, 0.242, 0.075, 0.09, 0.08, 0.087, 0.097, 0.096, 0.103, 0.098, 0.124, 0.085, 0.068, 0.085, 0.095, 0.136], [0.06, 0.068, 0.123, 0.084, 0.167, 0.097, 0.089, 0.073, 0.1, 0.109, 0.09, 0.089, 0.075, 0.104, 0.121, 0.089, 0.104, 0.085, 0.096, 0.085, 0.082, 0.09, 0.089, 0.102, 0.098, 0.091, 0.093, 0.096, 0.083, 0.066, 0.108, 0.079, 0.111, 0.094, 0.079, 0.083, 0.084, 0.088, 0.102, 0.12, 0.078, 0.109, 0.088, 0.182, 0.083, 0.088, 0.077, 0.072, 0.11, 0.071, 0.081, 0.074, 0.093, 0.104, 0.109, 0.068, 0.065, 0.063, 0.078, 0.245, 0.071, 0.075, 0.088, 0.082, 0.092, 0.082, 0.087, 0.088, 0.124, 0.118, 0.239, 0.084, 0.13, 0.125, 0.061, 0.103, 0.089, 0.115, 0.083, 0.082, 0.098, 0.114, 0.073, 0.077, 0.08, 0.079, 0.097, 0.08, 0.117, 0.113, 0.094, 0.071, 0.089, 0.071, 0.072, 0.069, 0.117, 0.133, 0.085, 0.076, 0.085, 0.076, 0.101, 0.082, 0.09, 0.089, 0.066, 0.086, 0.123, 0.073, 0.077, 0.072, 0.083, 0.093, 0.085, 0.076, 0.072, 0.088, 0.075, 0.066, 0.079, 0.077, 0.095, 0.074, 0.228, 0.082, 0.116, 0.078, 0.19, 0.069, 0.081, 0.083, 0.106, 0.082, 0.1, 0.152, 0.105, 0.216, 0.082, 0.072, 0.09, 0.092, 0.085, 0.062, 0.073, 0.124, 0.096, 0.093, 0.097, 0.076, 0.102, 0.134, 0.073, 0.109, 0.084, 0.079, 0.082, 0.098, 0.113, 0.097, 0.139, 0.086, 0.088, 0.082, 0.115, 0.089, 0.108, 0.083, 0.098, 0.077, 0.085, 0.075, 0.101, 0.134, 0.09, 0.079, 0.086, 0.111, 0.102, 0.087, 0.116, 0.129, 0.115, 0.091, 0.074, 0.091, 0.135, 0.097, 0.117, 0.128, 0.16, 0.119, 0.093, 0.141, 0.144, 0.123, 0.12, 0.122, 0.099, 0.077, 0.081, 0.084]
            ]
        ],
        [#dims
            [
                [0.173, 0.151, 0.172, 0.212, 0.17, 0.164, 0.223, 0.231, 0.152, 0.256, 0.157, 0.152, 0.166, 0.61, 0.159, 0.151, 0.157, 0.192, 0.139, 0.15, 0.128, 0.192, 0.17, 0.162, 0.143, 0.125, 0.21, 0.148, 0.254, 0.136, 0.195, 0.19, 0.142, 0.137, 0.231, 0.212, 0.126, 0.16, 0.122, 0.126, 0.119, 0.211, 0.121, 0.421, 0.161, 0.192, 0.178, 0.182, 0.189, 0.203, 0.14, 0.136, 0.231, 0.124, 0.111, 0.274, 0.206, 0.122, 0.153, 0.14, 0.191, 0.128, 0.151, 0.161, 0.327, 0.159, 0.142, 0.145, 0.126, 0.134, 0.143, 0.194, 0.126, 0.169, 0.141, 0.134, 0.096, 0.148, 0.2, 0.21, 0.177, 0.178, 0.283, 0.141, 0.177, 0.201, 0.186, 0.163, 0.15, 0.125, 0.111, 0.155, 0.138, 0.175, 0.188, 0.134, 0.155, 0.17, 0.234, 0.271, 0.178, 0.203, 0.166, 0.132, 0.144, 0.155, 0.156, 0.186, 0.195, 0.211, 0.118, 0.187, 0.217, 0.128, 0.182, 0.226, 0.198, 0.525, 0.185, 0.155, 0.132, 0.137, 0.204, 0.177, 0.14, 0.195, 0.177, 0.158, 0.152, 0.144, 2.159, 0.143, 0.224, 0.215, 0.138, 0.175, 0.145, 0.143, 0.21, 0.16, 0.156, 0.14, 0.166, 0.142, 0.28, 0.158, 0.149, 0.121, 0.238, 0.195, 0.141, 0.192, 0.241, 0.136, 0.18, 0.226, 0.208, 0.208, 0.195, 0.155, 0.199, 0.167, 0.21, 0.185, 0.26, 0.14, 0.134, 0.165, 0.14, 0.274, 0.201, 0.21, 0.162, 0.227, 0.159, 0.148, 0.152, 0.14, 0.155, 1.205, 0.159, 0.122, 0.138, 0.2, 0.129, 0.221, 0.215, 0.224, 0.164, 0.13, 0.149, 0.148, 0.243, 0.235, 0.193, 0.143, 0.167, 0.133, 0.179, 0.192, 0.134, 0.145, 0.202, 0.15, 0.167, 0.169, 0.218, 0.21, 0.17, 0.152, 0.183, 0.24, 0.145, 0.13, 0.144, 0.123, 0.144, 0.147, 0.143, 0.176, 0.202, 0.231, 0.238, 0.253, 0.217, 0.143, 0.189, 0.158, 0.139, 0.457, 0.224, 0.133, 0.209, 0.151, 0.22, 0.176, 0.141, 0.149, 0.242, 0.133, 0.12, 0.114, 0.155, 0.12, 0.168, 0.165, 0.122, 0.122, 0.12, 0.123, 0.094, 0.123, 0.105, 0.194, 0.119, 0.201, 0.123, 0.17, 0.125, 0.102, 0.155, 0.157, 0.141, 0.298, 0.18, 0.131, 0.123, 0.124, 0.163, 0.374, 0.126, 0.185, 0.157, 0.191, 0.182, 0.169, 0.111, 0.135, 0.21, 0.217, 0.181, 0.124, 0.126, 0.108, 0.13, 0.143, 0.174, 0.205, 0.205, 0.218, 0.189, 0.164, 0.152, 0.15, 0.183, 0.189, 0.152, 0.18, 0.136, 0.112, 0.357, 0.158, 0.182, 0.165, 0.173, 0.177, 0.156, 0.167, 0.173, 0.204, 0.125, 0.151, 0.148, 0.127, 0.108, 0.113, 0.13, 0.262, 0.141, 0.187, 0.13, 0.122, 0.108, 0.097, 0.11, 0.129, 0.185, 0.103, 0.147, 0.184, 0.129, 0.148, 0.115, 0.138, 0.122, 0.134, 0.152, 0.153, 0.103, 0.147, 0.117, 0.124, 0.177, 0.114, 0.13, 0.124, 0.196, 0.19, 0.217, 0.176, 0.118, 0.202, 0.138, 0.138, 0.166, 0.227, 0.179, 0.103, 0.243, 0.939, 0.115, 0.18, 0.171, 0.182, 0.143, 0.186, 0.125, 0.218, 0.144, 0.2, 0.197, 0.155, 0.127, 0.113, 0.293, 0.248, 0.114, 0.136, 0.151, 0.167, 0.15, 0.949, 0.186, 0.132, 0.207, 0.168, 0.17, 0.151, 0.134, 0.142, 0.164, 0.209, 0.169, 0.1, 0.175, 0.209, 0.203, 0.152, 0.191, 0.137, 0.17, 0.144, 0.146, 0.193, 0.141, 0.15, 0.182, 0.201, 0.122, 0.179, 0.161, 0.235, 0.199, 0.133, 0.187, 0.156, 0.136, 0.134, 0.362, 0.128, 0.241, 0.236, 0.187, 0.139, 0.154, 0.213, 0.192, 0.202, 0.13, 0.121, 0.127, 0.194, 0.133, 0.16, 0.115, 0.155, 0.167, 0.14, 0.126, 0.218, 0.114, 0.181, 0.16, 0.178, 0.21, 0.128, 0.159, 0.186, 0.156, 0.139, 0.125, 0.119, 0.121, 0.123, 0.17, 0.102, 0.161, 0.182, 0.187, 0.183, 0.108, 0.117, 0.142, 0.146, 0.12, 0.171, 0.139, 0.144, 0.143, 0.12, 0.124, 0.094, 0.104, 0.177, 0.196, 0.239, 0.128, 0.122, 0.108, 0.096, 0.1, 0.726, 0.155, 0.153, 0.124, 0.163, 0.202, 0.147, 0.15, 0.122, 0.119, 0.204, 0.169, 0.319, 0.128, 0.085, 0.098, 0.11, 0.117, 0.179], [ 0.152, 0.121, 0.164, 0.143, 0.156, 0.137, 0.217, 0.191, 0.128, 0.135, 0.12, 0.134, 0.199, 0.128, 0.167, 0.12, 0.11, 0.156, 0.176, 0.124, 0.129, 0.187, 0.136, 0.118, 0.176, 0.097, 0.278, 0.147, 0.355, 0.141, 0.599, 0.314, 0.122, 0.118, 0.116, 0.106, 0.125, 0.167, 0.104, 0.106, 0.209, 0.133, 0.178, 0.143, 0.198, 0.167, 0.141, 0.167, 0.102, 0.103, 0.109, 0.14, 0.106, 0.148, 0.113, 0.141, 0.13, 0.104, 0.156, 0.159, 0.144, 0.152, 0.146, 0.188, 0.102, 0.114, 0.163, 0.175, 0.115, 0.216, 0.162, 0.146, 0.133, 0.123, 0.131, 0.13, 0.11, 0.141, 0.124, 0.195, 0.363, 0.134, 0.12, 0.181, 0.185, 0.148, 0.163, 0.136, 0.109, 0.129, 0.1, 0.118, 1.186, 0.119, 0.164, 0.166, 0.194, 0.145, 0.166, 0.146, 0.114, 0.182, 0.205, 0.134, 0.145, 0.134, 0.138, 0.151, 0.161, 0.137, 0.154, 0.225, 0.103, 0.086, 0.107, 0.11, 0.136, 0.116, 0.144, 0.176, 0.155, 0.141, 0.128, 0.148, 0.144, 0.145, 0.116, 0.144, 0.129, 0.125, 0.171, 0.17, 0.215, 0.199, 0.141, 0.112, 0.124, 0.108, 0.142, 0.126, 0.135, 0.197, 0.186, 0.187, 0.18, 0.142, 0.134, 0.158, 0.115, 0.239, 0.15, 0.123, 0.143, 0.129, 0.139, 0.314, 0.129, 0.153, 0.151, 0.186, 0.185, 0.167, 0.136, 0.117, 0.294, 0.12, 0.139, 0.133, 0.128, 0.16, 0.175, 0.22, 0.166, 0.113, 0.129, 0.138, 0.169, 0.187, 0.143, 0.158, 0.115, 0.106, 0.223, 0.171, 0.264, 0.176, 0.163, 0.125, 0.115, 0.164, 0.159, 0.162, 0.121, 0.11, 0.123, 0.128, 0.97, 0.138, 0.11, 0.109, 0.115, 0.113, 0.104, 0.257, 0.107, 0.145, 0.161, 0.121, 0.178, 0.137, 0.154, 0.166, 0.205, 0.189, 0.236, 0.2, 0.228, 0.177, 0.151, 0.193, 0.147, 0.16, 0.141, 0.217, 0.104, 0.099, 0.116, 0.152, 0.122, 0.168, 0.135, 0.099, 0.163, 0.16, 0.427, 0.158, 0.183, 0.126, 0.952, 0.16, 0.141, 0.21, 0.155, 0.139, 0.242, 0.148, 0.083, 0.275, 0.124, 0.105, 0.115, 0.114, 0.13, 0.128, 0.178, 0.203, 0.11, 0.102, 0.117, 0.131, 0.115, 0.111, 0.134, 0.178, 0.208, 0.111, 0.163, 0.863, 0.159, 0.185, 0.227, 0.123, 0.172, 0.101, 0.106, 0.128, 0.177, 0.132, 0.145, 0.112, 0.197, 0.145, 0.235, 0.134, 0.135, 0.134, 0.134, 0.152, 0.126, 0.106, 0.098, 0.128, 0.15, 0.198, 0.148, 0.226, 0.124, 0.115, 0.108, 0.106, 0.145, 0.19, 0.135, 0.114, 0.116, 0.152, 0.125, 0.142, 0.117, 0.158, 0.101, 0.157, 0.084, 0.141, 0.118, 0.168, 0.149, 0.12, 0.144, 0.149, 0.161, 0.082, 0.136, 0.125, 0.111, 0.184, 0.168, 0.141, 0.129, 0.111, 0.153, 0.117, 0.131, 0.392, 0.132, 0.103, 0.117, 0.118, 0.2, 0.157, 0.139, 0.133, 0.169, 0.199, 0.119, 0.149, 0.116, 0.181, 0.162, 0.148, 0.113, 0.125, 0.207, 0.165, 0.147, 0.187, 0.165, 0.174, 0.223, 0.164, 0.151, 0.178, 0.165, 0.132, 0.165, 0.271, 0.209, 0.143, 0.131, 0.155, 0.134, 0.131, 0.123, 0.146, 0.139, 0.548, 0.121, 0.174, 0.143, 0.127, 0.26, 0.132, 0.115, 0.113, 0.179, 0.16, 0.107, 0.116, 0.221, 0.101, 0.12, 0.165, 0.098, 0.174, 0.161, 0.164, 0.181, 0.118, 0.151, 0.183, 0.186, 0.164, 0.167, 0.195, 0.306, 0.084, 0.117, 0.108, 0.114, 0.152, 0.149, 0.126, 0.205, 0.101, 0.145, 0.161, 0.199, 0.239, 0.128, 0.186, 0.142, 0.169, 0.128, 0.158, 0.204, 0.285, 0.151, 0.112, 0.194, 0.127, 0.186, 0.144, 0.149, 0.134, 0.204, 0.144, 0.186, 0.169, 0.131, 0.119, 0.126, 0.107, 0.152, 0.107, 0.208, 0.128, 0.172, 0.138, 0.217, 0.195, 0.17, 0.188, 0.165, 0.157, 0.124, 0.145, 0.217, 0.11, 0.102, 0.109, 0.159, 0.203, 0.103, 0.268, 0.127, 0.136, 0.137, 0.224, 0.15, 0.16, 0.179, 0.145, 0.116, 0.141, 0.147, 0.168, 0.169, 0.153, 2.091, 0.093, 0.092, 0.123, 0.19, 0.167, 0.256, 0.12, 0.244, 0.202, 0.16, 0.117, 0.137, 0.177, 0.17, 0.133, 0.18, 0.115, 0.1, 0.155, 0.188, 0.114], [ 0.162, 0.102, 0.484, 0.186, 0.125, 0.166, 0.173, 0.143, 0.155, 0.124, 0.173, 0.111, 0.109, 0.149, 0.138, 0.099, 0.108, 0.208, 0.187, 0.151, 0.135, 0.149, 0.122, 0.157, 0.134, 0.169, 0.152, 0.21, 0.159, 0.171, 0.126, 0.117, 0.1, 0.114, 0.088, 0.096, 0.105, 0.18, 0.203, 0.124, 0.108, 0.097, 0.161, 0.141, 0.188, 0.198, 0.143, 0.125, 1.031, 0.112, 0.155, 0.202, 0.133, 0.191, 0.226, 0.203, 0.105, 0.201, 0.141, 0.16, 0.209, 0.124, 0.13, 0.154, 0.15, 0.203, 0.205, 0.22, 0.174, 0.133, 0.228, 0.166, 0.157, 0.104, 0.143, 0.11, 0.186, 0.219, 0.161, 0.141, 0.127, 0.171, 0.201, 0.133, 0.124, 0.274, 0.133, 0.182, 0.124, 0.148, 0.111, 0.134, 0.161, 0.168, 0.287, 0.152, 0.126, 0.182, 0.107, 0.112, 0.104, 0.193, 0.132, 0.145, 0.172, 0.29, 0.104, 0.132, 0.12, 0.103, 0.121, 0.123, 0.108, 0.319, 0.137, 0.211, 0.18, 0.109, 0.141, 0.184, 0.163, 0.177, 0.251, 0.146, 0.141, 0.213, 0.213, 0.153, 0.716, 0.178, 0.106, 0.16, 0.121, 0.109, 0.107, 0.114, 0.158, 0.179, 0.192, 0.193, 0.134, 0.178, 0.149, 0.221, 0.117, 0.147, 0.133, 0.192, 0.122, 0.156, 0.148, 0.175, 0.12, 0.115, 0.168, 0.159, 0.151, 0.157, 0.213, 0.121, 0.187, 0.206, 0.112, 0.127, 0.111, 2.406, 0.164, 0.175, 0.18, 0.145, 0.227, 0.096, 0.095, 0.137, 0.165, 0.107, 0.106, 0.177, 0.105, 0.092, 0.218, 0.212, 0.124, 0.172, 0.194, 0.155, 1.178, 0.12, 0.11, 0.193, 0.148, 0.128, 0.256, 0.12, 0.099, 0.126, 0.099, 0.108, 0.133, 0.197, 0.188, 0.15, 0.126, 0.18, 0.159, 0.106, 0.13, 0.143, 0.219, 0.135, 0.677, 0.255, 0.174, 0.188, 0.178, 0.188, 0.12, 0.244, 0.248, 0.114, 0.167, 0.214, 0.127, 0.205, 0.137, 0.165, 0.139, 0.096, 0.143, 0.133, 0.116, 0.292, 0.105, 0.11, 0.124, 0.118, 0.132, 0.136, 0.146, 0.18, 0.12, 0.104, 0.148, 0.11, 0.171, 0.179, 0.175, 0.156, 0.121, 0.213, 0.105, 0.444, 0.201, 0.211, 0.119, 0.144, 0.273, 0.121, 0.114, 0.117, 0.128, 0.149, 0.197, 0.149, 0.208, 0.168, 0.138, 0.128, 0.141, 0.124, 0.149, 0.145, 0.152, 0.154, 0.154, 0.136, 0.151, 0.154, 0.164, 0.18, 0.122, 0.143, 0.164, 0.187, 0.174, 0.196, 0.232, 0.211, 0.154, 0.137, 0.185, 0.213, 0.14, 0.147, 0.097, 0.089, 0.124, 0.196, 0.126, 0.131, 0.135, 0.123, 0.117, 0.311, 0.131, 0.188, 0.178, 0.157, 0.172, 0.17, 0.164, 0.149, 0.16, 0.154, 0.144, 0.1, 0.195, 0.207, 0.308, 0.158, 0.131, 0.134, 0.239, 0.181, 0.122, 0.229, 0.211, 0.166, 0.171, 0.143, 0.139, 0.117, 0.127, 0.156, 0.12, 0.175, 0.179, 0.13, 0.174, 0.188, 0.172, 0.135, 0.109, 0.164, 0.347, 0.153, 0.154, 0.133, 0.108, 0.119, 0.141, 0.172, 0.172, 0.134, 0.161, 0.14, 0.128, 0.132, 0.195, 0.171, 0.206, 0.201, 0.226, 0.174, 0.154, 0.104, 0.179, 0.142, 0.133, 0.118, 0.137, 0.148, 0.128, 0.145, 0.142, 0.151, 0.125, 0.117, 0.132, 0.121, 0.132, 0.124, 0.14, 0.137, 0.178, 0.173, 0.155, 0.133, 0.129, 0.19, 0.114, 0.125, 0.181, 0.178, 0.188, 0.164, 0.144, 0.133, 0.188, 0.106, 0.129, 0.15, 0.167, 0.18, 0.963, 0.12, 0.128, 0.165, 0.336, 0.145, 0.134, 0.103, 0.123, 0.167, 0.1, 0.13, 0.162, 0.152, 0.128, 0.128, 0.119, 0.096, 0.098, 0.198, 0.136, 0.111, 0.222, 0.106, 0.147, 0.135, 0.107, 0.095, 0.126, 0.146, 0.117, 0.123, 0.145, 0.1, 0.155, 0.122, 0.205, 0.2, 0.248, 0.147, 0.131, 0.122, 0.13, 0.173, 0.123, 0.118, 0.128, 0.135, 0.161, 0.19, 0.174, 0.17, 0.13, 0.201, 0.127, 0.171, 0.145, 0.144, 0.149, 0.221, 0.147, 0.141, 0.295, 0.129, 0.138, 0.148, 0.191, 0.121, 0.17, 0.116, 0.272, 0.128, 0.127, 0.166, 0.117, 0.114, 0.122, 0.174, 0.11, 0.225, 0.214, 0.189, 0.425, 0.191, 0.108, 0.137, 0.115, 0.145, 0.159, 0.208, 0.101, 0.107, 0.102, 0.116, 0.146, 0.128], [ 0.162, 0.149, 0.133, 0.139, 0.111, 0.183, 0.09, 0.191, 0.133, 0.105, 0.11, 0.152, 0.091, 0.158, 0.135, 0.115, 0.096, 0.092, 0.162, 0.147, 0.121, 0.137, 0.31, 0.101, 0.13, 0.146, 0.158, 0.111, 0.151, 0.127, 0.148, 0.154, 0.181, 0.114, 0.189, 0.149, 0.106, 0.132, 0.205, 0.103, 0.106, 0.151, 0.202, 0.132, 0.347, 0.146, 0.113, 0.116, 0.125, 0.156, 0.092, 0.158, 0.192, 0.127, 0.112, 0.119, 0.133, 0.109, 0.103, 0.315, 0.123, 0.131, 0.164, 0.199, 0.157, 0.116, 0.1, 0.115, 0.134, 0.083, 0.679, 0.126, 0.278, 0.087, 0.12, 0.11, 0.189, 0.128, 0.096, 0.154, 0.157, 0.204, 0.095, 0.135, 0.119, 0.097, 0.139, 0.125, 0.14, 0.157, 0.098, 0.159, 0.129, 0.138, 0.155, 0.11, 0.138, 0.195, 0.164, 0.149, 0.115, 0.171, 0.099, 0.119, 0.154, 0.103, 0.131, 0.102, 0.128, 0.191, 0.114, 0.122, 0.199, 0.159, 0.2, 0.102, 0.124, 0.355, 0.105, 0.116, 0.102, 0.128, 0.101, 0.118, 0.139, 0.102, 0.136, 0.107, 0.434, 0.16, 0.138, 0.174, 0.141, 0.118, 0.18, 0.15, 0.139, 0.127, 0.118, 0.202, 0.113, 0.096, 0.119, 0.135, 0.151, 0.108, 0.106, 0.105, 0.179, 0.115, 0.208, 0.113, 0.16, 0.11, 0.205, 0.172, 0.105, 0.113, 0.121, 0.104, 0.103, 0.126, 0.12, 0.124, 0.101, 0.139, 0.127, 0.112, 0.197, 0.131, 0.134, 0.14, 0.144, 0.119, 0.233, 0.118, 0.106, 0.145, 0.117, 0.132, 0.115, 2.214, 0.156, 0.105, 0.149, 0.098, 0.158, 0.106, 0.151, 0.177, 0.151, 0.287, 0.111, 0.18, 0.121, 0.144, 0.135, 0.112, 0.173, 0.973, 0.15, 1.176, 0.144, 0.105, 0.147, 0.134, 0.103, 0.086, 0.165, 0.149, 0.123, 0.139, 0.146, 0.131, 0.127, 0.111, 0.101, 0.181, 0.112, 0.131, 0.101, 0.123, 0.201, 0.211, 0.129, 0.105, 0.09, 0.176, 0.129, 0.112, 0.089, 0.144, 0.121, 0.392, 0.133, 0.193, 0.168, 0.156, 0.142, 0.121, 0.097, 0.166, 0.131, 0.163, 0.109, 0.123, 0.094, 0.104, 0.088, 0.101, 0.096, 0.098, 0.127, 0.135, 0.117, 0.129, 0.087, 0.106, 0.101, 0.254, 0.116, 0.543, 0.14, 0.127, 0.105, 0.149, 0.291, 0.102, 0.111, 0.109, 0.094, 0.103, 0.119, 0.096, 0.135, 0.081, 0.168, 0.092, 0.103, 0.082, 0.101, 0.149, 0.108, 0.172, 0.113, 0.153, 0.099, 0.125, 0.131, 0.202, 0.208, 0.13, 0.259, 0.123, 0.121, 0.101, 0.102, 0.107, 0.106, 0.102, 0.14, 0.096, 0.197, 0.118, 0.099, 0.106, 0.151, 0.091, 0.091, 0.12, 0.126, 0.216, 0.202, 0.1, 0.129, 0.147, 0.162, 0.101, 0.089, 0.15, 0.095, 0.176, 0.094, 0.103, 0.154, 0.093, 0.255, 0.141, 0.094, 0.13, 0.118, 0.138, 0.212, 0.158, 0.196, 0.129, 0.109, 0.141, 0.192, 0.152, 0.193, 0.576, 0.134, 0.17, 0.127, 0.17, 0.13, 0.123, 0.101, 0.223, 0.204, 0.168, 0.128, 0.131, 0.149, 0.132, 0.204, 0.39, 0.121, 0.121, 0.141, 0.102, 0.173, 0.226, 0.19, 0.128, 0.125, 0.126, 0.136, 0.128, 0.137, 0.1, 0.118, 0.096, 0.087, 0.11, 0.089, 0.149, 0.183, 0.152, 0.115, 0.151, 0.209, 0.221, 0.227, 0.138, 0.16, 0.152, 0.127, 0.117, 0.106, 0.094, 0.265, 0.139, 0.126, 0.151, 0.105, 0.108, 0.107, 0.115, 0.103, 0.114, 0.139, 0.137, 0.176, 0.107, 0.289, 0.172, 0.15, 0.127, 0.126, 0.12, 0.124, 0.112, 0.126, 0.115, 0.16, 0.155, 0.127, 0.106, 0.127, 0.132, 0.134, 0.133, 0.11, 0.124, 0.139, 0.145, 0.158, 0.137, 0.147, 0.116, 0.186, 0.171, 0.124, 0.097, 0.128, 0.108, 0.095, 0.092, 0.107, 0.188, 0.126, 0.127, 0.137, 0.097, 0.099, 0.111, 0.109, 0.134, 0.114, 0.146, 0.109, 0.128, 0.204, 0.125, 0.172, 0.158, 0.139, 0.139, 0.154, 0.117, 0.138, 0.176, 0.136, 0.146, 0.216, 0.161, 0.146, 0.123, 0.095, 0.116, 0.105, 0.186, 0.098, 0.136, 0.926, 0.189, 0.162, 0.195, 0.173, 0.159, 0.112, 0.206, 0.108, 0.294, 0.194, 0.17, 0.192, 0.121, 0.227, 0.171, 0.136, 0.16, 0.172, 0.194, 0.233, 0.153, 0.132, 0.199], [ 0.122, 0.087, 0.091, 0.129, 0.219, 0.1, 0.151, 0.303, 0.212, 0.117, 0.182, 0.092, 0.121, 0.098, 0.121, 0.156, 0.144, 0.13, 0.156, 0.225, 0.165, 0.187, 0.126, 0.215, 0.139, 0.118, 0.134, 0.109, 0.161, 0.289, 0.169, 0.161, 0.167, 0.188, 0.195, 0.234, 0.15, 0.214, 0.211, 0.114, 0.144, 0.107, 0.157, 0.16, 0.108, 0.171, 0.135, 0.128, 0.162, 0.159, 0.147, 0.152, 0.122, 0.113, 0.139, 0.188, 0.178, 0.172, 0.155, 0.221, 0.172, 0.135, 0.137, 0.144, 0.151, 0.147, 0.137, 0.12, 0.174, 0.116, 0.155, 0.112, 0.131, 0.167, 0.166, 0.162, 0.11, 2.138, 0.105, 0.112, 0.114, 0.141, 0.147, 0.151, 0.305, 0.116, 0.138, 0.222, 0.109, 0.165, 0.121, 0.152, 0.194, 0.306, 0.123, 0.192, 0.144, 0.22, 0.216, 0.192, 0.222, 0.24, 0.147, 0.103, 0.175, 0.147, 0.115, 0.192, 0.116, 0.134, 0.126, 0.141, 0.152, 0.15, 0.124, 0.148, 0.11, 0.107, 0.097, 0.124, 0.218, 0.115, 0.126, 0.19, 0.113, 0.089, 0.124, 0.113, 0.174, 0.168, 0.129, 0.177, 0.15, 0.142, 0.14, 0.143, 0.121, 0.124, 0.094, 0.523, 0.151, 0.164, 0.121, 0.115, 0.189, 0.109, 0.162, 0.144, 0.147, 0.119, 0.159, 0.159, 0.936, 0.133, 0.127, 0.117, 0.144, 0.091, 0.116, 0.127, 0.102, 0.121, 0.143, 0.158, 0.138, 0.164, 0.175, 0.161, 0.101, 0.191, 0.121, 0.216, 0.214, 0.225, 0.234, 0.23, 0.138, 0.128, 0.14, 0.203, 0.117, 0.114, 0.188, 0.163, 0.181, 0.166, 0.11, 0.197, 0.123, 0.254, 0.109, 0.168, 0.144, 0.153, 0.119, 0.122, 0.153, 0.139, 0.133, 0.148, 0.144, 0.186, 0.153, 0.204, 0.2, 0.217, 0.15, 0.132, 0.13, 0.126, 0.141, 0.143, 0.139, 0.119, 0.153, 0.127, 0.225, 0.199, 0.111, 0.142, 0.135, 0.165, 0.142, 0.135, 0.102, 0.177, 0.18, 0.128, 0.123, 0.173, 0.107, 0.136, 0.14, 0.221, 0.108, 0.151, 0.12, 0.203, 0.113, 0.12, 0.123, 0.16, 0.136, 0.126, 0.143, 0.107, 0.103, 0.153, 0.171, 0.107, 0.168, 0.104, 0.113, 0.204, 0.124, 0.38, 0.169, 0.181, 0.514, 0.142, 0.128, 0.12, 0.194, 0.163, 0.168, 0.202, 0.154, 0.167, 0.158, 0.15, 0.179, 0.103, 0.139, 0.122, 0.163, 0.185, 0.147, 0.095, 0.147, 0.149, 0.156, 0.108, 0.106, 0.118, 0.187, 0.129, 0.142, 0.112, 0.094, 0.095, 0.127, 0.252, 0.152, 0.155, 0.125, 0.11, 0.118, 0.111, 0.125, 0.134, 0.124, 0.195, 0.154, 0.146, 0.219, 0.144, 0.2, 0.111, 0.147, 0.239, 0.195, 0.232, 0.095, 0.125, 0.16, 0.133, 0.15, 0.145, 0.143, 0.14, 0.126, 0.132, 0.112, 0.133, 0.098, 0.178, 0.109, 0.158, 0.152, 0.143, 0.125, 0.118, 0.137, 0.156, 0.117, 0.158, 0.157, 0.138, 0.165, 0.163, 0.122, 0.204, 0.165, 0.222, 0.12, 0.118, 0.123, 0.18, 0.198, 0.158, 0.116, 0.435, 0.142, 0.15, 0.154, 0.151, 0.22, 0.146, 0.188, 0.32, 0.125, 0.201, 0.117, 0.116, 0.126, 0.116, 0.105, 0.113, 0.125, 0.104, 0.124, 0.103, 0.108, 0.12, 0.152, 0.168, 0.141, 0.172, 0.254, 0.117, 0.276, 0.148, 0.115, 0.086, 0.123, 0.394, 0.119, 0.12, 0.177, 0.107, 0.14, 0.187, 0.111, 0.188, 0.14, 0.198, 0.129, 0.151, 0.116, 0.13, 0.148, 0.131, 0.169, 0.158, 0.156, 0.108, 0.207, 0.139, 0.942, 0.132, 0.181, 0.197, 0.192, 0.179, 0.181, 0.266, 0.114, 0.141, 0.12, 0.269, 0.12, 0.181, 0.228, 0.241, 1.176, 0.162, 0.14, 0.152, 0.177, 0.727, 0.131, 0.137, 0.196, 0.119, 0.12, 0.18, 0.126, 0.144, 0.323, 0.154, 0.153, 0.132, 0.125, 0.113, 0.203, 0.145, 0.252, 0.219, 0.181, 0.166, 0.143, 0.238, 0.148, 0.128, 0.165, 0.151, 0.121, 0.09, 0.117, 0.165, 0.262, 0.142, 0.137, 0.124, 0.149, 0.343, 0.127, 0.162, 0.587, 0.179, 0.151, 0.157, 0.128, 0.203, 0.142, 0.156, 0.119, 0.156, 0.119, 0.136, 0.145, 0.172, 0.163, 0.24, 0.23, 0.156, 0.107, 0.128, 0.179, 0.14, 0.22, 0.134, 0.247, 0.142, 0.13, 0.184, 0.179, 0.173, 0.107, 0.161]         
            ],
            [
                [0.206, 0.139, 0.151, 0.253, 0.213, 0.239, 0.23, 0.242, 0.135, 0.212, 0.154, 0.161, 0.174, 0.582, 0.142, 0.158, 0.175, 0.173, 0.161, 0.188, 0.156, 0.19, 0.176, 0.181, 0.178, 0.142, 0.207, 0.165, 0.189, 0.12, 0.247, 0.238, 0.176, 0.122, 0.281, 0.201, 0.164, 0.225, 0.148, 0.143, 0.131, 0.179, 0.137, 0.412, 0.149, 0.216, 0.185, 0.175, 0.222, 0.225, 0.152, 0.115, 0.235, 0.146, 0.165, 0.287, 0.195, 0.131, 0.137, 0.114, 0.198, 0.185, 0.236, 0.171, 0.367, 0.133, 0.157, 0.14, 0.184, 0.12, 0.156, 0.142, 0.125, 0.191, 0.17, 0.142, 0.145, 0.172, 0.149, 0.124, 0.126, 0.111, 0.251, 0.133, 0.164, 0.229, 0.186, 0.16, 0.222, 0.135, 0.129, 0.172, 0.173, 0.198, 0.149, 0.15, 0.162, 0.157, 0.23, 0.264, 0.225, 0.188, 0.226, 0.196, 0.16, 0.152, 0.148, 0.184, 0.162, 0.214, 0.164, 0.202, 0.236, 0.147, 0.199, 0.223, 0.17, 0.713, 0.148, 0.19, 0.137, 0.152, 0.189, 0.217, 0.155, 0.215, 0.193, 0.195, 0.144, 0.136, 2.191, 0.122, 0.206, 0.219, 0.136, 0.214, 0.134, 0.149, 0.186, 0.157, 0.189, 0.163, 0.18, 0.136, 0.276, 0.153, 0.112, 0.127, 0.179, 0.227, 0.147, 0.217, 0.249, 0.151, 0.252, 0.227, 0.177, 0.226, 0.184, 0.18, 0.211, 0.174, 0.261, 0.171, 0.208, 0.128, 0.151, 0.158, 0.157, 0.31, 0.193, 0.191, 0.16, 0.216, 0.229, 0.165, 0.241, 0.149, 0.146, 1.297, 0.176, 0.18, 0.139, 0.206, 0.132, 0.165, 0.148, 0.211, 0.141, 0.14, 0.171, 0.13, 0.305, 0.144, 0.163, 0.179, 0.15, 0.135, 0.139, 0.124, 0.105, 0.117, 0.155, 0.142, 0.158, 0.193, 0.202, 0.179, 0.139, 0.138, 0.216, 0.134, 0.157, 0.119, 0.127, 0.181, 0.115, 0.14, 0.154, 0.188, 0.137, 0.136, 0.128, 0.132, 0.206, 0.1, 0.188, 0.144, 0.141, 0.423, 0.23, 0.136, 0.207, 0.143, 0.202, 0.197, 0.135, 0.138, 0.271, 0.179, 0.182, 0.163, 0.245, 0.164, 0.162, 0.241, 0.165, 0.211, 0.146, 0.122, 0.164, 0.182, 0.174, 0.186, 0.15, 0.224, 0.141, 0.192, 0.115, 0.16, 0.206, 0.2, 0.177, 0.312, 0.249, 0.159, 0.133, 0.164, 0.166, 0.546, 0.145, 0.185, 0.152, 0.201, 0.234, 0.173, 0.112, 0.126, 0.238, 0.186, 0.185, 0.224, 0.154, 0.166, 0.161, 0.162, 0.227, 0.244, 0.159, 0.24, 0.214, 0.119, 0.119, 0.183, 0.162, 0.193, 0.151, 0.24, 0.088, 0.16, 0.494, 0.216, 0.144, 0.171, 0.156, 0.16, 0.129, 0.149, 0.167, 0.201, 0.204, 0.195, 0.199, 0.184, 0.172, 0.165, 0.223, 0.343, 0.168, 0.224, 0.172, 0.141, 0.169, 0.168, 0.155, 0.241, 0.207, 0.138, 0.194, 0.185, 0.125, 0.131, 0.113, 0.158, 0.119, 0.137, 0.166, 0.175, 0.166, 0.192, 0.14, 0.194, 0.223, 0.153, 0.152, 0.145, 0.222, 0.176, 0.233, 0.211, 0.149, 0.239, 0.144, 0.133, 0.173, 0.312, 0.22, 0.144, 0.186, 0.995, 0.145, 0.193, 0.146, 0.16, 0.16, 0.173, 0.167, 0.218, 0.185, 0.189, 0.239, 0.145, 0.147, 0.106, 0.295, 0.163, 0.155, 0.13, 0.148, 0.117, 0.137, 1.485, 0.145, 0.1, 0.167, 0.157, 0.213, 0.146, 0.12, 0.159, 0.197, 0.2, 0.225, 0.114, 0.25, 0.268, 0.169, 0.18, 0.215, 0.182, 0.217, 0.176, 0.142, 0.193, 0.193, 0.185, 0.219, 0.181, 0.129, 0.153, 0.155, 0.173, 0.155, 0.131, 0.168, 0.205, 0.166, 0.157, 0.366, 0.118, 0.345, 0.271, 0.228, 0.209, 0.148, 0.253, 0.167, 0.171, 0.12, 0.121, 0.157, 0.157, 0.192, 0.217, 0.132, 0.189, 0.167, 0.15, 0.194, 0.212, 0.169, 0.224, 0.194, 0.207, 0.178, 0.144, 0.194, 0.181, 0.195, 0.177, 0.15, 0.135, 0.106, 0.109, 0.137, 0.107, 0.159, 0.129, 0.146, 0.124, 0.119, 0.159, 0.201, 0.196, 0.165, 0.194, 0.199, 0.184, 0.173, 0.167, 0.155, 0.145, 0.157, 0.238, 0.266, 0.252, 0.144, 0.138, 0.18, 0.13, 0.117, 1.034, 0.201, 0.178, 0.151, 0.17, 0.19, 0.178, 0.188, 0.163, 0.135, 0.216, 0.219, 0.361, 0.137, 0.138, 0.14, 0.173, 0.154, 0.226], [0.189, 0.158, 0.178, 0.179, 0.175, 0.194, 0.208, 0.206, 0.156, 0.135, 0.156, 0.159, 0.167, 0.161, 0.213, 0.279, 0.162, 0.188, 0.214, 0.161, 0.138, 0.223, 0.138, 0.161, 0.162, 0.113, 0.353, 0.214, 0.401, 0.16, 0.591, 0.366, 0.159, 0.171, 0.19, 0.155, 0.174, 0.222, 0.148, 0.167, 0.259, 0.143, 0.193, 0.183, 0.193, 0.167, 0.14, 0.17, 0.162, 0.182, 0.18, 0.199, 0.154, 0.179, 0.19, 0.154, 0.16, 0.129, 0.17, 0.182, 0.166, 0.167, 0.175, 0.188, 0.136, 0.141, 0.224, 0.205, 0.09, 0.202, 0.237, 0.173, 0.145, 0.181, 0.161, 0.158, 0.18, 0.228, 0.236, 0.242, 0.594, 0.194, 0.147, 0.187, 0.234, 0.144, 0.224, 0.234, 0.163, 0.186, 0.154, 0.159, 1.267, 0.126, 0.161, 0.175, 0.22, 0.188, 0.222, 0.165, 0.113, 0.147, 0.155, 0.174, 0.194, 0.174, 0.169, 0.156, 0.149, 0.143, 0.181, 0.199, 0.196, 0.149, 0.228, 0.206, 0.219, 0.175, 0.182, 0.203, 0.181, 0.198, 0.233, 0.241, 0.227, 0.166, 0.145, 0.119, 0.109, 0.107, 0.182, 0.217, 0.254, 0.216, 0.177, 0.135, 0.162, 0.127, 0.162, 0.158, 0.183, 0.205, 0.235, 0.183, 0.201, 0.16, 0.139, 0.155, 0.148, 0.185, 0.158, 0.14, 0.151, 0.231, 0.175, 0.301, 0.145, 0.225, 0.203, 0.171, 0.141, 0.17, 0.217, 0.153, 0.318, 0.131, 0.183, 0.189, 0.202, 0.229, 0.183, 0.268, 0.12, 0.091, 0.137, 0.139, 0.177, 0.208, 0.199, 0.112, 0.094, 0.096, 0.114, 0.191, 0.243, 0.148, 0.145, 0.143, 0.149, 0.189, 0.166, 0.191, 0.168, 0.162, 0.147, 0.162, 0.989, 0.098, 0.109, 0.142, 0.144, 0.157, 0.166, 0.292, 0.129, 0.168, 0.19, 0.19, 0.204, 0.159, 0.161, 0.16, 0.187, 0.169, 0.16, 0.188, 0.196, 0.189, 0.19, 0.16, 0.151, 0.202, 0.176, 0.244, 0.165, 0.128, 0.13, 0.195, 0.146, 0.202, 0.15, 0.147, 0.17, 0.157, 0.421, 0.191, 0.188, 0.135, 1.005, 0.186, 0.183, 0.221, 0.173, 0.149, 0.179, 0.156, 0.136, 0.274, 0.151, 0.158, 0.134, 0.138, 0.143, 0.119, 0.14, 0.176, 0.169, 0.139, 0.153, 0.216, 0.146, 0.18, 0.166, 0.226, 0.171, 0.161, 0.195, 1.174, 0.148, 0.182, 0.189, 0.203, 0.223, 0.187, 0.154, 0.119, 0.174, 0.144, 0.131, 0.18, 0.192, 0.137, 0.307, 0.113, 0.171, 0.168, 0.157, 0.174, 0.194, 0.145, 0.145, 0.13, 0.168, 0.174, 0.205, 0.281, 0.172, 0.147, 0.151, 0.153, 0.177, 0.196, 0.141, 0.134, 0.115, 0.13, 0.106, 0.164, 0.109, 0.177, 0.129, 0.172, 0.135, 0.196, 0.157, 0.183, 0.175, 0.165, 0.18, 0.173, 0.159, 0.132, 0.194, 0.14, 0.119, 0.184, 0.161, 0.105, 0.159, 0.117, 0.148, 0.18, 0.176, 0.458, 0.213, 0.168, 0.214, 0.204, 0.308, 0.209, 0.162, 0.169, 0.197, 0.19, 0.127, 0.203, 0.145, 0.201, 0.156, 0.169, 0.13, 0.166, 0.183, 0.172, 0.151, 0.186, 0.173, 0.182, 0.24, 0.198, 0.177, 0.209, 0.219, 0.176, 0.215, 0.282, 0.155, 0.116, 0.124, 0.148, 0.125, 0.126, 0.127, 0.16, 0.144, 0.784, 0.141, 0.234, 0.184, 0.192, 0.282, 0.213, 0.167, 0.163, 0.197, 0.191, 0.157, 0.142, 0.245, 0.116, 0.136, 0.146, 0.135, 0.188, 0.183, 0.198, 0.165, 0.15, 0.199, 0.23, 0.179, 0.182, 0.191, 0.203, 0.321, 0.119, 0.145, 0.138, 0.192, 0.182, 0.174, 0.158, 0.21, 0.141, 0.192, 0.204, 0.254, 0.198, 0.142, 0.197, 0.188, 0.219, 0.198, 0.208, 0.206, 0.319, 0.193, 0.158, 0.135, 0.114, 0.155, 0.14, 0.138, 0.132, 0.179, 0.165, 0.194, 0.157, 0.115, 0.119, 0.142, 0.13, 0.179, 0.126, 0.154, 0.121, 0.171, 0.145, 0.245, 0.215, 0.16, 0.17, 0.137, 0.155, 0.131, 0.148, 0.16, 0.143, 0.15, 0.134, 0.198, 0.225, 0.136, 0.299, 0.187, 0.147, 0.179, 0.325, 0.212, 0.219, 0.185, 0.199, 0.155, 0.184, 0.17, 0.203, 0.213, 0.187, 2.187, 0.142, 0.111, 0.116, 0.207, 0.174, 0.361, 0.16, 0.297, 0.276, 0.183, 0.133, 0.166, 0.195, 0.21, 0.114, 0.144, 0.127, 0.109, 0.194, 0.154, 0.152], [0.158, 0.121, 0.663, 0.229, 0.188, 0.155, 0.178, 0.211, 0.234, 0.152, 0.207, 0.157, 0.157, 0.224, 0.154, 0.151, 0.206, 0.298, 0.211, 0.212, 0.147, 0.166, 0.168, 0.224, 0.209, 0.249, 0.126, 0.159, 0.183, 0.221, 0.185, 0.161, 0.131, 0.18, 0.167, 0.126, 0.142, 0.158, 0.186, 0.098, 0.155, 0.166, 0.193, 0.21, 0.224, 0.233, 0.22, 0.217, 1.579, 0.153, 0.221, 0.281, 0.158, 0.172, 0.217, 0.174, 0.138, 0.23, 0.139, 0.151, 0.217, 0.151, 0.156, 0.176, 0.162, 0.181, 0.199, 0.27, 0.183, 0.119, 0.236, 0.22, 0.193, 0.141, 0.148, 0.144, 0.186, 0.188, 0.165, 0.157, 0.18, 0.209, 0.254, 0.236, 0.196, 0.34, 0.142, 0.228, 0.215, 0.18, 0.11, 0.121, 0.135, 0.221, 0.334, 0.208, 0.167, 0.18, 0.141, 0.159, 0.145, 0.193, 0.143, 0.165, 0.19, 0.301, 0.142, 0.173, 0.159, 0.127, 0.114, 0.113, 0.127, 0.34, 0.123, 0.213, 0.216, 0.148, 0.152, 0.171, 0.192, 0.175, 0.175, 0.179, 0.155, 0.182, 0.206, 0.152, 1.042, 0.213, 0.112, 0.202, 0.132, 0.127, 0.107, 0.138, 0.193, 0.177, 0.194, 0.174, 0.124, 0.216, 0.223, 0.317, 0.134, 0.176, 0.14, 0.166, 0.189, 0.195, 0.18, 0.232, 0.184, 0.159, 0.203, 0.233, 0.187, 0.159, 0.237, 0.157, 0.194, 0.245, 0.146, 0.162, 0.156, 2.25, 0.212, 0.27, 0.228, 0.152, 0.21, 0.148, 0.141, 0.254, 0.246, 0.14, 0.18, 0.197, 0.135, 0.135, 0.181, 0.253, 0.126, 0.181, 0.208, 0.191, 1.29, 0.183, 0.214, 0.297, 0.231, 0.225, 0.32, 0.144, 0.152, 0.192, 0.137, 0.17, 0.159, 0.211, 0.227, 0.169, 0.161, 0.171, 0.235, 0.164, 0.146, 0.135, 0.195, 0.176, 0.594, 0.2, 0.207, 0.2, 0.212, 0.171, 0.15, 0.256, 0.262, 0.152, 0.19, 0.184, 0.123, 0.216, 0.144, 0.194, 0.208, 0.134, 0.237, 0.223, 0.166, 0.329, 0.146, 0.144, 0.163, 0.15, 0.138, 0.156, 0.158, 0.214, 0.196, 0.151, 0.177, 0.145, 0.206, 0.191, 0.201, 0.211, 0.153, 0.25, 0.194, 0.479, 0.177, 0.15, 0.16, 0.178, 0.305, 0.204, 0.143, 0.182, 0.131, 0.143, 0.232, 0.177, 0.205, 0.234, 0.124, 0.122, 0.137, 0.125, 0.126, 0.144, 0.124, 0.122, 0.162, 0.149, 0.211, 0.207, 0.182, 0.184, 0.165, 0.182, 0.18, 0.183, 0.189, 0.171, 0.172, 0.157, 0.148, 0.159, 0.244, 0.307, 0.213, 0.177, 0.148, 0.14, 0.15, 0.196, 0.156, 0.139, 0.158, 0.141, 0.139, 0.323, 0.143, 0.208, 0.183, 0.191, 0.237, 0.215, 0.23, 0.146, 0.165, 0.147, 0.16, 0.12, 0.175, 0.206, 0.499, 0.149, 0.15, 0.165, 0.203, 0.259, 0.144, 0.17, 0.21, 0.197, 0.223, 0.2, 0.192, 0.121, 0.114, 0.174, 0.134, 0.194, 0.21, 0.171, 0.19, 0.185, 0.206, 0.15, 0.168, 0.147, 0.568, 0.206, 0.235, 0.168, 0.141, 0.159, 0.179, 0.186, 0.224, 0.199, 0.209, 0.128, 0.172, 0.171, 0.188, 0.2, 0.183, 0.176, 0.245, 0.2, 0.189, 0.132, 0.207, 0.203, 0.139, 0.172, 0.164, 0.138, 0.128, 0.18, 0.158, 0.177, 0.16, 0.155, 0.17, 0.132, 0.133, 0.133, 0.157, 0.183, 0.182, 0.205, 0.192, 0.149, 0.188, 0.203, 0.137, 0.147, 0.191, 0.188, 0.171, 0.178, 0.189, 0.156, 0.185, 0.148, 0.134, 0.153, 0.191, 0.205, 1.022, 0.108, 0.15, 0.212, 0.517, 0.222, 0.173, 0.148, 0.159, 0.174, 0.144, 0.139, 0.188, 0.155, 0.185, 0.194, 0.177, 0.165, 0.155, 0.197, 0.216, 0.167, 0.251, 0.125, 0.191, 0.234, 0.129, 0.143, 0.188, 0.203, 0.113, 0.117, 0.162, 0.113, 0.153, 0.127, 0.209, 0.185, 0.262, 0.151, 0.135, 0.126, 0.178, 0.181, 0.161, 0.144, 0.135, 0.138, 0.221, 0.192, 0.202, 0.167, 0.131, 0.244, 0.159, 0.171, 0.173, 0.218, 0.236, 0.24, 0.183, 0.141, 0.336, 0.168, 0.165, 0.217, 0.205, 0.173, 0.185, 0.135, 0.296, 0.165, 0.169, 0.141, 0.139, 0.132, 0.18, 0.224, 0.132, 0.152, 0.163, 0.174, 0.428, 0.226, 0.157, 0.224, 0.157, 0.225, 0.188, 0.196, 0.133, 0.142, 0.146, 0.154, 0.188, 0.214], [0.125, 0.123, 0.137, 0.101, 0.096, 0.264, 0.147, 0.218, 0.182, 0.137, 0.178, 0.177, 0.139, 0.231, 0.214, 0.215, 0.163, 0.204, 0.224, 0.233, 0.142, 0.208, 0.324, 0.113, 0.182, 0.125, 0.193, 0.109, 0.197, 0.129, 0.18, 0.166, 0.199, 0.132, 0.155, 0.209, 0.191, 0.247, 0.233, 0.096, 0.101, 0.1, 0.117, 0.171, 0.507, 0.146, 0.127, 0.148, 0.162, 0.175, 0.118, 0.184, 0.221, 0.209, 0.186, 0.172, 0.195, 0.15, 0.179, 0.333, 0.139, 0.152, 0.202, 0.201, 0.188, 0.186, 0.17, 0.208, 0.192, 0.127, 1.054, 0.217, 0.337, 0.152, 0.14, 0.119, 0.195, 0.186, 0.146, 0.207, 0.221, 0.332, 0.208, 0.191, 0.177, 0.129, 0.202, 0.147, 0.194, 0.247, 0.178, 0.211, 0.24, 0.227, 0.252, 0.123, 0.29, 0.26, 0.225, 0.224, 0.167, 0.251, 0.169, 0.223, 0.24, 0.16, 0.181, 0.15, 0.192, 0.236, 0.191, 0.19, 0.169, 0.171, 0.132, 0.109, 0.166, 0.367, 0.173, 0.13, 0.158, 0.163, 0.137, 0.184, 0.206, 0.174, 0.159, 0.172, 0.422, 0.169, 0.21, 0.192, 0.199, 0.12, 0.172, 0.164, 0.148, 0.19, 0.176, 0.197, 0.205, 0.168, 0.188, 0.168, 0.187, 0.128, 0.14, 0.149, 0.216, 0.181, 0.257, 0.182, 0.223, 0.132, 0.232, 0.143, 0.117, 0.16, 0.155, 0.146, 0.152, 0.165, 0.156, 0.146, 0.13, 0.158, 0.114, 0.121, 0.213, 0.183, 0.219, 0.159, 0.221, 0.142, 0.333, 0.138, 0.126, 0.184, 0.144, 0.209, 0.192, 2.172, 0.204, 0.159, 0.186, 0.151, 0.202, 0.163, 0.191, 0.213, 0.211, 0.3, 0.16, 0.22, 0.114, 0.176, 0.213, 0.135, 0.15, 0.994, 0.251, 1.184, 0.198, 0.13, 0.23, 0.222, 0.195, 0.202, 0.214, 0.207, 0.165, 0.163, 0.214, 0.179, 0.14, 0.129, 0.166, 0.18, 0.141, 0.18, 0.171, 0.205, 0.192, 0.16, 0.126, 0.137, 0.154, 0.204, 0.179, 0.18, 0.137, 0.208, 0.206, 0.426, 0.21, 0.201, 0.193, 0.238, 0.193, 0.2, 0.143, 0.238, 0.251, 0.254, 0.161, 0.15, 0.157, 0.108, 0.143, 0.147, 0.218, 0.22, 0.206, 0.181, 0.199, 0.231, 0.159, 0.193, 0.224, 0.317, 0.151, 0.833, 0.297, 0.239, 0.157, 0.223, 0.308, 0.147, 0.186, 0.215, 0.163, 0.177, 0.224, 0.146, 0.189, 0.116, 0.186, 0.12, 0.142, 0.12, 0.138, 0.157, 0.109, 0.181, 0.133, 0.179, 0.124, 0.154, 0.274, 0.252, 0.231, 0.193, 0.304, 0.209, 0.14, 0.182, 0.162, 0.169, 0.185, 0.155, 0.236, 0.203, 0.26, 0.141, 0.146, 0.182, 0.204, 0.157, 0.17, 0.164, 0.205, 0.163, 0.199, 0.121, 0.175, 0.147, 0.201, 0.169, 0.16, 0.194, 0.163, 0.204, 0.136, 0.182, 0.192, 0.147, 0.255, 0.16, 0.144, 0.2, 0.146, 0.189, 0.202, 0.218, 0.212, 0.2, 0.197, 0.161, 0.181, 0.169, 0.215, 0.631, 0.21, 0.21, 0.159, 0.174, 0.22, 0.175, 0.144, 0.186, 0.174, 0.202, 0.174, 0.176, 0.178, 0.164, 0.215, 0.43, 0.169, 0.19, 0.211, 0.152, 0.236, 0.251, 0.242, 0.151, 0.146, 0.222, 0.191, 0.156, 0.167, 0.186, 0.187, 0.173, 0.169, 0.255, 0.192, 0.264, 0.231, 0.164, 0.154, 0.207, 0.284, 0.217, 0.213, 0.167, 0.248, 0.216, 0.171, 0.213, 0.159, 0.134, 0.308, 0.235, 0.193, 0.201, 0.147, 0.161, 0.22, 0.176, 0.168, 0.161, 0.179, 0.176, 0.201, 0.2, 0.316, 0.169, 0.169, 0.201, 0.201, 0.173, 0.181, 0.154, 0.173, 0.185, 0.226, 0.199, 0.189, 0.18, 0.267, 0.239, 0.213, 0.215, 0.194, 0.216, 0.212, 0.199, 0.217, 0.168, 0.194, 0.157, 0.145, 0.217, 0.141, 0.165, 0.175, 0.151, 0.165, 0.157, 0.211, 0.219, 0.21, 0.164, 0.211, 0.155, 0.158, 0.133, 0.133, 0.184, 0.143, 0.19, 0.133, 0.218, 0.194, 0.163, 0.197, 0.203, 0.195, 0.191, 0.206, 0.187, 0.203, 0.213, 0.182, 0.233, 0.304, 0.16, 0.183, 0.168, 0.113, 0.22, 0.14, 0.215, 0.148, 0.138, 1.021, 0.207, 0.204, 0.169, 0.202, 0.192, 0.144, 0.21, 0.128, 0.329, 0.199, 0.176, 0.189, 0.179, 0.147, 0.206, 0.153, 0.171, 0.179, 0.198, 0.291, 0.175, 0.199, 0.224], [0.165, 0.121, 0.153, 0.162, 0.24, 0.149, 0.215, 0.344, 0.298, 0.224, 0.246, 0.158, 0.226, 0.14, 0.15, 0.206, 0.15, 0.192, 0.241, 0.275, 0.221, 0.217, 0.166, 0.168, 0.15, 0.154, 0.116, 0.118, 0.184, 0.213, 0.21, 0.235, 0.21, 0.199, 0.235, 0.238, 0.147, 0.207, 0.174, 0.123, 0.209, 0.131, 0.203, 0.204, 0.149, 0.193, 0.125, 0.156, 0.201, 0.192, 0.201, 0.19, 0.124, 0.164, 0.153, 0.203, 0.178, 0.179, 0.158, 0.18, 0.183, 0.126, 0.149, 0.207, 0.168, 0.206, 0.201, 0.146, 0.204, 0.115, 0.178, 0.173, 0.203, 0.218, 0.22, 0.217, 0.168, 2.235, 0.141, 0.116, 0.137, 0.156, 0.245, 0.196, 0.343, 0.14, 0.135, 0.171, 0.137, 0.209, 0.145, 0.144, 0.229, 0.307, 0.136, 0.167, 0.152, 0.213, 0.246, 0.258, 0.242, 0.194, 0.189, 0.158, 0.186, 0.158, 0.126, 0.21, 0.142, 0.181, 0.197, 0.121, 0.164, 0.146, 0.144, 0.174, 0.118, 0.193, 0.181, 0.187, 0.277, 0.141, 0.177, 0.19, 0.144, 0.14, 0.17, 0.158, 0.149, 0.147, 0.135, 0.188, 0.15, 0.197, 0.175, 0.171, 0.184, 0.144, 0.145, 0.809, 0.186, 0.165, 0.174, 0.14, 0.222, 0.172, 0.195, 0.228, 0.151, 0.134, 0.164, 0.2, 1.513, 0.148, 0.145, 0.144, 0.176, 0.161, 0.138, 0.157, 0.171, 0.193, 0.171, 0.227, 0.166, 0.166, 0.246, 0.2, 0.141, 0.203, 0.134, 0.193, 0.22, 0.223, 0.251, 0.158, 0.157, 0.141, 0.157, 0.194, 0.133, 0.133, 0.203, 0.19, 0.263, 0.194, 0.14, 0.201, 0.139, 0.267, 0.13, 0.143, 0.135, 0.138, 0.109, 0.133, 0.17, 0.146, 0.169, 0.14, 0.156, 0.173, 0.142, 0.183, 0.186, 0.302, 0.132, 0.152, 0.146, 0.098, 0.201, 0.189, 0.1, 0.17, 0.167, 0.155, 0.278, 0.217, 0.128, 0.128, 0.158, 0.222, 0.193, 0.217, 0.152, 0.184, 0.2, 0.172, 0.173, 0.198, 0.142, 0.23, 0.177, 0.255, 0.131, 0.192, 0.167, 0.206, 0.179, 0.164, 0.175, 0.193, 0.186, 0.192, 0.197, 0.138, 0.14, 0.221, 0.192, 0.164, 0.211, 0.182, 0.135, 0.215, 0.131, 0.534, 0.157, 0.182, 0.878, 0.165, 0.173, 0.149, 0.194, 0.219, 0.21, 0.184, 0.214, 0.192, 0.181, 0.179, 0.194, 0.161, 0.164, 0.165, 0.22, 0.223, 0.237, 0.137, 0.151, 0.197, 0.185, 0.153, 0.148, 0.168, 0.203, 0.138, 0.202, 0.132, 0.141, 0.156, 0.148, 0.194, 0.208, 0.156, 0.147, 0.171, 0.135, 0.133, 0.167, 0.205, 0.14, 0.164, 0.132, 0.123, 0.193, 0.158, 0.151, 0.117, 0.138, 0.178, 0.201, 0.224, 0.15, 0.164, 0.181, 0.201, 0.174, 0.211, 0.151, 0.17, 0.148, 0.18, 0.139, 0.161, 0.134, 0.187, 0.143, 0.19, 0.184, 0.196, 0.154, 0.137, 0.164, 0.173, 0.136, 0.16, 0.174, 0.158, 0.147, 0.193, 0.144, 0.17, 0.201, 0.208, 0.14, 0.142, 0.137, 0.22, 0.245, 0.176, 0.124, 0.452, 0.159, 0.197, 0.165, 0.154, 0.214, 0.184, 0.217, 0.347, 0.15, 0.172, 0.14, 0.167, 0.176, 0.162, 0.147, 0.151, 0.173, 0.134, 0.177, 0.145, 0.146, 0.138, 0.205, 0.155, 0.174, 0.175, 0.296, 0.181, 0.303, 0.227, 0.22, 0.149, 0.199, 0.46, 0.169, 0.165, 0.148, 0.138, 0.156, 0.187, 0.145, 0.163, 0.19, 0.284, 0.158, 0.217, 0.169, 0.187, 0.194, 0.165, 0.215, 0.2, 0.22, 0.153, 0.207, 0.182, 1.04, 0.159, 0.24, 0.242, 0.217, 0.222, 0.203, 0.307, 0.142, 0.149, 0.154, 0.218, 0.12, 0.195, 0.231, 0.282, 1.187, 0.186, 0.159, 0.141, 0.219, 0.827, 0.147, 0.154, 0.233, 0.154, 0.203, 0.208, 0.16, 0.161, 0.346, 0.161, 0.213, 0.179, 0.156, 0.165, 0.233, 0.2, 0.197, 0.229, 0.2, 0.158, 0.156, 0.182, 0.155, 0.151, 0.162, 0.194, 0.166, 0.13, 0.11, 0.187, 0.168, 0.121, 0.147, 0.137, 0.234, 0.373, 0.143, 0.186, 0.673, 0.21, 0.195, 0.195, 0.196, 0.296, 0.174, 0.163, 0.147, 0.165, 0.151, 0.143, 0.156, 0.175, 0.203, 0.339, 0.223, 0.196, 0.169, 0.17, 0.194, 0.171, 0.186, 0.193, 0.275, 0.197, 0.129, 0.234, 0.244, 0.221, 0.135, 0.227], [0.094, 0.123, 0.197, 0.097, 0.136, 0.092, 0.163, 0.173, 0.13, 0.101, 0.12, 0.134, 0.162, 0.129, 0.102, 0.157, 0.164, 0.099, 0.152, 0.143, 0.143, 0.207, 0.103, 0.134, 0.151, 0.13, 0.156, 0.142, 0.118, 0.27, 0.112, 0.11, 0.113, 0.117, 0.123, 0.256, 0.184, 0.158, 0.125, 0.114, 0.16, 0.128, 0.127, 0.135, 0.142, 0.132, 0.096, 0.125, 0.186, 0.123, 0.12, 0.187, 0.149, 0.127, 0.191, 0.142, 0.155, 0.13, 0.129, 0.155, 0.128, 0.166, 0.309, 0.173, 0.229, 0.115, 0.176, 0.207, 0.299, 0.141, 0.138, 0.124, 0.168, 0.169, 0.184, 0.197, 0.208, 0.116, 0.18, 0.183, 0.173, 0.127, 0.15, 0.139, 0.137, 0.122, 0.158, 0.121, 0.152, 0.136, 0.149, 0.193, 0.116, 0.18, 0.156, 0.19, 0.143, 0.14, 0.131, 0.157, 0.137, 2.169, 0.131, 0.181, 0.104, 0.125, 0.199, 0.213, 0.155, 0.171, 1.113, 0.181, 0.31, 0.167, 0.169, 0.222, 0.215, 0.16, 0.121, 0.109, 0.117, 0.194, 0.202, 0.521, 0.157, 0.11, 0.131, 0.152, 0.176, 0.146, 0.169, 0.164, 0.192, 0.161, 0.188, 0.132, 0.182, 0.152, 0.167, 0.145, 0.232, 0.169, 0.118, 0.281, 0.148, 0.156, 0.222, 0.144, 0.125, 0.166, 0.192, 0.15, 0.184, 0.147, 0.11, 0.139, 0.156, 0.128, 0.152, 0.106, 0.185, 0.176, 0.228, 0.19, 0.221, 0.111, 0.199, 0.128, 0.177, 0.193, 0.189, 0.167, 0.191, 0.119, 0.12, 0.201, 0.147, 0.729, 0.125, 0.122, 0.136, 0.14, 0.098, 0.145, 0.109, 0.166, 0.195, 0.168, 0.147, 0.189, 0.152, 0.143, 0.216, 0.208, 0.139, 0.244, 0.164, 0.166, 0.133, 0.194, 0.162, 0.204, 0.104, 0.22, 0.294, 0.172, 0.227, 0.135, 0.146, 0.224, 0.204, 0.162, 0.17, 0.172, 0.13, 0.1, 0.127, 0.286, 0.168, 0.184, 0.159, 0.186, 0.14, 0.118, 0.197, 0.113, 0.116, 0.166, 0.163, 0.227, 0.187, 0.19, 0.973, 0.129, 0.15, 0.188, 0.179, 0.186, 0.199, 0.212, 0.209, 0.161, 0.136, 0.214, 0.169, 0.157, 0.14, 0.23, 0.197, 0.14, 0.348, 0.615, 0.189, 0.172, 0.23, 0.192, 0.179, 0.196, 0.138, 1.168, 0.179, 0.17, 0.148, 0.149, 0.185, 0.182, 0.22, 0.183, 0.158, 0.134, 0.134, 0.148, 0.204, 0.11, 0.171, 0.169, 0.199, 0.288, 0.18, 0.175, 0.232, 0.184, 0.283, 0.213, 0.191, 0.157, 0.151, 0.125, 0.118, 0.109, 0.125, 0.115, 0.212, 0.139, 0.146, 0.147, 0.165, 0.164, 0.139, 0.125, 0.109, 0.108, 0.204, 0.178, 0.206, 0.149, 0.15, 0.199, 0.276, 0.178, 0.128, 0.147, 0.157, 0.232, 0.15, 0.146, 0.205, 0.202, 0.176, 0.109, 0.154, 0.105, 0.186, 0.115, 0.115, 0.144, 0.159, 0.157, 0.123, 0.169, 0.128, 0.143, 0.178, 0.159, 0.299, 0.174, 0.171, 0.145, 0.157, 0.114, 0.122, 0.19, 0.123, 0.148, 0.12, 0.185, 0.125, 0.134, 0.112, 0.178, 0.16, 0.136, 0.123, 0.141, 0.111, 0.172, 0.138, 0.165, 0.126, 0.148, 0.191, 0.188, 0.129, 0.208, 0.113, 0.14, 0.196, 0.126, 0.111, 0.181, 0.227, 0.164, 0.15, 0.372, 0.162, 0.17, 0.14, 0.119, 0.465, 0.152, 0.164, 0.172, 0.122, 0.175, 0.171, 0.161, 0.143, 0.106, 0.284, 0.175, 0.123, 0.195, 0.147, 0.109, 0.152, 0.195, 0.182, 0.16, 0.151, 0.126, 0.159, 0.128, 0.162, 0.152, 0.118, 0.143, 0.203, 0.217, 0.126, 0.123, 0.108, 0.109, 0.137, 0.149, 0.141, 0.162, 0.302, 0.165, 0.111, 0.201, 0.145, 0.181, 0.426, 0.12, 0.129, 0.146, 0.164, 0.287, 0.399, 0.164, 0.184, 0.995, 0.187, 0.12, 0.126, 0.112, 0.153, 0.318, 0.238, 0.197, 0.144, 0.161, 0.123, 0.166, 0.192, 0.224, 0.149, 0.149, 0.192, 0.145, 0.108, 0.108, 0.113, 0.126, 0.14, 0.134, 0.162, 0.138, 0.101, 0.115, 0.132, 0.179, 0.126, 0.139, 0.152, 0.153, 0.152, 0.174, 0.22, 0.121, 0.155, 0.094, 0.121, 0.103, 0.212, 0.087, 0.093, 0.13, 0.122, 0.179, 0.157, 0.162, 0.15, 0.157, 0.146, 0.141, 0.219, 0.187, 0.191, 0.183, 0.207, 0.119, 0.274, 0.214, 0.198, 0.181, 0.128, 0.335, 0.251, 0.208], [0.108, 0.144, 0.149, 0.155, 0.274, 0.124, 0.103, 0.146, 0.119, 0.201, 0.189, 0.224, 0.11, 0.162, 0.163, 0.2, 0.181, 0.204, 0.096, 0.096, 0.117, 0.236, 0.18, 0.152, 0.178, 0.166, 0.187, 0.248, 0.25, 0.165, 0.143, 0.148, 0.169, 0.113, 0.187, 1.001, 0.154, 0.214, 0.221, 0.216, 0.343, 0.111, 0.724, 0.148, 0.191, 0.133, 0.266, 0.147, 0.143, 0.105, 0.116, 0.126, 0.476, 0.2, 0.126, 0.165, 0.164, 0.19, 0.132, 0.163, 0.201, 0.123, 0.147, 0.107, 0.194, 0.182, 0.151, 0.154, 0.121, 0.156, 0.194, 0.137, 0.21, 0.193, 0.137, 0.156, 0.204, 0.197, 0.209, 0.155, 0.148, 0.141, 0.168, 0.131, 0.175, 0.204, 0.218, 0.241, 0.15, 0.21, 0.168, 0.214, 0.148, 0.209, 0.167, 0.172, 0.175, 0.134, 0.175, 0.161, 0.21, 0.192, 0.162, 0.183, 0.115, 0.19, 0.165, 0.128, 0.111, 0.089, 0.103, 0.09, 0.221, 0.19, 0.17, 0.111, 0.111, 0.135, 0.117, 0.144, 0.123, 0.139, 0.161, 0.121, 0.136, 0.121, 0.11, 0.139, 0.161, 0.153, 0.128, 0.15, 0.152, 0.117, 0.256, 0.787, 0.145, 0.172, 0.175, 2.362, 0.145, 0.115, 0.145, 0.156, 0.122, 0.145, 0.187, 0.318, 0.142, 0.125, 0.108, 0.141, 0.177, 0.201, 0.16, 0.171, 0.128, 0.115, 0.137, 0.115, 0.155, 0.153, 0.141, 0.204, 0.142, 0.206, 0.114, 0.156, 0.124, 0.102, 0.14, 0.173, 0.165, 0.19, 0.173, 0.18, 0.112, 0.137, 0.114, 0.337, 1.006, 0.179, 0.136, 0.211, 0.187, 0.175, 0.192, 0.284, 0.171, 0.211, 0.23, 0.268, 0.186, 0.201, 0.167, 0.199, 0.15, 0.252, 0.204, 0.244, 0.206, 0.274, 0.187, 0.207, 0.247, 0.17, 0.179, 0.13, 0.153, 0.155, 0.187, 0.252, 0.345, 0.236, 0.213, 0.446, 0.179, 0.204, 0.159, 0.364, 0.209, 0.231, 0.168, 0.215, 0.227, 0.263, 0.214, 0.21, 0.124, 0.127, 0.157, 0.201, 0.131, 0.163, 0.171, 0.356, 0.151, 0.16, 0.169, 0.213, 0.166, 0.241, 0.199, 0.223, 0.141, 0.182, 0.191, 0.164, 0.169, 0.14, 0.19, 0.226, 0.221, 0.224, 0.177, 0.201, 0.192, 0.158, 0.192, 0.127, 0.124, 0.177, 0.141, 0.123, 0.188, 0.147, 0.202, 0.217, 0.198, 0.17, 0.204, 0.157, 0.167, 0.181, 0.145, 0.267, 0.169, 0.208, 0.233, 0.219, 0.207, 0.216, 0.184, 0.152, 0.209, 0.226, 0.454, 0.121, 0.196, 0.169, 0.143, 0.183, 0.226, 0.153, 0.218, 0.196, 0.19, 0.146, 0.148, 0.154, 0.225, 0.21, 0.196, 0.152, 0.19, 0.2, 0.168, 0.246, 0.245, 0.17, 0.226, 0.218, 0.189, 0.23, 0.129, 0.168, 0.167, 0.119, 0.113, 0.146, 0.18, 0.158, 0.197, 0.209, 0.216, 0.142, 0.17, 0.147, 0.194, 0.182, 0.184, 0.238, 0.238, 0.23, 0.237, 0.227, 0.138, 0.195, 0.209, 0.174, 0.161, 0.19, 0.211, 0.145, 0.134, 0.159, 0.194, 0.173, 0.257, 0.146, 0.334, 0.136, 0.149, 0.097, 0.117, 0.146, 0.144, 0.174, 0.154, 0.141, 0.163, 0.182, 0.187, 0.135, 0.155, 0.222, 0.18, 0.156, 0.228, 0.15, 0.222, 0.237, 0.146, 0.19, 0.162, 0.152, 0.241, 0.174, 0.168, 1.202, 0.195, 0.134, 0.227, 0.169, 0.227, 0.113, 0.17, 0.222, 0.138, 0.19, 0.185, 0.218, 0.243, 0.142, 0.157, 0.113, 0.263, 0.175, 0.171, 0.252, 0.226, 0.196, 0.143, 0.179, 0.327, 0.176, 0.138, 0.173, 0.138, 0.193, 0.164, 0.175, 0.299, 0.221, 0.205, 0.233, 0.124, 0.191, 0.211, 0.213, 0.136, 0.153, 0.141, 0.15, 0.188, 0.186, 0.176, 0.175, 0.22, 0.197, 0.212, 0.195, 0.2, 0.179, 0.154, 0.221, 0.189, 0.156, 0.243, 0.151, 0.206, 0.342, 0.208, 0.225, 0.152, 0.205, 0.246, 0.221, 0.23, 0.161, 0.154, 0.225, 0.234, 0.199, 0.153, 0.194, 0.134, 0.155, 0.16, 0.305, 0.12, 0.193, 0.208, 0.154, 0.217, 0.551, 0.151, 0.205, 0.2, 0.157, 0.214, 0.193, 0.219, 0.218, 0.229, 0.201, 0.195, 0.202, 0.204, 1.104, 0.288, 0.184, 0.152, 0.158, 0.187, 0.199, 0.215, 0.208, 0.204, 0.206, 0.225, 0.173, 0.155, 0.182, 0.153, 0.14, 0.216, 0.197, 0.246, 0.144], [0.114, 0.1, 0.149, 0.123, 0.119, 0.18, 0.12, 0.289, 0.159, 0.167, 0.184, 0.157, 0.129, 0.123, 0.122, 0.119, 0.148, 0.139, 0.151, 0.133, 0.176, 0.198, 0.176, 0.155, 0.158, 0.158, 0.19, 0.246, 0.122, 0.167, 0.145, 0.157, 0.36, 0.107, 0.143, 0.12, 0.134, 0.142, 0.179, 0.188, 0.155, 0.175, 0.161, 0.122, 0.147, 0.204, 0.114, 0.182, 0.166, 0.15, 0.122, 0.121, 0.141, 0.098, 0.218, 0.13, 0.114, 0.114, 0.122, 0.104, 0.096, 0.135, 0.12, 0.205, 0.322, 0.116, 0.13, 0.575, 0.139, 0.148, 0.196, 0.16, 0.14, 0.106, 1.077, 0.173, 0.108, 0.101, 0.142, 0.133, 0.125, 0.132, 0.165, 0.093, 0.123, 0.133, 0.169, 0.131, 0.169, 0.13, 0.131, 0.186, 0.134, 0.156, 0.224, 0.115, 0.151, 0.132, 0.171, 0.112, 0.156, 0.13, 0.173, 0.094, 0.146, 0.119, 0.149, 0.128, 0.171, 0.321, 0.142, 0.174, 0.162, 0.132, 0.155, 0.153, 0.289, 0.197, 0.178, 0.165, 0.168, 0.112, 0.154, 0.165, 0.107, 0.099, 0.445, 0.158, 0.116, 0.137, 0.178, 0.224, 0.152, 0.173, 0.124, 0.205, 0.139, 0.109, 0.191, 0.159, 0.148, 0.108, 0.156, 0.119, 0.123, 0.117, 0.181, 0.11, 0.165, 0.141, 0.157, 0.149, 0.159, 0.288, 0.154, 1.048, 0.122, 0.169, 0.2, 0.117, 0.19, 0.15, 0.097, 0.142, 0.145, 0.106, 0.166, 0.189, 0.168, 0.145, 0.139, 0.117, 0.156, 0.157, 0.132, 0.546, 0.161, 1.017, 0.203, 0.147, 0.147, 0.176, 0.132, 0.192, 0.144, 0.296, 0.176, 0.169, 0.196, 0.154, 0.125, 0.271, 0.096, 0.198, 0.137, 0.152, 0.172, 0.115, 0.128, 0.279, 0.11, 0.154, 0.137, 0.113, 0.137, 0.158, 0.133, 0.125, 0.129, 0.141, 0.116, 0.15, 0.123, 0.123, 0.263, 0.344, 0.166, 0.119, 0.115, 0.213, 0.212, 0.178, 0.108, 0.126, 0.115, 0.184, 0.148, 0.14, 0.15, 0.173, 0.133, 0.153, 0.17, 0.195, 0.154, 0.182, 0.189, 0.174, 0.206, 0.279, 0.218, 0.15, 0.155, 0.174, 0.214, 0.157, 0.246, 0.203, 0.171, 0.141, 0.207, 0.231, 0.204, 0.222, 0.194, 0.242, 0.142, 0.208, 0.218, 0.131, 0.115, 0.163, 0.145, 0.165, 0.126, 0.115, 0.149, 0.169, 0.199, 0.177, 0.144, 0.201, 0.148, 0.137, 0.138, 0.22, 0.154, 0.158, 0.161, 0.319, 0.582, 0.18, 0.143, 0.157, 0.178, 0.203, 0.121, 0.179, 0.154, 0.177, 0.155, 0.154, 0.273, 0.157, 0.184, 0.118, 0.191, 0.159, 0.159, 0.582, 0.131, 0.158, 0.127, 0.128, 0.111, 0.219, 0.192, 0.152, 0.208, 0.157, 0.256, 0.143, 0.518, 0.147, 0.162, 0.193, 0.208, 0.179, 0.117, 0.13, 0.152, 0.176, 0.248, 0.198, 0.221, 0.218, 0.183, 0.176, 0.182, 0.281, 0.141, 0.283, 0.291, 0.144, 0.243, 0.173, 0.123, 0.109, 0.104, 0.174, 0.179, 0.24, 0.163, 0.211, 0.171, 0.235, 0.226, 0.163, 0.136, 0.251, 0.157, 0.128, 0.118, 0.15, 0.147, 0.135, 0.132, 0.153, 0.219, 0.176, 0.173, 0.168, 0.206, 0.227, 0.173, 0.165, 0.211, 0.122, 0.187, 0.236, 0.176, 0.134, 0.149, 0.123, 0.13, 0.173, 0.175, 0.154, 0.225, 0.16, 0.215, 0.24, 0.153, 0.186, 0.22, 0.123, 0.2, 0.259, 0.169, 0.181, 0.246, 0.136, 0.181, 0.226, 0.214, 0.201, 0.145, 0.186, 0.193, 0.152, 0.127, 0.123, 0.206, 0.207, 0.136, 0.194, 0.217, 0.175, 0.18, 0.272, 0.211, 0.208, 0.165, 0.227, 0.15, 0.11, 0.184, 0.156, 0.166, 0.171, 0.288, 0.202, 0.211, 0.217, 0.269, 0.116, 0.162, 0.137, 0.167, 0.21, 0.177, 0.209, 0.119, 0.129, 0.186, 0.163, 0.151, 0.15, 0.159, 0.293, 0.166, 0.169, 0.141, 0.196, 0.14, 0.289, 0.225, 0.319, 0.149, 0.191, 0.153, 0.144, 0.226, 0.237, 0.137, 0.14, 0.166, 1.2, 0.301, 0.183, 0.18, 0.158, 0.18, 0.267, 0.131, 0.167, 0.149, 0.211, 0.13, 0.216, 0.266, 0.181, 0.216, 0.14, 2.137, 0.203, 0.275, 0.231, 0.139, 0.184, 0.205, 0.202, 0.265, 0.145, 0.13, 0.187, 0.214, 0.183, 0.205, 0.206, 0.125, 0.179, 0.192, 0.19, 0.131, 0.172, 0.234, 0.28, 0.182, 0.19], [0.177, 0.195, 0.131, 0.165, 0.171, 0.155, 0.287, 0.227, 0.183, 0.172, 0.253, 0.158, 0.155, 0.204, 0.185, 0.148, 0.152, 0.248, 0.149, 0.184, 0.211, 0.22, 0.19, 0.16, 0.197, 0.169, 0.195, 0.125, 0.223, 0.153, 0.598, 0.233, 0.206, 0.153, 0.238, 0.186, 0.322, 0.259, 0.189, 0.212, 0.212, 0.147, 0.157, 0.086, 0.164, 0.15, 0.174, 0.164, 0.214, 0.117, 0.206, 0.176, 0.221, 0.129, 0.15, 0.191, 0.217, 0.15, 0.185, 0.152, 0.158, 0.149, 0.27, 0.096, 0.095, 0.126, 0.093, 0.151, 0.137, 0.188, 0.184, 0.15, 0.163, 0.165, 0.252, 0.201, 0.208, 0.149, 0.2, 0.157, 0.205, 0.202, 0.27, 0.194, 0.258, 0.214, 0.146, 0.142, 0.238, 0.175, 0.239, 0.188, 0.213, 0.217, 0.272, 0.253, 0.304, 0.253, 0.194, 0.149, 0.298, 0.179, 0.178, 0.139, 0.212, 0.212, 0.246, 0.97, 0.178, 0.263, 0.163, 0.145, 0.215, 0.203, 0.194, 0.137, 0.175, 0.12, 0.302, 0.187, 0.129, 0.325, 0.15, 0.115, 0.174, 0.117, 0.173, 0.171, 0.154, 0.144, 0.284, 0.178, 0.136, 1.001, 0.197, 0.252, 0.148, 0.202, 0.169, 0.224, 0.53, 0.118, 0.111, 0.182, 0.193, 0.169, 0.126, 0.157, 0.142, 0.218, 0.184, 0.163, 0.175, 0.192, 0.139, 0.277, 0.12, 0.202, 0.193, 0.147, 0.197, 0.189, 0.568, 0.228, 0.145, 0.236, 0.181, 0.195, 0.23, 0.208, 0.147, 0.351, 0.15, 0.135, 0.204, 0.193, 0.239, 0.362, 0.385, 0.155, 0.142, 0.121, 0.204, 0.214, 0.195, 0.181, 0.197, 0.211, 0.15, 0.151, 0.192, 0.137, 0.224, 0.137, 0.198, 0.145, 0.231, 0.227, 0.181, 0.216, 0.16, 0.194, 0.197, 0.187, 0.145, 0.324, 0.109, 0.118, 0.141, 0.109, 0.14, 0.207, 0.114, 0.19, 0.132, 0.209, 0.213, 0.163, 0.177, 0.193, 0.164, 0.141, 0.21, 0.17, 0.144, 0.138, 0.164, 0.135, 0.14, 0.14, 0.193, 0.18, 0.188, 0.196, 0.191, 0.115, 0.2, 1.264, 0.2, 0.235, 0.238, 0.24, 0.23, 0.156, 0.154, 0.15, 0.143, 0.165, 0.125, 0.141, 0.136, 0.132, 0.153, 0.211, 0.192, 0.251, 0.195, 0.147, 0.155, 0.198, 0.149, 0.253, 0.174, 0.275, 0.156, 0.117, 0.152, 0.188, 0.166, 0.218, 0.185, 0.145, 0.168, 0.212, 0.483, 0.209, 0.146, 0.146, 0.161, 0.228, 0.24, 0.207, 0.175, 0.127, 0.291, 0.179, 0.148, 0.159, 0.15, 0.161, 0.173, 0.354, 0.154, 0.179, 0.21, 0.133, 0.125, 0.17, 0.154, 0.208, 0.147, 0.175, 0.212, 0.214, 0.127, 0.224, 0.15, 0.155, 0.154, 0.143, 0.141, 0.212, 0.171, 0.157, 0.158, 0.164, 0.191, 0.152, 0.243, 0.149, 0.22, 0.127, 0.224, 0.128, 0.188, 0.156, 0.135, 0.163, 0.159, 0.132, 0.176, 0.197, 0.178, 0.19, 0.188, 0.228, 0.148, 0.152, 0.141, 0.184, 1.08, 0.146, 0.223, 0.226, 0.196, 0.173, 0.17, 0.169, 0.171, 0.149, 0.214, 0.208, 0.138, 0.158, 0.159, 0.124, 0.189, 0.138, 0.144, 0.223, 0.245, 0.229, 0.129, 0.267, 0.174, 0.152, 0.147, 0.206, 0.228, 0.213, 0.208, 0.21, 0.164, 0.15, 0.192, 0.183, 0.129, 0.172, 0.149, 0.156, 0.165, 0.192, 0.192, 0.21, 0.224, 0.138, 0.223, 0.186, 0.217, 0.181, 0.133, 0.183, 0.147, 0.113, 0.202, 0.218, 0.28, 0.159, 0.169, 0.149, 0.123, 0.095, 0.166, 0.171, 0.136, 0.157, 0.146, 0.147, 0.137, 0.201, 0.12, 0.208, 0.169, 0.155, 0.202, 0.227, 0.178, 0.194, 0.165, 0.176, 0.21, 0.124, 0.196, 0.43, 0.172, 0.164, 0.106, 0.115, 0.149, 0.152, 0.138, 0.136, 0.295, 0.133, 0.148, 0.728, 0.22, 0.244, 0.193, 0.218, 0.129, 0.143, 0.133, 0.146, 0.136, 0.151, 0.194, 0.147, 0.151, 0.144, 0.15, 0.204, 0.196, 0.162, 0.166, 0.184, 0.184, 0.162, 0.182, 0.785, 0.144, 0.167, 0.169, 0.138, 0.138, 0.202, 0.234, 0.218, 0.233, 0.248, 0.158, 0.164, 0.267, 0.239, 0.155, 0.218, 4.321, 0.125, 0.158, 0.189, 0.16, 0.163, 0.124, 0.17, 0.224, 0.142, 0.185, 0.204, 0.14, 0.213, 0.153, 0.189, 0.142, 0.43, 0.138, 0.2, 0.16, 0.14, 0.183, 0.14]
            ]
        ],
        [#dims
            [
                [2.198, 5.82, 1.644, 2.446, 4.125, 3.16, 2.999, 2.422, 3.851, 3.294, 1.767, 8.1, 2.624, 20.112, 3.236, 2.9, 3.077, 20.598, 2.528, 2.163, 2.293, 1.638, 4.996, 3.241, 1.374, 1.561, 5.111, 2.202, 2.191, 1.834, 4.63, 4.664, 1.682, 1.372, 3.022, 9.643, 3.037, 2.765, 15.002, 1.884, 1.977, 4.527, 4.454, 1.989, 1.96, 1.65, 1.792, 2.738, 6.733, 3.232]
            ],
            [
                [3.732, 6.956, 2.661, 4.144, 8.312, 6.578, 6.191, 3.614, 8.927, 5.16, 3.447, 10.002, 4.014, 25.411, 4.581, 8.635, 5.95, 19.499, 4.922, 3.172, 2.375, 2.715, 10.492, 13.346, 4.257, 4.972, 9.5, 4.183, 3.647, 2.971, 8.03, 8.89, 2.213, 2.73, 5.569, 11.039, 7.405, 7.856, 10.59, 3.143, 2.851, 9.699, 8.615, 3.277, 3.942, 2.893, 3.379, 4.342, 10.463, 5.298], [2.712, 3.321, 12.619, 15.376, 5.145, 3.315, 4.404, 8.218, 20.964, 32.07, 2.807, 3.367, 2.623, 2.62, 3.79, 4.108, 6.413, 5.741, 4.275, 21.896, 8.563, 3.323, 4.82, 18.497, 4.214, 1.722, 14.493, 3.63, 4.89, 3.612, 3.006, 2.365, 2.062, 7.498, 3.37, 4.83, 4.269, 5.863, 4.796, 2.99, 5.631, 3.503, 4.99, 1.869, 3.844, 2.378, 6.51, 29.027, 6.616, 3.295], [11.748, 3.867, 4.396, 3.927, 19.239, 4.996, 3.876, 4.049, 7.851, 6.613, 4.113, 5.0, 14.934, 2.97, 4.736, 3.423, 34.848, 3.249, 30.293, 4.711, 9.741, 13.079, 3.302, 4.614, 4.161, 8.778, 1.737, 3.618, 2.07, 14.139, 6.045, 4.991, 2.887, 2.174, 5.255, 3.29, 4.348, 1.93, 3.366, 1.997, 15.43, 2.031, 2.451, 1.809, 3.593, 2.742, 3.658, 3.373, 6.012, 2.546], [5.497, 3.883, 5.276, 4.61, 7.009, 7.476, 2.815, 21.149, 7.299, 8.359, 3.542, 13.03, 10.285, 4.044, 3.684, 7.3, 6.843, 6.407, 50.788, 18.271, 19.806, 2.866, 2.843, 8.278, 4.227, 5.432, 10.718, 3.389, 3.555, 5.833, 4.567, 4.848, 4.717, 2.815, 8.644, 5.758, 3.996, 3.303, 2.825, 4.779, 5.169, 2.735, 3.577, 2.625, 3.421, 3.414, 3.856, 15.102, 5.794, 5.041], [9.971, 3.92, 2.125, 5.377, 3.336, 3.128, 3.664, 34.078, 5.026, 7.18, 3.666, 3.455, 3.416, 7.005, 1.957, 14.892, 5.007, 4.667, 5.985, 1.81, 3.272, 5.588, 3.312, 3.693, 2.967, 15.425, 4.247, 3.759, 2.48, 2.186, 2.705, 2.859, 2.213, 2.439, 3.232, 11.764, 2.43, 5.219, 10.089, 3.777, 14.31, 8.314, 54.291, 5.74, 4.919, 2.695, 13.661, 3.765, 5.871, 5.669], [3.236, 2.671, 5.814, 4.976, 3.457, 2.603, 6.468, 1.89, 1.846, 3.116, 37.668, 13.995, 5.501, 3.566, 4.076, 2.984, 3.793, 7.644, 1.897, 2.728, 10.438, 7.138, 3.374, 30.661, 3.228, 41.132, 2.567, 4.39, 4.178, 4.756, 5.136, 8.164, 1.736, 3.198, 2.975, 2.654, 1.494, 7.331, 4.488, 2.354, 1.94, 3.983, 10.947, 17.268, 2.572, 2.017, 3.808, 3.851, 4.15, 6.961], [7.537, 4.983, 7.16, 17.68, 9.787, 7.225, 4.545, 6.58, 3.237, 2.971, 1.654, 4.238, 2.256, 50.829, 4.308, 3.868, 4.408, 4.114, 29.766, 5.424, 3.148, 14.322, 3.373, 4.311, 2.098, 2.973, 1.982, 4.345, 8.322, 2.071, 6.698, 2.359, 2.119, 2.521, 2.453, 4.665, 3.399, 17.712, 3.512, 4.725, 5.85, 7.162, 4.688, 3.229, 5.02, 3.172, 5.507, 10.644, 2.715, 1.952], [3.49, 2.529, 3.641, 3.858, 1.466, 2.19, 6.459, 8.42, 1.487, 1.66, 4.821, 4.622, 5.609, 5.571, 2.879, 13.992, 2.303, 15.998, 4.643, 6.912, 2.316, 7.127, 4.993, 3.414, 3.07, 3.632, 2.377, 2.449, 11.217, 5.651, 2.16, 6.776, 3.799, 7.354, 4.803, 1.788, 4.166, 2.194, 3.128, 3.218, 3.029, 2.989, 5.056, 3.872, 4.959, 22.097, 4.166, 33.978, 2.565, 2.474], [4.336, 2.451, 1.85, 7.969, 1.962, 2.147, 3.131, 2.254, 2.741, 6.553, 14.917, 3.884, 4.148, 13.072, 4.716, 2.889, 6.683, 7.537, 2.387, 3.994, 3.353, 2.999, 1.806, 14.828, 2.04, 2.589, 2.7, 4.874, 3.071, 3.554, 1.887, 1.56, 1.504, 1.997, 8.004, 3.075, 3.127, 3.051, 4.555, 3.734, 2.353, 1.942, 3.676, 9.337, 2.511, 7.58, 2.793, 21.907, 1.97, 4.825]
            ]
        ],    
        [
            [
                [14.849, 7.229, 13.458, 9.353, 12.132, 17.089, 42.65, 9.868, 27.474, 8.853, 6.041, 14.518, 4.493, 13.703, 6.887, 16.5, 3.835, 25.077, 10.438, 20.706, 9.148, 11.729, 5.05, 8.112, 18.751]
            ],
            [
                [22.174, 11.216, 19.947, 17.87, 16.275, 23.255, 89.372, 11.384, 48.279, 13.587, 8.171, 21.217, 8.879, 27.455, 13.331, 35.09, 5.384, 40.399, 21.216, 43.755, 13.998, 23.449, 7.979, 12.028, 24.483], [9.841, 50.011, 18.667, 29.306, 63.957, 8.925, 8.148, 10.66, 36.816, 40.153, 12.376, 42.923, 8.803, 25.933, 14.411, 9.548, 17.995, 12.988, 21.031, 14.198, 16.339, 12.52, 10.014, 72.303, 21.754], [24.707, 13.314, 36.728, 11.408, 23.66, 20.209, 38.798, 13.554, 72.144, 50.169, 33.363, 13.411, 27.698, 19.078, 14.828, 28.281, 10.377, 18.118, 13.444, 7.83, 47.984, 8.147, 13.416, 14.169, 19.175], [14.801, 16.762, 25.255, 36.961, 21.271, 18.361, 20.811, 18.805, 10.548, 100.591, 43.61, 26.447, 19.854, 28.924, 17.922, 17.964, 14.313, 54.139, 13.654, 19.879, 15.395, 10.564, 11.967, 47.312, 33.505], [25.654, 13.237, 9.745, 145.075, 65.357, 62.178, 66.173, 67.421, 79.35, 23.917, 29.43, 13.6, 38.394, 15.902, 9.14, 10.926, 10.898, 27.438, 13.218, 28.75, 62.509, 70.508, 11.024, 34.541, 19.194], [10.817, 19.442, 11.032, 15.166, 9.682, 140.208, 25.428, 14.96, 30.77, 11.393, 34.491, 44.498, 67.044, 12.175, 14.531, 15.851, 14.736, 8.519, 18.857, 12.895, 13.053, 57.008, 6.689, 13.754, 30.256], [17.03, 52.323, 33.511, 10.526, 10.24, 9.643, 94.064, 23.349, 13.942, 65.536, 27.439, 12.929, 12.68, 19.586, 15.239, 20.577, 7.495, 11.895, 27.882, 18.007, 17.831, 14.709, 19.352, 32.425, 6.547], [14.85, 18.678, 9.584, 39.883, 7.94, 26.978, 18.485, 39.028, 43.304, 18.948, 12.676, 23.691, 12.484, 11.514, 32.996, 15.22, 29.752, 18.635, 8.742, 8.937, 11.952, 33.072, 50.096, 85.796, 8.85], [13.845, 25.947, 8.676, 9.507, 28.179, 41.059, 52.486, 22.9, 44.401, 15.235, 16.084, 43.017, 8.793, 23.497, 20.347, 8.742, 7.656, 29.065, 16.353, 21.15, 9.433, 32.137, 33.291, 61.35, 16.359]
            ]
        ],
        [
            [
                [66.519, 59.066, 159.58, 97.916, 48.263, 54.411, 71.096, 121.258, 56.131, 68.466]
            ],
            [
                [137.52, 108.837, 246.572, 154.826, 72.207, 91.959, 100.265, 194.845, 110.499, 105.434], [200.806, 230.496, 54.144, 169.071, 182.641, 132.875, 100.119, 105.447, 100.602, 255.987], [205.14, 147.829, 134.508, 239.642, 115.852, 74.865, 86.575, 51.963, 145.612, 135.914], [141.868, 246.479, 107.631, 290.425, 170.007, 138.145, 135.179, 192.867, 185.605, 258.184], [123.862, 212.337, 81.014, 131.813, 70.9, 103.839, 45.547, 138.468, 337.39, 151.631], [74.157, 75.901, 258.526, 85.102, 163.956, 215.382, 69.61, 112.424, 194.122, 119.476], [165.655, 63.929, 208.652, 148.711, 103.568, 87.623, 88.546, 158.681, 133.89, 127.948], [71.644, 128.312, 102.619, 177.731, 96.87, 137.776, 132.611, 71.119, 125.586, 311.709], [100.045, 77.098, 180.829, 110.486, 116.486, 96.684, 66.725, 86.089, 90.376, 214.9]
            ]
        ],
        [
            [
                [9806.265]
            ],
            [
                [12346.28], [12422.935]
            ]
        ]
        ,
        [
            [
                [140657.9864216444]
            ],
            [
                [177186.004324]
            ]
        ]
    ]
    ys_array, ci_array = [], []
    for m_i in range(len(ys_d4trainingtimerawinput_l)):
        # Summing the innermost lists for each configuration within a model
        model_sums = [[sum(inner) for inner in dim] for dim in ys_d4trainingtimerawinput_l[m_i]]
        
        # Calculating the mean for each configuration
        model_means = [np.mean(dim_sums) for dim_sums in model_sums]
        ys_array.append(model_means)
        
        # Calculating the standard deviation for each configuration
        model_stds = [np.std(dim_sums) / np.sqrt(len(dim_sums)) for dim_sums in model_sums]
        ci_array.append([1.96 * std for std in model_stds])

    # Convert to numpy arrays for plotting
    ys_array = np.array(ys_array).T  # Transpose to match the expected shape for plotting
    ci_array = np.array(ci_array).T

    for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v", "o", "s"]):
        ax.scatter(xs, ys, label=label, marker=mark)
        ax.errorbar(xs, ys, yerr=ci, fmt='^', capsize=10)
    ax.set_xticks(xs)
    ax.set_xticklabels(xs_label, fontsize=18)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # ax.set_xscale('log')
    ax.set_ylabel("Training Time(s)", fontsize=20)
    ax.set_yscale('log')
    ax.grid()
    plt.legend(prop={'size': 16})
    # plt.show()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()



    filename = "per_model_trainlatency_by_labels_per_model_with_rawinput_data_4"
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    xs_label = [3, 6, 60, 120, 300, "3000\n(DeltaSherlock)\n(XGBoost)", "3000\n(Praxi)\n(VW)"]
    xs = list(range(len(xs_label)))
    labels = ["Filter=25", "No Filter"]
    ys_d4permodeltrainlatencybylabelspermodel_l=[#models
        [#filter or not
            [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
                0.123, 0.1, 0.1, 0.1, 0.095, 0.078, 0.15, 0.085, 0.085, 0.077, 0.117, 0.123, 0.072, 0.105, 0.095, 0.075, 0.08, 0.077, 0.128, 0.068, 0.079, 0.094, 0.085, 0.089, 0.095, 0.07, 0.079, 0.682, 0.088, 0.091, 0.084, 0.091, 0.099, 0.122, 0.131, 0.078, 0.071, 0.09, 0.076, 0.114, 0.08, 0.09, 0.084, 0.133, 0.088, 0.094, 0.103, 0.086, 0.091, 0.104, 0.08, 0.087, 0.094, 0.145, 0.092, 0.096, 0.14, 0.086, 0.093, 0.082, 0.095, 0.108, 0.093, 0.115, 0.084, 0.086, 0.08, 0.093, 0.189, 0.072, 0.081, 0.148, 0.093, 0.079, 0.135, 0.07, 0.083, 0.076, 0.08, 0.074, 0.073, 0.074, 0.116, 0.082, 0.078, 0.083, 0.509, 0.078, 0.085, 0.1, 0.085, 0.126, 0.088, 0.072, 0.071, 0.096, 0.117, 0.076, 0.092, 0.096, 0.088, 0.075, 0.088, 0.065, 0.183, 0.091, 0.103, 0.072, 0.066, 0.07, 0.244, 0.096, 0.086, 0.116, 0.088, 0.082, 0.061, 0.069, 0.077, 0.079, 0.087, 0.096, 0.07, 0.069, 0.086, 0.093, 0.082, 0.071, 0.289, 0.067, 0.066, 0.078, 0.071, 0.082, 0.068, 0.085, 0.073, 0.08, 0.076, 0.069, 0.088, 0.088, 0.075, 0.08, 0.069, 0.07, 0.117, 0.082, 0.08, 0.074, 0.084, 0.077, 0.075, 0.086, 0.14, 0.08, 0.141, 0.099, 0.116, 0.094, 0.127, 0.128, 0.085, 0.133, 0.08, 0.259, 0.076, 0.073, 0.098, 0.057, 0.072, 0.159, 0.112, 0.106, 0.075, 0.068, 0.103, 0.075, 0.081, 0.089, 0.075, 0.083, 0.07, 0.084, 0.079, 0.075, 0.115, 0.089, 0.11, 0.07, 0.068, 0.062, 0.074, 0.086, 0.087, 0.078, 0.132, 0.055, 0.074, 0.227, 0.093, 0.092, 0.133, 0.106, 0.09, 0.098, 0.072, 0.091, 0.089, 0.067, 0.072, 0.106, 0.082, 0.093, 0.136, 0.061, 0.094, 0.101, 0.11, 0.079, 0.076, 0.093, 0.131, 0.088, 0.083, 0.154, 0.081, 0.076, 0.164, 0.087, 0.157, 0.084, 0.125, 0.081, 0.067, 0.699, 0.138, 0.093, 0.104, 0.129, 0.084, 0.077, 0.082, 0.088, 0.134, 0.156, 0.085, 0.156, 0.088, 0.079, 0.085, 0.12, 0.134, 0.164, 0.094, 0.081, 0.072, 0.081, 0.096, 0.11, 2.949, 0.095, 0.071, 0.087, 0.118, 0.091, 0.131, 0.074, 0.083, 0.065, 0.093, 0.077, 0.083, 0.077, 0.069, 0.09, 0.076, 0.121, 0.087, 0.105, 0.08, 0.07, 0.075, 0.07, 0.09, 0.083, 0.088, 0.085, 0.079, 0.244, 0.09, 0.084, 0.08, 0.078, 0.074, 0.075, 0.08, 0.134, 0.071, 0.107, 0.065, 0.067, 0.113, 0.072, 0.154, 0.16, 0.088, 0.089, 0.102, 0.078, 0.126, 0.078, 0.14, 0.07, 0.075, 0.096, 0.072, 0.145, 0.074, 0.089, 0.099, 0.126, 0.089, 0.081, 0.075, 0.145, 0.098, 0.095, 0.133, 0.097, 0.081, 0.088, 0.082, 0.084, 0.107, 0.08, 0.086, 0.083, 0.274, 0.092, 0.109, 0.091, 0.119, 0.082, 0.108, 0.084, 0.089, 0.129, 0.072, 0.091, 0.071, 0.068, 0.076, 0.105, 0.075, 0.067, 0.09, 0.074, 0.135, 1.473, 0.091, 0.087, 0.07, 0.096, 0.079, 0.084, 0.149, 0.107, 0.076, 0.08, 0.071, 0.1, 0.126, 0.098, 0.073, 0.182, 0.077, 0.072, 0.065, 0.082, 0.086, 0.092, 0.084, 0.074, 0.121, 0.21, 0.073, 0.11, 0.078, 0.111, 0.067, 0.074, 0.086, 0.083, 0.084, 0.075, 0.08, 0.093, 0.066, 0.082, 0.066, 0.076, 0.08, 0.074, 0.087, 0.109, 0.092, 0.089, 0.104, 0.113, 0.093, 0.089, 0.124, 0.077, 0.083, 0.11, 0.083, 0.096, 0.08, 0.071, 0.148, 0.086, 0.138, 0.078, 0.084, 0.076, 0.072, 0.079, 0.064, 0.069, 0.067, 0.082, 0.086, 0.079, 0.081, 0.097, 0.076, 0.071, 0.085, 0.071, 0.136, 0.068, 0.075, 0.128, 0.104, 0.091, 0.132, 0.083, 0.131, 0.088, 0.072, 0.07, 0.08, 0.064, 0.068, 0.078, 0.072, 0.07, 0.281, 0.141, 0.069, 0.186, 0.069, 0.08, 0.089, 0.108, 0.07, 0.083, 0.149, 0.142, 0.083, 0.093, 0.075, 0.068, 0.087, 0.076, 0.076, 0.112, 0.083, 0.089, 0.094, 0.075, 0.083, 0.084, 0.076, 0.135, 0.07, 0.086, 0.144, 0.09, 0.091, 0.093, 0.089, 0.073, 0.091, 0.089, 0.079, 0.08, 0.087, 0.091, 0.077, 0.08, 0.09, 0.095, 0.086, 0.073, 0.069, 0.108, 0.072, 0.082, 0.081, 0.12, 0.077, 0.081, 0.097, 0.115, 0.069, 0.072, 0.071, 0.096, 0.079, 0.058, 0.09, 0.058, 0.1, 0.072, 0.079, 0.285, 0.089, 0.067, 0.07, 0.084, 0.068, 0.078, 0.083, 0.081, 0.084, 0.084, 0.098, 0.37, 0.068, 0.094, 0.101, 0.068, 0.082, 0.093, 0.085, 0.127, 0.093, 0.084, 0.119, 0.092, 0.075, 0.084, 0.084, 0.082, 0.091, 0.193, 0.117, 0.083, 0.159, 0.104, 0.07, 0.096, 0.066, 0.082, 0.084, 0.081, 0.08, 0.076, 0.089, 0.076, 0.071, 0.116, 0.162, 0.078, 0.103, 0.095, 0.093, 0.121, 0.117, 0.081, 0.08, 0.097, 0.14, 0.095, 0.078, 0.091, 0.099, 0.072, 0.085, 0.111, 0.091, 0.083, 0.164, 0.112, 0.08, 0.088, 0.078, 0.071, 0.379, 0.086, 0.09, 0.085, 0.065, 0.092, 0.093, 0.068, 0.085, 0.129, 0.071, 0.071, 0.078, 0.101, 0.099, 0.142, 0.119, 0.094, 0.09, 0.155, 0.086, 0.058, 0.11, 0.067, 0.063, 0.092, 0.122, 0.077, 0.086, 0.079, 0.109, 0.084, 0.08, 0.111, 0.066, 0.266, 0.077, 0.09, 0.15, 0.087, 0.084, 0.082, 0.097, 0.082, 0.071, 0.074, 0.071, 0.08, 0.059, 0.069, 0.099, 0.112, 0.123, 0.064, 0.059, 0.075, 0.072, 0.134, 0.103, 0.091, 0.093, 0.08, 0.086, 0.078, 0.081, 0.08, 0.079, 0.098, 0.103, 0.091, 0.083, 0.086, 0.114, 0.081, 0.122, 0.08, 0.077, 0.084, 0.088, 0.073, 0.074, 0.078, 0.081, 0.092, 0.15, 0.11, 0.075, 0.084, 0.077, 0.064, 0.07, 0.079, 0.19, 0.087, 0.134, 0.08, 0.19, 0.074, 0.072, 0.103, 0.098, 0.102, 0.167, 0.072, 0.079, 0.088, 0.087, 0.085, 0.15, 0.089, 0.2, 0.096, 0.101, 0.08, 0.083, 0.088, 0.14, 0.089, 1.257, 0.073, 0.067, 0.067, 0.073, 0.076, 0.084, 0.071, 0.122, 0.082, 0.083, 0.081, 0.068, 0.094, 0.091, 0.077, 0.079, 0.189, 0.097, 0.093, 0.135, 0.13, 0.102, 0.074, 0.086, 0.089, 0.09, 0.075, 0.074, 0.085, 0.097, 0.279, 0.151, 0.08, 0.078, 0.069, 0.071, 0.088, 0.093, 0.111, 0.116, 0.083, 0.101, 0.118, 1.188, 0.089, 0.085, 0.083, 0.077, 0.076, 0.132, 0.072, 0.087, 0.084, 0.08, 0.064, 0.084, 0.077, 0.079, 0.088, 0.099, 0.072, 0.072, 0.115, 0.107, 0.103, 0.125, 0.084, 0.063, 0.086, 0.12, 0.101, 0.066, 0.137, 0.078, 0.143, 0.063, 0.098, 0.081, 0.092, 0.103, 0.078, 0.136, 0.082, 0.091, 0.076, 0.091, 0.084, 0.128, 0.08, 0.077, 0.094, 0.07, 0.073, 0.066, 0.144, 0.084, 0.13, 0.085, 0.069, 0.083, 0.116, 0.083, 0.088, 0.137, 0.082, 0.133, 0.091, 0.08, 0.084, 0.084, 0.078, 0.067, 0.101, 0.068, 0.063, 0.066, 0.084, 0.259, 0.105, 0.074, 0.068, 0.206, 0.07, 0.072, 0.175, 0.117, 0.088, 0.085, 0.061, 0.071, 0.062, 0.187, 0.065, 0.117, 0.087, 0.129, 0.076, 0.074, 0.073, 0.089, 0.085, 0.07, 0.081, 0.099, 0.122, 0.072, 0.097, 0.128, 0.091, 0.075, 0.079, 0.074, 0.12, 0.076, 0.09, 0.078, 0.077, 0.085, 0.076, 0.071, 0.117, 0.072, 0.098, 0.099, 0.098, 0.068, 0.079, 0.07, 0.12, 0.103, 0.061, 0.079, 0.074, 0.072, 0.119, 0.099, 0.141, 0.086, 0.082, 0.073, 0.086, 0.076, 0.075, 0.077, 0.071, 0.069, 0.081, 0.076, 0.072, 0.106, 0.077, 0.077, 0.078, 0.128, 0.072, 0.101, 0.102, 0.119, 0.09, 0.133, 0.096, 0.087, 0.08, 0.077, 0.081, 0.118, 0.102, 0.144, 0.099, 0.105, 0.081, 0.081, 0.112, 0.097, 0.132, 0.083, 0.097, 0.089, 0.132, 0.092, 0.079, 0.079, 0.092, 0.07, 0.072, 0.082, 0.069, 0.091, 0.093, 0.078, 0.168, 0.226, 0.075, 0.083, 0.094, 0.089, 0.088, 0.078, 0.094, 0.09, 0.083, 0.087, 0.081, 0.838, 0.082, 0.082, 0.084, 0.08, 0.083, 0.076, 0.072, 0.071, 0.147, 0.085, 0.107, 0.084, 0.089, 0.085, 0.126, 0.102, 0.073, 0.077, 0.078, 0.092, 0.117, 0.104, 0.127, 0.076, 0.328, 0.073, 0.08, 0.081, 0.081, 0.075, 0.07, 0.08, 0.072, 0.075, 0.08, 0.119, 0.083, 0.077, 0.109, 0.08, 0.069, 0.082, 0.102, 0.063, 0.091, 0.09, 0.127, 0.097, 0.093, 0.086, 0.148, 0.136, 0.089, 0.078, 0.102, 0.09, 0.072, 0.073, 0.083, 0.07, 0.094, 0.128, 0.107, 0.08, 0.081, 0.114, 0.097, 0.095, 0.103, 0.076, 0.07, 0.097, 0.112, 0.089, 0.146, 0.095, 0.089, 0.083, 0.075, 0.092, 0.164, 0.075, 0.076, 0.074, 0.066, 0.077, 0.135, 0.074, 0.08, 0.077, 0.299, 0.108, 0.081, 0.368, 0.065, 0.069, 0.08, 0.836, 0.06, 0.302, 0.066, 0.066, 0.073, 0.077, 0.083, 0.084, 0.07, 0.096, 0.074, 0.094, 0.078, 0.148, 0.103, 0.087, 0.085, 0.074, 0.08, 0.181, 0.122, 0.072, 0.074, 0.117, 0.107, 0.137, 0.072, 0.095, 0.102, 0.087, 0.091, 0.088, 0.082, 0.102, 0.069, 0.072, 0.067, 0.09, 0.074, 0.082, 0.138, 0.079, 0.091, 0.088, 0.084, 0.145, 0.095, 0.09, 0.102, 0.091, 0.11, 0.09, 0.09, 0.073, 0.088, 0.102, 0.109, 0.102, 0.142, 0.076, 0.094, 0.087, 0.086, 0.101, 0.068, 0.12, 0.091, 0.069, 0.075, 0.091, 0.087, 0.131, 0.139, 0.126, 0.089, 0.067, 0.077, 0.079, 0.168, 0.139, 0.118, 0.073, 0.124, 0.071, 0.094, 0.081, 0.088, 0.079, 0.107, 0.079, 0.078, 0.065, 0.064, 0.083, 0.075, 0.074, 0.095, 0.081, 0.178, 0.411, 0.067, 0.094, 0.097, 0.087, 0.076, 0.113, 0.083, 0.12, 0.08, 0.087, 0.078, 0.074, 0.148, 0.136, 0.088, 0.095, 0.089, 0.066, 0.134, 0.079, 0.071, 0.096, 0.073, 0.124, 1.486, 0.076, 0.078, 0.131, 0.094, 0.086, 0.156, 0.086, 0.195, 0.08, 0.109, 0.099, 0.136, 0.135, 0.098, 0.081, 0.081, 0.094, 0.114, 0.079, 0.084, 0.081, 0.071, 0.078, 0.124, 0.075, 0.102, 0.078, 0.101, 0.106, 0.074, 0.088, 0.074, 0.084, 0.078, 0.103, 0.099, 0.082, 0.143, 0.083, 0.102, 0.083, 0.078, 0.077, 0.077, 0.088, 0.078, 0.077, 0.139, 0.079, 0.075, 0.077, 0.074, 0.078, 0.115, 0.079, 0.083, 0.149, 0.083, 0.085, 0.105, 0.103, 0.105, 0.141, 0.083, 0.082, 0.112, 0.087, 0.093, 0.077, 0.098, 0.086, 0.089, 0.084, 0.086, 0.09, 0.132, 0.08, 0.099, 0.11, 0.087, 0.061, 0.102, 0.071, 0.077, 0.068, 0.076, 0.068, 0.09, 0.07, 0.09, 0.1, 0.084, 0.085, 0.089, 0.095, 0.092, 0.121, 0.094, 0.088, 0.108, 0.098, 0.126, 0.153, 0.064, 0.078, 0.081, 0.083, 0.089, 0.072, 0.084, 0.089, 0.078, 0.07, 0.111, 0.084, 0.088, 0.074, 0.072, 0.076, 0.077, 0.095, 0.08, 0.08, 0.081, 0.087, 0.286, 0.078, 0.086, 0.112, 0.091, 0.088, 0.084, 0.077, 0.098, 0.084, 0.121, 0.066, 0.137, 0.076, 0.082, 0.076, 0.079, 0.08, 0.297, 0.076, 0.066, 0.087, 0.082, 0.094, 0.077, 0.126, 0.078, 0.07, 0.134, 0.156, 0.072, 0.127, 0.17, 0.1, 0.087, 0.085, 0.077, 0.076, 0.11, 0.072, 0.09, 0.078, 0.112, 0.068, 0.155, 0.092, 0.079, 0.077, 0.084, 0.078, 0.078, 0.093, 0.092, 0.07, 0.096, 0.124, 0.126, 0.171, 0.168, 0.099, 0.075, 0.095, 0.061, 0.078, 0.098, 0.098, 0.088, 0.091, 0.085, 0.077, 0.08, 0.123, 0.082, 0.076, 0.081, 0.092, 0.087, 0.081, 0.066, 0.083, 0.067, 0.066, 1.014, 0.068, 0.073, 0.079, 0.07, 0.073, 0.072, 0.08, 0.076, 0.088, 0.081, 0.084, 0.079, 0.241, 0.102, 0.073, 0.085, 0.072, 0.072, 0.124, 0.126, 0.08, 0.086, 0.072, 0.102, 0.078, 0.086, 0.101, 0.093, 0.095, 0.118, 0.101, 0.093, 0.08, 0.132, 0.069, 0.125, 0.107, 0.087, 0.137, 0.085, 0.08, 0.109, 0.066, 0.097, 0.111, 0.08, 0.087, 0.086, 0.093, 0.132, 0.112, 0.127, 0.185, 0.087, 0.079, 0.087, 0.083, 0.06, 0.073, 0.08, 0.095, 0.082, 0.082, 0.09, 0.09, 0.131, 0.095, 0.103, 0.076, 0.081, 0.075, 0.107, 0.078, 0.114, 0.471, 0.079, 0.087, 0.1, 0.107, 0.154, 0.098, 0.075, 1.219, 0.077, 0.091, 0.095, 0.078, 0.079, 0.096, 0.117, 0.085, 0.078, 0.076, 0.081, 0.078, 0.115, 0.071, 0.086, 0.072, 0.08, 0.274, 0.076, 0.084, 0.098, 0.092, 0.073, 0.082, 0.084, 0.081, 0.087, 0.091, 0.087, 0.085, 0.092, 0.082, 0.082, 0.066, 0.117, 0.078, 0.101, 0.08, 0.088, 0.089, 0.068, 0.08, 0.115, 0.088, 0.086, 0.082, 0.137, 0.082, 0.09, 0.081, 0.129, 0.067, 0.139, 0.069, 0.086, 0.09, 0.087, 0.874, 0.1, 0.082, 0.085, 0.076, 0.071, 0.07, 0.108, 0.12, 0.092, 0.183, 0.074, 0.085, 0.085, 0.081, 0.092, 0.091, 0.091, 0.114, 0.062, 0.089, 0.076, 0.07, 0.08, 0.09, 0.089, 0.08, 0.177, 0.099, 0.097, 0.072, 0.208, 0.089, 0.089, 0.108, 0.083, 0.102, 0.093, 0.082, 0.078, 0.079, 0.125, 0.082, 0.069, 0.084, 0.067, 0.075, 0.072, 0.094, 0.08, 0.084, 0.089, 0.122, 0.071, 0.072, 0.106, 0.198, 0.081, 0.089, 0.078, 0.082, 0.083, 0.081, 0.081, 0.082, 0.09, 0.085, 0.11, 0.167, 0.082, 0.077, 0.099, 0.084, 0.085, 0.081, 0.073, 0.136, 0.082, 0.074, 0.085, 0.095, 0.095, 0.065, 0.071, 0.138, 0.099, 0.086, 0.062, 0.084, 0.084, 0.084, 0.073, 0.096, 0.107, 0.079, 0.092, 0.13, 0.079, 0.067, 0.088, 0.083, 0.064, 0.079, 0.081, 0.061, 0.077, 0.102, 0.095, 0.085, 0.067, 0.113, 0.098, 0.094, 0.084, 0.084, 0.082, 0.085, 0.101, 0.097, 0.081, 0.103, 0.077, 0.113, 0.076, 0.091, 0.091, 0.07, 0.125, 0.092, 0.071, 0.083, 0.125, 0.284, 0.105, 0.086, 0.094, 0.071, 0.086, 0.122, 0.077, 0.138, 0.081, 0.109, 0.21, 0.082, 0.135, 0.089, 0.082, 0.089, 0.08, 0.067, 0.144, 0.085, 0.121, 0.073, 0.069, 0.079, 0.116, 0.067, 0.067, 0.064, 0.073, 0.07, 0.125, 0.073, 0.106, 0.08, 0.075, 0.088, 0.077, 0.094, 0.092, 0.125, 0.123, 0.081, 0.078, 0.099, 0.065, 0.101, 0.087, 0.09, 0.088, 0.21, 0.084, 0.145, 0.074, 0.102, 0.101, 0.069, 0.085, 0.088, 0.114, 0.087, 0.073, 0.084, 0.13, 0.285, 0.084, 0.111, 0.133, 0.092, 0.094, 0.082, 0.08, 0.084, 0.081, 0.083, 0.083, 0.089, 0.076, 0.059, 0.07, 0.089, 0.063, 0.074, 0.083, 0.51, 0.075, 0.066, 0.081, 0.077, 0.113, 0.073, 0.114, 0.09, 0.085, 0.07, 0.246, 0.064, 0.095, 0.074, 0.081, 0.088, 0.09, 0.08, 0.116, 0.075, 0.128, 0.071, 0.103, 0.063, 0.078, 0.126, 0.178, 0.079, 0.075, 0.072, 0.086, 0.093, 0.115, 0.075, 0.061, 0.068, 0.106, 0.089, 0.079, 0.106, 0.088, 0.098, 0.129, 0.094, 0.096, 0.08, 0.084, 0.07, 0.13, 0.075, 0.126, 0.076, 0.102, 0.08, 0.059, 0.102, 0.149, 0.289, 0.078, 0.058, 0.073, 0.081, 0.068, 0.077, 0.075, 0.107, 0.071, 0.072, 0.072, 0.086, 0.079, 0.081, 0.059, 0.119, 0.092, 0.074, 0.072, 0.061, 0.091, 0.091, 0.062, 0.079, 0.173, 0.067, 0.115, 0.081, 0.088, 0.095, 0.128, 0.088, 0.11, 0.098, 0.13, 0.086, 0.08, 0.089, 0.088, 0.088, 0.115, 0.248, 0.075, 0.078, 0.07, 0.07, 0.061, 0.094, 0.093, 0.078, 0.072, 0.07, 0.096, 0.082, 0.086, 0.082, 0.062, 0.091, 0.074, 0.088, 0.098, 0.086, 0.08, 0.092, 0.141, 0.069, 0.119, 0.061, 0.091, 0.063, 0.083, 0.08, 0.073, 0.083, 0.086, 0.079, 0.102, 0.07, 0.058, 0.089, 0.115, 0.075, 0.085, 0.081, 0.089, 0.089, 0.088, 0.073, 0.13, 0.172, 0.077, 0.111, 0.119, 0.129, 0.082, 0.086, 0.103, 0.106, 0.072, 0.097, 0.086, 0.095, 0.097, 0.07, 0.134, 0.071, 0.096, 0.081, 0.062, 0.075, 0.083, 0.12, 0.092, 0.098, 0.188, 0.082, 0.078, 0.126, 0.269, 0.065, 0.086, 0.075, 0.065, 0.074, 0.089, 0.217, 0.094, 0.071, 0.131, 0.087, 0.124, 0.139, 0.092, 0.088, 0.139, 0.083, 0.084, 0.109, 0.081, 0.097, 0.079, 0.083, 0.095, 0.109, 0.092, 0.143, 0.076, 0.075, 3.058, 0.082, 0.073, 0.089, 0.085, 0.076, 0.08, 0.094, 0.129, 0.174, 0.1, 0.214, 0.155, 0.085, 0.078, 0.087, 0.235, 0.165, 0.112, 0.08, 0.111, 0.08, 0.075, 0.07, 0.097, 0.074, 0.146, 0.149, 0.093, 0.073, 0.075, 0.119, 0.086, 0.078, 0.067, 0.067, 0.097, 0.07, 0.141, 0.121, 0.079, 0.076, 0.07, 0.119, 0.08, 0.063, 0.063, 0.575, 0.075, 0.117, 0.11, 0.098, 0.076, 0.075, 0.158, 0.069, 0.129, 0.09, 0.085, 0.158, 0.083, 0.085, 0.074, 0.084, 0.16, 0.08, 0.078, 0.067, 0.083, 0.086, 0.076, 0.074, 0.076, 0.069, 0.074, 0.065, 0.087, 0.169, 0.114, 0.092, 0.075, 0.076, 0.069, 0.062, 0.061, 0.068, 0.072, 0.062, 0.081, 0.126, 0.091, 0.084, 0.072, 0.149, 0.076, 0.07, 0.073, 0.109, 0.076, 0.08, 0.127, 0.07, 0.074, 0.079, 0.066, 0.068, 0.06, 0.076, 0.078, 0.094, 0.079, 0.069, 0.079, 0.063, 0.078, 0.07, 0.098, 0.071, 0.135, 0.181, 0.07, 0.085, 0.086, 0.084, 0.083, 0.069, 0.064, 0.148, 0.077, 0.079, 0.082, 0.149, 0.07, 0.075, 0.176, 0.082, 0.088, 0.092, 0.091, 1.155, 0.084, 0.083, 0.08, 0.122, 0.078, 0.086, 0.197, 0.109, 0.066, 0.107, 0.095, 0.061, 0.154, 0.066, 0.102, 0.075, 0.066, 0.107, 0.072, 0.067, 0.074, 0.091, 0.071, 0.085, 0.107, 0.07, 0.066, 0.071, 0.067, 0.073, 0.073, 0.071, 0.094, 0.068, 0.101, 0.097, 0.076, 0.075, 0.207, 0.077, 0.086, 0.061, 0.063, 0.062, 0.213, 0.067, 0.104, 0.085, 0.085, 0.084, 0.075, 0.069, 0.076, 0.071, 0.074, 0.096, 0.107, 0.166, 0.077, 0.065, 0.09, 0.081, 0.072, 0.095, 0.077, 0.138, 0.114, 0.189, 0.094, 0.101, 0.108, 0.089, 0.068, 0.076, 0.337, 0.064, 0.077, 0.085, 0.14, 0.091, 0.096, 0.091, 0.135, 0.07, 0.081, 0.094, 0.069, 0.092, 0.071, 0.137, 0.09, 0.307, 0.076, 0.065, 0.097, 0.055, 0.07, 0.091, 0.067, 0.066, 0.065, 0.056, 0.088, 0.073, 0.063, 0.059, 0.088, 0.067, 0.073, 0.082, 0.091, 0.091, 0.118, 0.073, 0.242, 0.069, 0.077, 0.075, 0.066, 0.072, 0.084, 0.065, 0.08, 0.094, 0.086, 0.083, 0.074, 0.077, 0.077, 0.332, 0.068, 0.06, 0.079, 0.11, 0.123, 0.068, 0.102, 0.084, 0.073, 0.081, 0.07, 0.073, 0.109, 0.098, 0.119, 0.079, 0.094, 0.124, 0.076, 0.072, 0.071, 0.071, 0.062, 0.131, 0.073, 0.112, 0.113, 0.084, 0.069, 0.063, 0.814, 0.058, 0.141, 0.072, 0.066, 0.124, 0.078, 0.082, 0.067, 0.072, 0.099, 0.074, 0.076, 0.076, 0.068, 0.064, 0.111, 0.118, 0.088, 0.091, 0.108, 0.117, 0.084, 0.08, 0.086, 0.076, 0.098, 0.078, 0.094, 0.08, 0.209, 0.079, 0.077, 0.07, 0.087, 0.068, 0.072, 0.14, 0.084, 0.074, 0.083, 0.103, 0.072, 0.14, 0.091, 0.079, 0.115, 0.083, 0.075, 0.084, 0.073, 0.105, 0.074, 0.123, 0.127, 0.093, 0.092, 0.088, 0.096, 0.162, 0.086, 0.084, 0.074, 0.108, 0.113, 0.08, 0.144, 0.109, 0.097, 0.068, 0.093, 0.098, 0.082, 0.069, 3.079, 0.127, 0.09, 0.087, 0.093, 0.134, 0.086, 0.08, 0.071, 0.135, 0.084, 0.079, 0.077, 0.078, 0.098, 0.142, 0.078, 0.079, 0.129, 0.081, 0.07, 0.062, 0.075, 0.069, 0.096, 0.073, 0.085, 0.087, 0.084, 0.111, 0.102, 0.195, 0.071, 0.069, 0.071, 0.085, 0.07, 0.065, 0.097, 0.097, 0.065, 1.575, 0.09, 0.065, 0.082, 0.064, 0.081, 0.085, 0.177, 0.088, 0.116, 0.09, 0.084, 0.071, 0.28, 0.091, 0.079, 0.08, 0.074, 0.079, 0.091, 0.07, 0.063, 0.068, 0.067, 0.065, 0.077, 0.077, 0.081, 0.126, 0.082, 0.093, 0.064, 0.076, 0.083, 0.094, 0.099, 0.079, 0.071, 0.086, 0.08, 0.083, 0.094, 0.092, 0.077, 0.113, 0.069, 0.079, 0.082, 0.673, 0.134, 0.097, 0.098, 0.094, 0.067, 0.139, 0.091, 0.072, 0.087, 0.079, 0.078, 0.063, 0.074, 0.073, 0.206, 0.21, 0.074, 0.065, 0.071, 0.085, 0.098, 0.07, 0.098, 0.072, 0.066, 0.113, 0.083, 0.072, 0.069, 0.143, 0.076, 0.091, 0.09, 0.06, 0.085, 0.089, 0.075, 0.077, 0.076, 0.06, 0.07, 0.073, 0.297, 0.075, 0.071, 0.085, 0.075, 0.062, 0.08, 0.082, 0.088, 0.088, 0.075, 0.072, 0.081, 0.092, 0.081, 0.076, 0.098, 0.079, 0.088, 0.086, 0.086, 0.099, 0.086, 0.089, 0.092, 0.11, 0.076, 0.098, 0.068, 0.139, 0.076, 0.1, 0.093, 0.098, 0.081, 0.133, 0.172, 0.093, 0.084, 0.071, 0.298, 0.153, 0.078, 0.073, 0.107, 0.079, 0.08, 0.104, 0.111, 0.273, 0.073, 0.074, 0.069, 0.077, 0.076, 0.087, 0.092, 0.095, 0.09, 0.071, 0.096, 0.103, 0.074, 0.068, 0.072, 0.094, 0.067, 0.073, 0.086, 0.085, 0.075, 0.087, 0.073, 0.086, 0.083, 0.07, 0.09, 0.092, 0.079, 0.089, 0.102, 0.081, 0.077, 0.084, 0.081, 0.069, 0.089, 0.079, 0.069, 0.089, 0.102, 0.114, 0.147, 0.13, 0.068, 0.089, 0.157, 0.078, 0.085, 0.082, 0.072, 0.086, 0.081, 0.096, 0.102, 0.077, 0.107, 0.091, 0.09, 0.119, 0.071, 0.1, 0.072, 0.064, 0.074, 0.081, 0.08, 0.142, 0.079, 0.209, 0.08, 0.087, 0.094, 0.125, 0.069, 0.067, 0.066, 0.085, 0.074, 0.085, 0.083, 0.154, 0.093, 0.096, 0.079, 0.095, 0.087, 0.08, 0.077, 0.071, 0.074, 0.077, 0.073, 0.074, 0.262, 0.081, 0.08, 0.071, 0.12, 0.15, 0.092, 0.102, 0.073, 0.08, 0.106, 0.105, 0.084, 0.081, 0.07, 0.074, 0.095, 0.099, 0.078, 0.077, 0.087, 0.09, 0.074, 0.085, 0.085, 0.102, 0.092, 0.115, 0.087, 0.219, 0.193, 0.122, 0.084, 0.079, 0.079, 0.077, 0.075, 0.075, 0.124, 0.102, 0.085, 0.079, 0.079, 0.108, 0.078, 0.095, 0.087, 0.146, 0.093, 0.112, 0.074, 0.094, 0.097, 0.089, 0.085, 0.089, 0.082, 0.077, 0.061, 0.142, 0.099, 0.072, 0.075, 0.133, 0.096, 0.073, 0.107, 0.07, 0.065, 0.077, 0.084, 0.075, 0.073, 0.081, 0.076, 0.077, 0.074, 0.072, 0.075, 0.095, 0.081, 0.073, 0.411, 0.068, 0.085, 0.079, 0.063, 0.076, 0.076, 0.081, 0.072, 0.07, 0.082, 0.084, 0.074, 0.083, 0.07, 0.087, 0.094, 0.095, 0.078, 0.112, 0.107, 0.061, 0.087, 0.092, 0.07, 0.064, 0.078, 0.102, 0.079, 0.069, 0.076, 0.09, 0.108, 0.071, 0.1, 0.067, 0.153, 0.135, 0.067, 0.106, 0.088, 0.089, 0.078, 0.133, 0.123, 0.069, 0.105, 0.067, 0.064, 0.065, 0.067, 0.094, 0.068, 0.098, 0.091, 0.086, 0.084, 0.105, 0.093, 0.072, 0.09, 0.155, 0.084, 0.072, 0.072, 0.081, 0.081, 0.098, 0.076, 0.083, 0.074, 0.11, 0.08, 0.091, 0.082, 0.077, 0.076, 0.092, 0.098, 0.076, 0.147, 0.122, 0.122, 0.074, 0.073, 0.077, 0.072, 0.092, 0.087, 0.133, 0.074, 0.082, 0.08, 0.085, 0.082, 0.118, 0.117, 0.087, 0.094, 0.102, 0.079, 0.096, 0.078, 0.116, 0.09, 0.089, 0.08, 0.092, 0.073, 0.074, 0.088, 0.076, 0.069, 0.132, 0.109, 0.095, 0.095, 0.152, 0.096, 1.285, 0.084, 0.078, 0.082, 0.081, 0.068, 0.095, 0.096, 0.102, 0.392, 0.102, 0.094, 0.079, 0.09, 0.08, 0.08, 0.089, 0.093, 0.106, 0.122, 0.078, 0.072, 0.08, 0.08, 0.1, 0.077, 0.076, 0.086, 0.071, 0.117, 0.089, 0.135, 0.069, 0.098, 0.093, 0.106, 0.079, 0.09, 0.13, 0.086, 0.067, 0.101, 0.063, 0.079, 0.13, 0.091, 0.069, 0.082, 0.091, 0.088, 0.077, 0.098, 0.085, 0.08, 0.078, 0.081, 0.08, 0.072, 0.126, 0.086, 0.078, 0.1, 0.072, 0.087, 0.142, 0.089, 0.08, 0.076, 0.098, 0.092, 0.073, 0.087, 0.124, 0.086, 0.093, 0.122, 0.167, 0.158, 0.125, 0.082, 0.104, 0.084, 0.091, 0.078, 0.074, 0.081, 0.162, 0.078, 0.071, 0.073, 0.077, 0.092, 0.084, 0.075, 0.072, 0.07, 0.08, 0.136, 0.081, 0.134, 0.155, 0.125, 0.077, 0.141, 0.084, 0.065, 0.134, 0.116, 0.091, 0.068, 0.09, 0.091, 0.089, 0.068, 0.088, 0.089, 0.092, 0.147, 0.108, 0.066, 0.076, 0.099, 0.082, 0.07, 0.098, 0.293, 0.095, 0.075, 0.097, 0.094, 0.088, 0.143, 0.134, 0.094, 0.091, 0.09, 0.104, 0.096, 0.095, 0.087, 0.235, 0.102, 0.135, 0.085, 0.081, 0.082, 0.096, 0.079, 0.078, 0.063, 0.083, 0.098, 0.091, 0.082, 0.09, 0.117, 0.077, 0.071, 0.108, 0.097, 0.101, 0.099, 0.105, 0.114, 0.479, 0.08, 0.189, 0.087, 0.074, 0.086, 0.093, 0.089, 0.064, 0.073, 0.107, 0.087, 0.097, 0.08, 0.12, 0.112, 0.079, 0.083, 0.083, 0.092, 0.084, 0.082, 0.088, 0.081, 0.08, 0.137, 0.078, 0.119    
            ],
            [
                0.151, 0.101, 0.085, 0.061, 0.087, 0.068, 0.163, 0.079, 0.105, 0.077, 0.173, 0.122, 0.107, 0.135, 0.138, 0.081, 0.081, 0.083, 0.136, 0.087, 0.081, 0.104, 0.103, 0.095, 0.11, 0.09, 0.09, 0.817, 0.093, 0.074, 0.086, 0.104, 0.087, 0.143, 0.127, 0.081, 0.082, 0.082, 0.08, 0.108, 0.076, 0.102, 0.079, 0.124, 0.102, 0.095, 0.098, 0.095, 0.091, 0.095, 0.091, 0.089, 0.094, 0.129, 0.093, 0.079, 0.135, 0.116, 0.084, 0.082, 0.098, 0.116, 0.089, 0.134, 0.091, 0.101, 0.089, 0.093, 0.193, 0.081, 0.087, 0.147, 0.083, 0.078, 0.147, 0.097, 0.081, 0.088, 0.082, 0.092, 0.085, 0.084, 0.126, 0.091, 0.079, 0.092, 0.565, 0.075, 0.085, 0.097, 0.083, 0.108, 0.112, 0.083, 0.074, 0.119, 0.103, 0.073, 0.122, 0.087, 0.074, 0.064, 0.064, 0.07, 0.189, 0.099, 0.088, 0.102, 0.087, 0.093, 0.292, 0.085, 0.101, 0.113, 0.064, 0.07, 0.091, 0.095, 0.083, 0.058, 0.11, 0.126, 0.073, 0.102, 0.097, 0.101, 0.104, 0.084, 0.31, 0.075, 0.081, 0.074, 0.078, 0.106, 0.071, 0.075, 0.073, 0.085, 0.071, 0.09, 0.083, 0.079, 0.086, 0.125, 0.069, 0.082, 0.143, 0.094, 0.091, 0.081, 0.078, 0.078, 0.066, 0.065, 0.125, 0.068, 0.105, 0.066, 0.111, 0.072, 0.134, 0.114, 0.079, 0.113, 0.095, 0.26, 0.088, 0.078, 0.11, 0.117, 0.101, 0.165, 0.099, 0.103, 0.107, 0.078, 0.138, 0.066, 0.08, 0.109, 0.076, 0.072, 0.088, 0.114, 0.08, 0.103, 0.157, 0.082, 0.13, 0.085, 0.084, 0.088, 0.092, 0.085, 0.09, 0.084, 0.094, 0.075, 0.073, 0.285, 0.106, 0.109, 0.144, 0.111, 0.102, 0.085, 0.073, 0.088, 0.115, 0.077, 0.079, 0.077, 0.081, 0.1, 0.152, 0.08, 0.104, 0.126, 0.135, 0.084, 0.075, 0.087, 0.14, 0.096, 0.102, 0.165, 0.081, 0.077, 0.176, 0.106, 0.2, 0.106, 0.146, 0.076, 0.088, 0.783, 0.105, 0.074, 0.106, 0.135, 0.081, 0.1, 0.076, 0.077, 0.129, 0.127, 0.101, 0.184, 0.11, 0.105, 0.092, 0.128, 0.113, 0.12, 0.09, 0.099, 0.092, 0.072, 0.096, 0.082, 2.938, 0.092, 0.083, 0.086, 0.144, 0.101, 0.143, 0.084, 0.069, 0.074, 0.116, 0.102, 0.079, 0.093, 0.098, 0.08, 0.081, 0.11, 0.083, 0.088, 0.116, 0.087, 0.065, 0.079, 0.09, 0.085, 0.097, 0.087, 0.08, 0.26, 0.077, 0.098, 0.1, 0.087, 0.081, 0.1, 0.081, 0.114, 0.076, 0.122, 0.086, 0.085, 0.134, 0.077, 0.14, 0.149, 0.07, 0.065, 0.082, 0.119, 0.128, 0.076, 0.12, 0.075, 0.088, 0.085, 0.07, 0.138, 0.072, 0.11, 0.109, 0.097, 0.105, 0.082, 0.082, 0.154, 0.088, 0.078, 0.117, 0.108, 0.084, 0.1, 0.081, 0.076, 0.105, 0.088, 0.083, 0.078, 0.264, 0.088, 0.113, 0.092, 0.125, 0.068, 0.102, 0.083, 0.101, 0.143, 0.079, 0.108, 0.095, 0.097, 0.087, 0.135, 0.088, 0.08, 0.094, 0.086, 0.146, 1.463, 0.088, 0.082, 0.081, 0.085, 0.076, 0.07, 0.136, 0.139, 0.072, 0.076, 0.07, 0.131, 0.112, 0.098, 0.089, 0.216, 0.094, 0.074, 0.078, 0.082, 0.068, 0.093, 0.084, 0.073, 0.122, 0.232, 0.08, 0.084, 0.078, 0.092, 0.107, 0.09, 0.072, 0.089, 0.093, 0.057, 0.074, 0.108, 0.085, 0.119, 0.08, 0.069, 0.065, 0.079, 0.067, 0.101, 0.083, 0.081, 0.098, 0.092, 0.083, 0.084, 0.091, 0.081, 0.104, 0.109, 0.097, 0.099, 0.087, 0.066, 0.167, 0.074, 0.099, 0.074, 0.09, 0.08, 0.077, 0.068, 0.072, 0.071, 0.064, 0.071, 0.073, 0.064, 0.069, 0.114, 0.071, 0.084, 0.101, 0.076, 0.113, 0.094, 0.074, 0.132, 0.12, 0.115, 0.129, 0.084, 0.119, 0.092, 0.081, 0.09, 0.111, 0.084, 0.082, 0.063, 0.08, 0.073, 0.288, 0.11, 0.07, 0.197, 0.084, 0.073, 0.093, 0.143, 0.085, 0.08, 0.13, 0.143, 0.084, 0.108, 0.068, 0.075, 0.087, 0.083, 0.088, 0.13, 0.084, 0.08, 0.092, 0.088, 0.095, 0.078, 0.088, 0.114, 0.089, 0.111, 0.138, 0.074, 0.09, 0.096, 0.103, 0.071, 0.069, 0.097, 0.099, 0.082, 0.08, 0.093, 0.091, 0.084, 0.075, 0.082, 0.073, 0.093, 0.081, 0.109, 0.089, 0.094, 0.083, 0.113, 0.095, 0.08, 0.105, 0.145, 0.08, 0.081, 0.092, 0.079, 0.132, 0.086, 0.138, 0.095, 0.109, 0.089, 0.096, 0.307, 0.149, 0.079, 0.085, 0.103, 0.075, 0.076, 0.092, 0.096, 0.098, 0.085, 0.148, 0.397, 0.081, 0.081, 0.117, 0.08, 0.067, 0.095, 0.067, 0.122, 0.095, 0.075, 0.094, 0.074, 0.087, 0.076, 0.077, 0.078, 0.073, 0.191, 0.075, 0.082, 0.138, 0.131, 0.089, 0.091, 0.084, 0.084, 0.1, 0.069, 0.097, 0.097, 0.093, 0.08, 0.075, 0.108, 0.196, 0.061, 0.11, 0.108, 0.089, 0.119, 0.112, 0.084, 0.076, 0.101, 0.126, 0.115, 0.083, 0.105, 0.121, 0.078, 0.08, 0.145, 0.101, 0.102, 0.155, 0.122, 0.078, 0.075, 0.069, 0.092, 0.397, 0.09, 0.126, 0.086, 0.087, 0.081, 0.078, 0.088, 0.086, 0.143, 0.104, 0.093, 0.07, 0.093, 0.111, 0.137, 0.141, 0.173, 0.078, 0.154, 0.116, 0.063, 0.126, 0.077, 0.088, 0.104, 0.129, 0.077, 0.078, 0.088, 0.112, 0.081, 0.074, 0.134, 0.08, 0.307, 0.107, 0.111, 0.177, 0.091, 0.11, 0.076, 0.083, 0.075, 0.066, 0.099, 0.079, 0.073, 0.075, 0.086, 0.127, 0.132, 0.153, 0.071, 0.068, 0.079, 0.085, 0.11, 0.092, 0.11, 0.086, 0.089, 0.087, 0.108, 0.081, 0.077, 0.066, 0.072, 0.072, 0.087, 0.084, 0.093, 0.09, 0.077, 0.097, 0.074, 0.075, 0.088, 0.118, 0.09, 0.075, 0.078, 0.069, 0.108, 0.133, 0.133, 0.089, 0.093, 0.08, 0.077, 0.079, 0.084, 0.206, 0.084, 0.115, 0.084, 0.192, 0.068, 0.071, 0.09, 0.096, 0.083, 0.1, 0.077, 0.07, 0.075, 0.081, 0.072, 0.105, 0.09, 0.229, 0.091, 0.113, 0.061, 0.085, 0.078, 0.125, 0.085, 1.158, 0.089, 0.085, 0.069, 0.064, 0.104, 0.112, 0.079, 0.128, 0.086, 0.098, 0.078, 0.084, 0.104, 0.096, 0.086, 0.084, 0.209, 0.119, 0.089, 0.13, 0.14, 0.136, 0.066, 0.079, 0.087, 0.099, 0.077, 0.077, 0.083, 0.102, 0.292, 0.139, 0.077, 0.076, 0.081, 0.084, 0.107, 0.09, 0.132, 0.114, 0.095, 0.096, 0.139, 1.122, 0.07, 0.07, 0.077, 0.085, 0.079, 0.094, 0.077, 0.075, 0.122, 0.127, 0.079, 0.098, 0.106, 0.091, 0.088, 0.104, 0.084, 0.069, 0.122, 0.133, 0.107, 0.133, 0.082, 0.066, 0.071, 0.129, 0.093, 0.082, 0.127, 0.09, 0.123, 0.071, 0.112, 0.12, 0.109, 0.116, 0.09, 0.139, 0.082, 0.098, 0.087, 0.089, 0.084, 0.125, 0.102, 0.069, 0.107, 0.108, 0.073, 0.067, 0.148, 0.077, 0.112, 0.076, 0.086, 0.155, 0.115, 0.138, 0.095, 0.136, 0.087, 0.15, 0.088, 0.091, 0.096, 0.106, 0.086, 0.089, 0.105, 0.084, 0.105, 0.095, 0.109, 0.296, 0.153, 0.084, 0.091, 0.237, 0.09, 0.082, 0.197, 0.133, 0.122, 0.123, 0.113, 0.076, 0.078, 0.211, 0.067, 0.12, 0.121, 0.135, 0.086, 0.088, 0.087, 0.078, 0.097, 0.094, 0.119, 0.082, 0.085, 0.06, 0.068, 0.199, 0.102, 0.076, 0.09, 0.084, 0.124, 0.084, 0.138, 0.086, 0.103, 0.115, 0.101, 0.082, 0.105, 0.085, 0.091, 0.089, 0.11, 0.1, 0.123, 0.084, 0.168, 0.136, 0.102, 0.08, 0.108, 0.095, 0.123, 0.123, 0.148, 0.088, 0.089, 0.093, 0.097, 0.071, 0.098, 0.081, 0.064, 0.072, 0.085, 0.111, 0.087, 0.133, 0.079, 0.071, 0.089, 0.126, 0.075, 0.096, 0.105, 0.156, 0.091, 0.138, 0.066, 0.098, 0.101, 0.093, 0.09, 0.1, 0.112, 0.142, 0.076, 0.077, 0.072, 0.085, 0.124, 0.095, 0.125, 0.091, 0.113, 0.095, 0.109, 0.097, 0.084, 0.1, 0.085, 0.096, 0.088, 0.081, 0.082, 0.069, 0.077, 0.065, 0.189, 0.219, 0.085, 0.087, 0.087, 0.06, 0.085, 0.079, 0.102, 0.092, 0.086, 0.085, 0.077, 0.904, 0.072, 0.105, 0.112, 0.086, 0.125, 0.088, 0.097, 0.065, 0.122, 0.1, 0.122, 0.078, 0.105, 0.092, 0.133, 0.091, 0.061, 0.083, 0.063, 0.098, 0.114, 0.128, 0.133, 0.071, 0.36, 0.084, 0.088, 0.092, 0.094, 0.095, 0.092, 0.098, 0.093, 0.092, 0.091, 0.127, 0.086, 0.084, 0.113, 0.084, 0.077, 0.086, 0.102, 0.084, 0.111, 0.078, 0.128, 0.097, 0.089, 0.091, 0.144, 0.082, 0.073, 0.052, 0.083, 0.082, 0.082, 0.076, 0.098, 0.084, 0.094, 0.121, 0.15, 0.1, 0.083, 0.122, 0.111, 0.09, 0.139, 0.119, 0.088, 0.114, 0.135, 0.078, 0.143, 0.091, 0.077, 0.082, 0.071, 0.09, 0.176, 0.088, 0.102, 0.09, 0.098, 0.082, 0.139, 0.08, 0.085, 0.08, 0.318, 0.122, 0.114, 0.424, 0.081, 0.104, 0.083, 0.727, 0.072, 0.339, 0.081, 0.076, 0.099, 0.105, 0.083, 0.088, 0.092, 0.096, 0.085, 0.104, 0.082, 0.154, 0.104, 0.084, 0.079, 0.088, 0.09, 0.21, 0.102, 0.078, 0.079, 0.138, 0.101, 0.116, 0.07, 0.095, 0.12, 0.082, 0.093, 0.069, 0.099, 0.111, 0.086, 0.098, 0.104, 0.112, 0.074, 0.079, 0.1, 0.087, 0.111, 0.108, 0.068, 0.128, 0.099, 0.092, 0.105, 0.089, 0.116, 0.106, 0.085, 0.071, 0.07, 0.092, 0.133, 0.119, 0.122, 0.075, 0.126, 0.091, 0.111, 0.1, 0.076, 0.118, 0.117, 0.093, 0.065, 0.074, 0.079, 0.123, 0.124, 0.143, 0.08, 0.061, 0.076, 0.087, 0.175, 0.127, 0.127, 0.071, 0.104, 0.089, 0.101, 0.09, 0.103, 0.068, 0.09, 0.062, 0.101, 0.09, 0.089, 0.099, 0.069, 0.092, 0.13, 0.075, 0.217, 0.388, 0.068, 0.096, 0.109, 0.091, 0.082, 0.141, 0.092, 0.146, 0.087, 0.088, 0.079, 0.084, 0.163, 0.107, 0.098, 0.083, 0.073, 0.072, 0.105, 0.076, 0.076, 0.08, 0.065, 0.12, 1.531, 0.091, 0.071, 0.127, 0.118, 0.1, 0.125, 0.08, 0.188, 0.096, 0.107, 0.094, 0.174, 0.163, 0.093, 0.079, 0.064, 0.121, 0.124, 0.126, 0.138, 0.104, 0.074, 0.088, 0.102, 0.076, 0.086, 0.07, 0.096, 0.103, 0.089, 0.105, 0.092, 0.09, 0.083, 0.095, 0.108, 0.089, 0.148, 0.095, 0.104, 0.09, 0.075, 0.099, 0.1, 0.094, 0.092, 0.1, 0.139, 0.084, 0.095, 0.08, 0.079, 0.109, 0.114, 0.083, 0.085, 0.167, 0.085, 0.078, 0.118, 0.093, 0.121, 0.1, 0.092, 0.079, 0.089, 0.079, 0.102, 0.084, 0.082, 0.086, 0.088, 0.087, 0.072, 0.09, 0.096, 0.075, 0.119, 0.118, 0.09, 0.076, 0.103, 0.083, 0.086, 0.092, 0.086, 0.085, 0.088, 0.079, 0.072, 0.118, 0.1, 0.075, 0.104, 0.092, 0.088, 0.131, 0.103, 0.089, 0.116, 0.115, 0.097, 0.098, 0.077, 0.091, 0.097, 0.086, 0.098, 0.099, 0.125, 0.076, 0.093, 0.087, 0.134, 0.08, 0.083, 0.087, 0.074, 0.081, 0.062, 0.095, 0.069, 0.11, 0.068, 0.08, 0.309, 0.087, 0.073, 0.091, 0.093, 0.094, 0.084, 0.092, 0.117, 0.094, 0.11, 0.074, 0.127, 0.071, 0.129, 0.08, 0.09, 0.091, 0.31, 0.093, 0.086, 0.101, 0.091, 0.103, 0.061, 0.135, 0.077, 0.086, 0.131, 0.134, 0.077, 0.126, 0.171, 0.063, 0.096, 0.083, 0.083, 0.104, 0.107, 0.097, 0.083, 0.084, 0.113, 0.083, 0.132, 0.129, 0.088, 0.119, 0.099, 0.085, 0.09, 0.095, 0.072, 0.078, 0.125, 0.128, 0.138, 0.15, 0.178, 0.095, 0.077, 0.09, 0.08, 0.091, 0.102, 0.104, 0.086, 0.111, 0.103, 0.085, 0.101, 0.101, 0.075, 0.088, 0.09, 0.093, 0.071, 0.062, 0.075, 0.078, 0.085, 0.091, 1.139, 0.066, 0.088, 0.091, 0.087, 0.088, 0.073, 0.08, 0.089, 0.087, 0.09, 0.08, 0.078, 0.241, 0.119, 0.085, 0.079, 0.1, 0.088, 0.128, 0.126, 0.1, 0.107, 0.082, 0.112, 0.093, 0.1, 0.111, 0.085, 0.111, 0.148, 0.099, 0.12, 0.09, 0.145, 0.092, 0.083, 0.084, 0.083, 0.129, 0.075, 0.089, 0.115, 0.076, 0.118, 0.122, 0.082, 0.095, 0.07, 0.094, 0.118, 0.114, 0.115, 0.2, 0.09, 0.084, 0.087, 0.079, 0.07, 0.059, 0.08, 0.098, 0.115, 0.1, 0.081, 0.06, 0.125, 0.099, 0.07, 0.081, 0.08, 0.072, 0.099, 0.087, 0.124, 0.506, 0.105, 0.095, 0.12, 0.09, 0.156, 0.081, 0.067, 1.278, 0.093, 0.083, 0.078, 0.082, 0.074, 0.089, 0.106, 0.083, 0.076, 0.077, 0.096, 0.07, 0.134, 0.078, 0.094, 0.086, 0.089, 0.25, 0.095, 0.08, 0.106, 0.086, 0.079, 0.076, 0.09, 0.082, 0.086, 0.103, 0.086, 0.065, 0.076, 0.075, 0.067, 0.095, 0.106, 0.079, 0.086, 0.079, 0.084, 0.092, 0.072, 0.084, 0.116, 0.081, 0.07, 0.072, 0.134, 0.065, 0.093, 0.099, 0.123, 0.084, 0.146, 0.066, 0.099, 0.079, 0.089, 0.847, 0.102, 0.084, 0.066, 0.069, 0.1, 0.075, 0.1, 0.108, 0.075, 0.196, 0.094, 0.088, 0.068, 0.079, 0.072, 0.08, 0.074, 0.103, 0.066, 0.082, 0.064, 0.069, 0.075, 0.069, 0.074, 0.082, 0.147, 0.096, 0.092, 0.083, 0.237, 0.076, 0.07, 0.118, 0.074, 0.083, 0.072, 0.075, 0.077, 0.067, 0.126, 0.091, 0.112, 0.087, 0.085, 0.085, 0.083, 0.09, 0.069, 0.091, 0.088, 0.118, 0.075, 0.101, 0.119, 0.209, 0.082, 0.11, 0.089, 0.09, 0.075, 0.081, 0.094, 0.08, 0.077, 0.072, 0.107, 0.18, 0.063, 0.093, 0.102, 0.092, 0.087, 0.073, 0.097, 0.15, 0.078, 0.072, 0.09, 0.085, 0.083, 0.089, 0.072, 0.107, 0.071, 0.068, 0.077, 0.089, 0.076, 0.079, 0.072, 0.08, 0.09, 0.064, 0.08, 0.117, 0.077, 0.082, 0.098, 0.086, 0.084, 0.085, 0.077, 0.082, 0.081, 0.087, 0.074, 0.073, 0.067, 0.119, 0.08, 0.069, 0.091, 0.078, 0.071, 0.088, 0.094, 0.09, 0.087, 0.081, 0.078, 0.117, 0.075, 0.067, 0.071, 0.095, 0.14, 0.1, 0.078, 0.07, 0.108, 0.279, 0.107, 0.097, 0.101, 0.083, 0.076, 0.106, 0.083, 0.111, 0.088, 0.092, 0.181, 0.066, 0.078, 0.071, 0.075, 0.081, 0.07, 0.063, 0.121, 0.082, 0.113, 0.08, 0.082, 0.08, 0.139, 0.069, 0.074, 0.067, 0.093, 0.07, 0.085, 0.074, 0.1, 0.079, 0.076, 0.103, 0.086, 0.123, 0.087, 0.12, 0.127, 0.124, 0.069, 0.105, 0.073, 0.108, 0.082, 0.102, 0.123, 0.219, 0.072, 0.131, 0.1, 0.087, 0.085, 0.063, 0.099, 0.085, 0.116, 0.07, 0.067, 0.082, 0.1, 0.278, 0.095, 0.132, 0.108, 0.083, 0.067, 0.07, 0.077, 0.077, 0.076, 0.09, 0.079, 0.098, 0.078, 0.08, 0.073, 0.104, 0.072, 0.079, 0.084, 0.678, 0.087, 0.083, 0.083, 0.088, 0.126, 0.082, 0.109, 0.106, 0.078, 0.074, 0.272, 0.086, 0.091, 0.081, 0.093, 0.094, 0.085, 0.086, 0.122, 0.062, 0.114, 0.064, 0.085, 0.085, 0.093, 0.134, 0.194, 0.084, 0.07, 0.068, 0.109, 0.092, 0.111, 0.07, 0.081, 0.071, 0.108, 0.11, 0.087, 0.105, 0.075, 0.072, 0.118, 0.085, 0.074, 0.065, 0.093, 0.067, 0.125, 0.083, 0.104, 0.069, 0.095, 0.098, 0.066, 0.1, 0.121, 0.274, 0.093, 0.075, 0.073, 0.069, 0.098, 0.085, 0.07, 0.092, 0.076, 0.088, 0.084, 0.079, 0.078, 0.093, 0.068, 0.134, 0.102, 0.071, 0.084, 0.072, 0.138, 0.095, 0.06, 0.073, 0.191, 0.077, 0.119, 0.09, 0.092, 0.1, 0.123, 0.082, 0.099, 0.098, 0.132, 0.077, 0.091, 0.115, 0.099, 0.082, 0.125, 0.267, 0.116, 0.129, 0.083, 0.088, 0.094, 0.128, 0.095, 0.084, 0.079, 0.069, 0.085, 0.067, 0.093, 0.086, 0.08, 0.076, 0.082, 0.094, 0.118, 0.111, 0.083, 0.099, 0.135, 0.087, 0.095, 0.086, 0.071, 0.072, 0.071, 0.071, 0.061, 0.069, 0.091, 0.069, 0.104, 0.078, 0.082, 0.098, 0.111, 0.077, 0.061, 0.075, 0.077, 0.083, 0.07, 0.095, 0.191, 0.186, 0.095, 0.117, 0.109, 0.105, 0.076, 0.091, 0.096, 0.1, 0.076, 0.087, 0.09, 0.077, 0.092, 0.078, 0.104, 0.066, 0.067, 0.087, 0.071, 0.065, 0.091, 0.102, 0.072, 0.072, 0.201, 0.074, 0.072, 0.113, 0.259, 0.073, 0.078, 0.078, 0.07, 0.073, 0.086, 0.23, 0.089, 0.065, 0.127, 0.098, 0.128, 0.145, 0.103, 0.097, 0.137, 0.086, 0.107, 0.113, 0.069, 0.091, 0.101, 0.078, 0.115, 0.14, 0.101, 0.125, 0.086, 0.067, 3.096, 0.085, 0.089, 0.086, 0.076, 0.09, 0.075, 0.104, 0.125, 0.157, 0.092, 0.22, 0.143, 0.107, 0.094, 0.102, 0.264, 0.152, 0.123, 0.081, 0.126, 0.091, 0.103, 0.096, 0.129, 0.099, 0.153, 0.139, 0.125, 0.088, 0.094, 0.148, 0.107, 0.087, 0.117, 0.097, 0.096, 0.082, 0.131, 0.13, 0.097, 0.122, 0.097, 0.12, 0.081, 0.101, 0.082, 0.632, 0.075, 0.121, 0.105, 0.105, 0.079, 0.081, 0.126, 0.091, 0.15, 0.134, 0.114, 0.175, 0.102, 0.092, 0.092, 0.087, 0.157, 0.092, 0.09, 0.086, 0.078, 0.108, 0.067, 0.094, 0.087, 0.087, 0.092, 0.099, 0.103, 0.192, 0.12, 0.118, 0.08, 0.091, 0.104, 0.083, 0.082, 0.09, 0.083, 0.082, 0.1, 0.137, 0.099, 0.125, 0.085, 0.18, 0.091, 0.1, 0.09, 0.123, 0.089, 0.104, 0.13, 0.082, 0.089, 0.098, 0.071, 0.071, 0.1, 0.086, 0.086, 0.162, 0.083, 0.084, 0.113, 0.101, 0.122, 0.094, 0.156, 0.098, 0.135, 0.177, 0.088, 0.093, 0.088, 0.074, 0.081, 0.075, 0.083, 0.167, 0.064, 0.107, 0.097, 0.138, 0.087, 0.121, 0.2, 0.092, 0.135, 0.121, 0.132, 1.336, 0.129, 0.088, 0.09, 0.16, 0.108, 0.09, 0.249, 0.115, 0.089, 0.134, 0.08, 0.087, 0.195, 0.097, 0.129, 0.091, 0.096, 0.147, 0.098, 0.086, 0.091, 0.088, 0.101, 0.134, 0.138, 0.09, 0.103, 0.096, 0.084, 0.1, 0.089, 0.084, 0.102, 0.105, 0.123, 0.149, 0.112, 0.091, 0.206, 0.101, 0.109, 0.086, 0.079, 0.084, 0.206, 0.081, 0.137, 0.104, 0.105, 0.092, 0.09, 0.088, 0.114, 0.106, 0.082, 0.127, 0.138, 0.141, 0.078, 0.078, 0.123, 0.11, 0.098, 0.116, 0.091, 0.147, 0.106, 0.21, 0.086, 0.128, 0.104, 0.106, 0.1, 0.08, 0.335, 0.09, 0.084, 0.134, 0.152, 0.112, 0.115, 0.105, 0.142, 0.1, 0.089, 0.09, 0.094, 0.107, 0.093, 0.133, 0.102, 0.308, 0.092, 0.097, 0.139, 0.1, 0.089, 0.112, 0.1, 0.089, 0.085, 0.096, 0.108, 0.091, 0.097, 0.09, 0.145, 0.089, 0.091, 0.098, 0.083, 0.15, 0.154, 0.091, 0.287, 0.088, 0.086, 0.104, 0.096, 0.087, 0.101, 0.091, 0.088, 0.09, 0.091, 0.091, 0.085, 0.088, 0.087, 0.351, 0.088, 0.075, 0.094, 0.147, 0.146, 0.084, 0.156, 0.081, 0.091, 0.089, 0.094, 0.098, 0.146, 0.129, 0.163, 0.087, 0.136, 0.161, 0.109, 0.098, 0.108, 0.107, 0.093, 0.166, 0.086, 0.117, 0.135, 0.093, 0.087, 0.089, 0.899, 0.079, 0.146, 0.092, 0.083, 0.155, 0.092, 0.095, 0.084, 0.078, 0.088, 0.08, 0.088, 0.082, 0.093, 0.095, 0.126, 0.124, 0.102, 0.098, 0.135, 0.124, 0.083, 0.079, 0.084, 0.076, 0.122, 0.088, 0.137, 0.102, 0.221, 0.087, 0.098, 0.091, 0.093, 0.084, 0.087, 0.146, 0.095, 0.084, 0.107, 0.117, 0.093, 0.116, 0.099, 0.094, 0.097, 0.075, 0.091, 0.072, 0.065, 0.112, 0.072, 0.105, 0.112, 0.077, 0.104, 0.073, 0.124, 0.166, 0.093, 0.08, 0.079, 0.123, 0.108, 0.085, 0.125, 0.087, 0.094, 0.097, 0.088, 0.092, 0.077, 0.096, 3.321, 0.136, 0.086, 0.116, 0.112, 0.153, 0.102, 0.097, 0.089, 0.129, 0.106, 0.083, 0.082, 0.069, 0.07, 0.161, 0.09, 0.096, 0.164, 0.083, 0.092, 0.08, 0.087, 0.081, 0.123, 0.092, 0.078, 0.081, 0.084, 0.105, 0.104, 0.203, 0.079, 0.085, 0.08, 0.091, 0.09, 0.08, 0.138, 0.117, 0.089, 1.429, 0.146, 0.093, 0.117, 0.098, 0.128, 0.098, 0.214, 0.121, 0.148, 0.122, 0.084, 0.072, 0.275, 0.093, 0.07, 0.065, 0.075, 0.095, 0.085, 0.071, 0.087, 0.085, 0.083, 0.09, 0.09, 0.074, 0.113, 0.118, 0.079, 0.1, 0.088, 0.095, 0.087, 0.136, 0.118, 0.108, 0.096, 0.097, 0.09, 0.076, 0.088, 0.075, 0.078, 0.099, 0.076, 0.08, 0.063, 0.759, 0.099, 0.09, 0.117, 0.112, 0.081, 0.108, 0.077, 0.079, 0.104, 0.118, 0.09, 0.075, 0.08, 0.073, 0.256, 0.238, 0.085, 0.096, 0.084, 0.095, 0.12, 0.076, 0.115, 0.081, 0.097, 0.125, 0.099, 0.095, 0.086, 0.132, 0.091, 0.106, 0.093, 0.076, 0.087, 0.094, 0.092, 0.116, 0.09, 0.084, 0.096, 0.084, 0.328, 0.078, 0.076, 0.086, 0.088, 0.087, 0.091, 0.075, 0.091, 0.089, 0.081, 0.082, 0.089, 0.093, 0.091, 0.081, 0.112, 0.103, 0.088, 0.086, 0.069, 0.097, 0.111, 0.079, 0.082, 0.127, 0.08, 0.111, 0.069, 0.142, 0.073, 0.087, 0.1, 0.082, 0.09, 0.128, 0.171, 0.083, 0.111, 0.1, 0.292, 0.122, 0.078, 0.086, 0.095, 0.097, 0.084, 0.11, 0.079, 0.285, 0.092, 0.1, 0.091, 0.089, 0.094, 0.089, 0.102, 0.07, 0.071, 0.072, 0.095, 0.116, 0.069, 0.084, 0.075, 0.119, 0.08, 0.096, 0.116, 0.092, 0.082, 0.073, 0.089, 0.084, 0.09, 0.081, 0.101, 0.106, 0.103, 0.097, 0.097, 0.082, 0.093, 0.077, 0.089, 0.08, 0.068, 0.088, 0.081, 0.119, 0.086, 0.115, 0.106, 0.123, 0.071, 0.093, 0.171, 0.083, 0.094, 0.081, 0.084, 0.111, 0.097, 0.106, 0.086, 0.089, 0.082, 0.104, 0.116, 0.12, 0.083, 0.114, 0.079, 0.083, 0.096, 0.096, 0.085, 0.171, 0.085, 0.217, 0.085, 0.085, 0.126, 0.145, 0.096, 0.094, 0.098, 0.08, 0.089, 0.097, 0.082, 0.111, 0.096, 0.074, 0.068, 0.085, 0.091, 0.095, 0.085, 0.093, 0.092, 0.084, 0.082, 0.084, 0.304, 0.08, 0.081, 0.09, 0.13, 0.166, 0.098, 0.129, 0.079, 0.063, 0.103, 0.094, 0.07, 0.127, 0.076, 0.081, 0.087, 0.082, 0.109, 0.067, 0.078, 0.086, 0.079, 0.081, 0.083, 0.09, 0.079, 0.11, 0.092, 0.221, 0.207, 0.125, 0.07, 0.063, 0.076, 0.082, 0.071, 0.082, 0.126, 0.117, 0.095, 0.089, 0.082, 0.12, 0.093, 0.11, 0.082, 0.128, 0.079, 0.122, 0.096, 0.116, 0.129, 0.116, 0.078, 0.085, 0.083, 0.098, 0.089, 0.119, 0.109, 0.089, 0.095, 0.137, 0.105, 0.095, 0.132, 0.096, 0.085, 0.112, 0.113, 0.106, 0.1, 0.114, 0.075, 0.082, 0.073, 0.07, 0.082, 0.134, 0.107, 0.104, 0.41, 0.071, 0.09, 0.097, 0.067, 0.097, 0.076, 0.068, 0.061, 0.069, 0.105, 0.107, 0.093, 0.122, 0.101, 0.069, 0.113, 0.104, 0.075, 0.104, 0.142, 0.097, 0.096, 0.082, 0.086, 0.069, 0.079, 0.106, 0.088, 0.113, 0.113, 0.106, 0.129, 0.097, 0.103, 0.068, 0.163, 0.143, 0.079, 0.1, 0.091, 0.071, 0.068, 0.139, 0.151, 0.089, 0.113, 0.081, 0.085, 0.096, 0.082, 0.091, 0.095, 0.1, 0.083, 0.088, 0.077, 0.118, 0.097, 0.08, 0.09, 0.101, 0.087, 0.098, 0.126, 0.092, 0.078, 0.096, 0.091, 0.097, 0.088, 0.109, 0.082, 0.095, 0.089, 0.097, 0.08, 0.09, 0.116, 0.09, 0.168, 0.123, 0.148, 0.099, 0.102, 0.088, 0.094, 0.108, 0.083, 0.134, 0.087, 0.091, 0.083, 0.092, 0.078, 0.104, 0.094, 0.084, 0.122, 0.122, 0.11, 0.099, 0.097, 0.101, 0.101, 0.083, 0.071, 0.097, 0.066, 0.069, 0.094, 0.081, 0.063, 0.123, 0.091, 0.102, 0.107, 0.128, 0.097, 1.129, 0.079, 0.088, 0.069, 0.092, 0.092, 0.105, 0.124, 0.09, 0.433, 0.119, 0.099, 0.1, 0.095, 0.096, 0.083, 0.106, 0.093, 0.117, 0.107, 0.096, 0.077, 0.083, 0.08, 0.092, 0.102, 0.099, 0.078, 0.072, 0.107, 0.088, 0.139, 0.08, 0.11, 0.091, 0.082, 0.097, 0.084, 0.135, 0.093, 0.086, 0.14, 0.09, 0.096, 0.148, 0.12, 0.085, 0.098, 0.114, 0.101, 0.087, 0.147, 0.087, 0.079, 0.069, 0.073, 0.07, 0.088, 0.127, 0.092, 0.078, 0.082, 0.083, 0.088, 0.106, 0.078, 0.061, 0.073, 0.076, 0.085, 0.07, 0.076, 0.091, 0.091, 0.075, 0.103, 0.177, 0.18, 0.141, 0.085, 0.107, 0.098, 0.081, 0.095, 0.086, 0.084, 0.125, 0.101, 0.091, 0.084, 0.083, 0.078, 0.079, 0.079, 0.081, 0.098, 0.09, 0.124, 0.09, 0.128, 0.106, 0.128, 0.089, 0.096, 0.071, 0.077, 0.136, 0.114, 0.084, 0.085, 0.089, 0.09, 0.103, 0.073, 0.075, 0.104, 0.078, 0.091, 0.13, 0.07, 0.099, 0.098, 0.083, 0.086, 0.105, 0.309, 0.094, 0.086, 0.088, 0.087, 0.086, 0.117, 0.116, 0.095, 0.098, 0.106, 0.109, 0.098, 0.095, 0.093, 0.238, 0.113, 0.129, 0.083, 0.095, 0.127, 0.134, 0.08, 0.096, 0.088, 0.085, 0.096, 0.089, 0.064, 0.09, 0.126, 0.091, 0.075, 0.103, 0.09, 0.141, 0.124, 0.116, 0.09, 0.527, 0.068, 0.207, 0.089, 0.086, 0.081, 0.105, 0.105, 0.079, 0.095, 0.092, 0.108, 0.102, 0.102, 0.137, 0.128, 0.09, 0.077, 0.093, 0.086, 0.079, 0.095, 0.091, 0.075, 0.077, 0.119, 0.089, 0.145, 0.099, 0.064, 0.098, 0.08, 0.088, 0.092, 0.08, 0.078, 0.066, 0.067, 0.063, 0.183, 0.089, 0.084, 0.185, 0.081, 0.069, 0.102, 0.074, 0.065, 0.086, 0.095, 0.073, 0.125, 0.086, 0.091, 0.158, 0.135, 0.094, 0.117, 0.095, 0.108, 0.093, 0.104, 0.084, 0.103, 0.129, 0.116, 0.099, 0.084, 0.083, 0.098, 0.101, 0.109, 0.304, 0.084, 0.07, 0.085, 0.105, 0.1, 0.074, 0.077, 0.079, 0.12, 0.077, 0.09, 0.09, 0.093, 0.108, 0.088, 0.116, 0.09, 0.084, 0.154, 0.13, 0.082, 0.067, 0.068, 0.114, 0.072, 0.099, 0.079, 0.105, 0.079, 0.075, 0.097, 0.145, 0.135, 0.067, 0.068, 0.081, 0.079, 0.073, 0.084, 0.102, 0.072, 0.089, 0.095, 0.378, 0.105, 0.112, 0.096, 0.081, 0.083, 0.081, 0.073, 0.074, 0.075, 0.108, 0.105, 0.091, 0.074, 0.076, 0.112, 0.215, 0.093, 0.122, 0.077, 0.11, 0.077, 0.096, 0.129, 0.102, 0.084, 0.088, 0.083, 0.07, 0.099, 0.067, 0.323, 0.085, 0.071, 0.083, 0.075, 0.141, 0.084, 0.145, 0.104, 0.116, 0.098, 0.07, 0.073, 0.093, 0.076, 0.072, 0.094, 0.061, 0.116, 0.068, 0.061, 0.08, 0.839, 0.129, 0.085, 0.316, 0.097, 0.088, 0.071, 0.125, 0.07, 0.084, 0.099, 0.111, 0.164, 0.071, 0.127, 0.096, 0.1, 0.093, 0.094, 0.073, 0.112, 0.112, 0.22, 0.089, 0.093, 0.09, 0.129, 0.112, 0.113, 0.089, 0.072, 0.088, 0.151, 0.075, 0.079, 0.11, 0.083, 0.137, 0.091, 0.08, 0.086, 0.126, 0.122, 0.099, 0.102, 0.084, 0.114, 0.098, 0.156, 0.079, 0.073, 0.083, 0.09, 0.114, 0.134, 0.137, 0.067, 0.111, 0.099, 0.07, 0.079, 0.128, 0.068, 0.08, 0.071, 0.077, 0.093, 0.084, 0.114, 0.07, 0.09, 0.083, 0.077, 0.067, 0.069, 0.076, 0.082, 0.117, 0.09, 0.1, 0.096, 0.074, 0.076, 0.079, 0.118, 0.083, 0.112, 0.109, 0.083, 0.077, 0.075, 0.104, 0.098, 0.272, 0.214, 0.069, 0.119, 0.09, 0.079, 0.071, 0.075, 0.105, 0.089, 0.086, 0.092, 0.082, 0.097, 0.07, 0.103, 0.102, 0.07, 0.08, 0.072, 0.069, 0.089, 0.064, 0.502, 0.091, 0.127, 0.075, 0.089, 0.099, 0.139, 0.11, 0.093, 0.087, 0.073, 0.065, 0.136, 0.063, 0.082, 0.072, 0.064, 0.079, 0.074, 0.069, 0.108, 0.107, 0.109, 0.123, 0.061, 0.079, 0.07, 0.071, 0.11, 0.076, 0.07, 0.126, 0.098, 0.091, 0.07, 0.089, 0.092, 0.086, 0.093, 0.187, 0.073, 0.098, 0.085, 0.2, 0.097, 0.15, 0.074, 0.097, 0.142, 0.081, 0.101, 0.204, 0.092, 0.085, 0.159, 0.087, 0.085, 0.089, 0.083, 0.097, 0.091, 0.068, 0.088, 0.096, 0.071, 0.071, 0.089, 0.074, 0.091, 0.094, 0.09, 0.074, 0.1, 0.129, 0.074, 0.083, 0.092, 0.087, 0.07, 0.101, 0.068, 0.079, 0.085, 0.105, 0.087, 0.08, 0.067, 0.08, 0.072, 0.087, 0.09, 0.218, 0.076, 0.076, 0.079, 0.065, 0.068, 0.163, 0.068, 0.068, 0.088, 0.098, 0.083, 0.089, 0.072, 0.099, 3.036, 0.061, 0.104, 0.065, 0.076, 0.07, 0.118, 0.083, 0.082, 0.095, 0.125, 0.092, 0.086, 0.091, 0.108, 0.08, 0.156, 0.068, 0.103, 0.326, 0.079, 0.096, 0.069, 0.094, 0.16, 0.074, 0.063, 0.112, 0.073, 0.085, 0.076, 0.084, 0.077, 0.078, 0.099, 0.065, 1.296, 0.109, 0.071, 0.112, 1.457, 0.077, 0.135, 0.084, 0.067, 0.094, 0.155, 0.071, 0.141, 0.07, 0.082, 0.076, 0.124, 0.127, 0.08, 0.092, 0.07, 0.078, 0.079, 0.08, 0.062, 0.078, 0.122, 0.083, 0.083, 0.069, 0.074, 0.074, 0.072, 0.079, 0.075, 0.083, 0.089, 0.099, 0.083, 0.095, 0.116, 0.081, 0.085, 0.081, 0.095, 0.121, 0.113, 0.089, 0.105, 0.084, 0.091, 0.115, 0.077, 0.072, 0.069, 0.106, 0.129, 0.107, 0.112, 0.11, 0.08, 0.083, 0.069, 0.1, 0.111, 0.079, 0.103, 0.272, 0.079, 0.114, 0.083, 0.103, 0.119, 0.088, 0.113, 0.068, 0.135, 0.144, 0.146, 0.074, 0.102, 0.067, 0.065, 0.164, 0.08, 0.08, 0.11, 0.066, 0.19, 0.076, 0.076, 0.093, 0.065, 0.077, 0.09, 0.074, 0.067, 0.093, 0.096, 0.098, 0.074, 0.106, 0.085, 0.106, 0.085, 0.076, 0.108, 0.117, 0.14, 0.085, 0.084, 0.127, 0.07, 0.071, 0.078, 0.096, 0.101, 0.108, 0.07, 0.261, 0.074, 0.076, 0.066, 0.587, 0.148, 0.086, 0.14, 0.128, 0.07, 0.075, 0.086, 0.094, 0.087, 0.284, 0.088, 0.101, 0.088, 0.098, 0.093, 0.098, 0.092, 0.08, 0.079, 0.093, 0.088, 0.102, 0.08, 0.07, 0.082, 0.079, 0.126, 0.066, 0.076, 0.07, 0.168, 0.076, 0.097, 0.091, 0.077, 0.069, 0.1, 0.083, 0.078, 0.081, 0.091, 0.06, 0.077, 0.104, 0.096, 0.088, 0.091, 0.085, 0.103, 0.073, 0.064, 0.074, 0.076, 0.111, 0.078, 0.216, 0.076, 0.109, 0.228, 0.075, 0.131, 0.129, 0.226, 0.09, 0.072, 0.09, 0.065, 0.085, 0.065, 0.07, 0.081, 0.087, 0.076, 0.107, 0.068, 0.077, 0.075, 0.138, 0.082, 0.08, 0.101, 0.203, 0.087, 0.086, 0.066, 0.069, 0.073, 0.126, 0.08, 0.153, 0.09, 0.083, 0.086, 0.077, 0.075, 0.09, 0.133, 0.067, 0.119, 0.134, 0.089, 0.075, 0.128, 0.086, 0.081, 0.084, 0.069, 0.106, 0.067, 0.061, 0.16, 0.066, 0.093, 0.082, 0.076, 0.168, 0.087, 0.084, 0.1, 0.074, 0.131, 0.074, 0.077, 0.096, 0.09, 0.098, 0.166, 0.082, 0.081, 0.124, 0.25, 0.095, 0.07, 0.064, 0.065, 0.128, 0.084, 0.083, 0.079, 0.105, 0.07, 0.065, 0.121, 0.104, 0.079, 0.149, 0.096, 0.093, 0.091, 0.094, 0.099, 0.068, 0.066, 0.09, 0.083, 0.07, 0.083, 0.103, 0.091, 0.681, 0.079, 0.073, 0.1, 0.069, 0.101, 0.074, 0.089, 0.091, 0.075, 0.11, 0.07, 0.1, 0.082, 0.086, 0.092, 0.086, 0.111, 0.072, 0.132, 0.109, 0.075, 0.093, 0.093, 0.076, 0.093, 0.076, 0.074, 0.1, 0.084, 0.076, 0.156, 0.087, 0.414, 0.078, 0.105, 0.094, 0.066, 0.071, 0.099, 0.105, 0.083, 0.071, 0.128, 0.065, 0.18, 0.16, 0.082, 0.078, 0.066, 0.066, 0.076, 0.067, 0.103, 0.087, 0.079, 0.075, 0.091, 0.105, 0.074, 0.095, 0.098, 0.082, 0.079, 0.069, 0.08, 0.062, 0.074, 0.1, 0.083, 0.078, 0.068, 0.095, 0.075, 0.105, 0.131, 0.099, 0.074, 0.073, 0.062, 0.063, 0.104, 0.08, 0.1, 0.089, 0.075, 0.102, 0.107, 0.093, 0.067, 0.085, 0.063, 0.118, 0.112, 0.068, 0.085, 0.088, 0.065, 0.073, 0.067, 0.064, 0.067, 0.081, 0.271, 0.118, 0.099, 0.077, 0.117, 0.091, 0.07, 0.061, 0.068, 0.073, 0.07, 0.09, 0.096, 0.105, 0.106, 0.09, 0.078, 0.074, 0.083, 0.124, 0.075, 0.093, 0.068, 0.105, 0.076, 0.071, 0.076, 0.066, 0.276, 0.088, 0.065, 0.074, 0.082, 0.063, 0.104, 0.095, 0.091, 0.086, 0.078, 0.059, 0.084, 0.074, 0.069, 0.069, 0.087, 0.096, 0.074, 0.094, 0.066, 0.07, 0.09, 0.097, 0.087, 0.065, 0.09, 0.067, 0.098, 0.078, 0.087, 0.064, 0.096, 0.105, 0.071, 0.078, 0.096, 0.126, 0.089, 0.116, 0.099, 0.084, 0.069, 0.071, 0.096, 0.06, 0.071, 0.082, 0.126, 0.081, 0.074, 0.096, 0.085, 0.073, 0.148, 0.081, 0.074, 0.079, 0.073, 0.091, 0.089, 0.095, 0.089, 0.069, 0.075, 0.093, 0.082, 0.084, 0.071, 0.072, 0.171, 0.069, 0.103, 0.101, 0.088, 0.126, 0.1, 0.087, 0.083, 0.063, 0.093, 0.094, 0.069, 0.093, 0.074, 0.062, 0.096, 0.094, 0.102, 0.132, 0.073, 0.071, 0.06, 0.065, 0.121, 0.105, 0.084, 0.062, 0.094, 0.109, 0.066, 0.117, 0.085, 0.083, 0.07, 0.072, 0.069, 0.083, 0.104, 0.068, 0.077, 0.08, 0.084, 0.073, 0.076, 0.065, 0.102, 0.069, 0.105, 0.119, 0.152, 0.082, 0.081, 0.078, 0.088, 0.069, 0.086, 0.075, 0.067, 0.094, 0.082, 0.073, 0.086, 0.188, 0.08, 0.072, 0.079, 0.09, 0.088, 0.066, 1.078, 0.082, 0.104, 0.142, 0.12, 0.13, 0.104, 0.082, 0.125, 0.094, 0.114, 0.073, 0.088, 0.071, 0.097, 0.079, 0.07, 0.066, 0.293, 0.086, 0.116, 0.122, 0.085, 0.08, 0.156, 0.109, 0.075, 0.104, 0.102, 0.141, 0.075, 0.087, 0.068, 0.119, 0.083, 0.076, 0.098, 0.113, 0.09, 0.207, 0.112, 0.07, 0.089, 0.077, 0.084, 0.092, 0.077, 0.074, 0.081, 0.082, 0.094, 0.074, 0.078, 0.133, 0.084, 0.097, 0.207, 0.085, 0.09, 0.078, 0.135, 0.081, 0.357, 0.089, 0.238, 0.102, 0.068, 0.124, 0.091, 0.083, 0.063, 0.084, 0.087, 0.073, 0.075, 0.07, 0.084, 0.125, 0.068, 0.066, 0.077, 0.087, 0.066, 0.068, 0.096, 0.094, 0.208, 0.115, 0.126, 0.096, 0.125, 0.095, 0.074, 0.109, 0.058, 0.061, 0.072, 0.06, 0.063, 0.058, 0.077, 0.068, 0.08, 0.078, 0.116, 0.126, 0.089, 0.082, 0.108, 0.128, 0.127, 0.105, 0.109, 0.07, 0.139, 0.09, 0.131, 0.143, 0.144, 0.076, 0.084, 0.097, 0.144, 0.094, 0.136, 0.081, 0.083, 0.084, 0.111, 0.092, 0.083, 0.099, 0.11, 0.074, 0.092, 0.073, 0.074, 0.095, 0.083, 0.078, 0.084, 0.074, 0.092, 0.121, 0.077, 0.115, 0.078, 0.103, 0.135, 0.101, 0.099, 0.084, 0.08, 0.107, 0.093, 0.11, 0.082, 0.137, 0.08, 0.094, 0.069, 0.114, 0.09, 0.083, 0.083, 0.12, 0.163, 0.097, 0.132, 0.096, 0.076, 0.059, 0.069, 0.095, 0.092, 0.108, 0.086, 0.083, 0.146, 0.085, 0.11, 0.082, 0.081, 0.15, 0.145, 0.08, 0.09, 0.105, 0.086, 0.072, 0.058, 0.091, 0.074, 0.105, 0.134, 0.11, 0.086, 0.105, 0.134, 0.111, 0.077, 2.943, 0.084, 0.093, 0.085, 0.086, 0.085, 0.082, 0.074, 0.091, 0.103, 0.067, 0.089, 0.084, 0.078, 0.072, 0.298, 0.08, 0.064, 0.07, 0.068, 0.081, 0.089, 0.06, 0.063, 0.075, 0.143, 0.086, 0.077, 0.081, 0.09, 0.133, 0.138, 0.089, 0.287, 0.098, 0.085, 0.137, 0.095, 0.078, 0.084, 0.102, 0.096, 0.07, 0.213, 0.174, 0.068, 0.121, 0.129, 0.1, 0.088, 0.134, 0.108, 0.086, 0.097, 0.082, 0.084, 0.075, 0.085, 0.08, 0.073, 0.117, 0.085, 0.063, 0.071, 0.069, 0.101, 0.071, 0.106, 0.091, 0.093, 0.077, 0.121, 0.082, 0.107, 0.08, 0.079, 0.074, 0.144, 0.088, 0.072, 0.134, 0.104, 0.113, 0.086, 0.13, 0.13, 0.207, 0.095, 0.074, 0.081, 0.1, 0.099, 0.108, 0.092, 0.074, 0.071, 0.086, 0.088, 0.088, 0.082, 0.092, 0.093, 0.136, 0.109, 0.075, 0.103, 0.077, 0.087, 0.08, 0.102, 0.065, 0.086, 0.096, 0.087, 0.086, 0.088, 0.1, 0.071, 0.101, 0.102, 0.102, 0.084, 0.075, 0.088, 0.661, 0.116, 0.091, 0.121, 0.081, 0.136, 0.112, 0.084, 0.077, 0.1, 0.092, 0.13, 0.087, 0.09, 0.094, 0.075, 0.123, 0.091, 0.089, 0.082, 0.077, 0.083, 0.079, 0.065, 0.118, 0.079, 1.189, 0.094, 0.07, 0.067, 0.071, 0.075, 0.085, 0.088, 0.078, 0.094, 0.074, 0.08, 0.064, 0.068, 0.067, 0.078, 0.077, 0.068, 0.121, 0.069, 0.088, 0.082, 0.088, 0.13, 0.098, 0.08, 0.142, 0.12, 0.07, 0.153, 0.078, 0.15, 0.075, 0.076, 0.081, 0.103, 0.079, 0.072, 0.154, 0.111, 0.089, 0.157, 0.115, 0.104, 0.11, 0.171, 0.104, 0.118, 0.088, 0.095, 0.095, 0.084, 0.103, 0.069, 0.073, 0.116, 0.075, 0.066, 0.085, 0.082, 0.112, 0.108, 0.121, 0.089, 0.165, 0.091, 0.103, 0.064, 0.073, 0.074, 0.06, 0.173, 0.082, 0.096, 0.221, 0.086, 0.073, 0.088, 0.09, 0.136, 0.097, 0.085, 0.122, 0.086, 0.08, 0.081, 0.09, 0.08, 0.095, 0.076, 0.113, 0.093, 0.073, 0.073, 0.064, 0.063, 0.072, 0.079, 0.069, 0.093, 0.074, 0.081, 0.105, 0.087, 0.097, 0.093, 0.072, 0.213, 0.079, 0.081, 0.104, 0.082, 0.104, 0.073, 0.071, 0.075, 0.09, 0.096, 0.069, 0.105, 0.074, 0.062, 0.096, 0.084, 0.081, 0.127, 0.105, 0.084, 0.075, 0.2, 0.106, 0.201, 0.101, 0.061, 0.08, 0.084, 0.081, 0.081, 0.076, 0.095, 0.085, 0.099, 0.086, 0.09, 0.093, 0.08, 0.104, 0.089, 0.134, 0.089, 0.087, 0.102, 0.089, 0.089, 0.092, 0.11, 0.094, 0.091, 0.114, 0.093, 0.09, 0.111, 0.213, 0.095, 0.067, 0.078, 0.098, 0.077, 0.087, 0.104, 0.092, 0.084, 0.086, 0.072, 0.085, 0.084, 0.106, 0.077, 0.104, 0.123, 0.093, 0.081, 0.085, 0.085, 0.097, 0.102, 0.071, 0.071, 0.08, 0.068, 0.086, 0.12, 0.144, 0.08, 0.067, 0.075, 0.107, 0.085, 0.079, 0.082, 0.067, 0.073, 0.201, 0.077, 0.071, 0.086, 0.074, 0.387, 0.082, 0.124, 0.109, 0.084, 0.294, 0.403, 0.073, 0.084, 0.075, 0.067, 0.074, 0.084, 0.13, 0.112, 0.076, 0.115, 0.083, 0.072, 0.072, 0.098, 0.067, 0.106, 0.104, 0.082, 0.105, 0.165, 0.087, 0.078, 0.114, 0.132, 0.067, 0.067, 0.069, 0.057, 0.084, 0.074, 0.102, 0.09, 0.087, 0.151, 0.096, 0.089, 0.071, 0.078, 0.077, 0.093, 0.086, 0.081, 0.079, 0.128, 0.088, 0.069, 0.077, 0.073, 0.081, 0.084, 0.083, 0.147, 0.081, 0.078, 0.093, 0.078, 0.077, 0.081, 0.089, 0.087, 0.086, 0.083, 0.064, 0.069, 0.062, 0.09, 0.078, 0.099, 0.114, 0.108, 0.076, 0.084, 0.082, 0.076, 0.062, 0.063, 0.069, 0.08, 0.093, 0.091, 0.1, 0.091, 0.074, 0.081, 0.084, 0.138, 0.09, 0.093, 0.073, 0.079, 0.086, 0.092, 0.094, 0.096, 0.101, 0.074, 0.086, 0.073, 0.081, 0.069, 0.079, 0.113, 0.128, 0.072, 0.098, 0.093, 0.078, 0.065, 0.079, 0.082, 0.1, 0.084, 0.077, 0.073, 0.106, 0.09, 0.09, 0.112, 0.08, 0.083, 0.09, 0.097, 0.075, 0.077, 0.085, 0.083, 0.077, 0.073, 0.083, 0.094, 0.079, 0.077, 0.094, 0.134, 0.068, 0.069, 0.066, 0.091, 0.084, 0.095, 0.086, 0.068, 0.072, 0.071, 0.07, 0.071, 0.061, 0.089, 0.124, 0.117, 0.093, 0.063, 0.103, 0.111, 0.095, 0.128, 0.101, 0.081, 0.079, 0.107, 0.086, 0.099, 0.079, 0.084, 0.071, 0.102, 0.073, 0.098, 0.095, 0.078, 0.068, 0.068, 0.084, 0.064, 0.072, 0.075, 0.082, 0.081, 0.063, 0.16, 0.079, 0.109, 0.08, 0.071, 0.085, 0.448, 0.086, 0.08, 0.098, 0.107, 0.095, 0.08, 0.09, 0.089, 0.098, 0.129, 0.09, 0.086, 0.12, 0.073, 0.275, 0.132, 0.083, 0.088, 0.139, 0.097, 0.095, 0.08, 0.07, 0.107, 0.1, 0.096, 0.101, 0.088, 0.072, 0.079, 0.066, 0.085, 0.082, 0.103, 0.078, 0.07, 0.09, 0.088, 0.085, 0.081, 0.088, 0.085, 0.075, 0.062, 0.125, 0.081, 0.093, 0.108, 0.08, 0.08, 0.069, 0.087, 0.066, 0.28, 0.079, 0.078, 0.264, 0.084, 0.071, 0.185, 0.084, 0.101, 0.06, 0.071, 0.111, 0.073, 0.274, 0.075, 0.076, 0.08, 0.062, 0.079, 0.082, 0.097, 0.081, 0.086, 0.1, 0.095, 0.079, 0.104, 0.076, 0.076, 0.13, 0.084, 0.093, 0.092, 0.101, 0.204, 0.086, 0.079, 0.061, 0.123, 0.092, 0.101, 0.096, 0.098, 0.094, 0.095, 0.084, 0.093, 0.147, 0.094, 0.098, 0.066, 0.111, 0.131, 0.086, 0.098, 0.103, 0.133, 0.093, 0.098, 0.116, 1.033, 0.078, 0.079, 0.135, 0.15, 0.081, 0.086, 0.089, 0.169, 0.102, 0.086, 0.097, 0.102, 0.172, 0.161, 0.061, 0.065, 0.083, 0.079, 0.081, 0.062, 0.102, 0.162, 0.088, 0.064, 0.107, 0.115, 0.084, 0.127, 0.096, 0.238, 1.517, 0.072, 0.083, 0.093, 0.065, 0.085, 0.083, 0.077, 0.106, 0.093, 0.82, 0.139, 0.087, 0.107, 0.093, 0.111, 0.121, 0.124, 0.104, 0.092, 0.083, 0.088, 0.128, 0.085, 0.077, 0.087, 0.094, 0.076, 0.301, 0.073, 0.07, 0.072, 0.113, 0.088, 0.075, 0.083, 0.075, 0.078, 0.085, 0.084, 0.082, 0.154, 0.112, 0.085, 0.095, 0.081, 0.088, 0.154, 0.098, 0.083, 0.095, 0.09, 0.072, 0.083, 0.101, 0.068, 0.071, 0.077, 0.081, 0.072, 0.096, 0.086, 0.107, 0.073, 0.095, 0.092, 0.086, 0.086, 0.075, 0.069, 0.088, 0.13, 0.122, 0.085, 0.077, 0.067, 0.084, 0.08, 0.067, 0.082, 0.076, 0.112, 0.337, 0.137, 0.075, 0.085, 0.079, 0.093, 0.75, 0.114, 0.084, 0.083, 0.084, 0.121, 0.11, 0.09, 0.074, 0.089, 0.102, 0.197, 0.112, 0.091, 0.09, 0.068, 0.073, 0.076, 0.086, 0.124, 0.093, 0.095, 0.076, 0.087, 0.086, 0.098, 0.089, 0.081, 0.104, 0.073, 0.078, 0.228, 0.087, 0.185, 0.087, 0.081, 0.095, 0.088, 0.104, 0.093, 0.111, 0.098, 0.078, 0.101, 0.094, 0.125, 0.085, 0.122, 0.095, 0.242, 0.075, 0.09, 0.08, 0.087, 0.097, 0.096, 0.103, 0.098, 0.124, 0.085, 0.068, 0.085, 0.095, 0.136, 0.06, 0.068, 0.123, 0.084, 0.167, 0.097, 0.089, 0.073, 0.1, 0.109, 0.09, 0.089, 0.075, 0.104, 0.121, 0.089, 0.104, 0.085, 0.096, 0.085, 0.082, 0.09, 0.089, 0.102, 0.098, 0.091, 0.093, 0.096, 0.083, 0.066, 0.108, 0.079, 0.111, 0.094, 0.079, 0.083, 0.084, 0.088, 0.102, 0.12, 0.078, 0.109, 0.088, 0.182, 0.083, 0.088, 0.077, 0.072, 0.11, 0.071, 0.081, 0.074, 0.093, 0.104, 0.109, 0.068, 0.065, 0.063, 0.078, 0.245, 0.071, 0.075, 0.088, 0.082, 0.092, 0.082, 0.087, 0.088, 0.124, 0.118, 0.239, 0.084, 0.13, 0.125, 0.061, 0.103, 0.089, 0.115, 0.083, 0.082, 0.098, 0.114, 0.073, 0.077, 0.08, 0.079, 0.097, 0.08, 0.117, 0.113, 0.094, 0.071, 0.089, 0.071, 0.072, 0.069, 0.117, 0.133, 0.085, 0.076, 0.085, 0.076, 0.101, 0.082, 0.09, 0.089, 0.066, 0.086, 0.123, 0.073, 0.077, 0.072, 0.083, 0.093, 0.085, 0.076, 0.072, 0.088, 0.075, 0.066, 0.079, 0.077, 0.095, 0.074, 0.228, 0.082, 0.116, 0.078, 0.19, 0.069, 0.081, 0.083, 0.106, 0.082, 0.1, 0.152, 0.105, 0.216, 0.082, 0.072, 0.09, 0.092, 0.085, 0.062, 0.073, 0.124, 0.096, 0.093, 0.097, 0.076, 0.102, 0.134, 0.073, 0.109, 0.084, 0.079, 0.082, 0.098, 0.113, 0.097, 0.139, 0.086, 0.088, 0.082, 0.115, 0.089, 0.108, 0.083, 0.098, 0.077, 0.085, 0.075, 0.101, 0.134, 0.09, 0.079, 0.086, 0.111, 0.102, 0.087, 0.116, 0.129, 0.115, 0.091, 0.074, 0.091, 0.135, 0.097, 0.117, 0.128, 0.16, 0.119, 0.093, 0.141, 0.144, 0.123, 0.12, 0.122, 0.099, 0.077, 0.081, 0.084
            ]
        ], 
        [#filter or not
            [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
                0.173, 0.151, 0.172, 0.212, 0.17, 0.164, 0.223, 0.231, 0.152, 0.256, 0.157, 0.152, 0.166, 0.61, 0.159, 0.151, 0.157, 0.192, 0.139, 0.15, 0.128, 0.192, 0.17, 0.162, 0.143, 0.125, 0.21, 0.148, 0.254, 0.136, 0.195, 0.19, 0.142, 0.137, 0.231, 0.212, 0.126, 0.16, 0.122, 0.126, 0.119, 0.211, 0.121, 0.421, 0.161, 0.192, 0.178, 0.182, 0.189, 0.203, 0.14, 0.136, 0.231, 0.124, 0.111, 0.274, 0.206, 0.122, 0.153, 0.14, 0.191, 0.128, 0.151, 0.161, 0.327, 0.159, 0.142, 0.145, 0.126, 0.134, 0.143, 0.194, 0.126, 0.169, 0.141, 0.134, 0.096, 0.148, 0.2, 0.21, 0.177, 0.178, 0.283, 0.141, 0.177, 0.201, 0.186, 0.163, 0.15, 0.125, 0.111, 0.155, 0.138, 0.175, 0.188, 0.134, 0.155, 0.17, 0.234, 0.271, 0.178, 0.203, 0.166, 0.132, 0.144, 0.155, 0.156, 0.186, 0.195, 0.211, 0.118, 0.187, 0.217, 0.128, 0.182, 0.226, 0.198, 0.525, 0.185, 0.155, 0.132, 0.137, 0.204, 0.177, 0.14, 0.195, 0.177, 0.158, 0.152, 0.144, 2.159, 0.143, 0.224, 0.215, 0.138, 0.175, 0.145, 0.143, 0.21, 0.16, 0.156, 0.14, 0.166, 0.142, 0.28, 0.158, 0.149, 0.121, 0.238, 0.195, 0.141, 0.192, 0.241, 0.136, 0.18, 0.226, 0.208, 0.208, 0.195, 0.155, 0.199, 0.167, 0.21, 0.185, 0.26, 0.14, 0.134, 0.165, 0.14, 0.274, 0.201, 0.21, 0.162, 0.227, 0.159, 0.148, 0.152, 0.14, 0.155, 1.205, 0.159, 0.122, 0.138, 0.2, 0.129, 0.221, 0.215, 0.224, 0.164, 0.13, 0.149, 0.148, 0.243, 0.235, 0.193, 0.143, 0.167, 0.133, 0.179, 0.192, 0.134, 0.145, 0.202, 0.15, 0.167, 0.169, 0.218, 0.21, 0.17, 0.152, 0.183, 0.24, 0.145, 0.13, 0.144, 0.123, 0.144, 0.147, 0.143, 0.176, 0.202, 0.231, 0.238, 0.253, 0.217, 0.143, 0.189, 0.158, 0.139, 0.457, 0.224, 0.133, 0.209, 0.151, 0.22, 0.176, 0.141, 0.149, 0.242, 0.133, 0.12, 0.114, 0.155, 0.12, 0.168, 0.165, 0.122, 0.122, 0.12, 0.123, 0.094, 0.123, 0.105, 0.194, 0.119, 0.201, 0.123, 0.17, 0.125, 0.102, 0.155, 0.157, 0.141, 0.298, 0.18, 0.131, 0.123, 0.124, 0.163, 0.374, 0.126, 0.185, 0.157, 0.191, 0.182, 0.169, 0.111, 0.135, 0.21, 0.217, 0.181, 0.124, 0.126, 0.108, 0.13, 0.143, 0.174, 0.205, 0.205, 0.218, 0.189, 0.164, 0.152, 0.15, 0.183, 0.189, 0.152, 0.18, 0.136, 0.112, 0.357, 0.158, 0.182, 0.165, 0.173, 0.177, 0.156, 0.167, 0.173, 0.204, 0.125, 0.151, 0.148, 0.127, 0.108, 0.113, 0.13, 0.262, 0.141, 0.187, 0.13, 0.122, 0.108, 0.097, 0.11, 0.129, 0.185, 0.103, 0.147, 0.184, 0.129, 0.148, 0.115, 0.138, 0.122, 0.134, 0.152, 0.153, 0.103, 0.147, 0.117, 0.124, 0.177, 0.114, 0.13, 0.124, 0.196, 0.19, 0.217, 0.176, 0.118, 0.202, 0.138, 0.138, 0.166, 0.227, 0.179, 0.103, 0.243, 0.939, 0.115, 0.18, 0.171, 0.182, 0.143, 0.186, 0.125, 0.218, 0.144, 0.2, 0.197, 0.155, 0.127, 0.113, 0.293, 0.248, 0.114, 0.136, 0.151, 0.167, 0.15, 0.949, 0.186, 0.132, 0.207, 0.168, 0.17, 0.151, 0.134, 0.142, 0.164, 0.209, 0.169, 0.1, 0.175, 0.209, 0.203, 0.152, 0.191, 0.137, 0.17, 0.144, 0.146, 0.193, 0.141, 0.15, 0.182, 0.201, 0.122, 0.179, 0.161, 0.235, 0.199, 0.133, 0.187, 0.156, 0.136, 0.134, 0.362, 0.128, 0.241, 0.236, 0.187, 0.139, 0.154, 0.213, 0.192, 0.202, 0.13, 0.121, 0.127, 0.194, 0.133, 0.16, 0.115, 0.155, 0.167, 0.14, 0.126, 0.218, 0.114, 0.181, 0.16, 0.178, 0.21, 0.128, 0.159, 0.186, 0.156, 0.139, 0.125, 0.119, 0.121, 0.123, 0.17, 0.102, 0.161, 0.182, 0.187, 0.183, 0.108, 0.117, 0.142, 0.146, 0.12, 0.171, 0.139, 0.144, 0.143, 0.12, 0.124, 0.094, 0.104, 0.177, 0.196, 0.239, 0.128, 0.122, 0.108, 0.096, 0.1, 0.726, 0.155, 0.153, 0.124, 0.163, 0.202, 0.147, 0.15, 0.122, 0.119, 0.204, 0.169, 0.319, 0.128, 0.085, 0.098, 0.11, 0.117, 0.179, 0.152, 0.121, 0.164, 0.143, 0.156, 0.137, 0.217, 0.191, 0.128, 0.135, 0.12, 0.134, 0.199, 0.128, 0.167, 0.12, 0.11, 0.156, 0.176, 0.124, 0.129, 0.187, 0.136, 0.118, 0.176, 0.097, 0.278, 0.147, 0.355, 0.141, 0.599, 0.314, 0.122, 0.118, 0.116, 0.106, 0.125, 0.167, 0.104, 0.106, 0.209, 0.133, 0.178, 0.143, 0.198, 0.167, 0.141, 0.167, 0.102, 0.103, 0.109, 0.14, 0.106, 0.148, 0.113, 0.141, 0.13, 0.104, 0.156, 0.159, 0.144, 0.152, 0.146, 0.188, 0.102, 0.114, 0.163, 0.175, 0.115, 0.216, 0.162, 0.146, 0.133, 0.123, 0.131, 0.13, 0.11, 0.141, 0.124, 0.195, 0.363, 0.134, 0.12, 0.181, 0.185, 0.148, 0.163, 0.136, 0.109, 0.129, 0.1, 0.118, 1.186, 0.119, 0.164, 0.166, 0.194, 0.145, 0.166, 0.146, 0.114, 0.182, 0.205, 0.134, 0.145, 0.134, 0.138, 0.151, 0.161, 0.137, 0.154, 0.225, 0.103, 0.086, 0.107, 0.11, 0.136, 0.116, 0.144, 0.176, 0.155, 0.141, 0.128, 0.148, 0.144, 0.145, 0.116, 0.144, 0.129, 0.125, 0.171, 0.17, 0.215, 0.199, 0.141, 0.112, 0.124, 0.108, 0.142, 0.126, 0.135, 0.197, 0.186, 0.187, 0.18, 0.142, 0.134, 0.158, 0.115, 0.239, 0.15, 0.123, 0.143, 0.129, 0.139, 0.314, 0.129, 0.153, 0.151, 0.186, 0.185, 0.167, 0.136, 0.117, 0.294, 0.12, 0.139, 0.133, 0.128, 0.16, 0.175, 0.22, 0.166, 0.113, 0.129, 0.138, 0.169, 0.187, 0.143, 0.158, 0.115, 0.106, 0.223, 0.171, 0.264, 0.176, 0.163, 0.125, 0.115, 0.164, 0.159, 0.162, 0.121, 0.11, 0.123, 0.128, 0.97, 0.138, 0.11, 0.109, 0.115, 0.113, 0.104, 0.257, 0.107, 0.145, 0.161, 0.121, 0.178, 0.137, 0.154, 0.166, 0.205, 0.189, 0.236, 0.2, 0.228, 0.177, 0.151, 0.193, 0.147, 0.16, 0.141, 0.217, 0.104, 0.099, 0.116, 0.152, 0.122, 0.168, 0.135, 0.099, 0.163, 0.16, 0.427, 0.158, 0.183, 0.126, 0.952, 0.16, 0.141, 0.21, 0.155, 0.139, 0.242, 0.148, 0.083, 0.275, 0.124, 0.105, 0.115, 0.114, 0.13, 0.128, 0.178, 0.203, 0.11, 0.102, 0.117, 0.131, 0.115, 0.111, 0.134, 0.178, 0.208, 0.111, 0.163, 0.863, 0.159, 0.185, 0.227, 0.123, 0.172, 0.101, 0.106, 0.128, 0.177, 0.132, 0.145, 0.112, 0.197, 0.145, 0.235, 0.134, 0.135, 0.134, 0.134, 0.152, 0.126, 0.106, 0.098, 0.128, 0.15, 0.198, 0.148, 0.226, 0.124, 0.115, 0.108, 0.106, 0.145, 0.19, 0.135, 0.114, 0.116, 0.152, 0.125, 0.142, 0.117, 0.158, 0.101, 0.157, 0.084, 0.141, 0.118, 0.168, 0.149, 0.12, 0.144, 0.149, 0.161, 0.082, 0.136, 0.125, 0.111, 0.184, 0.168, 0.141, 0.129, 0.111, 0.153, 0.117, 0.131, 0.392, 0.132, 0.103, 0.117, 0.118, 0.2, 0.157, 0.139, 0.133, 0.169, 0.199, 0.119, 0.149, 0.116, 0.181, 0.162, 0.148, 0.113, 0.125, 0.207, 0.165, 0.147, 0.187, 0.165, 0.174, 0.223, 0.164, 0.151, 0.178, 0.165, 0.132, 0.165, 0.271, 0.209, 0.143, 0.131, 0.155, 0.134, 0.131, 0.123, 0.146, 0.139, 0.548, 0.121, 0.174, 0.143, 0.127, 0.26, 0.132, 0.115, 0.113, 0.179, 0.16, 0.107, 0.116, 0.221, 0.101, 0.12, 0.165, 0.098, 0.174, 0.161, 0.164, 0.181, 0.118, 0.151, 0.183, 0.186, 0.164, 0.167, 0.195, 0.306, 0.084, 0.117, 0.108, 0.114, 0.152, 0.149, 0.126, 0.205, 0.101, 0.145, 0.161, 0.199, 0.239, 0.128, 0.186, 0.142, 0.169, 0.128, 0.158, 0.204, 0.285, 0.151, 0.112, 0.194, 0.127, 0.186, 0.144, 0.149, 0.134, 0.204, 0.144, 0.186, 0.169, 0.131, 0.119, 0.126, 0.107, 0.152, 0.107, 0.208, 0.128, 0.172, 0.138, 0.217, 0.195, 0.17, 0.188, 0.165, 0.157, 0.124, 0.145, 0.217, 0.11, 0.102, 0.109, 0.159, 0.203, 0.103, 0.268, 0.127, 0.136, 0.137, 0.224, 0.15, 0.16, 0.179, 0.145, 0.116, 0.141, 0.147, 0.168, 0.169, 0.153, 2.091, 0.093, 0.092, 0.123, 0.19, 0.167, 0.256, 0.12, 0.244, 0.202, 0.16, 0.117, 0.137, 0.177, 0.17, 0.133, 0.18, 0.115, 0.1, 0.155, 0.188, 0.114, 0.162, 0.102, 0.484, 0.186, 0.125, 0.166, 0.173, 0.143, 0.155, 0.124, 0.173, 0.111, 0.109, 0.149, 0.138, 0.099, 0.108, 0.208, 0.187, 0.151, 0.135, 0.149, 0.122, 0.157, 0.134, 0.169, 0.152, 0.21, 0.159, 0.171, 0.126, 0.117, 0.1, 0.114, 0.088, 0.096, 0.105, 0.18, 0.203, 0.124, 0.108, 0.097, 0.161, 0.141, 0.188, 0.198, 0.143, 0.125, 1.031, 0.112, 0.155, 0.202, 0.133, 0.191, 0.226, 0.203, 0.105, 0.201, 0.141, 0.16, 0.209, 0.124, 0.13, 0.154, 0.15, 0.203, 0.205, 0.22, 0.174, 0.133, 0.228, 0.166, 0.157, 0.104, 0.143, 0.11, 0.186, 0.219, 0.161, 0.141, 0.127, 0.171, 0.201, 0.133, 0.124, 0.274, 0.133, 0.182, 0.124, 0.148, 0.111, 0.134, 0.161, 0.168, 0.287, 0.152, 0.126, 0.182, 0.107, 0.112, 0.104, 0.193, 0.132, 0.145, 0.172, 0.29, 0.104, 0.132, 0.12, 0.103, 0.121, 0.123, 0.108, 0.319, 0.137, 0.211, 0.18, 0.109, 0.141, 0.184, 0.163, 0.177, 0.251, 0.146, 0.141, 0.213, 0.213, 0.153, 0.716, 0.178, 0.106, 0.16, 0.121, 0.109, 0.107, 0.114, 0.158, 0.179, 0.192, 0.193, 0.134, 0.178, 0.149, 0.221, 0.117, 0.147, 0.133, 0.192, 0.122, 0.156, 0.148, 0.175, 0.12, 0.115, 0.168, 0.159, 0.151, 0.157, 0.213, 0.121, 0.187, 0.206, 0.112, 0.127, 0.111, 2.406, 0.164, 0.175, 0.18, 0.145, 0.227, 0.096, 0.095, 0.137, 0.165, 0.107, 0.106, 0.177, 0.105, 0.092, 0.218, 0.212, 0.124, 0.172, 0.194, 0.155, 1.178, 0.12, 0.11, 0.193, 0.148, 0.128, 0.256, 0.12, 0.099, 0.126, 0.099, 0.108, 0.133, 0.197, 0.188, 0.15, 0.126, 0.18, 0.159, 0.106, 0.13, 0.143, 0.219, 0.135, 0.677, 0.255, 0.174, 0.188, 0.178, 0.188, 0.12, 0.244, 0.248, 0.114, 0.167, 0.214, 0.127, 0.205, 0.137, 0.165, 0.139, 0.096, 0.143, 0.133, 0.116, 0.292, 0.105, 0.11, 0.124, 0.118, 0.132, 0.136, 0.146, 0.18, 0.12, 0.104, 0.148, 0.11, 0.171, 0.179, 0.175, 0.156, 0.121, 0.213, 0.105, 0.444, 0.201, 0.211, 0.119, 0.144, 0.273, 0.121, 0.114, 0.117, 0.128, 0.149, 0.197, 0.149, 0.208, 0.168, 0.138, 0.128, 0.141, 0.124, 0.149, 0.145, 0.152, 0.154, 0.154, 0.136, 0.151, 0.154, 0.164, 0.18, 0.122, 0.143, 0.164, 0.187, 0.174, 0.196, 0.232, 0.211, 0.154, 0.137, 0.185, 0.213, 0.14, 0.147, 0.097, 0.089, 0.124, 0.196, 0.126, 0.131, 0.135, 0.123, 0.117, 0.311, 0.131, 0.188, 0.178, 0.157, 0.172, 0.17, 0.164, 0.149, 0.16, 0.154, 0.144, 0.1, 0.195, 0.207, 0.308, 0.158, 0.131, 0.134, 0.239, 0.181, 0.122, 0.229, 0.211, 0.166, 0.171, 0.143, 0.139, 0.117, 0.127, 0.156, 0.12, 0.175, 0.179, 0.13, 0.174, 0.188, 0.172, 0.135, 0.109, 0.164, 0.347, 0.153, 0.154, 0.133, 0.108, 0.119, 0.141, 0.172, 0.172, 0.134, 0.161, 0.14, 0.128, 0.132, 0.195, 0.171, 0.206, 0.201, 0.226, 0.174, 0.154, 0.104, 0.179, 0.142, 0.133, 0.118, 0.137, 0.148, 0.128, 0.145, 0.142, 0.151, 0.125, 0.117, 0.132, 0.121, 0.132, 0.124, 0.14, 0.137, 0.178, 0.173, 0.155, 0.133, 0.129, 0.19, 0.114, 0.125, 0.181, 0.178, 0.188, 0.164, 0.144, 0.133, 0.188, 0.106, 0.129, 0.15, 0.167, 0.18, 0.963, 0.12, 0.128, 0.165, 0.336, 0.145, 0.134, 0.103, 0.123, 0.167, 0.1, 0.13, 0.162, 0.152, 0.128, 0.128, 0.119, 0.096, 0.098, 0.198, 0.136, 0.111, 0.222, 0.106, 0.147, 0.135, 0.107, 0.095, 0.126, 0.146, 0.117, 0.123, 0.145, 0.1, 0.155, 0.122, 0.205, 0.2, 0.248, 0.147, 0.131, 0.122, 0.13, 0.173, 0.123, 0.118, 0.128, 0.135, 0.161, 0.19, 0.174, 0.17, 0.13, 0.201, 0.127, 0.171, 0.145, 0.144, 0.149, 0.221, 0.147, 0.141, 0.295, 0.129, 0.138, 0.148, 0.191, 0.121, 0.17, 0.116, 0.272, 0.128, 0.127, 0.166, 0.117, 0.114, 0.122, 0.174, 0.11, 0.225, 0.214, 0.189, 0.425, 0.191, 0.108, 0.137, 0.115, 0.145, 0.159, 0.208, 0.101, 0.107, 0.102, 0.116, 0.146, 0.128, 0.162, 0.149, 0.133, 0.139, 0.111, 0.183, 0.09, 0.191, 0.133, 0.105, 0.11, 0.152, 0.091, 0.158, 0.135, 0.115, 0.096, 0.092, 0.162, 0.147, 0.121, 0.137, 0.31, 0.101, 0.13, 0.146, 0.158, 0.111, 0.151, 0.127, 0.148, 0.154, 0.181, 0.114, 0.189, 0.149, 0.106, 0.132, 0.205, 0.103, 0.106, 0.151, 0.202, 0.132, 0.347, 0.146, 0.113, 0.116, 0.125, 0.156, 0.092, 0.158, 0.192, 0.127, 0.112, 0.119, 0.133, 0.109, 0.103, 0.315, 0.123, 0.131, 0.164, 0.199, 0.157, 0.116, 0.1, 0.115, 0.134, 0.083, 0.679, 0.126, 0.278, 0.087, 0.12, 0.11, 0.189, 0.128, 0.096, 0.154, 0.157, 0.204, 0.095, 0.135, 0.119, 0.097, 0.139, 0.125, 0.14, 0.157, 0.098, 0.159, 0.129, 0.138, 0.155, 0.11, 0.138, 0.195, 0.164, 0.149, 0.115, 0.171, 0.099, 0.119, 0.154, 0.103, 0.131, 0.102, 0.128, 0.191, 0.114, 0.122, 0.199, 0.159, 0.2, 0.102, 0.124, 0.355, 0.105, 0.116, 0.102, 0.128, 0.101, 0.118, 0.139, 0.102, 0.136, 0.107, 0.434, 0.16, 0.138, 0.174, 0.141, 0.118, 0.18, 0.15, 0.139, 0.127, 0.118, 0.202, 0.113, 0.096, 0.119, 0.135, 0.151, 0.108, 0.106, 0.105, 0.179, 0.115, 0.208, 0.113, 0.16, 0.11, 0.205, 0.172, 0.105, 0.113, 0.121, 0.104, 0.103, 0.126, 0.12, 0.124, 0.101, 0.139, 0.127, 0.112, 0.197, 0.131, 0.134, 0.14, 0.144, 0.119, 0.233, 0.118, 0.106, 0.145, 0.117, 0.132, 0.115, 2.214, 0.156, 0.105, 0.149, 0.098, 0.158, 0.106, 0.151, 0.177, 0.151, 0.287, 0.111, 0.18, 0.121, 0.144, 0.135, 0.112, 0.173, 0.973, 0.15, 1.176, 0.144, 0.105, 0.147, 0.134, 0.103, 0.086, 0.165, 0.149, 0.123, 0.139, 0.146, 0.131, 0.127, 0.111, 0.101, 0.181, 0.112, 0.131, 0.101, 0.123, 0.201, 0.211, 0.129, 0.105, 0.09, 0.176, 0.129, 0.112, 0.089, 0.144, 0.121, 0.392, 0.133, 0.193, 0.168, 0.156, 0.142, 0.121, 0.097, 0.166, 0.131, 0.163, 0.109, 0.123, 0.094, 0.104, 0.088, 0.101, 0.096, 0.098, 0.127, 0.135, 0.117, 0.129, 0.087, 0.106, 0.101, 0.254, 0.116, 0.543, 0.14, 0.127, 0.105, 0.149, 0.291, 0.102, 0.111, 0.109, 0.094, 0.103, 0.119, 0.096, 0.135, 0.081, 0.168, 0.092, 0.103, 0.082, 0.101, 0.149, 0.108, 0.172, 0.113, 0.153, 0.099, 0.125, 0.131, 0.202, 0.208, 0.13, 0.259, 0.123, 0.121, 0.101, 0.102, 0.107, 0.106, 0.102, 0.14, 0.096, 0.197, 0.118, 0.099, 0.106, 0.151, 0.091, 0.091, 0.12, 0.126, 0.216, 0.202, 0.1, 0.129, 0.147, 0.162, 0.101, 0.089, 0.15, 0.095, 0.176, 0.094, 0.103, 0.154, 0.093, 0.255, 0.141, 0.094, 0.13, 0.118, 0.138, 0.212, 0.158, 0.196, 0.129, 0.109, 0.141, 0.192, 0.152, 0.193, 0.576, 0.134, 0.17, 0.127, 0.17, 0.13, 0.123, 0.101, 0.223, 0.204, 0.168, 0.128, 0.131, 0.149, 0.132, 0.204, 0.39, 0.121, 0.121, 0.141, 0.102, 0.173, 0.226, 0.19, 0.128, 0.125, 0.126, 0.136, 0.128, 0.137, 0.1, 0.118, 0.096, 0.087, 0.11, 0.089, 0.149, 0.183, 0.152, 0.115, 0.151, 0.209, 0.221, 0.227, 0.138, 0.16, 0.152, 0.127, 0.117, 0.106, 0.094, 0.265, 0.139, 0.126, 0.151, 0.105, 0.108, 0.107, 0.115, 0.103, 0.114, 0.139, 0.137, 0.176, 0.107, 0.289, 0.172, 0.15, 0.127, 0.126, 0.12, 0.124, 0.112, 0.126, 0.115, 0.16, 0.155, 0.127, 0.106, 0.127, 0.132, 0.134, 0.133, 0.11, 0.124, 0.139, 0.145, 0.158, 0.137, 0.147, 0.116, 0.186, 0.171, 0.124, 0.097, 0.128, 0.108, 0.095, 0.092, 0.107, 0.188, 0.126, 0.127, 0.137, 0.097, 0.099, 0.111, 0.109, 0.134, 0.114, 0.146, 0.109, 0.128, 0.204, 0.125, 0.172, 0.158, 0.139, 0.139, 0.154, 0.117, 0.138, 0.176, 0.136, 0.146, 0.216, 0.161, 0.146, 0.123, 0.095, 0.116, 0.105, 0.186, 0.098, 0.136, 0.926, 0.189, 0.162, 0.195, 0.173, 0.159, 0.112, 0.206, 0.108, 0.294, 0.194, 0.17, 0.192, 0.121, 0.227, 0.171, 0.136, 0.16, 0.172, 0.194, 0.233, 0.153, 0.132, 0.199, 0.122, 0.087, 0.091, 0.129, 0.219, 0.1, 0.151, 0.303, 0.212, 0.117, 0.182, 0.092, 0.121, 0.098, 0.121, 0.156, 0.144, 0.13, 0.156, 0.225, 0.165, 0.187, 0.126, 0.215, 0.139, 0.118, 0.134, 0.109, 0.161, 0.289, 0.169, 0.161, 0.167, 0.188, 0.195, 0.234, 0.15, 0.214, 0.211, 0.114, 0.144, 0.107, 0.157, 0.16, 0.108, 0.171, 0.135, 0.128, 0.162, 0.159, 0.147, 0.152, 0.122, 0.113, 0.139, 0.188, 0.178, 0.172, 0.155, 0.221, 0.172, 0.135, 0.137, 0.144, 0.151, 0.147, 0.137, 0.12, 0.174, 0.116, 0.155, 0.112, 0.131, 0.167, 0.166, 0.162, 0.11, 2.138, 0.105, 0.112, 0.114, 0.141, 0.147, 0.151, 0.305, 0.116, 0.138, 0.222, 0.109, 0.165, 0.121, 0.152, 0.194, 0.306, 0.123, 0.192, 0.144, 0.22, 0.216, 0.192, 0.222, 0.24, 0.147, 0.103, 0.175, 0.147, 0.115, 0.192, 0.116, 0.134, 0.126, 0.141, 0.152, 0.15, 0.124, 0.148, 0.11, 0.107, 0.097, 0.124, 0.218, 0.115, 0.126, 0.19, 0.113, 0.089, 0.124, 0.113, 0.174, 0.168, 0.129, 0.177, 0.15, 0.142, 0.14, 0.143, 0.121, 0.124, 0.094, 0.523, 0.151, 0.164, 0.121, 0.115, 0.189, 0.109, 0.162, 0.144, 0.147, 0.119, 0.159, 0.159, 0.936, 0.133, 0.127, 0.117, 0.144, 0.091, 0.116, 0.127, 0.102, 0.121, 0.143, 0.158, 0.138, 0.164, 0.175, 0.161, 0.101, 0.191, 0.121, 0.216, 0.214, 0.225, 0.234, 0.23, 0.138, 0.128, 0.14, 0.203, 0.117, 0.114, 0.188, 0.163, 0.181, 0.166, 0.11, 0.197, 0.123, 0.254, 0.109, 0.168, 0.144, 0.153, 0.119, 0.122, 0.153, 0.139, 0.133, 0.148, 0.144, 0.186, 0.153, 0.204, 0.2, 0.217, 0.15, 0.132, 0.13, 0.126, 0.141, 0.143, 0.139, 0.119, 0.153, 0.127, 0.225, 0.199, 0.111, 0.142, 0.135, 0.165, 0.142, 0.135, 0.102, 0.177, 0.18, 0.128, 0.123, 0.173, 0.107, 0.136, 0.14, 0.221, 0.108, 0.151, 0.12, 0.203, 0.113, 0.12, 0.123, 0.16, 0.136, 0.126, 0.143, 0.107, 0.103, 0.153, 0.171, 0.107, 0.168, 0.104, 0.113, 0.204, 0.124, 0.38, 0.169, 0.181, 0.514, 0.142, 0.128, 0.12, 0.194, 0.163, 0.168, 0.202, 0.154, 0.167, 0.158, 0.15, 0.179, 0.103, 0.139, 0.122, 0.163, 0.185, 0.147, 0.095, 0.147, 0.149, 0.156, 0.108, 0.106, 0.118, 0.187, 0.129, 0.142, 0.112, 0.094, 0.095, 0.127, 0.252, 0.152, 0.155, 0.125, 0.11, 0.118, 0.111, 0.125, 0.134, 0.124, 0.195, 0.154, 0.146, 0.219, 0.144, 0.2, 0.111, 0.147, 0.239, 0.195, 0.232, 0.095, 0.125, 0.16, 0.133, 0.15, 0.145, 0.143, 0.14, 0.126, 0.132, 0.112, 0.133, 0.098, 0.178, 0.109, 0.158, 0.152, 0.143, 0.125, 0.118, 0.137, 0.156, 0.117, 0.158, 0.157, 0.138, 0.165, 0.163, 0.122, 0.204, 0.165, 0.222, 0.12, 0.118, 0.123, 0.18, 0.198, 0.158, 0.116, 0.435, 0.142, 0.15, 0.154, 0.151, 0.22, 0.146, 0.188, 0.32, 0.125, 0.201, 0.117, 0.116, 0.126, 0.116, 0.105, 0.113, 0.125, 0.104, 0.124, 0.103, 0.108, 0.12, 0.152, 0.168, 0.141, 0.172, 0.254, 0.117, 0.276, 0.148, 0.115, 0.086, 0.123, 0.394, 0.119, 0.12, 0.177, 0.107, 0.14, 0.187, 0.111, 0.188, 0.14, 0.198, 0.129, 0.151, 0.116, 0.13, 0.148, 0.131, 0.169, 0.158, 0.156, 0.108, 0.207, 0.139, 0.942, 0.132, 0.181, 0.197, 0.192, 0.179, 0.181, 0.266, 0.114, 0.141, 0.12, 0.269, 0.12, 0.181, 0.228, 0.241, 1.176, 0.162, 0.14, 0.152, 0.177, 0.727, 0.131, 0.137, 0.196, 0.119, 0.12, 0.18, 0.126, 0.144, 0.323, 0.154, 0.153, 0.132, 0.125, 0.113, 0.203, 0.145, 0.252, 0.219, 0.181, 0.166, 0.143, 0.238, 0.148, 0.128, 0.165, 0.151, 0.121, 0.09, 0.117, 0.165, 0.262, 0.142, 0.137, 0.124, 0.149, 0.343, 0.127, 0.162, 0.587, 0.179, 0.151, 0.157, 0.128, 0.203, 0.142, 0.156, 0.119, 0.156, 0.119, 0.136, 0.145, 0.172, 0.163, 0.24, 0.23, 0.156, 0.107, 0.128, 0.179, 0.14, 0.22, 0.134, 0.247, 0.142, 0.13, 0.184, 0.179, 0.173, 0.107, 0.161, 0.118, 0.176, 0.185, 0.1, 0.149, 0.105, 0.122, 0.207, 0.141, 0.104, 0.131, 0.119, 0.117, 0.144, 0.131, 0.133, 0.115, 0.125, 0.12, 0.18, 0.161, 0.2, 0.117, 0.099, 0.173, 0.118, 0.151, 0.212, 0.115, 0.267, 0.147, 0.146, 0.13, 0.179, 0.201, 0.263, 0.215, 0.167, 0.115, 0.132, 0.143, 0.113, 0.128, 0.21, 0.172, 0.141, 0.101, 0.121, 0.169, 0.139, 0.139, 0.145, 0.122, 0.133, 0.166, 0.132, 0.184, 0.171, 0.138, 0.116, 0.15, 0.13, 0.217, 0.132, 0.205, 0.103, 0.177, 0.178, 0.242, 0.083, 0.128, 0.114, 0.137, 0.147, 0.139, 0.168, 0.107, 0.128, 0.151, 0.126, 0.151, 0.102, 0.133, 0.143, 0.15, 0.104, 0.182, 0.144, 0.163, 0.132, 0.131, 0.129, 0.11, 0.146, 0.149, 0.158, 0.18, 0.184, 0.157, 0.114, 0.115, 2.078, 0.154, 0.209, 0.105, 0.115, 0.188, 0.135, 0.11, 0.134, 0.708, 0.153, 0.299, 0.164, 0.124, 0.167, 0.164, 0.164, 0.116, 0.123, 0.108, 0.159, 0.191, 0.345, 0.137, 0.116, 0.085, 0.131, 0.105, 0.117, 0.122, 0.134, 0.104, 0.101, 0.127, 0.13, 0.154, 0.14, 0.143, 0.115, 0.137, 0.137, 0.103, 0.287, 0.181, 0.17, 0.212, 0.112, 0.1, 0.124, 0.158, 0.193, 0.139, 0.111, 0.092, 0.094, 0.147, 0.167, 0.188, 0.118, 0.116, 0.112, 0.23, 0.184, 0.159, 0.107, 0.147, 0.142, 0.115, 0.163
            ],
            [
                0.206, 0.139, 0.151, 0.253, 0.213, 0.239, 0.23, 0.242, 0.135, 0.212, 0.154, 0.161, 0.174, 0.582, 0.142, 0.158, 0.175, 0.173, 0.161, 0.188, 0.156, 0.19, 0.176, 0.181, 0.178, 0.142, 0.207, 0.165, 0.189, 0.12, 0.247, 0.238, 0.176, 0.122, 0.281, 0.201, 0.164, 0.225, 0.148, 0.143, 0.131, 0.179, 0.137, 0.412, 0.149, 0.216, 0.185, 0.175, 0.222, 0.225, 0.152, 0.115, 0.235, 0.146, 0.165, 0.287, 0.195, 0.131, 0.137, 0.114, 0.198, 0.185, 0.236, 0.171, 0.367, 0.133, 0.157, 0.14, 0.184, 0.12, 0.156, 0.142, 0.125, 0.191, 0.17, 0.142, 0.145, 0.172, 0.149, 0.124, 0.126, 0.111, 0.251, 0.133, 0.164, 0.229, 0.186, 0.16, 0.222, 0.135, 0.129, 0.172, 0.173, 0.198, 0.149, 0.15, 0.162, 0.157, 0.23, 0.264, 0.225, 0.188, 0.226, 0.196, 0.16, 0.152, 0.148, 0.184, 0.162, 0.214, 0.164, 0.202, 0.236, 0.147, 0.199, 0.223, 0.17, 0.713, 0.148, 0.19, 0.137, 0.152, 0.189, 0.217, 0.155, 0.215, 0.193, 0.195, 0.144, 0.136, 2.191, 0.122, 0.206, 0.219, 0.136, 0.214, 0.134, 0.149, 0.186, 0.157, 0.189, 0.163, 0.18, 0.136, 0.276, 0.153, 0.112, 0.127, 0.179, 0.227, 0.147, 0.217, 0.249, 0.151, 0.252, 0.227, 0.177, 0.226, 0.184, 0.18, 0.211, 0.174, 0.261, 0.171, 0.208, 0.128, 0.151, 0.158, 0.157, 0.31, 0.193, 0.191, 0.16, 0.216, 0.229, 0.165, 0.241, 0.149, 0.146, 1.297, 0.176, 0.18, 0.139, 0.206, 0.132, 0.165, 0.148, 0.211, 0.141, 0.14, 0.171, 0.13, 0.305, 0.144, 0.163, 0.179, 0.15, 0.135, 0.139, 0.124, 0.105, 0.117, 0.155, 0.142, 0.158, 0.193, 0.202, 0.179, 0.139, 0.138, 0.216, 0.134, 0.157, 0.119, 0.127, 0.181, 0.115, 0.14, 0.154, 0.188, 0.137, 0.136, 0.128, 0.132, 0.206, 0.1, 0.188, 0.144, 0.141, 0.423, 0.23, 0.136, 0.207, 0.143, 0.202, 0.197, 0.135, 0.138, 0.271, 0.179, 0.182, 0.163, 0.245, 0.164, 0.162, 0.241, 0.165, 0.211, 0.146, 0.122, 0.164, 0.182, 0.174, 0.186, 0.15, 0.224, 0.141, 0.192, 0.115, 0.16, 0.206, 0.2, 0.177, 0.312, 0.249, 0.159, 0.133, 0.164, 0.166, 0.546, 0.145, 0.185, 0.152, 0.201, 0.234, 0.173, 0.112, 0.126, 0.238, 0.186, 0.185, 0.224, 0.154, 0.166, 0.161, 0.162, 0.227, 0.244, 0.159, 0.24, 0.214, 0.119, 0.119, 0.183, 0.162, 0.193, 0.151, 0.24, 0.088, 0.16, 0.494, 0.216, 0.144, 0.171, 0.156, 0.16, 0.129, 0.149, 0.167, 0.201, 0.204, 0.195, 0.199, 0.184, 0.172, 0.165, 0.223, 0.343, 0.168, 0.224, 0.172, 0.141, 0.169, 0.168, 0.155, 0.241, 0.207, 0.138, 0.194, 0.185, 0.125, 0.131, 0.113, 0.158, 0.119, 0.137, 0.166, 0.175, 0.166, 0.192, 0.14, 0.194, 0.223, 0.153, 0.152, 0.145, 0.222, 0.176, 0.233, 0.211, 0.149, 0.239, 0.144, 0.133, 0.173, 0.312, 0.22, 0.144, 0.186, 0.995, 0.145, 0.193, 0.146, 0.16, 0.16, 0.173, 0.167, 0.218, 0.185, 0.189, 0.239, 0.145, 0.147, 0.106, 0.295, 0.163, 0.155, 0.13, 0.148, 0.117, 0.137, 1.485, 0.145, 0.1, 0.167, 0.157, 0.213, 0.146, 0.12, 0.159, 0.197, 0.2, 0.225, 0.114, 0.25, 0.268, 0.169, 0.18, 0.215, 0.182, 0.217, 0.176, 0.142, 0.193, 0.193, 0.185, 0.219, 0.181, 0.129, 0.153, 0.155, 0.173, 0.155, 0.131, 0.168, 0.205, 0.166, 0.157, 0.366, 0.118, 0.345, 0.271, 0.228, 0.209, 0.148, 0.253, 0.167, 0.171, 0.12, 0.121, 0.157, 0.157, 0.192, 0.217, 0.132, 0.189, 0.167, 0.15, 0.194, 0.212, 0.169, 0.224, 0.194, 0.207, 0.178, 0.144, 0.194, 0.181, 0.195, 0.177, 0.15, 0.135, 0.106, 0.109, 0.137, 0.107, 0.159, 0.129, 0.146, 0.124, 0.119, 0.159, 0.201, 0.196, 0.165, 0.194, 0.199, 0.184, 0.173, 0.167, 0.155, 0.145, 0.157, 0.238, 0.266, 0.252, 0.144, 0.138, 0.18, 0.13, 0.117, 1.034, 0.201, 0.178, 0.151, 0.17, 0.19, 0.178, 0.188, 0.163, 0.135, 0.216, 0.219, 0.361, 0.137, 0.138, 0.14, 0.173, 0.154, 0.226, 0.189, 0.158, 0.178, 0.179, 0.175, 0.194, 0.208, 0.206, 0.156, 0.135, 0.156, 0.159, 0.167, 0.161, 0.213, 0.279, 0.162, 0.188, 0.214, 0.161, 0.138, 0.223, 0.138, 0.161, 0.162, 0.113, 0.353, 0.214, 0.401, 0.16, 0.591, 0.366, 0.159, 0.171, 0.19, 0.155, 0.174, 0.222, 0.148, 0.167, 0.259, 0.143, 0.193, 0.183, 0.193, 0.167, 0.14, 0.17, 0.162, 0.182, 0.18, 0.199, 0.154, 0.179, 0.19, 0.154, 0.16, 0.129, 0.17, 0.182, 0.166, 0.167, 0.175, 0.188, 0.136, 0.141, 0.224, 0.205, 0.09, 0.202, 0.237, 0.173, 0.145, 0.181, 0.161, 0.158, 0.18, 0.228, 0.236, 0.242, 0.594, 0.194, 0.147, 0.187, 0.234, 0.144, 0.224, 0.234, 0.163, 0.186, 0.154, 0.159, 1.267, 0.126, 0.161, 0.175, 0.22, 0.188, 0.222, 0.165, 0.113, 0.147, 0.155, 0.174, 0.194, 0.174, 0.169, 0.156, 0.149, 0.143, 0.181, 0.199, 0.196, 0.149, 0.228, 0.206, 0.219, 0.175, 0.182, 0.203, 0.181, 0.198, 0.233, 0.241, 0.227, 0.166, 0.145, 0.119, 0.109, 0.107, 0.182, 0.217, 0.254, 0.216, 0.177, 0.135, 0.162, 0.127, 0.162, 0.158, 0.183, 0.205, 0.235, 0.183, 0.201, 0.16, 0.139, 0.155, 0.148, 0.185, 0.158, 0.14, 0.151, 0.231, 0.175, 0.301, 0.145, 0.225, 0.203, 0.171, 0.141, 0.17, 0.217, 0.153, 0.318, 0.131, 0.183, 0.189, 0.202, 0.229, 0.183, 0.268, 0.12, 0.091, 0.137, 0.139, 0.177, 0.208, 0.199, 0.112, 0.094, 0.096, 0.114, 0.191, 0.243, 0.148, 0.145, 0.143, 0.149, 0.189, 0.166, 0.191, 0.168, 0.162, 0.147, 0.162, 0.989, 0.098, 0.109, 0.142, 0.144, 0.157, 0.166, 0.292, 0.129, 0.168, 0.19, 0.19, 0.204, 0.159, 0.161, 0.16, 0.187, 0.169, 0.16, 0.188, 0.196, 0.189, 0.19, 0.16, 0.151, 0.202, 0.176, 0.244, 0.165, 0.128, 0.13, 0.195, 0.146, 0.202, 0.15, 0.147, 0.17, 0.157, 0.421, 0.191, 0.188, 0.135, 1.005, 0.186, 0.183, 0.221, 0.173, 0.149, 0.179, 0.156, 0.136, 0.274, 0.151, 0.158, 0.134, 0.138, 0.143, 0.119, 0.14, 0.176, 0.169, 0.139, 0.153, 0.216, 0.146, 0.18, 0.166, 0.226, 0.171, 0.161, 0.195, 1.174, 0.148, 0.182, 0.189, 0.203, 0.223, 0.187, 0.154, 0.119, 0.174, 0.144, 0.131, 0.18, 0.192, 0.137, 0.307, 0.113, 0.171, 0.168, 0.157, 0.174, 0.194, 0.145, 0.145, 0.13, 0.168, 0.174, 0.205, 0.281, 0.172, 0.147, 0.151, 0.153, 0.177, 0.196, 0.141, 0.134, 0.115, 0.13, 0.106, 0.164, 0.109, 0.177, 0.129, 0.172, 0.135, 0.196, 0.157, 0.183, 0.175, 0.165, 0.18, 0.173, 0.159, 0.132, 0.194, 0.14, 0.119, 0.184, 0.161, 0.105, 0.159, 0.117, 0.148, 0.18, 0.176, 0.458, 0.213, 0.168, 0.214, 0.204, 0.308, 0.209, 0.162, 0.169, 0.197, 0.19, 0.127, 0.203, 0.145, 0.201, 0.156, 0.169, 0.13, 0.166, 0.183, 0.172, 0.151, 0.186, 0.173, 0.182, 0.24, 0.198, 0.177, 0.209, 0.219, 0.176, 0.215, 0.282, 0.155, 0.116, 0.124, 0.148, 0.125, 0.126, 0.127, 0.16, 0.144, 0.784, 0.141, 0.234, 0.184, 0.192, 0.282, 0.213, 0.167, 0.163, 0.197, 0.191, 0.157, 0.142, 0.245, 0.116, 0.136, 0.146, 0.135, 0.188, 0.183, 0.198, 0.165, 0.15, 0.199, 0.23, 0.179, 0.182, 0.191, 0.203, 0.321, 0.119, 0.145, 0.138, 0.192, 0.182, 0.174, 0.158, 0.21, 0.141, 0.192, 0.204, 0.254, 0.198, 0.142, 0.197, 0.188, 0.219, 0.198, 0.208, 0.206, 0.319, 0.193, 0.158, 0.135, 0.114, 0.155, 0.14, 0.138, 0.132, 0.179, 0.165, 0.194, 0.157, 0.115, 0.119, 0.142, 0.13, 0.179, 0.126, 0.154, 0.121, 0.171, 0.145, 0.245, 0.215, 0.16, 0.17, 0.137, 0.155, 0.131, 0.148, 0.16, 0.143, 0.15, 0.134, 0.198, 0.225, 0.136, 0.299, 0.187, 0.147, 0.179, 0.325, 0.212, 0.219, 0.185, 0.199, 0.155, 0.184, 0.17, 0.203, 0.213, 0.187, 2.187, 0.142, 0.111, 0.116, 0.207, 0.174, 0.361, 0.16, 0.297, 0.276, 0.183, 0.133, 0.166, 0.195, 0.21, 0.114, 0.144, 0.127, 0.109, 0.194, 0.154, 0.152, 0.158, 0.121, 0.663, 0.229, 0.188, 0.155, 0.178, 0.211, 0.234, 0.152, 0.207, 0.157, 0.157, 0.224, 0.154, 0.151, 0.206, 0.298, 0.211, 0.212, 0.147, 0.166, 0.168, 0.224, 0.209, 0.249, 0.126, 0.159, 0.183, 0.221, 0.185, 0.161, 0.131, 0.18, 0.167, 0.126, 0.142, 0.158, 0.186, 0.098, 0.155, 0.166, 0.193, 0.21, 0.224, 0.233, 0.22, 0.217, 1.579, 0.153, 0.221, 0.281, 0.158, 0.172, 0.217, 0.174, 0.138, 0.23, 0.139, 0.151, 0.217, 0.151, 0.156, 0.176, 0.162, 0.181, 0.199, 0.27, 0.183, 0.119, 0.236, 0.22, 0.193, 0.141, 0.148, 0.144, 0.186, 0.188, 0.165, 0.157, 0.18, 0.209, 0.254, 0.236, 0.196, 0.34, 0.142, 0.228, 0.215, 0.18, 0.11, 0.121, 0.135, 0.221, 0.334, 0.208, 0.167, 0.18, 0.141, 0.159, 0.145, 0.193, 0.143, 0.165, 0.19, 0.301, 0.142, 0.173, 0.159, 0.127, 0.114, 0.113, 0.127, 0.34, 0.123, 0.213, 0.216, 0.148, 0.152, 0.171, 0.192, 0.175, 0.175, 0.179, 0.155, 0.182, 0.206, 0.152, 1.042, 0.213, 0.112, 0.202, 0.132, 0.127, 0.107, 0.138, 0.193, 0.177, 0.194, 0.174, 0.124, 0.216, 0.223, 0.317, 0.134, 0.176, 0.14, 0.166, 0.189, 0.195, 0.18, 0.232, 0.184, 0.159, 0.203, 0.233, 0.187, 0.159, 0.237, 0.157, 0.194, 0.245, 0.146, 0.162, 0.156, 2.25, 0.212, 0.27, 0.228, 0.152, 0.21, 0.148, 0.141, 0.254, 0.246, 0.14, 0.18, 0.197, 0.135, 0.135, 0.181, 0.253, 0.126, 0.181, 0.208, 0.191, 1.29, 0.183, 0.214, 0.297, 0.231, 0.225, 0.32, 0.144, 0.152, 0.192, 0.137, 0.17, 0.159, 0.211, 0.227, 0.169, 0.161, 0.171, 0.235, 0.164, 0.146, 0.135, 0.195, 0.176, 0.594, 0.2, 0.207, 0.2, 0.212, 0.171, 0.15, 0.256, 0.262, 0.152, 0.19, 0.184, 0.123, 0.216, 0.144, 0.194, 0.208, 0.134, 0.237, 0.223, 0.166, 0.329, 0.146, 0.144, 0.163, 0.15, 0.138, 0.156, 0.158, 0.214, 0.196, 0.151, 0.177, 0.145, 0.206, 0.191, 0.201, 0.211, 0.153, 0.25, 0.194, 0.479, 0.177, 0.15, 0.16, 0.178, 0.305, 0.204, 0.143, 0.182, 0.131, 0.143, 0.232, 0.177, 0.205, 0.234, 0.124, 0.122, 0.137, 0.125, 0.126, 0.144, 0.124, 0.122, 0.162, 0.149, 0.211, 0.207, 0.182, 0.184, 0.165, 0.182, 0.18, 0.183, 0.189, 0.171, 0.172, 0.157, 0.148, 0.159, 0.244, 0.307, 0.213, 0.177, 0.148, 0.14, 0.15, 0.196, 0.156, 0.139, 0.158, 0.141, 0.139, 0.323, 0.143, 0.208, 0.183, 0.191, 0.237, 0.215, 0.23, 0.146, 0.165, 0.147, 0.16, 0.12, 0.175, 0.206, 0.499, 0.149, 0.15, 0.165, 0.203, 0.259, 0.144, 0.17, 0.21, 0.197, 0.223, 0.2, 0.192, 0.121, 0.114, 0.174, 0.134, 0.194, 0.21, 0.171, 0.19, 0.185, 0.206, 0.15, 0.168, 0.147, 0.568, 0.206, 0.235, 0.168, 0.141, 0.159, 0.179, 0.186, 0.224, 0.199, 0.209, 0.128, 0.172, 0.171, 0.188, 0.2, 0.183, 0.176, 0.245, 0.2, 0.189, 0.132, 0.207, 0.203, 0.139, 0.172, 0.164, 0.138, 0.128, 0.18, 0.158, 0.177, 0.16, 0.155, 0.17, 0.132, 0.133, 0.133, 0.157, 0.183, 0.182, 0.205, 0.192, 0.149, 0.188, 0.203, 0.137, 0.147, 0.191, 0.188, 0.171, 0.178, 0.189, 0.156, 0.185, 0.148, 0.134, 0.153, 0.191, 0.205, 1.022, 0.108, 0.15, 0.212, 0.517, 0.222, 0.173, 0.148, 0.159, 0.174, 0.144, 0.139, 0.188, 0.155, 0.185, 0.194, 0.177, 0.165, 0.155, 0.197, 0.216, 0.167, 0.251, 0.125, 0.191, 0.234, 0.129, 0.143, 0.188, 0.203, 0.113, 0.117, 0.162, 0.113, 0.153, 0.127, 0.209, 0.185, 0.262, 0.151, 0.135, 0.126, 0.178, 0.181, 0.161, 0.144, 0.135, 0.138, 0.221, 0.192, 0.202, 0.167, 0.131, 0.244, 0.159, 0.171, 0.173, 0.218, 0.236, 0.24, 0.183, 0.141, 0.336, 0.168, 0.165, 0.217, 0.205, 0.173, 0.185, 0.135, 0.296, 0.165, 0.169, 0.141, 0.139, 0.132, 0.18, 0.224, 0.132, 0.152, 0.163, 0.174, 0.428, 0.226, 0.157, 0.224, 0.157, 0.225, 0.188, 0.196, 0.133, 0.142, 0.146, 0.154, 0.188, 0.214, 0.125, 0.123, 0.137, 0.101, 0.096, 0.264, 0.147, 0.218, 0.182, 0.137, 0.178, 0.177, 0.139, 0.231, 0.214, 0.215, 0.163, 0.204, 0.224, 0.233, 0.142, 0.208, 0.324, 0.113, 0.182, 0.125, 0.193, 0.109, 0.197, 0.129, 0.18, 0.166, 0.199, 0.132, 0.155, 0.209, 0.191, 0.247, 0.233, 0.096, 0.101, 0.1, 0.117, 0.171, 0.507, 0.146, 0.127, 0.148, 0.162, 0.175, 0.118, 0.184, 0.221, 0.209, 0.186, 0.172, 0.195, 0.15, 0.179, 0.333, 0.139, 0.152, 0.202, 0.201, 0.188, 0.186, 0.17, 0.208, 0.192, 0.127, 1.054, 0.217, 0.337, 0.152, 0.14, 0.119, 0.195, 0.186, 0.146, 0.207, 0.221, 0.332, 0.208, 0.191, 0.177, 0.129, 0.202, 0.147, 0.194, 0.247, 0.178, 0.211, 0.24, 0.227, 0.252, 0.123, 0.29, 0.26, 0.225, 0.224, 0.167, 0.251, 0.169, 0.223, 0.24, 0.16, 0.181, 0.15, 0.192, 0.236, 0.191, 0.19, 0.169, 0.171, 0.132, 0.109, 0.166, 0.367, 0.173, 0.13, 0.158, 0.163, 0.137, 0.184, 0.206, 0.174, 0.159, 0.172, 0.422, 0.169, 0.21, 0.192, 0.199, 0.12, 0.172, 0.164, 0.148, 0.19, 0.176, 0.197, 0.205, 0.168, 0.188, 0.168, 0.187, 0.128, 0.14, 0.149, 0.216, 0.181, 0.257, 0.182, 0.223, 0.132, 0.232, 0.143, 0.117, 0.16, 0.155, 0.146, 0.152, 0.165, 0.156, 0.146, 0.13, 0.158, 0.114, 0.121, 0.213, 0.183, 0.219, 0.159, 0.221, 0.142, 0.333, 0.138, 0.126, 0.184, 0.144, 0.209, 0.192, 2.172, 0.204, 0.159, 0.186, 0.151, 0.202, 0.163, 0.191, 0.213, 0.211, 0.3, 0.16, 0.22, 0.114, 0.176, 0.213, 0.135, 0.15, 0.994, 0.251, 1.184, 0.198, 0.13, 0.23, 0.222, 0.195, 0.202, 0.214, 0.207, 0.165, 0.163, 0.214, 0.179, 0.14, 0.129, 0.166, 0.18, 0.141, 0.18, 0.171, 0.205, 0.192, 0.16, 0.126, 0.137, 0.154, 0.204, 0.179, 0.18, 0.137, 0.208, 0.206, 0.426, 0.21, 0.201, 0.193, 0.238, 0.193, 0.2, 0.143, 0.238, 0.251, 0.254, 0.161, 0.15, 0.157, 0.108, 0.143, 0.147, 0.218, 0.22, 0.206, 0.181, 0.199, 0.231, 0.159, 0.193, 0.224, 0.317, 0.151, 0.833, 0.297, 0.239, 0.157, 0.223, 0.308, 0.147, 0.186, 0.215, 0.163, 0.177, 0.224, 0.146, 0.189, 0.116, 0.186, 0.12, 0.142, 0.12, 0.138, 0.157, 0.109, 0.181, 0.133, 0.179, 0.124, 0.154, 0.274, 0.252, 0.231, 0.193, 0.304, 0.209, 0.14, 0.182, 0.162, 0.169, 0.185, 0.155, 0.236, 0.203, 0.26, 0.141, 0.146, 0.182, 0.204, 0.157, 0.17, 0.164, 0.205, 0.163, 0.199, 0.121, 0.175, 0.147, 0.201, 0.169, 0.16, 0.194, 0.163, 0.204, 0.136, 0.182, 0.192, 0.147, 0.255, 0.16, 0.144, 0.2, 0.146, 0.189, 0.202, 0.218, 0.212, 0.2, 0.197, 0.161, 0.181, 0.169, 0.215, 0.631, 0.21, 0.21, 0.159, 0.174, 0.22, 0.175, 0.144, 0.186, 0.174, 0.202, 0.174, 0.176, 0.178, 0.164, 0.215, 0.43, 0.169, 0.19, 0.211, 0.152, 0.236, 0.251, 0.242, 0.151, 0.146, 0.222, 0.191, 0.156, 0.167, 0.186, 0.187, 0.173, 0.169, 0.255, 0.192, 0.264, 0.231, 0.164, 0.154, 0.207, 0.284, 0.217, 0.213, 0.167, 0.248, 0.216, 0.171, 0.213, 0.159, 0.134, 0.308, 0.235, 0.193, 0.201, 0.147, 0.161, 0.22, 0.176, 0.168, 0.161, 0.179, 0.176, 0.201, 0.2, 0.316, 0.169, 0.169, 0.201, 0.201, 0.173, 0.181, 0.154, 0.173, 0.185, 0.226, 0.199, 0.189, 0.18, 0.267, 0.239, 0.213, 0.215, 0.194, 0.216, 0.212, 0.199, 0.217, 0.168, 0.194, 0.157, 0.145, 0.217, 0.141, 0.165, 0.175, 0.151, 0.165, 0.157, 0.211, 0.219, 0.21, 0.164, 0.211, 0.155, 0.158, 0.133, 0.133, 0.184, 0.143, 0.19, 0.133, 0.218, 0.194, 0.163, 0.197, 0.203, 0.195, 0.191, 0.206, 0.187, 0.203, 0.213, 0.182, 0.233, 0.304, 0.16, 0.183, 0.168, 0.113, 0.22, 0.14, 0.215, 0.148, 0.138, 1.021, 0.207, 0.204, 0.169, 0.202, 0.192, 0.144, 0.21, 0.128, 0.329, 0.199, 0.176, 0.189, 0.179, 0.147, 0.206, 0.153, 0.171, 0.179, 0.198, 0.291, 0.175, 0.199, 0.224, 0.165, 0.121, 0.153, 0.162, 0.24, 0.149, 0.215, 0.344, 0.298, 0.224, 0.246, 0.158, 0.226, 0.14, 0.15, 0.206, 0.15, 0.192, 0.241, 0.275, 0.221, 0.217, 0.166, 0.168, 0.15, 0.154, 0.116, 0.118, 0.184, 0.213, 0.21, 0.235, 0.21, 0.199, 0.235, 0.238, 0.147, 0.207, 0.174, 0.123, 0.209, 0.131, 0.203, 0.204, 0.149, 0.193, 0.125, 0.156, 0.201, 0.192, 0.201, 0.19, 0.124, 0.164, 0.153, 0.203, 0.178, 0.179, 0.158, 0.18, 0.183, 0.126, 0.149, 0.207, 0.168, 0.206, 0.201, 0.146, 0.204, 0.115, 0.178, 0.173, 0.203, 0.218, 0.22, 0.217, 0.168, 2.235, 0.141, 0.116, 0.137, 0.156, 0.245, 0.196, 0.343, 0.14, 0.135, 0.171, 0.137, 0.209, 0.145, 0.144, 0.229, 0.307, 0.136, 0.167, 0.152, 0.213, 0.246, 0.258, 0.242, 0.194, 0.189, 0.158, 0.186, 0.158, 0.126, 0.21, 0.142, 0.181, 0.197, 0.121, 0.164, 0.146, 0.144, 0.174, 0.118, 0.193, 0.181, 0.187, 0.277, 0.141, 0.177, 0.19, 0.144, 0.14, 0.17, 0.158, 0.149, 0.147, 0.135, 0.188, 0.15, 0.197, 0.175, 0.171, 0.184, 0.144, 0.145, 0.809, 0.186, 0.165, 0.174, 0.14, 0.222, 0.172, 0.195, 0.228, 0.151, 0.134, 0.164, 0.2, 1.513, 0.148, 0.145, 0.144, 0.176, 0.161, 0.138, 0.157, 0.171, 0.193, 0.171, 0.227, 0.166, 0.166, 0.246, 0.2, 0.141, 0.203, 0.134, 0.193, 0.22, 0.223, 0.251, 0.158, 0.157, 0.141, 0.157, 0.194, 0.133, 0.133, 0.203, 0.19, 0.263, 0.194, 0.14, 0.201, 0.139, 0.267, 0.13, 0.143, 0.135, 0.138, 0.109, 0.133, 0.17, 0.146, 0.169, 0.14, 0.156, 0.173, 0.142, 0.183, 0.186, 0.302, 0.132, 0.152, 0.146, 0.098, 0.201, 0.189, 0.1, 0.17, 0.167, 0.155, 0.278, 0.217, 0.128, 0.128, 0.158, 0.222, 0.193, 0.217, 0.152, 0.184, 0.2, 0.172, 0.173, 0.198, 0.142, 0.23, 0.177, 0.255, 0.131, 0.192, 0.167, 0.206, 0.179, 0.164, 0.175, 0.193, 0.186, 0.192, 0.197, 0.138, 0.14, 0.221, 0.192, 0.164, 0.211, 0.182, 0.135, 0.215, 0.131, 0.534, 0.157, 0.182, 0.878, 0.165, 0.173, 0.149, 0.194, 0.219, 0.21, 0.184, 0.214, 0.192, 0.181, 0.179, 0.194, 0.161, 0.164, 0.165, 0.22, 0.223, 0.237, 0.137, 0.151, 0.197, 0.185, 0.153, 0.148, 0.168, 0.203, 0.138, 0.202, 0.132, 0.141, 0.156, 0.148, 0.194, 0.208, 0.156, 0.147, 0.171, 0.135, 0.133, 0.167, 0.205, 0.14, 0.164, 0.132, 0.123, 0.193, 0.158, 0.151, 0.117, 0.138, 0.178, 0.201, 0.224, 0.15, 0.164, 0.181, 0.201, 0.174, 0.211, 0.151, 0.17, 0.148, 0.18, 0.139, 0.161, 0.134, 0.187, 0.143, 0.19, 0.184, 0.196, 0.154, 0.137, 0.164, 0.173, 0.136, 0.16, 0.174, 0.158, 0.147, 0.193, 0.144, 0.17, 0.201, 0.208, 0.14, 0.142, 0.137, 0.22, 0.245, 0.176, 0.124, 0.452, 0.159, 0.197, 0.165, 0.154, 0.214, 0.184, 0.217, 0.347, 0.15, 0.172, 0.14, 0.167, 0.176, 0.162, 0.147, 0.151, 0.173, 0.134, 0.177, 0.145, 0.146, 0.138, 0.205, 0.155, 0.174, 0.175, 0.296, 0.181, 0.303, 0.227, 0.22, 0.149, 0.199, 0.46, 0.169, 0.165, 0.148, 0.138, 0.156, 0.187, 0.145, 0.163, 0.19, 0.284, 0.158, 0.217, 0.169, 0.187, 0.194, 0.165, 0.215, 0.2, 0.22, 0.153, 0.207, 0.182, 1.04, 0.159, 0.24, 0.242, 0.217, 0.222, 0.203, 0.307, 0.142, 0.149, 0.154, 0.218, 0.12, 0.195, 0.231, 0.282, 1.187, 0.186, 0.159, 0.141, 0.219, 0.827, 0.147, 0.154, 0.233, 0.154, 0.203, 0.208, 0.16, 0.161, 0.346, 0.161, 0.213, 0.179, 0.156, 0.165, 0.233, 0.2, 0.197, 0.229, 0.2, 0.158, 0.156, 0.182, 0.155, 0.151, 0.162, 0.194, 0.166, 0.13, 0.11, 0.187, 0.168, 0.121, 0.147, 0.137, 0.234, 0.373, 0.143, 0.186, 0.673, 0.21, 0.195, 0.195, 0.196, 0.296, 0.174, 0.163, 0.147, 0.165, 0.151, 0.143, 0.156, 0.175, 0.203, 0.339, 0.223, 0.196, 0.169, 0.17, 0.194, 0.171, 0.186, 0.193, 0.275, 0.197, 0.129, 0.234, 0.244, 0.221, 0.135, 0.227, 0.094, 0.123, 0.197, 0.097, 0.136, 0.092, 0.163, 0.173, 0.13, 0.101, 0.12, 0.134, 0.162, 0.129, 0.102, 0.157, 0.164, 0.099, 0.152, 0.143, 0.143, 0.207, 0.103, 0.134, 0.151, 0.13, 0.156, 0.142, 0.118, 0.27, 0.112, 0.11, 0.113, 0.117, 0.123, 0.256, 0.184, 0.158, 0.125, 0.114, 0.16, 0.128, 0.127, 0.135, 0.142, 0.132, 0.096, 0.125, 0.186, 0.123, 0.12, 0.187, 0.149, 0.127, 0.191, 0.142, 0.155, 0.13, 0.129, 0.155, 0.128, 0.166, 0.309, 0.173, 0.229, 0.115, 0.176, 0.207, 0.299, 0.141, 0.138, 0.124, 0.168, 0.169, 0.184, 0.197, 0.208, 0.116, 0.18, 0.183, 0.173, 0.127, 0.15, 0.139, 0.137, 0.122, 0.158, 0.121, 0.152, 0.136, 0.149, 0.193, 0.116, 0.18, 0.156, 0.19, 0.143, 0.14, 0.131, 0.157, 0.137, 2.169, 0.131, 0.181, 0.104, 0.125, 0.199, 0.213, 0.155, 0.171, 1.113, 0.181, 0.31, 0.167, 0.169, 0.222, 0.215, 0.16, 0.121, 0.109, 0.117, 0.194, 0.202, 0.521, 0.157, 0.11, 0.131, 0.152, 0.176, 0.146, 0.169, 0.164, 0.192, 0.161, 0.188, 0.132, 0.182, 0.152, 0.167, 0.145, 0.232, 0.169, 0.118, 0.281, 0.148, 0.156, 0.222, 0.144, 0.125, 0.166, 0.192, 0.15, 0.184, 0.147, 0.11, 0.139, 0.156, 0.128, 0.152, 0.106, 0.185, 0.176, 0.228, 0.19, 0.221, 0.111, 0.199, 0.128, 0.177, 0.193, 0.189, 0.167, 0.191, 0.119, 0.12, 0.201, 0.147, 0.729, 0.125, 0.122, 0.136, 0.14, 0.098, 0.145, 0.109, 0.166, 0.195, 0.168, 0.147, 0.189, 0.152, 0.143, 0.216, 0.208, 0.139, 0.244, 0.164, 0.166, 0.133, 0.194, 0.162, 0.204, 0.104, 0.22, 0.294, 0.172, 0.227, 0.135, 0.146, 0.224, 0.204, 0.162, 0.17, 0.172, 0.13, 0.1, 0.127, 0.286, 0.168, 0.184, 0.159, 0.186, 0.14, 0.118, 0.197, 0.113, 0.116, 0.166, 0.163, 0.227, 0.187, 0.19, 0.973, 0.129, 0.15, 0.188, 0.179, 0.186, 0.199, 0.212, 0.209, 0.161, 0.136, 0.214, 0.169, 0.157, 0.14, 0.23, 0.197, 0.14, 0.348, 0.615, 0.189, 0.172, 0.23, 0.192, 0.179, 0.196, 0.138, 1.168, 0.179, 0.17, 0.148, 0.149, 0.185, 0.182, 0.22, 0.183, 0.158, 0.134, 0.134, 0.148, 0.204, 0.11, 0.171, 0.169, 0.199, 0.288, 0.18, 0.175, 0.232, 0.184, 0.283, 0.213, 0.191, 0.157, 0.151, 0.125, 0.118, 0.109, 0.125, 0.115, 0.212, 0.139, 0.146, 0.147, 0.165, 0.164, 0.139, 0.125, 0.109, 0.108, 0.204, 0.178, 0.206, 0.149, 0.15, 0.199, 0.276, 0.178, 0.128, 0.147, 0.157, 0.232, 0.15, 0.146, 0.205, 0.202, 0.176, 0.109, 0.154, 0.105, 0.186, 0.115, 0.115, 0.144, 0.159, 0.157, 0.123, 0.169, 0.128, 0.143, 0.178, 0.159, 0.299, 0.174, 0.171, 0.145, 0.157, 0.114, 0.122, 0.19, 0.123, 0.148, 0.12, 0.185, 0.125, 0.134, 0.112, 0.178, 0.16, 0.136, 0.123, 0.141, 0.111, 0.172, 0.138, 0.165, 0.126, 0.148, 0.191, 0.188, 0.129, 0.208, 0.113, 0.14, 0.196, 0.126, 0.111, 0.181, 0.227, 0.164, 0.15, 0.372, 0.162, 0.17, 0.14, 0.119, 0.465, 0.152, 0.164, 0.172, 0.122, 0.175, 0.171, 0.161, 0.143, 0.106, 0.284, 0.175, 0.123, 0.195, 0.147, 0.109, 0.152, 0.195, 0.182, 0.16, 0.151, 0.126, 0.159, 0.128, 0.162, 0.152, 0.118, 0.143, 0.203, 0.217, 0.126, 0.123, 0.108, 0.109, 0.137, 0.149, 0.141, 0.162, 0.302, 0.165, 0.111, 0.201, 0.145, 0.181, 0.426, 0.12, 0.129, 0.146, 0.164, 0.287, 0.399, 0.164, 0.184, 0.995, 0.187, 0.12, 0.126, 0.112, 0.153, 0.318, 0.238, 0.197, 0.144, 0.161, 0.123, 0.166, 0.192, 0.224, 0.149, 0.149, 0.192, 0.145, 0.108, 0.108, 0.113, 0.126, 0.14, 0.134, 0.162, 0.138, 0.101, 0.115, 0.132, 0.179, 0.126, 0.139, 0.152, 0.153, 0.152, 0.174, 0.22, 0.121, 0.155, 0.094, 0.121, 0.103, 0.212, 0.087, 0.093, 0.13, 0.122, 0.179, 0.157, 0.162, 0.15, 0.157, 0.146, 0.141, 0.219, 0.187, 0.191, 0.183, 0.207, 0.119, 0.274, 0.214, 0.198, 0.181, 0.128, 0.335, 0.251, 0.208, 0.108, 0.144, 0.149, 0.155, 0.274, 0.124, 0.103, 0.146, 0.119, 0.201, 0.189, 0.224, 0.11, 0.162, 0.163, 0.2, 0.181, 0.204, 0.096, 0.096, 0.117, 0.236, 0.18, 0.152, 0.178, 0.166, 0.187, 0.248, 0.25, 0.165, 0.143, 0.148, 0.169, 0.113, 0.187, 1.001, 0.154, 0.214, 0.221, 0.216, 0.343, 0.111, 0.724, 0.148, 0.191, 0.133, 0.266, 0.147, 0.143, 0.105, 0.116, 0.126, 0.476, 0.2, 0.126, 0.165, 0.164, 0.19, 0.132, 0.163, 0.201, 0.123, 0.147, 0.107, 0.194, 0.182, 0.151, 0.154, 0.121, 0.156, 0.194, 0.137, 0.21, 0.193, 0.137, 0.156, 0.204, 0.197, 0.209, 0.155, 0.148, 0.141, 0.168, 0.131, 0.175, 0.204, 0.218, 0.241, 0.15, 0.21, 0.168, 0.214, 0.148, 0.209, 0.167, 0.172, 0.175, 0.134, 0.175, 0.161, 0.21, 0.192, 0.162, 0.183, 0.115, 0.19, 0.165, 0.128, 0.111, 0.089, 0.103, 0.09, 0.221, 0.19, 0.17, 0.111, 0.111, 0.135, 0.117, 0.144, 0.123, 0.139, 0.161, 0.121, 0.136, 0.121, 0.11, 0.139, 0.161, 0.153, 0.128, 0.15, 0.152, 0.117, 0.256, 0.787, 0.145, 0.172, 0.175, 2.362, 0.145, 0.115, 0.145, 0.156, 0.122, 0.145, 0.187, 0.318, 0.142, 0.125, 0.108, 0.141, 0.177, 0.201, 0.16, 0.171, 0.128, 0.115, 0.137, 0.115, 0.155, 0.153, 0.141, 0.204, 0.142, 0.206, 0.114, 0.156, 0.124, 0.102, 0.14, 0.173, 0.165, 0.19, 0.173, 0.18, 0.112, 0.137, 0.114, 0.337, 1.006, 0.179, 0.136, 0.211, 0.187, 0.175, 0.192, 0.284, 0.171, 0.211, 0.23, 0.268, 0.186, 0.201, 0.167, 0.199, 0.15, 0.252, 0.204, 0.244, 0.206, 0.274, 0.187, 0.207, 0.247, 0.17, 0.179, 0.13, 0.153, 0.155, 0.187, 0.252, 0.345, 0.236, 0.213, 0.446, 0.179, 0.204, 0.159, 0.364, 0.209, 0.231, 0.168, 0.215, 0.227, 0.263, 0.214, 0.21, 0.124, 0.127, 0.157, 0.201, 0.131, 0.163, 0.171, 0.356, 0.151, 0.16, 0.169, 0.213, 0.166, 0.241, 0.199, 0.223, 0.141, 0.182, 0.191, 0.164, 0.169, 0.14, 0.19, 0.226, 0.221, 0.224, 0.177, 0.201, 0.192, 0.158, 0.192, 0.127, 0.124, 0.177, 0.141, 0.123, 0.188, 0.147, 0.202, 0.217, 0.198, 0.17, 0.204, 0.157, 0.167, 0.181, 0.145, 0.267, 0.169, 0.208, 0.233, 0.219, 0.207, 0.216, 0.184, 0.152, 0.209, 0.226, 0.454, 0.121, 0.196, 0.169, 0.143, 0.183, 0.226, 0.153, 0.218, 0.196, 0.19, 0.146, 0.148, 0.154, 0.225, 0.21, 0.196, 0.152, 0.19, 0.2, 0.168, 0.246, 0.245, 0.17, 0.226, 0.218, 0.189, 0.23, 0.129, 0.168, 0.167, 0.119, 0.113, 0.146, 0.18, 0.158, 0.197, 0.209, 0.216, 0.142, 0.17, 0.147, 0.194, 0.182, 0.184, 0.238, 0.238, 0.23, 0.237, 0.227, 0.138, 0.195, 0.209, 0.174, 0.161, 0.19, 0.211, 0.145, 0.134, 0.159, 0.194, 0.173, 0.257, 0.146, 0.334, 0.136, 0.149, 0.097, 0.117, 0.146, 0.144, 0.174, 0.154, 0.141, 0.163, 0.182, 0.187, 0.135, 0.155, 0.222, 0.18, 0.156, 0.228, 0.15, 0.222, 0.237, 0.146, 0.19, 0.162, 0.152, 0.241, 0.174, 0.168, 1.202, 0.195, 0.134, 0.227, 0.169, 0.227, 0.113, 0.17, 0.222, 0.138, 0.19, 0.185, 0.218, 0.243, 0.142, 0.157, 0.113, 0.263, 0.175, 0.171, 0.252, 0.226, 0.196, 0.143, 0.179, 0.327, 0.176, 0.138, 0.173, 0.138, 0.193, 0.164, 0.175, 0.299, 0.221, 0.205, 0.233, 0.124, 0.191, 0.211, 0.213, 0.136, 0.153, 0.141, 0.15, 0.188, 0.186, 0.176, 0.175, 0.22, 0.197, 0.212, 0.195, 0.2, 0.179, 0.154, 0.221, 0.189, 0.156, 0.243, 0.151, 0.206, 0.342, 0.208, 0.225, 0.152, 0.205, 0.246, 0.221, 0.23, 0.161, 0.154, 0.225, 0.234, 0.199, 0.153, 0.194, 0.134, 0.155, 0.16, 0.305, 0.12, 0.193, 0.208, 0.154, 0.217, 0.551, 0.151, 0.205, 0.2, 0.157, 0.214, 0.193, 0.219, 0.218, 0.229, 0.201, 0.195, 0.202, 0.204, 1.104, 0.288, 0.184, 0.152, 0.158, 0.187, 0.199, 0.215, 0.208, 0.204, 0.206, 0.225, 0.173, 0.155, 0.182, 0.153, 0.14, 0.216, 0.197, 0.246, 0.144, 0.114, 0.1, 0.149, 0.123, 0.119, 0.18, 0.12, 0.289, 0.159, 0.167, 0.184, 0.157, 0.129, 0.123, 0.122, 0.119, 0.148, 0.139, 0.151, 0.133, 0.176, 0.198, 0.176, 0.155, 0.158, 0.158, 0.19, 0.246, 0.122, 0.167, 0.145, 0.157, 0.36, 0.107, 0.143, 0.12, 0.134, 0.142, 0.179, 0.188, 0.155, 0.175, 0.161, 0.122, 0.147, 0.204, 0.114, 0.182, 0.166, 0.15, 0.122, 0.121, 0.141, 0.098, 0.218, 0.13, 0.114, 0.114, 0.122, 0.104, 0.096, 0.135, 0.12, 0.205, 0.322, 0.116, 0.13, 0.575, 0.139, 0.148, 0.196, 0.16, 0.14, 0.106, 1.077, 0.173, 0.108, 0.101, 0.142, 0.133, 0.125, 0.132, 0.165, 0.093, 0.123, 0.133, 0.169, 0.131, 0.169, 0.13, 0.131, 0.186, 0.134, 0.156, 0.224, 0.115, 0.151, 0.132, 0.171, 0.112, 0.156, 0.13, 0.173, 0.094, 0.146, 0.119, 0.149, 0.128, 0.171, 0.321, 0.142, 0.174, 0.162, 0.132, 0.155, 0.153, 0.289, 0.197, 0.178, 0.165, 0.168, 0.112, 0.154, 0.165, 0.107, 0.099, 0.445, 0.158, 0.116, 0.137, 0.178, 0.224, 0.152, 0.173, 0.124, 0.205, 0.139, 0.109, 0.191, 0.159, 0.148, 0.108, 0.156, 0.119, 0.123, 0.117, 0.181, 0.11, 0.165, 0.141, 0.157, 0.149, 0.159, 0.288, 0.154, 1.048, 0.122, 0.169, 0.2, 0.117, 0.19, 0.15, 0.097, 0.142, 0.145, 0.106, 0.166, 0.189, 0.168, 0.145, 0.139, 0.117, 0.156, 0.157, 0.132, 0.546, 0.161, 1.017, 0.203, 0.147, 0.147, 0.176, 0.132, 0.192, 0.144, 0.296, 0.176, 0.169, 0.196, 0.154, 0.125, 0.271, 0.096, 0.198, 0.137, 0.152, 0.172, 0.115, 0.128, 0.279, 0.11, 0.154, 0.137, 0.113, 0.137, 0.158, 0.133, 0.125, 0.129, 0.141, 0.116, 0.15, 0.123, 0.123, 0.263, 0.344, 0.166, 0.119, 0.115, 0.213, 0.212, 0.178, 0.108, 0.126, 0.115, 0.184, 0.148, 0.14, 0.15, 0.173, 0.133, 0.153, 0.17, 0.195, 0.154, 0.182, 0.189, 0.174, 0.206, 0.279, 0.218, 0.15, 0.155, 0.174, 0.214, 0.157, 0.246, 0.203, 0.171, 0.141, 0.207, 0.231, 0.204, 0.222, 0.194, 0.242, 0.142, 0.208, 0.218, 0.131, 0.115, 0.163, 0.145, 0.165, 0.126, 0.115, 0.149, 0.169, 0.199, 0.177, 0.144, 0.201, 0.148, 0.137, 0.138, 0.22, 0.154, 0.158, 0.161, 0.319, 0.582, 0.18, 0.143, 0.157, 0.178, 0.203, 0.121, 0.179, 0.154, 0.177, 0.155, 0.154, 0.273, 0.157, 0.184, 0.118, 0.191, 0.159, 0.159, 0.582, 0.131, 0.158, 0.127, 0.128, 0.111, 0.219, 0.192, 0.152, 0.208, 0.157, 0.256, 0.143, 0.518, 0.147, 0.162, 0.193, 0.208, 0.179, 0.117, 0.13, 0.152, 0.176, 0.248, 0.198, 0.221, 0.218, 0.183, 0.176, 0.182, 0.281, 0.141, 0.283, 0.291, 0.144, 0.243, 0.173, 0.123, 0.109, 0.104, 0.174, 0.179, 0.24, 0.163, 0.211, 0.171, 0.235, 0.226, 0.163, 0.136, 0.251, 0.157, 0.128, 0.118, 0.15, 0.147, 0.135, 0.132, 0.153, 0.219, 0.176, 0.173, 0.168, 0.206, 0.227, 0.173, 0.165, 0.211, 0.122, 0.187, 0.236, 0.176, 0.134, 0.149, 0.123, 0.13, 0.173, 0.175, 0.154, 0.225, 0.16, 0.215, 0.24, 0.153, 0.186, 0.22, 0.123, 0.2, 0.259, 0.169, 0.181, 0.246, 0.136, 0.181, 0.226, 0.214, 0.201, 0.145, 0.186, 0.193, 0.152, 0.127, 0.123, 0.206, 0.207, 0.136, 0.194, 0.217, 0.175, 0.18, 0.272, 0.211, 0.208, 0.165, 0.227, 0.15, 0.11, 0.184, 0.156, 0.166, 0.171, 0.288, 0.202, 0.211, 0.217, 0.269, 0.116, 0.162, 0.137, 0.167, 0.21, 0.177, 0.209, 0.119, 0.129, 0.186, 0.163, 0.151, 0.15, 0.159, 0.293, 0.166, 0.169, 0.141, 0.196, 0.14, 0.289, 0.225, 0.319, 0.149, 0.191, 0.153, 0.144, 0.226, 0.237, 0.137, 0.14, 0.166, 1.2, 0.301, 0.183, 0.18, 0.158, 0.18, 0.267, 0.131, 0.167, 0.149, 0.211, 0.13, 0.216, 0.266, 0.181, 0.216, 0.14, 2.137, 0.203, 0.275, 0.231, 0.139, 0.184, 0.205, 0.202, 0.265, 0.145, 0.13, 0.187, 0.214, 0.183, 0.205, 0.206, 0.125, 0.179, 0.192, 0.19, 0.131, 0.172, 0.234, 0.28, 0.182, 0.19, 0.177, 0.195, 0.131, 0.165, 0.171, 0.155, 0.287, 0.227, 0.183, 0.172, 0.253, 0.158, 0.155, 0.204, 0.185, 0.148, 0.152, 0.248, 0.149, 0.184, 0.211, 0.22, 0.19, 0.16, 0.197, 0.169, 0.195, 0.125, 0.223, 0.153, 0.598, 0.233, 0.206, 0.153, 0.238, 0.186, 0.322, 0.259, 0.189, 0.212, 0.212, 0.147, 0.157, 0.086, 0.164, 0.15, 0.174, 0.164, 0.214, 0.117, 0.206, 0.176, 0.221, 0.129, 0.15, 0.191, 0.217, 0.15, 0.185, 0.152, 0.158, 0.149, 0.27, 0.096, 0.095, 0.126, 0.093, 0.151, 0.137, 0.188, 0.184, 0.15, 0.163, 0.165, 0.252, 0.201, 0.208, 0.149, 0.2, 0.157, 0.205, 0.202, 0.27, 0.194, 0.258, 0.214, 0.146, 0.142, 0.238, 0.175, 0.239, 0.188, 0.213, 0.217, 0.272, 0.253, 0.304, 0.253, 0.194, 0.149, 0.298, 0.179, 0.178, 0.139, 0.212, 0.212, 0.246, 0.97, 0.178, 0.263, 0.163, 0.145, 0.215, 0.203, 0.194, 0.137, 0.175, 0.12, 0.302, 0.187, 0.129, 0.325, 0.15, 0.115, 0.174, 0.117, 0.173, 0.171, 0.154, 0.144, 0.284, 0.178, 0.136, 1.001, 0.197, 0.252, 0.148, 0.202, 0.169, 0.224, 0.53, 0.118, 0.111, 0.182, 0.193, 0.169, 0.126, 0.157, 0.142, 0.218, 0.184, 0.163, 0.175, 0.192, 0.139, 0.277, 0.12, 0.202, 0.193, 0.147, 0.197, 0.189, 0.568, 0.228, 0.145, 0.236, 0.181, 0.195, 0.23, 0.208, 0.147, 0.351, 0.15, 0.135, 0.204, 0.193, 0.239, 0.362, 0.385, 0.155, 0.142, 0.121, 0.204, 0.214, 0.195, 0.181, 0.197, 0.211, 0.15, 0.151, 0.192, 0.137, 0.224, 0.137, 0.198, 0.145, 0.231, 0.227, 0.181, 0.216, 0.16, 0.194, 0.197, 0.187, 0.145, 0.324, 0.109, 0.118, 0.141, 0.109, 0.14, 0.207, 0.114, 0.19, 0.132, 0.209, 0.213, 0.163, 0.177, 0.193, 0.164, 0.141, 0.21, 0.17, 0.144, 0.138, 0.164, 0.135, 0.14, 0.14, 0.193, 0.18, 0.188, 0.196, 0.191, 0.115, 0.2, 1.264, 0.2, 0.235, 0.238, 0.24, 0.23, 0.156, 0.154, 0.15, 0.143, 0.165, 0.125, 0.141, 0.136, 0.132, 0.153, 0.211, 0.192, 0.251, 0.195, 0.147, 0.155, 0.198, 0.149, 0.253, 0.174, 0.275, 0.156, 0.117, 0.152, 0.188, 0.166, 0.218, 0.185, 0.145, 0.168, 0.212, 0.483, 0.209, 0.146, 0.146, 0.161, 0.228, 0.24, 0.207, 0.175, 0.127, 0.291, 0.179, 0.148, 0.159, 0.15, 0.161, 0.173, 0.354, 0.154, 0.179, 0.21, 0.133, 0.125, 0.17, 0.154, 0.208, 0.147, 0.175, 0.212, 0.214, 0.127, 0.224, 0.15, 0.155, 0.154, 0.143, 0.141, 0.212, 0.171, 0.157, 0.158, 0.164, 0.191, 0.152, 0.243, 0.149, 0.22, 0.127, 0.224, 0.128, 0.188, 0.156, 0.135, 0.163, 0.159, 0.132, 0.176, 0.197, 0.178, 0.19, 0.188, 0.228, 0.148, 0.152, 0.141, 0.184, 1.08, 0.146, 0.223, 0.226, 0.196, 0.173, 0.17, 0.169, 0.171, 0.149, 0.214, 0.208, 0.138, 0.158, 0.159, 0.124, 0.189, 0.138, 0.144, 0.223, 0.245, 0.229, 0.129, 0.267, 0.174, 0.152, 0.147, 0.206, 0.228, 0.213, 0.208, 0.21, 0.164, 0.15, 0.192, 0.183, 0.129, 0.172, 0.149, 0.156, 0.165, 0.192, 0.192, 0.21, 0.224, 0.138, 0.223, 0.186, 0.217, 0.181, 0.133, 0.183, 0.147, 0.113, 0.202, 0.218, 0.28, 0.159, 0.169, 0.149, 0.123, 0.095, 0.166, 0.171, 0.136, 0.157, 0.146, 0.147, 0.137, 0.201, 0.12, 0.208, 0.169, 0.155, 0.202, 0.227, 0.178, 0.194, 0.165, 0.176, 0.21, 0.124, 0.196, 0.43, 0.172, 0.164, 0.106, 0.115, 0.149, 0.152, 0.138, 0.136, 0.295, 0.133, 0.148, 0.728, 0.22, 0.244, 0.193, 0.218, 0.129, 0.143, 0.133, 0.146, 0.136, 0.151, 0.194, 0.147, 0.151, 0.144, 0.15, 0.204, 0.196, 0.162, 0.166, 0.184, 0.184, 0.162, 0.182, 0.785, 0.144, 0.167, 0.169, 0.138, 0.138, 0.202, 0.234, 0.218, 0.233, 0.248, 0.158, 0.164, 0.267, 0.239, 0.155, 0.218, 4.321, 0.125, 0.158, 0.189, 0.16, 0.163, 0.124, 0.17, 0.224, 0.142, 0.185, 0.204, 0.14, 0.213, 0.153, 0.189, 0.142, 0.43, 0.138, 0.2, 0.16, 0.14, 0.183, 0.14
            ]
        ], 
        [#filter or not
            [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
                2.198, 5.82, 1.644, 2.446, 4.125, 3.16, 2.999, 2.422, 3.851, 3.294, 1.767, 8.1, 2.624, 20.112, 3.236, 2.9, 3.077, 20.598, 2.528, 2.163, 2.293, 1.638, 4.996, 3.241, 1.374, 1.561, 5.111, 2.202, 2.191, 1.834, 4.63, 4.664, 1.682, 1.372, 3.022, 9.643, 3.037, 2.765, 15.002, 1.884, 1.977, 4.527, 4.454, 1.989, 1.96, 1.65, 1.792, 2.738, 6.733, 3.232, 1.479, 1.82, 5.173
            ],
            [
                3.732, 6.956, 2.661, 4.144, 8.312, 6.578, 6.191, 3.614, 8.927, 5.16, 3.447, 10.002, 4.014, 25.411, 4.581, 8.635, 5.95, 19.499, 4.922, 3.172, 2.375, 2.715, 10.492, 13.346, 4.257, 4.972, 9.5, 4.183, 3.647, 2.971, 8.03, 8.89, 2.213, 2.73, 5.569, 11.039, 7.405, 7.856, 10.59, 3.143, 2.851, 9.699, 8.615, 3.277, 3.942, 2.893, 3.379, 4.342, 10.463, 5.298, 2.712, 3.321, 12.619, 15.376, 5.145, 3.315, 4.404, 8.218, 20.964, 32.07, 2.807, 3.367, 2.623, 2.62, 3.79, 4.108, 6.413, 5.741, 4.275, 21.896, 8.563, 3.323, 4.82, 18.497, 4.214, 1.722, 14.493, 3.63, 4.89, 3.612, 3.006, 2.365, 2.062, 7.498, 3.37, 4.83, 4.269, 5.863, 4.796, 2.99, 5.631, 3.503, 4.99, 1.869, 3.844, 2.378, 6.51, 29.027, 6.616, 3.295, 11.748, 3.867, 4.396, 3.927, 19.239, 4.996, 3.876, 4.049, 7.851, 6.613, 4.113, 5.0, 14.934, 2.97, 4.736, 3.423, 34.848, 3.249, 30.293, 4.711, 9.741, 13.079, 3.302, 4.614, 4.161, 8.778, 1.737, 3.618, 2.07, 14.139, 6.045, 4.991, 2.887, 2.174, 5.255, 3.29, 4.348, 1.93, 3.366, 1.997, 15.43, 2.031, 2.451, 1.809, 3.593, 2.742, 3.658, 3.373, 6.012, 2.546, 5.497, 3.883, 5.276, 4.61, 7.009, 7.476, 2.815, 21.149, 7.299, 8.359, 3.542, 13.03, 10.285, 4.044, 3.684, 7.3, 6.843, 6.407, 50.788, 18.271, 19.806, 2.866, 2.843, 8.278, 4.227, 5.432, 10.718, 3.389, 3.555, 5.833, 4.567, 4.848, 4.717, 2.815, 8.644, 5.758, 3.996, 3.303, 2.825, 4.779, 5.169, 2.735, 3.577, 2.625, 3.421, 3.414, 3.856, 15.102, 5.794, 5.041, 9.971, 3.92, 2.125, 5.377, 3.336, 3.128, 3.664, 34.078, 5.026, 7.18, 3.666, 3.455, 3.416, 7.005, 1.957, 14.892, 5.007, 4.667, 5.985, 1.81, 3.272, 5.588, 3.312, 3.693, 2.967, 15.425, 4.247, 3.759, 2.48, 2.186, 2.705, 2.859, 2.213, 2.439, 3.232, 11.764, 2.43, 5.219, 10.089, 3.777, 14.31, 8.314, 54.291, 5.74, 4.919, 2.695, 13.661, 3.765, 5.871, 5.669, 3.236, 2.671, 5.814, 4.976, 3.457, 2.603, 6.468, 1.89, 1.846, 3.116, 37.668, 13.995, 5.501, 3.566, 4.076, 2.984, 3.793, 7.644, 1.897, 2.728, 10.438, 7.138, 3.374, 30.661, 3.228, 41.132, 2.567, 4.39, 4.178, 4.756, 5.136, 8.164, 1.736, 3.198, 2.975, 2.654, 1.494, 7.331, 4.488, 2.354, 1.94, 3.983, 10.947, 17.268, 2.572, 2.017, 3.808, 3.851, 4.15, 6.961, 7.537, 4.983, 7.16, 17.68, 9.787, 7.225, 4.545, 6.58, 3.237, 2.971, 1.654, 4.238, 2.256, 50.829, 4.308, 3.868, 4.408, 4.114, 29.766, 5.424, 3.148, 14.322, 3.373, 4.311, 2.098, 2.973, 1.982, 4.345, 8.322, 2.071, 6.698, 2.359, 2.119, 2.521, 2.453, 4.665, 3.399, 17.712, 3.512, 4.725, 5.85, 7.162, 4.688, 3.229, 5.02, 3.172, 5.507, 10.644, 2.715, 1.952, 3.49, 2.529, 3.641, 3.858, 1.466, 2.19, 6.459, 8.42, 1.487, 1.66, 4.821, 4.622, 5.609, 5.571, 2.879, 13.992, 2.303, 15.998, 4.643, 6.912, 2.316, 7.127, 4.993, 3.414, 3.07, 3.632, 2.377, 2.449, 11.217, 5.651, 2.16, 6.776, 3.799, 7.354, 4.803, 1.788, 4.166, 2.194, 3.128, 3.218, 3.029, 2.989, 5.056, 3.872, 4.959, 22.097, 4.166, 33.978, 2.565, 2.474, 4.336, 2.451, 1.85, 7.969, 1.962, 2.147, 3.131, 2.254, 2.741, 6.553, 14.917, 3.884, 4.148, 13.072, 4.716, 2.889, 6.683, 7.537, 2.387, 3.994, 3.353, 2.999, 1.806, 14.828, 2.04, 2.589, 2.7, 4.874, 3.071, 3.554, 1.887, 1.56, 1.504, 1.997, 8.004, 3.075, 3.127, 3.051, 4.555, 3.734, 2.353, 1.942, 3.676, 9.337, 2.511, 7.58, 2.793, 21.907, 1.97, 4.825
            ]
        ], 
        [
            [
                14.849, 7.229, 13.458, 9.353, 12.132, 17.089, 42.65, 9.868, 27.474, 8.853, 6.041, 14.518, 4.493, 13.703, 6.887, 16.5, 3.835, 25.077, 10.438, 20.706, 9.148, 11.729, 5.05, 8.112, 18.751, 5.126, 24.539, 7.303, 8.02, 37.465, 4.7, 3.902, 6.786, 11.231, 21.064, 7.205, 35.583, 5.925, 17.05, 9.274, 5.668, 12.107
            ],
            [
                22.174, 11.216, 19.947, 17.87, 16.275, 23.255, 89.372, 11.384, 48.279, 13.587, 8.171, 21.217, 8.879, 27.455, 13.331, 35.09, 5.384, 40.399, 21.216, 43.755, 13.998, 23.449, 7.979, 12.028, 24.483, 9.841, 50.011, 18.667, 29.306, 63.957, 8.925, 8.148, 10.66, 36.816, 40.153, 12.376, 42.923, 8.803, 25.933, 14.411, 9.548, 17.995, 12.988, 21.031, 14.198, 16.339, 12.52, 10.014, 72.303, 21.754, 24.707, 13.314, 36.728, 11.408, 23.66, 20.209, 38.798, 13.554, 72.144, 50.169, 33.363, 13.411, 27.698, 19.078, 14.828, 28.281, 10.377, 18.118, 13.444, 7.83, 47.984, 8.147, 13.416, 14.169, 19.175, 14.801, 16.762, 25.255, 36.961, 21.271, 18.361, 20.811, 18.805, 10.548, 100.591, 43.61, 26.447, 19.854, 28.924, 17.922, 17.964, 14.313, 54.139, 13.654, 19.879, 15.395, 10.564, 11.967, 47.312, 33.505, 25.654, 13.237, 9.745, 145.075, 65.357, 62.178, 66.173, 67.421, 79.35, 23.917, 29.43, 13.6, 38.394, 15.902, 9.14, 10.926, 10.898, 27.438, 13.218, 28.75, 62.509, 70.508, 11.024, 34.541, 19.194, 10.817, 19.442, 11.032, 15.166, 9.682, 140.208, 25.428, 14.96, 30.77, 11.393, 34.491, 44.498, 67.044, 12.175, 14.531, 15.851, 14.736, 8.519, 18.857, 12.895, 13.053, 57.008, 6.689, 13.754, 30.256, 17.03, 52.323, 33.511, 10.526, 10.24, 9.643, 94.064, 23.349, 13.942, 65.536, 27.439, 12.929, 12.68, 19.586, 15.239, 20.577, 7.495, 11.895, 27.882, 18.007, 17.831, 14.709, 19.352, 32.425, 6.547, 14.85, 18.678, 9.584, 39.883, 7.94, 26.978, 18.485, 39.028, 43.304, 18.948, 12.676, 23.691, 12.484, 11.514, 32.996, 15.22, 29.752, 18.635, 8.742, 8.937, 11.952, 33.072, 50.096, 85.796, 8.85, 13.845, 25.947, 8.676, 9.507, 28.179, 41.059, 52.486, 22.9, 44.401, 15.235, 16.084, 43.017, 8.793, 23.497, 20.347, 8.742, 7.656, 29.065, 16.353, 21.15, 9.433, 32.137, 33.291, 61.35, 16.359
            ]
        ],   
        [
            [
                66.519, 59.066, 159.58, 97.916, 48.263, 54.411, 71.096, 121.258, 56.131, 68.466, 80.879, 102.242, 22.25, 95.597, 107.314, 67.143, 49.235, 72.488, 53.172, 195.691
            ],
            [
                137.52, 108.837, 246.572, 154.826, 72.207, 91.959, 100.265, 194.845, 110.499, 105.434, 200.806, 230.496, 54.144, 169.071, 182.641, 132.875, 100.119, 105.447, 100.602, 255.987, 205.14, 147.829, 134.508, 239.642, 115.852, 74.865, 86.575, 51.963, 145.612, 135.914, 141.868, 246.479, 107.631, 290.425, 170.007, 138.145, 135.179, 192.867, 185.605, 258.184, 123.862, 212.337, 81.014, 131.813, 70.9, 103.839, 45.547, 138.468, 337.39, 151.631, 74.157, 75.901, 258.526, 85.102, 163.956, 215.382, 69.61, 112.424, 194.122, 119.476, 165.655, 63.929, 208.652, 148.711, 103.568, 87.623, 88.546, 158.681, 133.89, 127.948, 71.644, 128.312, 102.619, 177.731, 96.87, 137.776, 132.611, 71.119, 125.586, 311.709, 100.045, 77.098, 180.829, 110.486, 116.486, 96.684, 66.725, 86.089, 90.376, 214.9
            ]
        ],  
        [
            [
                9806.265
            ],
            [
                12346.28, 12422.935
            ]
        ]
        ,
        [
            [
                140657.9864216444
            ],
            [
                177186.004324
            ]
        ]
    ]
    ys_array, ci_array = [], []
    for m_i in range(len(ys_d4permodeltrainlatencybylabelspermodel_l)):
        local_ys_array, local_ci_array = [], []
        for f_i in range(len(ys_d4permodeltrainlatencybylabelspermodel_l[m_i])):
            local_ys_array.append(np.mean(ys_d4permodeltrainlatencybylabelspermodel_l[m_i][f_i], axis=(0)))
            local_ci_array.append(1.96 * np.std(ys_d4permodeltrainlatencybylabelspermodel_l[m_i][f_i], axis=0)/np.sqrt(len(ys_d4permodeltrainlatencybylabelspermodel_l[m_i][f_i])))
        ys_array.append(local_ys_array)
        ci_array.append(local_ci_array)
    ys_array = np.array(ys_array).T
    ci_array = np.array(ci_array).T
    for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
        ax.scatter(xs, ys, label=label, marker=mark)
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
    ax.set_xticks(xs)
    ax.set_xticklabels(xs_label, fontsize=18)
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
    # ax.set_ylim(0.3,1)
    # ax.set_xscale('log')
    ax.set_yscale("log")
    ax.set_ylabel("Incremental Training Time (s)", fontsize=20)
    ax.grid()
    plt.legend(prop={'size': 16})
    # plt.show()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()


    filename = "testing_per_model_trainlatency_by_labels_per_model_with_rawinput_data_4"
    from matplotlib.ticker import ScalarFormatter

    # Data definition
    # Data from your earlier script setup
    ys_d4permodeltrainlatencybylabelspermodel_l = [
        [#filter or not
            [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
                0.123, 0.1, 0.1, 0.1, 0.095, 0.078, 0.15, 0.085, 0.085, 0.077, 0.117, 0.123, 0.072, 0.105, 0.095, 0.075, 0.08, 0.077, 0.128, 0.068, 0.079, 0.094, 0.085, 0.089, 0.095, 0.07, 0.079, 0.682, 0.088, 0.091, 0.084, 0.091, 0.099, 0.122, 0.131, 0.078, 0.071, 0.09, 0.076, 0.114, 0.08, 0.09, 0.084, 0.133, 0.088, 0.094, 0.103, 0.086, 0.091, 0.104, 0.08, 0.087, 0.094, 0.145, 0.092, 0.096, 0.14, 0.086, 0.093, 0.082, 0.095, 0.108, 0.093, 0.115, 0.084, 0.086, 0.08, 0.093, 0.189, 0.072, 0.081, 0.148, 0.093, 0.079, 0.135, 0.07, 0.083, 0.076, 0.08, 0.074, 0.073, 0.074, 0.116, 0.082, 0.078, 0.083, 0.509, 0.078, 0.085, 0.1, 0.085, 0.126, 0.088, 0.072, 0.071, 0.096, 0.117, 0.076, 0.092, 0.096, 0.088, 0.075, 0.088, 0.065, 0.183, 0.091, 0.103, 0.072, 0.066, 0.07, 0.244, 0.096, 0.086, 0.116, 0.088, 0.082, 0.061, 0.069, 0.077, 0.079, 0.087, 0.096, 0.07, 0.069, 0.086, 0.093, 0.082, 0.071, 0.289, 0.067, 0.066, 0.078, 0.071, 0.082, 0.068, 0.085, 0.073, 0.08, 0.076, 0.069, 0.088, 0.088, 0.075, 0.08, 0.069, 0.07, 0.117, 0.082, 0.08, 0.074, 0.084, 0.077, 0.075, 0.086, 0.14, 0.08, 0.141, 0.099, 0.116, 0.094, 0.127, 0.128, 0.085, 0.133, 0.08, 0.259, 0.076, 0.073, 0.098, 0.057, 0.072, 0.159, 0.112, 0.106, 0.075, 0.068, 0.103, 0.075, 0.081, 0.089, 0.075, 0.083, 0.07, 0.084, 0.079, 0.075, 0.115, 0.089, 0.11, 0.07, 0.068, 0.062, 0.074, 0.086, 0.087, 0.078, 0.132, 0.055, 0.074, 0.227, 0.093, 0.092, 0.133, 0.106, 0.09, 0.098, 0.072, 0.091, 0.089, 0.067, 0.072, 0.106, 0.082, 0.093, 0.136, 0.061, 0.094, 0.101, 0.11, 0.079, 0.076, 0.093, 0.131, 0.088, 0.083, 0.154, 0.081, 0.076, 0.164, 0.087, 0.157, 0.084, 0.125, 0.081, 0.067, 0.699, 0.138, 0.093, 0.104, 0.129, 0.084, 0.077, 0.082, 0.088, 0.134, 0.156, 0.085, 0.156, 0.088, 0.079, 0.085, 0.12, 0.134, 0.164, 0.094, 0.081, 0.072, 0.081, 0.096, 0.11, 2.949, 0.095, 0.071, 0.087, 0.118, 0.091, 0.131, 0.074, 0.083, 0.065, 0.093, 0.077, 0.083, 0.077, 0.069, 0.09, 0.076, 0.121, 0.087, 0.105, 0.08, 0.07, 0.075, 0.07, 0.09, 0.083, 0.088, 0.085, 0.079, 0.244, 0.09, 0.084, 0.08, 0.078, 0.074, 0.075, 0.08, 0.134, 0.071, 0.107, 0.065, 0.067, 0.113, 0.072, 0.154, 0.16, 0.088, 0.089, 0.102, 0.078, 0.126, 0.078, 0.14, 0.07, 0.075, 0.096, 0.072, 0.145, 0.074, 0.089, 0.099, 0.126, 0.089, 0.081, 0.075, 0.145, 0.098, 0.095, 0.133, 0.097, 0.081, 0.088, 0.082, 0.084, 0.107, 0.08, 0.086, 0.083, 0.274, 0.092, 0.109, 0.091, 0.119, 0.082, 0.108, 0.084, 0.089, 0.129, 0.072, 0.091, 0.071, 0.068, 0.076, 0.105, 0.075, 0.067, 0.09, 0.074, 0.135, 1.473, 0.091, 0.087, 0.07, 0.096, 0.079, 0.084, 0.149, 0.107, 0.076, 0.08, 0.071, 0.1, 0.126, 0.098, 0.073, 0.182, 0.077, 0.072, 0.065, 0.082, 0.086, 0.092, 0.084, 0.074, 0.121, 0.21, 0.073, 0.11, 0.078, 0.111, 0.067, 0.074, 0.086, 0.083, 0.084, 0.075, 0.08, 0.093, 0.066, 0.082, 0.066, 0.076, 0.08, 0.074, 0.087, 0.109, 0.092, 0.089, 0.104, 0.113, 0.093, 0.089, 0.124, 0.077, 0.083, 0.11, 0.083, 0.096, 0.08, 0.071, 0.148, 0.086, 0.138, 0.078, 0.084, 0.076, 0.072, 0.079, 0.064, 0.069, 0.067, 0.082, 0.086, 0.079, 0.081, 0.097, 0.076, 0.071, 0.085, 0.071, 0.136, 0.068, 0.075, 0.128, 0.104, 0.091, 0.132, 0.083, 0.131, 0.088, 0.072, 0.07, 0.08, 0.064, 0.068, 0.078, 0.072, 0.07, 0.281, 0.141, 0.069, 0.186, 0.069, 0.08, 0.089, 0.108, 0.07, 0.083, 0.149, 0.142, 0.083, 0.093, 0.075, 0.068, 0.087, 0.076, 0.076, 0.112, 0.083, 0.089, 0.094, 0.075, 0.083, 0.084, 0.076, 0.135, 0.07, 0.086, 0.144, 0.09, 0.091, 0.093, 0.089, 0.073, 0.091, 0.089, 0.079, 0.08, 0.087, 0.091, 0.077, 0.08, 0.09, 0.095, 0.086, 0.073, 0.069, 0.108, 0.072, 0.082, 0.081, 0.12, 0.077, 0.081, 0.097, 0.115, 0.069, 0.072, 0.071, 0.096, 0.079, 0.058, 0.09, 0.058, 0.1, 0.072, 0.079, 0.285, 0.089, 0.067, 0.07, 0.084, 0.068, 0.078, 0.083, 0.081, 0.084, 0.084, 0.098, 0.37, 0.068, 0.094, 0.101, 0.068, 0.082, 0.093, 0.085, 0.127, 0.093, 0.084, 0.119, 0.092, 0.075, 0.084, 0.084, 0.082, 0.091, 0.193, 0.117, 0.083, 0.159, 0.104, 0.07, 0.096, 0.066, 0.082, 0.084, 0.081, 0.08, 0.076, 0.089, 0.076, 0.071, 0.116, 0.162, 0.078, 0.103, 0.095, 0.093, 0.121, 0.117, 0.081, 0.08, 0.097, 0.14, 0.095, 0.078, 0.091, 0.099, 0.072, 0.085, 0.111, 0.091, 0.083, 0.164, 0.112, 0.08, 0.088, 0.078, 0.071, 0.379, 0.086, 0.09, 0.085, 0.065, 0.092, 0.093, 0.068, 0.085, 0.129, 0.071, 0.071, 0.078, 0.101, 0.099, 0.142, 0.119, 0.094, 0.09, 0.155, 0.086, 0.058, 0.11, 0.067, 0.063, 0.092, 0.122, 0.077, 0.086, 0.079, 0.109, 0.084, 0.08, 0.111, 0.066, 0.266, 0.077, 0.09, 0.15, 0.087, 0.084, 0.082, 0.097, 0.082, 0.071, 0.074, 0.071, 0.08, 0.059, 0.069, 0.099, 0.112, 0.123, 0.064, 0.059, 0.075, 0.072, 0.134, 0.103, 0.091, 0.093, 0.08, 0.086, 0.078, 0.081, 0.08, 0.079, 0.098, 0.103, 0.091, 0.083, 0.086, 0.114, 0.081, 0.122, 0.08, 0.077, 0.084, 0.088, 0.073, 0.074, 0.078, 0.081, 0.092, 0.15, 0.11, 0.075, 0.084, 0.077, 0.064, 0.07, 0.079, 0.19, 0.087, 0.134, 0.08, 0.19, 0.074, 0.072, 0.103, 0.098, 0.102, 0.167, 0.072, 0.079, 0.088, 0.087, 0.085, 0.15, 0.089, 0.2, 0.096, 0.101, 0.08, 0.083, 0.088, 0.14, 0.089, 1.257, 0.073, 0.067, 0.067, 0.073, 0.076, 0.084, 0.071, 0.122, 0.082, 0.083, 0.081, 0.068, 0.094, 0.091, 0.077, 0.079, 0.189, 0.097, 0.093, 0.135, 0.13, 0.102, 0.074, 0.086, 0.089, 0.09, 0.075, 0.074, 0.085, 0.097, 0.279, 0.151, 0.08, 0.078, 0.069, 0.071, 0.088, 0.093, 0.111, 0.116, 0.083, 0.101, 0.118, 1.188, 0.089, 0.085, 0.083, 0.077, 0.076, 0.132, 0.072, 0.087, 0.084, 0.08, 0.064, 0.084, 0.077, 0.079, 0.088, 0.099, 0.072, 0.072, 0.115, 0.107, 0.103, 0.125, 0.084, 0.063, 0.086, 0.12, 0.101, 0.066, 0.137, 0.078, 0.143, 0.063, 0.098, 0.081, 0.092, 0.103, 0.078, 0.136, 0.082, 0.091, 0.076, 0.091, 0.084, 0.128, 0.08, 0.077, 0.094, 0.07, 0.073, 0.066, 0.144, 0.084, 0.13, 0.085, 0.069, 0.083, 0.116, 0.083, 0.088, 0.137, 0.082, 0.133, 0.091, 0.08, 0.084, 0.084, 0.078, 0.067, 0.101, 0.068, 0.063, 0.066, 0.084, 0.259, 0.105, 0.074, 0.068, 0.206, 0.07, 0.072, 0.175, 0.117, 0.088, 0.085, 0.061, 0.071, 0.062, 0.187, 0.065, 0.117, 0.087, 0.129, 0.076, 0.074, 0.073, 0.089, 0.085, 0.07, 0.081, 0.099, 0.122, 0.072, 0.097, 0.128, 0.091, 0.075, 0.079, 0.074, 0.12, 0.076, 0.09, 0.078, 0.077, 0.085, 0.076, 0.071, 0.117, 0.072, 0.098, 0.099, 0.098, 0.068, 0.079, 0.07, 0.12, 0.103, 0.061, 0.079, 0.074, 0.072, 0.119, 0.099, 0.141, 0.086, 0.082, 0.073, 0.086, 0.076, 0.075, 0.077, 0.071, 0.069, 0.081, 0.076, 0.072, 0.106, 0.077, 0.077, 0.078, 0.128, 0.072, 0.101, 0.102, 0.119, 0.09, 0.133, 0.096, 0.087, 0.08, 0.077, 0.081, 0.118, 0.102, 0.144, 0.099, 0.105, 0.081, 0.081, 0.112, 0.097, 0.132, 0.083, 0.097, 0.089, 0.132, 0.092, 0.079, 0.079, 0.092, 0.07, 0.072, 0.082, 0.069, 0.091, 0.093, 0.078, 0.168, 0.226, 0.075, 0.083, 0.094, 0.089, 0.088, 0.078, 0.094, 0.09, 0.083, 0.087, 0.081, 0.838, 0.082, 0.082, 0.084, 0.08, 0.083, 0.076, 0.072, 0.071, 0.147, 0.085, 0.107, 0.084, 0.089, 0.085, 0.126, 0.102, 0.073, 0.077, 0.078, 0.092, 0.117, 0.104, 0.127, 0.076, 0.328, 0.073, 0.08, 0.081, 0.081, 0.075, 0.07, 0.08, 0.072, 0.075, 0.08, 0.119, 0.083, 0.077, 0.109, 0.08, 0.069, 0.082, 0.102, 0.063, 0.091, 0.09, 0.127, 0.097, 0.093, 0.086, 0.148, 0.136, 0.089, 0.078, 0.102, 0.09, 0.072, 0.073, 0.083, 0.07, 0.094, 0.128, 0.107, 0.08, 0.081, 0.114, 0.097, 0.095, 0.103, 0.076, 0.07, 0.097, 0.112, 0.089, 0.146, 0.095, 0.089, 0.083, 0.075, 0.092, 0.164, 0.075, 0.076, 0.074, 0.066, 0.077, 0.135, 0.074, 0.08, 0.077, 0.299, 0.108, 0.081, 0.368, 0.065, 0.069, 0.08, 0.836, 0.06, 0.302, 0.066, 0.066, 0.073, 0.077, 0.083, 0.084, 0.07, 0.096, 0.074, 0.094, 0.078, 0.148, 0.103, 0.087, 0.085, 0.074, 0.08, 0.181, 0.122, 0.072, 0.074, 0.117, 0.107, 0.137, 0.072, 0.095, 0.102, 0.087, 0.091, 0.088, 0.082, 0.102, 0.069, 0.072, 0.067, 0.09, 0.074, 0.082, 0.138, 0.079, 0.091, 0.088, 0.084, 0.145, 0.095, 0.09, 0.102, 0.091, 0.11, 0.09, 0.09, 0.073, 0.088, 0.102, 0.109, 0.102, 0.142, 0.076, 0.094, 0.087, 0.086, 0.101, 0.068, 0.12, 0.091, 0.069, 0.075, 0.091, 0.087, 0.131, 0.139, 0.126, 0.089, 0.067, 0.077, 0.079, 0.168, 0.139, 0.118, 0.073, 0.124, 0.071, 0.094, 0.081, 0.088, 0.079, 0.107, 0.079, 0.078, 0.065, 0.064, 0.083, 0.075, 0.074, 0.095, 0.081, 0.178, 0.411, 0.067, 0.094, 0.097, 0.087, 0.076, 0.113, 0.083, 0.12, 0.08, 0.087, 0.078, 0.074, 0.148, 0.136, 0.088, 0.095, 0.089, 0.066, 0.134, 0.079, 0.071, 0.096, 0.073, 0.124, 1.486, 0.076, 0.078, 0.131, 0.094, 0.086, 0.156, 0.086, 0.195, 0.08, 0.109, 0.099, 0.136, 0.135, 0.098, 0.081, 0.081, 0.094, 0.114, 0.079, 0.084, 0.081, 0.071, 0.078, 0.124, 0.075, 0.102, 0.078, 0.101, 0.106, 0.074, 0.088, 0.074, 0.084, 0.078, 0.103, 0.099, 0.082, 0.143, 0.083, 0.102, 0.083, 0.078, 0.077, 0.077, 0.088, 0.078, 0.077, 0.139, 0.079, 0.075, 0.077, 0.074, 0.078, 0.115, 0.079, 0.083, 0.149, 0.083, 0.085, 0.105, 0.103, 0.105, 0.141, 0.083, 0.082, 0.112, 0.087, 0.093, 0.077, 0.098, 0.086, 0.089, 0.084, 0.086, 0.09, 0.132, 0.08, 0.099, 0.11, 0.087, 0.061, 0.102, 0.071, 0.077, 0.068, 0.076, 0.068, 0.09, 0.07, 0.09, 0.1, 0.084, 0.085, 0.089, 0.095, 0.092, 0.121, 0.094, 0.088, 0.108, 0.098, 0.126, 0.153, 0.064, 0.078, 0.081, 0.083, 0.089, 0.072, 0.084, 0.089, 0.078, 0.07, 0.111, 0.084, 0.088, 0.074, 0.072, 0.076, 0.077, 0.095, 0.08, 0.08, 0.081, 0.087, 0.286, 0.078, 0.086, 0.112, 0.091, 0.088, 0.084, 0.077, 0.098, 0.084, 0.121, 0.066, 0.137, 0.076, 0.082, 0.076, 0.079, 0.08, 0.297, 0.076, 0.066, 0.087, 0.082, 0.094, 0.077, 0.126, 0.078, 0.07, 0.134, 0.156, 0.072, 0.127, 0.17, 0.1, 0.087, 0.085, 0.077, 0.076, 0.11, 0.072, 0.09, 0.078, 0.112, 0.068, 0.155, 0.092, 0.079, 0.077, 0.084, 0.078, 0.078, 0.093, 0.092, 0.07, 0.096, 0.124, 0.126, 0.171, 0.168, 0.099, 0.075, 0.095, 0.061, 0.078, 0.098, 0.098, 0.088, 0.091, 0.085, 0.077, 0.08, 0.123, 0.082, 0.076, 0.081, 0.092, 0.087, 0.081, 0.066, 0.083, 0.067, 0.066, 1.014, 0.068, 0.073, 0.079, 0.07, 0.073, 0.072, 0.08, 0.076, 0.088, 0.081, 0.084, 0.079, 0.241, 0.102, 0.073, 0.085, 0.072, 0.072, 0.124, 0.126, 0.08, 0.086, 0.072, 0.102, 0.078, 0.086, 0.101, 0.093, 0.095, 0.118, 0.101, 0.093, 0.08, 0.132, 0.069, 0.125, 0.107, 0.087, 0.137, 0.085, 0.08, 0.109, 0.066, 0.097, 0.111, 0.08, 0.087, 0.086, 0.093, 0.132, 0.112, 0.127, 0.185, 0.087, 0.079, 0.087, 0.083, 0.06, 0.073, 0.08, 0.095, 0.082, 0.082, 0.09, 0.09, 0.131, 0.095, 0.103, 0.076, 0.081, 0.075, 0.107, 0.078, 0.114, 0.471, 0.079, 0.087, 0.1, 0.107, 0.154, 0.098, 0.075, 1.219, 0.077, 0.091, 0.095, 0.078, 0.079, 0.096, 0.117, 0.085, 0.078, 0.076, 0.081, 0.078, 0.115, 0.071, 0.086, 0.072, 0.08, 0.274, 0.076, 0.084, 0.098, 0.092, 0.073, 0.082, 0.084, 0.081, 0.087, 0.091, 0.087, 0.085, 0.092, 0.082, 0.082, 0.066, 0.117, 0.078, 0.101, 0.08, 0.088, 0.089, 0.068, 0.08, 0.115, 0.088, 0.086, 0.082, 0.137, 0.082, 0.09, 0.081, 0.129, 0.067, 0.139, 0.069, 0.086, 0.09, 0.087, 0.874, 0.1, 0.082, 0.085, 0.076, 0.071, 0.07, 0.108, 0.12, 0.092, 0.183, 0.074, 0.085, 0.085, 0.081, 0.092, 0.091, 0.091, 0.114, 0.062, 0.089, 0.076, 0.07, 0.08, 0.09, 0.089, 0.08, 0.177, 0.099, 0.097, 0.072, 0.208, 0.089, 0.089, 0.108, 0.083, 0.102, 0.093, 0.082, 0.078, 0.079, 0.125, 0.082, 0.069, 0.084, 0.067, 0.075, 0.072, 0.094, 0.08, 0.084, 0.089, 0.122, 0.071, 0.072, 0.106, 0.198, 0.081, 0.089, 0.078, 0.082, 0.083, 0.081, 0.081, 0.082, 0.09, 0.085, 0.11, 0.167, 0.082, 0.077, 0.099, 0.084, 0.085, 0.081, 0.073, 0.136, 0.082, 0.074, 0.085, 0.095, 0.095, 0.065, 0.071, 0.138, 0.099, 0.086, 0.062, 0.084, 0.084, 0.084, 0.073, 0.096, 0.107, 0.079, 0.092, 0.13, 0.079, 0.067, 0.088, 0.083, 0.064, 0.079, 0.081, 0.061, 0.077, 0.102, 0.095, 0.085, 0.067, 0.113, 0.098, 0.094, 0.084, 0.084, 0.082, 0.085, 0.101, 0.097, 0.081, 0.103, 0.077, 0.113, 0.076, 0.091, 0.091, 0.07, 0.125, 0.092, 0.071, 0.083, 0.125, 0.284, 0.105, 0.086, 0.094, 0.071, 0.086, 0.122, 0.077, 0.138, 0.081, 0.109, 0.21, 0.082, 0.135, 0.089, 0.082, 0.089, 0.08, 0.067, 0.144, 0.085, 0.121, 0.073, 0.069, 0.079, 0.116, 0.067, 0.067, 0.064, 0.073, 0.07, 0.125, 0.073, 0.106, 0.08, 0.075, 0.088, 0.077, 0.094, 0.092, 0.125, 0.123, 0.081, 0.078, 0.099, 0.065, 0.101, 0.087, 0.09, 0.088, 0.21, 0.084, 0.145, 0.074, 0.102, 0.101, 0.069, 0.085, 0.088, 0.114, 0.087, 0.073, 0.084, 0.13, 0.285, 0.084, 0.111, 0.133, 0.092, 0.094, 0.082, 0.08, 0.084, 0.081, 0.083, 0.083, 0.089, 0.076, 0.059, 0.07, 0.089, 0.063, 0.074, 0.083, 0.51, 0.075, 0.066, 0.081, 0.077, 0.113, 0.073, 0.114, 0.09, 0.085, 0.07, 0.246, 0.064, 0.095, 0.074, 0.081, 0.088, 0.09, 0.08, 0.116, 0.075, 0.128, 0.071, 0.103, 0.063, 0.078, 0.126, 0.178, 0.079, 0.075, 0.072, 0.086, 0.093, 0.115, 0.075, 0.061, 0.068, 0.106, 0.089, 0.079, 0.106, 0.088, 0.098, 0.129, 0.094, 0.096, 0.08, 0.084, 0.07, 0.13, 0.075, 0.126, 0.076, 0.102, 0.08, 0.059, 0.102, 0.149, 0.289, 0.078, 0.058, 0.073, 0.081, 0.068, 0.077, 0.075, 0.107, 0.071, 0.072, 0.072, 0.086, 0.079, 0.081, 0.059, 0.119, 0.092, 0.074, 0.072, 0.061, 0.091, 0.091, 0.062, 0.079, 0.173, 0.067, 0.115, 0.081, 0.088, 0.095, 0.128, 0.088, 0.11, 0.098, 0.13, 0.086, 0.08, 0.089, 0.088, 0.088, 0.115, 0.248, 0.075, 0.078, 0.07, 0.07, 0.061, 0.094, 0.093, 0.078, 0.072, 0.07, 0.096, 0.082, 0.086, 0.082, 0.062, 0.091, 0.074, 0.088, 0.098, 0.086, 0.08, 0.092, 0.141, 0.069, 0.119, 0.061, 0.091, 0.063, 0.083, 0.08, 0.073, 0.083, 0.086, 0.079, 0.102, 0.07, 0.058, 0.089, 0.115, 0.075, 0.085, 0.081, 0.089, 0.089, 0.088, 0.073, 0.13, 0.172, 0.077, 0.111, 0.119, 0.129, 0.082, 0.086, 0.103, 0.106, 0.072, 0.097, 0.086, 0.095, 0.097, 0.07, 0.134, 0.071, 0.096, 0.081, 0.062, 0.075, 0.083, 0.12, 0.092, 0.098, 0.188, 0.082, 0.078, 0.126, 0.269, 0.065, 0.086, 0.075, 0.065, 0.074, 0.089, 0.217, 0.094, 0.071, 0.131, 0.087, 0.124, 0.139, 0.092, 0.088, 0.139, 0.083, 0.084, 0.109, 0.081, 0.097, 0.079, 0.083, 0.095, 0.109, 0.092, 0.143, 0.076, 0.075, 3.058, 0.082, 0.073, 0.089, 0.085, 0.076, 0.08, 0.094, 0.129, 0.174, 0.1, 0.214, 0.155, 0.085, 0.078, 0.087, 0.235, 0.165, 0.112, 0.08, 0.111, 0.08, 0.075, 0.07, 0.097, 0.074, 0.146, 0.149, 0.093, 0.073, 0.075, 0.119, 0.086, 0.078, 0.067, 0.067, 0.097, 0.07, 0.141, 0.121, 0.079, 0.076, 0.07, 0.119, 0.08, 0.063, 0.063, 0.575, 0.075, 0.117, 0.11, 0.098, 0.076, 0.075, 0.158, 0.069, 0.129, 0.09, 0.085, 0.158, 0.083, 0.085, 0.074, 0.084, 0.16, 0.08, 0.078, 0.067, 0.083, 0.086, 0.076, 0.074, 0.076, 0.069, 0.074, 0.065, 0.087, 0.169, 0.114, 0.092, 0.075, 0.076, 0.069, 0.062, 0.061, 0.068, 0.072, 0.062, 0.081, 0.126, 0.091, 0.084, 0.072, 0.149, 0.076, 0.07, 0.073, 0.109, 0.076, 0.08, 0.127, 0.07, 0.074, 0.079, 0.066, 0.068, 0.06, 0.076, 0.078, 0.094, 0.079, 0.069, 0.079, 0.063, 0.078, 0.07, 0.098, 0.071, 0.135, 0.181, 0.07, 0.085, 0.086, 0.084, 0.083, 0.069, 0.064, 0.148, 0.077, 0.079, 0.082, 0.149, 0.07, 0.075, 0.176, 0.082, 0.088, 0.092, 0.091, 1.155, 0.084, 0.083, 0.08, 0.122, 0.078, 0.086, 0.197, 0.109, 0.066, 0.107, 0.095, 0.061, 0.154, 0.066, 0.102, 0.075, 0.066, 0.107, 0.072, 0.067, 0.074, 0.091, 0.071, 0.085, 0.107, 0.07, 0.066, 0.071, 0.067, 0.073, 0.073, 0.071, 0.094, 0.068, 0.101, 0.097, 0.076, 0.075, 0.207, 0.077, 0.086, 0.061, 0.063, 0.062, 0.213, 0.067, 0.104, 0.085, 0.085, 0.084, 0.075, 0.069, 0.076, 0.071, 0.074, 0.096, 0.107, 0.166, 0.077, 0.065, 0.09, 0.081, 0.072, 0.095, 0.077, 0.138, 0.114, 0.189, 0.094, 0.101, 0.108, 0.089, 0.068, 0.076, 0.337, 0.064, 0.077, 0.085, 0.14, 0.091, 0.096, 0.091, 0.135, 0.07, 0.081, 0.094, 0.069, 0.092, 0.071, 0.137, 0.09, 0.307, 0.076, 0.065, 0.097, 0.055, 0.07, 0.091, 0.067, 0.066, 0.065, 0.056, 0.088, 0.073, 0.063, 0.059, 0.088, 0.067, 0.073, 0.082, 0.091, 0.091, 0.118, 0.073, 0.242, 0.069, 0.077, 0.075, 0.066, 0.072, 0.084, 0.065, 0.08, 0.094, 0.086, 0.083, 0.074, 0.077, 0.077, 0.332, 0.068, 0.06, 0.079, 0.11, 0.123, 0.068, 0.102, 0.084, 0.073, 0.081, 0.07, 0.073, 0.109, 0.098, 0.119, 0.079, 0.094, 0.124, 0.076, 0.072, 0.071, 0.071, 0.062, 0.131, 0.073, 0.112, 0.113, 0.084, 0.069, 0.063, 0.814, 0.058, 0.141, 0.072, 0.066, 0.124, 0.078, 0.082, 0.067, 0.072, 0.099, 0.074, 0.076, 0.076, 0.068, 0.064, 0.111, 0.118, 0.088, 0.091, 0.108, 0.117, 0.084, 0.08, 0.086, 0.076, 0.098, 0.078, 0.094, 0.08, 0.209, 0.079, 0.077, 0.07, 0.087, 0.068, 0.072, 0.14, 0.084, 0.074, 0.083, 0.103, 0.072, 0.14, 0.091, 0.079, 0.115, 0.083, 0.075, 0.084, 0.073, 0.105, 0.074, 0.123, 0.127, 0.093, 0.092, 0.088, 0.096, 0.162, 0.086, 0.084, 0.074, 0.108, 0.113, 0.08, 0.144, 0.109, 0.097, 0.068, 0.093, 0.098, 0.082, 0.069, 3.079, 0.127, 0.09, 0.087, 0.093, 0.134, 0.086, 0.08, 0.071, 0.135, 0.084, 0.079, 0.077, 0.078, 0.098, 0.142, 0.078, 0.079, 0.129, 0.081, 0.07, 0.062, 0.075, 0.069, 0.096, 0.073, 0.085, 0.087, 0.084, 0.111, 0.102, 0.195, 0.071, 0.069, 0.071, 0.085, 0.07, 0.065, 0.097, 0.097, 0.065, 1.575, 0.09, 0.065, 0.082, 0.064, 0.081, 0.085, 0.177, 0.088, 0.116, 0.09, 0.084, 0.071, 0.28, 0.091, 0.079, 0.08, 0.074, 0.079, 0.091, 0.07, 0.063, 0.068, 0.067, 0.065, 0.077, 0.077, 0.081, 0.126, 0.082, 0.093, 0.064, 0.076, 0.083, 0.094, 0.099, 0.079, 0.071, 0.086, 0.08, 0.083, 0.094, 0.092, 0.077, 0.113, 0.069, 0.079, 0.082, 0.673, 0.134, 0.097, 0.098, 0.094, 0.067, 0.139, 0.091, 0.072, 0.087, 0.079, 0.078, 0.063, 0.074, 0.073, 0.206, 0.21, 0.074, 0.065, 0.071, 0.085, 0.098, 0.07, 0.098, 0.072, 0.066, 0.113, 0.083, 0.072, 0.069, 0.143, 0.076, 0.091, 0.09, 0.06, 0.085, 0.089, 0.075, 0.077, 0.076, 0.06, 0.07, 0.073, 0.297, 0.075, 0.071, 0.085, 0.075, 0.062, 0.08, 0.082, 0.088, 0.088, 0.075, 0.072, 0.081, 0.092, 0.081, 0.076, 0.098, 0.079, 0.088, 0.086, 0.086, 0.099, 0.086, 0.089, 0.092, 0.11, 0.076, 0.098, 0.068, 0.139, 0.076, 0.1, 0.093, 0.098, 0.081, 0.133, 0.172, 0.093, 0.084, 0.071, 0.298, 0.153, 0.078, 0.073, 0.107, 0.079, 0.08, 0.104, 0.111, 0.273, 0.073, 0.074, 0.069, 0.077, 0.076, 0.087, 0.092, 0.095, 0.09, 0.071, 0.096, 0.103, 0.074, 0.068, 0.072, 0.094, 0.067, 0.073, 0.086, 0.085, 0.075, 0.087, 0.073, 0.086, 0.083, 0.07, 0.09, 0.092, 0.079, 0.089, 0.102, 0.081, 0.077, 0.084, 0.081, 0.069, 0.089, 0.079, 0.069, 0.089, 0.102, 0.114, 0.147, 0.13, 0.068, 0.089, 0.157, 0.078, 0.085, 0.082, 0.072, 0.086, 0.081, 0.096, 0.102, 0.077, 0.107, 0.091, 0.09, 0.119, 0.071, 0.1, 0.072, 0.064, 0.074, 0.081, 0.08, 0.142, 0.079, 0.209, 0.08, 0.087, 0.094, 0.125, 0.069, 0.067, 0.066, 0.085, 0.074, 0.085, 0.083, 0.154, 0.093, 0.096, 0.079, 0.095, 0.087, 0.08, 0.077, 0.071, 0.074, 0.077, 0.073, 0.074, 0.262, 0.081, 0.08, 0.071, 0.12, 0.15, 0.092, 0.102, 0.073, 0.08, 0.106, 0.105, 0.084, 0.081, 0.07, 0.074, 0.095, 0.099, 0.078, 0.077, 0.087, 0.09, 0.074, 0.085, 0.085, 0.102, 0.092, 0.115, 0.087, 0.219, 0.193, 0.122, 0.084, 0.079, 0.079, 0.077, 0.075, 0.075, 0.124, 0.102, 0.085, 0.079, 0.079, 0.108, 0.078, 0.095, 0.087, 0.146, 0.093, 0.112, 0.074, 0.094, 0.097, 0.089, 0.085, 0.089, 0.082, 0.077, 0.061, 0.142, 0.099, 0.072, 0.075, 0.133, 0.096, 0.073, 0.107, 0.07, 0.065, 0.077, 0.084, 0.075, 0.073, 0.081, 0.076, 0.077, 0.074, 0.072, 0.075, 0.095, 0.081, 0.073, 0.411, 0.068, 0.085, 0.079, 0.063, 0.076, 0.076, 0.081, 0.072, 0.07, 0.082, 0.084, 0.074, 0.083, 0.07, 0.087, 0.094, 0.095, 0.078, 0.112, 0.107, 0.061, 0.087, 0.092, 0.07, 0.064, 0.078, 0.102, 0.079, 0.069, 0.076, 0.09, 0.108, 0.071, 0.1, 0.067, 0.153, 0.135, 0.067, 0.106, 0.088, 0.089, 0.078, 0.133, 0.123, 0.069, 0.105, 0.067, 0.064, 0.065, 0.067, 0.094, 0.068, 0.098, 0.091, 0.086, 0.084, 0.105, 0.093, 0.072, 0.09, 0.155, 0.084, 0.072, 0.072, 0.081, 0.081, 0.098, 0.076, 0.083, 0.074, 0.11, 0.08, 0.091, 0.082, 0.077, 0.076, 0.092, 0.098, 0.076, 0.147, 0.122, 0.122, 0.074, 0.073, 0.077, 0.072, 0.092, 0.087, 0.133, 0.074, 0.082, 0.08, 0.085, 0.082, 0.118, 0.117, 0.087, 0.094, 0.102, 0.079, 0.096, 0.078, 0.116, 0.09, 0.089, 0.08, 0.092, 0.073, 0.074, 0.088, 0.076, 0.069, 0.132, 0.109, 0.095, 0.095, 0.152, 0.096, 1.285, 0.084, 0.078, 0.082, 0.081, 0.068, 0.095, 0.096, 0.102, 0.392, 0.102, 0.094, 0.079, 0.09, 0.08, 0.08, 0.089, 0.093, 0.106, 0.122, 0.078, 0.072, 0.08, 0.08, 0.1, 0.077, 0.076, 0.086, 0.071, 0.117, 0.089, 0.135, 0.069, 0.098, 0.093, 0.106, 0.079, 0.09, 0.13, 0.086, 0.067, 0.101, 0.063, 0.079, 0.13, 0.091, 0.069, 0.082, 0.091, 0.088, 0.077, 0.098, 0.085, 0.08, 0.078, 0.081, 0.08, 0.072, 0.126, 0.086, 0.078, 0.1, 0.072, 0.087, 0.142, 0.089, 0.08, 0.076, 0.098, 0.092, 0.073, 0.087, 0.124, 0.086, 0.093, 0.122, 0.167, 0.158, 0.125, 0.082, 0.104, 0.084, 0.091, 0.078, 0.074, 0.081, 0.162, 0.078, 0.071, 0.073, 0.077, 0.092, 0.084, 0.075, 0.072, 0.07, 0.08, 0.136, 0.081, 0.134, 0.155, 0.125, 0.077, 0.141, 0.084, 0.065, 0.134, 0.116, 0.091, 0.068, 0.09, 0.091, 0.089, 0.068, 0.088, 0.089, 0.092, 0.147, 0.108, 0.066, 0.076, 0.099, 0.082, 0.07, 0.098, 0.293, 0.095, 0.075, 0.097, 0.094, 0.088, 0.143, 0.134, 0.094, 0.091, 0.09, 0.104, 0.096, 0.095, 0.087, 0.235, 0.102, 0.135, 0.085, 0.081, 0.082, 0.096, 0.079, 0.078, 0.063, 0.083, 0.098, 0.091, 0.082, 0.09, 0.117, 0.077, 0.071, 0.108, 0.097, 0.101, 0.099, 0.105, 0.114, 0.479, 0.08, 0.189, 0.087, 0.074, 0.086, 0.093, 0.089, 0.064, 0.073, 0.107, 0.087, 0.097, 0.08, 0.12, 0.112, 0.079, 0.083, 0.083, 0.092, 0.084, 0.082, 0.088, 0.081, 0.08, 0.137, 0.078, 0.119    
            ],
            [
                0.151, 0.101, 0.085, 0.061, 0.087, 0.068, 0.163, 0.079, 0.105, 0.077, 0.173, 0.122, 0.107, 0.135, 0.138, 0.081, 0.081, 0.083, 0.136, 0.087, 0.081, 0.104, 0.103, 0.095, 0.11, 0.09, 0.09, 0.817, 0.093, 0.074, 0.086, 0.104, 0.087, 0.143, 0.127, 0.081, 0.082, 0.082, 0.08, 0.108, 0.076, 0.102, 0.079, 0.124, 0.102, 0.095, 0.098, 0.095, 0.091, 0.095, 0.091, 0.089, 0.094, 0.129, 0.093, 0.079, 0.135, 0.116, 0.084, 0.082, 0.098, 0.116, 0.089, 0.134, 0.091, 0.101, 0.089, 0.093, 0.193, 0.081, 0.087, 0.147, 0.083, 0.078, 0.147, 0.097, 0.081, 0.088, 0.082, 0.092, 0.085, 0.084, 0.126, 0.091, 0.079, 0.092, 0.565, 0.075, 0.085, 0.097, 0.083, 0.108, 0.112, 0.083, 0.074, 0.119, 0.103, 0.073, 0.122, 0.087, 0.074, 0.064, 0.064, 0.07, 0.189, 0.099, 0.088, 0.102, 0.087, 0.093, 0.292, 0.085, 0.101, 0.113, 0.064, 0.07, 0.091, 0.095, 0.083, 0.058, 0.11, 0.126, 0.073, 0.102, 0.097, 0.101, 0.104, 0.084, 0.31, 0.075, 0.081, 0.074, 0.078, 0.106, 0.071, 0.075, 0.073, 0.085, 0.071, 0.09, 0.083, 0.079, 0.086, 0.125, 0.069, 0.082, 0.143, 0.094, 0.091, 0.081, 0.078, 0.078, 0.066, 0.065, 0.125, 0.068, 0.105, 0.066, 0.111, 0.072, 0.134, 0.114, 0.079, 0.113, 0.095, 0.26, 0.088, 0.078, 0.11, 0.117, 0.101, 0.165, 0.099, 0.103, 0.107, 0.078, 0.138, 0.066, 0.08, 0.109, 0.076, 0.072, 0.088, 0.114, 0.08, 0.103, 0.157, 0.082, 0.13, 0.085, 0.084, 0.088, 0.092, 0.085, 0.09, 0.084, 0.094, 0.075, 0.073, 0.285, 0.106, 0.109, 0.144, 0.111, 0.102, 0.085, 0.073, 0.088, 0.115, 0.077, 0.079, 0.077, 0.081, 0.1, 0.152, 0.08, 0.104, 0.126, 0.135, 0.084, 0.075, 0.087, 0.14, 0.096, 0.102, 0.165, 0.081, 0.077, 0.176, 0.106, 0.2, 0.106, 0.146, 0.076, 0.088, 0.783, 0.105, 0.074, 0.106, 0.135, 0.081, 0.1, 0.076, 0.077, 0.129, 0.127, 0.101, 0.184, 0.11, 0.105, 0.092, 0.128, 0.113, 0.12, 0.09, 0.099, 0.092, 0.072, 0.096, 0.082, 2.938, 0.092, 0.083, 0.086, 0.144, 0.101, 0.143, 0.084, 0.069, 0.074, 0.116, 0.102, 0.079, 0.093, 0.098, 0.08, 0.081, 0.11, 0.083, 0.088, 0.116, 0.087, 0.065, 0.079, 0.09, 0.085, 0.097, 0.087, 0.08, 0.26, 0.077, 0.098, 0.1, 0.087, 0.081, 0.1, 0.081, 0.114, 0.076, 0.122, 0.086, 0.085, 0.134, 0.077, 0.14, 0.149, 0.07, 0.065, 0.082, 0.119, 0.128, 0.076, 0.12, 0.075, 0.088, 0.085, 0.07, 0.138, 0.072, 0.11, 0.109, 0.097, 0.105, 0.082, 0.082, 0.154, 0.088, 0.078, 0.117, 0.108, 0.084, 0.1, 0.081, 0.076, 0.105, 0.088, 0.083, 0.078, 0.264, 0.088, 0.113, 0.092, 0.125, 0.068, 0.102, 0.083, 0.101, 0.143, 0.079, 0.108, 0.095, 0.097, 0.087, 0.135, 0.088, 0.08, 0.094, 0.086, 0.146, 1.463, 0.088, 0.082, 0.081, 0.085, 0.076, 0.07, 0.136, 0.139, 0.072, 0.076, 0.07, 0.131, 0.112, 0.098, 0.089, 0.216, 0.094, 0.074, 0.078, 0.082, 0.068, 0.093, 0.084, 0.073, 0.122, 0.232, 0.08, 0.084, 0.078, 0.092, 0.107, 0.09, 0.072, 0.089, 0.093, 0.057, 0.074, 0.108, 0.085, 0.119, 0.08, 0.069, 0.065, 0.079, 0.067, 0.101, 0.083, 0.081, 0.098, 0.092, 0.083, 0.084, 0.091, 0.081, 0.104, 0.109, 0.097, 0.099, 0.087, 0.066, 0.167, 0.074, 0.099, 0.074, 0.09, 0.08, 0.077, 0.068, 0.072, 0.071, 0.064, 0.071, 0.073, 0.064, 0.069, 0.114, 0.071, 0.084, 0.101, 0.076, 0.113, 0.094, 0.074, 0.132, 0.12, 0.115, 0.129, 0.084, 0.119, 0.092, 0.081, 0.09, 0.111, 0.084, 0.082, 0.063, 0.08, 0.073, 0.288, 0.11, 0.07, 0.197, 0.084, 0.073, 0.093, 0.143, 0.085, 0.08, 0.13, 0.143, 0.084, 0.108, 0.068, 0.075, 0.087, 0.083, 0.088, 0.13, 0.084, 0.08, 0.092, 0.088, 0.095, 0.078, 0.088, 0.114, 0.089, 0.111, 0.138, 0.074, 0.09, 0.096, 0.103, 0.071, 0.069, 0.097, 0.099, 0.082, 0.08, 0.093, 0.091, 0.084, 0.075, 0.082, 0.073, 0.093, 0.081, 0.109, 0.089, 0.094, 0.083, 0.113, 0.095, 0.08, 0.105, 0.145, 0.08, 0.081, 0.092, 0.079, 0.132, 0.086, 0.138, 0.095, 0.109, 0.089, 0.096, 0.307, 0.149, 0.079, 0.085, 0.103, 0.075, 0.076, 0.092, 0.096, 0.098, 0.085, 0.148, 0.397, 0.081, 0.081, 0.117, 0.08, 0.067, 0.095, 0.067, 0.122, 0.095, 0.075, 0.094, 0.074, 0.087, 0.076, 0.077, 0.078, 0.073, 0.191, 0.075, 0.082, 0.138, 0.131, 0.089, 0.091, 0.084, 0.084, 0.1, 0.069, 0.097, 0.097, 0.093, 0.08, 0.075, 0.108, 0.196, 0.061, 0.11, 0.108, 0.089, 0.119, 0.112, 0.084, 0.076, 0.101, 0.126, 0.115, 0.083, 0.105, 0.121, 0.078, 0.08, 0.145, 0.101, 0.102, 0.155, 0.122, 0.078, 0.075, 0.069, 0.092, 0.397, 0.09, 0.126, 0.086, 0.087, 0.081, 0.078, 0.088, 0.086, 0.143, 0.104, 0.093, 0.07, 0.093, 0.111, 0.137, 0.141, 0.173, 0.078, 0.154, 0.116, 0.063, 0.126, 0.077, 0.088, 0.104, 0.129, 0.077, 0.078, 0.088, 0.112, 0.081, 0.074, 0.134, 0.08, 0.307, 0.107, 0.111, 0.177, 0.091, 0.11, 0.076, 0.083, 0.075, 0.066, 0.099, 0.079, 0.073, 0.075, 0.086, 0.127, 0.132, 0.153, 0.071, 0.068, 0.079, 0.085, 0.11, 0.092, 0.11, 0.086, 0.089, 0.087, 0.108, 0.081, 0.077, 0.066, 0.072, 0.072, 0.087, 0.084, 0.093, 0.09, 0.077, 0.097, 0.074, 0.075, 0.088, 0.118, 0.09, 0.075, 0.078, 0.069, 0.108, 0.133, 0.133, 0.089, 0.093, 0.08, 0.077, 0.079, 0.084, 0.206, 0.084, 0.115, 0.084, 0.192, 0.068, 0.071, 0.09, 0.096, 0.083, 0.1, 0.077, 0.07, 0.075, 0.081, 0.072, 0.105, 0.09, 0.229, 0.091, 0.113, 0.061, 0.085, 0.078, 0.125, 0.085, 1.158, 0.089, 0.085, 0.069, 0.064, 0.104, 0.112, 0.079, 0.128, 0.086, 0.098, 0.078, 0.084, 0.104, 0.096, 0.086, 0.084, 0.209, 0.119, 0.089, 0.13, 0.14, 0.136, 0.066, 0.079, 0.087, 0.099, 0.077, 0.077, 0.083, 0.102, 0.292, 0.139, 0.077, 0.076, 0.081, 0.084, 0.107, 0.09, 0.132, 0.114, 0.095, 0.096, 0.139, 1.122, 0.07, 0.07, 0.077, 0.085, 0.079, 0.094, 0.077, 0.075, 0.122, 0.127, 0.079, 0.098, 0.106, 0.091, 0.088, 0.104, 0.084, 0.069, 0.122, 0.133, 0.107, 0.133, 0.082, 0.066, 0.071, 0.129, 0.093, 0.082, 0.127, 0.09, 0.123, 0.071, 0.112, 0.12, 0.109, 0.116, 0.09, 0.139, 0.082, 0.098, 0.087, 0.089, 0.084, 0.125, 0.102, 0.069, 0.107, 0.108, 0.073, 0.067, 0.148, 0.077, 0.112, 0.076, 0.086, 0.155, 0.115, 0.138, 0.095, 0.136, 0.087, 0.15, 0.088, 0.091, 0.096, 0.106, 0.086, 0.089, 0.105, 0.084, 0.105, 0.095, 0.109, 0.296, 0.153, 0.084, 0.091, 0.237, 0.09, 0.082, 0.197, 0.133, 0.122, 0.123, 0.113, 0.076, 0.078, 0.211, 0.067, 0.12, 0.121, 0.135, 0.086, 0.088, 0.087, 0.078, 0.097, 0.094, 0.119, 0.082, 0.085, 0.06, 0.068, 0.199, 0.102, 0.076, 0.09, 0.084, 0.124, 0.084, 0.138, 0.086, 0.103, 0.115, 0.101, 0.082, 0.105, 0.085, 0.091, 0.089, 0.11, 0.1, 0.123, 0.084, 0.168, 0.136, 0.102, 0.08, 0.108, 0.095, 0.123, 0.123, 0.148, 0.088, 0.089, 0.093, 0.097, 0.071, 0.098, 0.081, 0.064, 0.072, 0.085, 0.111, 0.087, 0.133, 0.079, 0.071, 0.089, 0.126, 0.075, 0.096, 0.105, 0.156, 0.091, 0.138, 0.066, 0.098, 0.101, 0.093, 0.09, 0.1, 0.112, 0.142, 0.076, 0.077, 0.072, 0.085, 0.124, 0.095, 0.125, 0.091, 0.113, 0.095, 0.109, 0.097, 0.084, 0.1, 0.085, 0.096, 0.088, 0.081, 0.082, 0.069, 0.077, 0.065, 0.189, 0.219, 0.085, 0.087, 0.087, 0.06, 0.085, 0.079, 0.102, 0.092, 0.086, 0.085, 0.077, 0.904, 0.072, 0.105, 0.112, 0.086, 0.125, 0.088, 0.097, 0.065, 0.122, 0.1, 0.122, 0.078, 0.105, 0.092, 0.133, 0.091, 0.061, 0.083, 0.063, 0.098, 0.114, 0.128, 0.133, 0.071, 0.36, 0.084, 0.088, 0.092, 0.094, 0.095, 0.092, 0.098, 0.093, 0.092, 0.091, 0.127, 0.086, 0.084, 0.113, 0.084, 0.077, 0.086, 0.102, 0.084, 0.111, 0.078, 0.128, 0.097, 0.089, 0.091, 0.144, 0.082, 0.073, 0.052, 0.083, 0.082, 0.082, 0.076, 0.098, 0.084, 0.094, 0.121, 0.15, 0.1, 0.083, 0.122, 0.111, 0.09, 0.139, 0.119, 0.088, 0.114, 0.135, 0.078, 0.143, 0.091, 0.077, 0.082, 0.071, 0.09, 0.176, 0.088, 0.102, 0.09, 0.098, 0.082, 0.139, 0.08, 0.085, 0.08, 0.318, 0.122, 0.114, 0.424, 0.081, 0.104, 0.083, 0.727, 0.072, 0.339, 0.081, 0.076, 0.099, 0.105, 0.083, 0.088, 0.092, 0.096, 0.085, 0.104, 0.082, 0.154, 0.104, 0.084, 0.079, 0.088, 0.09, 0.21, 0.102, 0.078, 0.079, 0.138, 0.101, 0.116, 0.07, 0.095, 0.12, 0.082, 0.093, 0.069, 0.099, 0.111, 0.086, 0.098, 0.104, 0.112, 0.074, 0.079, 0.1, 0.087, 0.111, 0.108, 0.068, 0.128, 0.099, 0.092, 0.105, 0.089, 0.116, 0.106, 0.085, 0.071, 0.07, 0.092, 0.133, 0.119, 0.122, 0.075, 0.126, 0.091, 0.111, 0.1, 0.076, 0.118, 0.117, 0.093, 0.065, 0.074, 0.079, 0.123, 0.124, 0.143, 0.08, 0.061, 0.076, 0.087, 0.175, 0.127, 0.127, 0.071, 0.104, 0.089, 0.101, 0.09, 0.103, 0.068, 0.09, 0.062, 0.101, 0.09, 0.089, 0.099, 0.069, 0.092, 0.13, 0.075, 0.217, 0.388, 0.068, 0.096, 0.109, 0.091, 0.082, 0.141, 0.092, 0.146, 0.087, 0.088, 0.079, 0.084, 0.163, 0.107, 0.098, 0.083, 0.073, 0.072, 0.105, 0.076, 0.076, 0.08, 0.065, 0.12, 1.531, 0.091, 0.071, 0.127, 0.118, 0.1, 0.125, 0.08, 0.188, 0.096, 0.107, 0.094, 0.174, 0.163, 0.093, 0.079, 0.064, 0.121, 0.124, 0.126, 0.138, 0.104, 0.074, 0.088, 0.102, 0.076, 0.086, 0.07, 0.096, 0.103, 0.089, 0.105, 0.092, 0.09, 0.083, 0.095, 0.108, 0.089, 0.148, 0.095, 0.104, 0.09, 0.075, 0.099, 0.1, 0.094, 0.092, 0.1, 0.139, 0.084, 0.095, 0.08, 0.079, 0.109, 0.114, 0.083, 0.085, 0.167, 0.085, 0.078, 0.118, 0.093, 0.121, 0.1, 0.092, 0.079, 0.089, 0.079, 0.102, 0.084, 0.082, 0.086, 0.088, 0.087, 0.072, 0.09, 0.096, 0.075, 0.119, 0.118, 0.09, 0.076, 0.103, 0.083, 0.086, 0.092, 0.086, 0.085, 0.088, 0.079, 0.072, 0.118, 0.1, 0.075, 0.104, 0.092, 0.088, 0.131, 0.103, 0.089, 0.116, 0.115, 0.097, 0.098, 0.077, 0.091, 0.097, 0.086, 0.098, 0.099, 0.125, 0.076, 0.093, 0.087, 0.134, 0.08, 0.083, 0.087, 0.074, 0.081, 0.062, 0.095, 0.069, 0.11, 0.068, 0.08, 0.309, 0.087, 0.073, 0.091, 0.093, 0.094, 0.084, 0.092, 0.117, 0.094, 0.11, 0.074, 0.127, 0.071, 0.129, 0.08, 0.09, 0.091, 0.31, 0.093, 0.086, 0.101, 0.091, 0.103, 0.061, 0.135, 0.077, 0.086, 0.131, 0.134, 0.077, 0.126, 0.171, 0.063, 0.096, 0.083, 0.083, 0.104, 0.107, 0.097, 0.083, 0.084, 0.113, 0.083, 0.132, 0.129, 0.088, 0.119, 0.099, 0.085, 0.09, 0.095, 0.072, 0.078, 0.125, 0.128, 0.138, 0.15, 0.178, 0.095, 0.077, 0.09, 0.08, 0.091, 0.102, 0.104, 0.086, 0.111, 0.103, 0.085, 0.101, 0.101, 0.075, 0.088, 0.09, 0.093, 0.071, 0.062, 0.075, 0.078, 0.085, 0.091, 1.139, 0.066, 0.088, 0.091, 0.087, 0.088, 0.073, 0.08, 0.089, 0.087, 0.09, 0.08, 0.078, 0.241, 0.119, 0.085, 0.079, 0.1, 0.088, 0.128, 0.126, 0.1, 0.107, 0.082, 0.112, 0.093, 0.1, 0.111, 0.085, 0.111, 0.148, 0.099, 0.12, 0.09, 0.145, 0.092, 0.083, 0.084, 0.083, 0.129, 0.075, 0.089, 0.115, 0.076, 0.118, 0.122, 0.082, 0.095, 0.07, 0.094, 0.118, 0.114, 0.115, 0.2, 0.09, 0.084, 0.087, 0.079, 0.07, 0.059, 0.08, 0.098, 0.115, 0.1, 0.081, 0.06, 0.125, 0.099, 0.07, 0.081, 0.08, 0.072, 0.099, 0.087, 0.124, 0.506, 0.105, 0.095, 0.12, 0.09, 0.156, 0.081, 0.067, 1.278, 0.093, 0.083, 0.078, 0.082, 0.074, 0.089, 0.106, 0.083, 0.076, 0.077, 0.096, 0.07, 0.134, 0.078, 0.094, 0.086, 0.089, 0.25, 0.095, 0.08, 0.106, 0.086, 0.079, 0.076, 0.09, 0.082, 0.086, 0.103, 0.086, 0.065, 0.076, 0.075, 0.067, 0.095, 0.106, 0.079, 0.086, 0.079, 0.084, 0.092, 0.072, 0.084, 0.116, 0.081, 0.07, 0.072, 0.134, 0.065, 0.093, 0.099, 0.123, 0.084, 0.146, 0.066, 0.099, 0.079, 0.089, 0.847, 0.102, 0.084, 0.066, 0.069, 0.1, 0.075, 0.1, 0.108, 0.075, 0.196, 0.094, 0.088, 0.068, 0.079, 0.072, 0.08, 0.074, 0.103, 0.066, 0.082, 0.064, 0.069, 0.075, 0.069, 0.074, 0.082, 0.147, 0.096, 0.092, 0.083, 0.237, 0.076, 0.07, 0.118, 0.074, 0.083, 0.072, 0.075, 0.077, 0.067, 0.126, 0.091, 0.112, 0.087, 0.085, 0.085, 0.083, 0.09, 0.069, 0.091, 0.088, 0.118, 0.075, 0.101, 0.119, 0.209, 0.082, 0.11, 0.089, 0.09, 0.075, 0.081, 0.094, 0.08, 0.077, 0.072, 0.107, 0.18, 0.063, 0.093, 0.102, 0.092, 0.087, 0.073, 0.097, 0.15, 0.078, 0.072, 0.09, 0.085, 0.083, 0.089, 0.072, 0.107, 0.071, 0.068, 0.077, 0.089, 0.076, 0.079, 0.072, 0.08, 0.09, 0.064, 0.08, 0.117, 0.077, 0.082, 0.098, 0.086, 0.084, 0.085, 0.077, 0.082, 0.081, 0.087, 0.074, 0.073, 0.067, 0.119, 0.08, 0.069, 0.091, 0.078, 0.071, 0.088, 0.094, 0.09, 0.087, 0.081, 0.078, 0.117, 0.075, 0.067, 0.071, 0.095, 0.14, 0.1, 0.078, 0.07, 0.108, 0.279, 0.107, 0.097, 0.101, 0.083, 0.076, 0.106, 0.083, 0.111, 0.088, 0.092, 0.181, 0.066, 0.078, 0.071, 0.075, 0.081, 0.07, 0.063, 0.121, 0.082, 0.113, 0.08, 0.082, 0.08, 0.139, 0.069, 0.074, 0.067, 0.093, 0.07, 0.085, 0.074, 0.1, 0.079, 0.076, 0.103, 0.086, 0.123, 0.087, 0.12, 0.127, 0.124, 0.069, 0.105, 0.073, 0.108, 0.082, 0.102, 0.123, 0.219, 0.072, 0.131, 0.1, 0.087, 0.085, 0.063, 0.099, 0.085, 0.116, 0.07, 0.067, 0.082, 0.1, 0.278, 0.095, 0.132, 0.108, 0.083, 0.067, 0.07, 0.077, 0.077, 0.076, 0.09, 0.079, 0.098, 0.078, 0.08, 0.073, 0.104, 0.072, 0.079, 0.084, 0.678, 0.087, 0.083, 0.083, 0.088, 0.126, 0.082, 0.109, 0.106, 0.078, 0.074, 0.272, 0.086, 0.091, 0.081, 0.093, 0.094, 0.085, 0.086, 0.122, 0.062, 0.114, 0.064, 0.085, 0.085, 0.093, 0.134, 0.194, 0.084, 0.07, 0.068, 0.109, 0.092, 0.111, 0.07, 0.081, 0.071, 0.108, 0.11, 0.087, 0.105, 0.075, 0.072, 0.118, 0.085, 0.074, 0.065, 0.093, 0.067, 0.125, 0.083, 0.104, 0.069, 0.095, 0.098, 0.066, 0.1, 0.121, 0.274, 0.093, 0.075, 0.073, 0.069, 0.098, 0.085, 0.07, 0.092, 0.076, 0.088, 0.084, 0.079, 0.078, 0.093, 0.068, 0.134, 0.102, 0.071, 0.084, 0.072, 0.138, 0.095, 0.06, 0.073, 0.191, 0.077, 0.119, 0.09, 0.092, 0.1, 0.123, 0.082, 0.099, 0.098, 0.132, 0.077, 0.091, 0.115, 0.099, 0.082, 0.125, 0.267, 0.116, 0.129, 0.083, 0.088, 0.094, 0.128, 0.095, 0.084, 0.079, 0.069, 0.085, 0.067, 0.093, 0.086, 0.08, 0.076, 0.082, 0.094, 0.118, 0.111, 0.083, 0.099, 0.135, 0.087, 0.095, 0.086, 0.071, 0.072, 0.071, 0.071, 0.061, 0.069, 0.091, 0.069, 0.104, 0.078, 0.082, 0.098, 0.111, 0.077, 0.061, 0.075, 0.077, 0.083, 0.07, 0.095, 0.191, 0.186, 0.095, 0.117, 0.109, 0.105, 0.076, 0.091, 0.096, 0.1, 0.076, 0.087, 0.09, 0.077, 0.092, 0.078, 0.104, 0.066, 0.067, 0.087, 0.071, 0.065, 0.091, 0.102, 0.072, 0.072, 0.201, 0.074, 0.072, 0.113, 0.259, 0.073, 0.078, 0.078, 0.07, 0.073, 0.086, 0.23, 0.089, 0.065, 0.127, 0.098, 0.128, 0.145, 0.103, 0.097, 0.137, 0.086, 0.107, 0.113, 0.069, 0.091, 0.101, 0.078, 0.115, 0.14, 0.101, 0.125, 0.086, 0.067, 3.096, 0.085, 0.089, 0.086, 0.076, 0.09, 0.075, 0.104, 0.125, 0.157, 0.092, 0.22, 0.143, 0.107, 0.094, 0.102, 0.264, 0.152, 0.123, 0.081, 0.126, 0.091, 0.103, 0.096, 0.129, 0.099, 0.153, 0.139, 0.125, 0.088, 0.094, 0.148, 0.107, 0.087, 0.117, 0.097, 0.096, 0.082, 0.131, 0.13, 0.097, 0.122, 0.097, 0.12, 0.081, 0.101, 0.082, 0.632, 0.075, 0.121, 0.105, 0.105, 0.079, 0.081, 0.126, 0.091, 0.15, 0.134, 0.114, 0.175, 0.102, 0.092, 0.092, 0.087, 0.157, 0.092, 0.09, 0.086, 0.078, 0.108, 0.067, 0.094, 0.087, 0.087, 0.092, 0.099, 0.103, 0.192, 0.12, 0.118, 0.08, 0.091, 0.104, 0.083, 0.082, 0.09, 0.083, 0.082, 0.1, 0.137, 0.099, 0.125, 0.085, 0.18, 0.091, 0.1, 0.09, 0.123, 0.089, 0.104, 0.13, 0.082, 0.089, 0.098, 0.071, 0.071, 0.1, 0.086, 0.086, 0.162, 0.083, 0.084, 0.113, 0.101, 0.122, 0.094, 0.156, 0.098, 0.135, 0.177, 0.088, 0.093, 0.088, 0.074, 0.081, 0.075, 0.083, 0.167, 0.064, 0.107, 0.097, 0.138, 0.087, 0.121, 0.2, 0.092, 0.135, 0.121, 0.132, 1.336, 0.129, 0.088, 0.09, 0.16, 0.108, 0.09, 0.249, 0.115, 0.089, 0.134, 0.08, 0.087, 0.195, 0.097, 0.129, 0.091, 0.096, 0.147, 0.098, 0.086, 0.091, 0.088, 0.101, 0.134, 0.138, 0.09, 0.103, 0.096, 0.084, 0.1, 0.089, 0.084, 0.102, 0.105, 0.123, 0.149, 0.112, 0.091, 0.206, 0.101, 0.109, 0.086, 0.079, 0.084, 0.206, 0.081, 0.137, 0.104, 0.105, 0.092, 0.09, 0.088, 0.114, 0.106, 0.082, 0.127, 0.138, 0.141, 0.078, 0.078, 0.123, 0.11, 0.098, 0.116, 0.091, 0.147, 0.106, 0.21, 0.086, 0.128, 0.104, 0.106, 0.1, 0.08, 0.335, 0.09, 0.084, 0.134, 0.152, 0.112, 0.115, 0.105, 0.142, 0.1, 0.089, 0.09, 0.094, 0.107, 0.093, 0.133, 0.102, 0.308, 0.092, 0.097, 0.139, 0.1, 0.089, 0.112, 0.1, 0.089, 0.085, 0.096, 0.108, 0.091, 0.097, 0.09, 0.145, 0.089, 0.091, 0.098, 0.083, 0.15, 0.154, 0.091, 0.287, 0.088, 0.086, 0.104, 0.096, 0.087, 0.101, 0.091, 0.088, 0.09, 0.091, 0.091, 0.085, 0.088, 0.087, 0.351, 0.088, 0.075, 0.094, 0.147, 0.146, 0.084, 0.156, 0.081, 0.091, 0.089, 0.094, 0.098, 0.146, 0.129, 0.163, 0.087, 0.136, 0.161, 0.109, 0.098, 0.108, 0.107, 0.093, 0.166, 0.086, 0.117, 0.135, 0.093, 0.087, 0.089, 0.899, 0.079, 0.146, 0.092, 0.083, 0.155, 0.092, 0.095, 0.084, 0.078, 0.088, 0.08, 0.088, 0.082, 0.093, 0.095, 0.126, 0.124, 0.102, 0.098, 0.135, 0.124, 0.083, 0.079, 0.084, 0.076, 0.122, 0.088, 0.137, 0.102, 0.221, 0.087, 0.098, 0.091, 0.093, 0.084, 0.087, 0.146, 0.095, 0.084, 0.107, 0.117, 0.093, 0.116, 0.099, 0.094, 0.097, 0.075, 0.091, 0.072, 0.065, 0.112, 0.072, 0.105, 0.112, 0.077, 0.104, 0.073, 0.124, 0.166, 0.093, 0.08, 0.079, 0.123, 0.108, 0.085, 0.125, 0.087, 0.094, 0.097, 0.088, 0.092, 0.077, 0.096, 3.321, 0.136, 0.086, 0.116, 0.112, 0.153, 0.102, 0.097, 0.089, 0.129, 0.106, 0.083, 0.082, 0.069, 0.07, 0.161, 0.09, 0.096, 0.164, 0.083, 0.092, 0.08, 0.087, 0.081, 0.123, 0.092, 0.078, 0.081, 0.084, 0.105, 0.104, 0.203, 0.079, 0.085, 0.08, 0.091, 0.09, 0.08, 0.138, 0.117, 0.089, 1.429, 0.146, 0.093, 0.117, 0.098, 0.128, 0.098, 0.214, 0.121, 0.148, 0.122, 0.084, 0.072, 0.275, 0.093, 0.07, 0.065, 0.075, 0.095, 0.085, 0.071, 0.087, 0.085, 0.083, 0.09, 0.09, 0.074, 0.113, 0.118, 0.079, 0.1, 0.088, 0.095, 0.087, 0.136, 0.118, 0.108, 0.096, 0.097, 0.09, 0.076, 0.088, 0.075, 0.078, 0.099, 0.076, 0.08, 0.063, 0.759, 0.099, 0.09, 0.117, 0.112, 0.081, 0.108, 0.077, 0.079, 0.104, 0.118, 0.09, 0.075, 0.08, 0.073, 0.256, 0.238, 0.085, 0.096, 0.084, 0.095, 0.12, 0.076, 0.115, 0.081, 0.097, 0.125, 0.099, 0.095, 0.086, 0.132, 0.091, 0.106, 0.093, 0.076, 0.087, 0.094, 0.092, 0.116, 0.09, 0.084, 0.096, 0.084, 0.328, 0.078, 0.076, 0.086, 0.088, 0.087, 0.091, 0.075, 0.091, 0.089, 0.081, 0.082, 0.089, 0.093, 0.091, 0.081, 0.112, 0.103, 0.088, 0.086, 0.069, 0.097, 0.111, 0.079, 0.082, 0.127, 0.08, 0.111, 0.069, 0.142, 0.073, 0.087, 0.1, 0.082, 0.09, 0.128, 0.171, 0.083, 0.111, 0.1, 0.292, 0.122, 0.078, 0.086, 0.095, 0.097, 0.084, 0.11, 0.079, 0.285, 0.092, 0.1, 0.091, 0.089, 0.094, 0.089, 0.102, 0.07, 0.071, 0.072, 0.095, 0.116, 0.069, 0.084, 0.075, 0.119, 0.08, 0.096, 0.116, 0.092, 0.082, 0.073, 0.089, 0.084, 0.09, 0.081, 0.101, 0.106, 0.103, 0.097, 0.097, 0.082, 0.093, 0.077, 0.089, 0.08, 0.068, 0.088, 0.081, 0.119, 0.086, 0.115, 0.106, 0.123, 0.071, 0.093, 0.171, 0.083, 0.094, 0.081, 0.084, 0.111, 0.097, 0.106, 0.086, 0.089, 0.082, 0.104, 0.116, 0.12, 0.083, 0.114, 0.079, 0.083, 0.096, 0.096, 0.085, 0.171, 0.085, 0.217, 0.085, 0.085, 0.126, 0.145, 0.096, 0.094, 0.098, 0.08, 0.089, 0.097, 0.082, 0.111, 0.096, 0.074, 0.068, 0.085, 0.091, 0.095, 0.085, 0.093, 0.092, 0.084, 0.082, 0.084, 0.304, 0.08, 0.081, 0.09, 0.13, 0.166, 0.098, 0.129, 0.079, 0.063, 0.103, 0.094, 0.07, 0.127, 0.076, 0.081, 0.087, 0.082, 0.109, 0.067, 0.078, 0.086, 0.079, 0.081, 0.083, 0.09, 0.079, 0.11, 0.092, 0.221, 0.207, 0.125, 0.07, 0.063, 0.076, 0.082, 0.071, 0.082, 0.126, 0.117, 0.095, 0.089, 0.082, 0.12, 0.093, 0.11, 0.082, 0.128, 0.079, 0.122, 0.096, 0.116, 0.129, 0.116, 0.078, 0.085, 0.083, 0.098, 0.089, 0.119, 0.109, 0.089, 0.095, 0.137, 0.105, 0.095, 0.132, 0.096, 0.085, 0.112, 0.113, 0.106, 0.1, 0.114, 0.075, 0.082, 0.073, 0.07, 0.082, 0.134, 0.107, 0.104, 0.41, 0.071, 0.09, 0.097, 0.067, 0.097, 0.076, 0.068, 0.061, 0.069, 0.105, 0.107, 0.093, 0.122, 0.101, 0.069, 0.113, 0.104, 0.075, 0.104, 0.142, 0.097, 0.096, 0.082, 0.086, 0.069, 0.079, 0.106, 0.088, 0.113, 0.113, 0.106, 0.129, 0.097, 0.103, 0.068, 0.163, 0.143, 0.079, 0.1, 0.091, 0.071, 0.068, 0.139, 0.151, 0.089, 0.113, 0.081, 0.085, 0.096, 0.082, 0.091, 0.095, 0.1, 0.083, 0.088, 0.077, 0.118, 0.097, 0.08, 0.09, 0.101, 0.087, 0.098, 0.126, 0.092, 0.078, 0.096, 0.091, 0.097, 0.088, 0.109, 0.082, 0.095, 0.089, 0.097, 0.08, 0.09, 0.116, 0.09, 0.168, 0.123, 0.148, 0.099, 0.102, 0.088, 0.094, 0.108, 0.083, 0.134, 0.087, 0.091, 0.083, 0.092, 0.078, 0.104, 0.094, 0.084, 0.122, 0.122, 0.11, 0.099, 0.097, 0.101, 0.101, 0.083, 0.071, 0.097, 0.066, 0.069, 0.094, 0.081, 0.063, 0.123, 0.091, 0.102, 0.107, 0.128, 0.097, 1.129, 0.079, 0.088, 0.069, 0.092, 0.092, 0.105, 0.124, 0.09, 0.433, 0.119, 0.099, 0.1, 0.095, 0.096, 0.083, 0.106, 0.093, 0.117, 0.107, 0.096, 0.077, 0.083, 0.08, 0.092, 0.102, 0.099, 0.078, 0.072, 0.107, 0.088, 0.139, 0.08, 0.11, 0.091, 0.082, 0.097, 0.084, 0.135, 0.093, 0.086, 0.14, 0.09, 0.096, 0.148, 0.12, 0.085, 0.098, 0.114, 0.101, 0.087, 0.147, 0.087, 0.079, 0.069, 0.073, 0.07, 0.088, 0.127, 0.092, 0.078, 0.082, 0.083, 0.088, 0.106, 0.078, 0.061, 0.073, 0.076, 0.085, 0.07, 0.076, 0.091, 0.091, 0.075, 0.103, 0.177, 0.18, 0.141, 0.085, 0.107, 0.098, 0.081, 0.095, 0.086, 0.084, 0.125, 0.101, 0.091, 0.084, 0.083, 0.078, 0.079, 0.079, 0.081, 0.098, 0.09, 0.124, 0.09, 0.128, 0.106, 0.128, 0.089, 0.096, 0.071, 0.077, 0.136, 0.114, 0.084, 0.085, 0.089, 0.09, 0.103, 0.073, 0.075, 0.104, 0.078, 0.091, 0.13, 0.07, 0.099, 0.098, 0.083, 0.086, 0.105, 0.309, 0.094, 0.086, 0.088, 0.087, 0.086, 0.117, 0.116, 0.095, 0.098, 0.106, 0.109, 0.098, 0.095, 0.093, 0.238, 0.113, 0.129, 0.083, 0.095, 0.127, 0.134, 0.08, 0.096, 0.088, 0.085, 0.096, 0.089, 0.064, 0.09, 0.126, 0.091, 0.075, 0.103, 0.09, 0.141, 0.124, 0.116, 0.09, 0.527, 0.068, 0.207, 0.089, 0.086, 0.081, 0.105, 0.105, 0.079, 0.095, 0.092, 0.108, 0.102, 0.102, 0.137, 0.128, 0.09, 0.077, 0.093, 0.086, 0.079, 0.095, 0.091, 0.075, 0.077, 0.119, 0.089, 0.145, 0.099, 0.064, 0.098, 0.08, 0.088, 0.092, 0.08, 0.078, 0.066, 0.067, 0.063, 0.183, 0.089, 0.084, 0.185, 0.081, 0.069, 0.102, 0.074, 0.065, 0.086, 0.095, 0.073, 0.125, 0.086, 0.091, 0.158, 0.135, 0.094, 0.117, 0.095, 0.108, 0.093, 0.104, 0.084, 0.103, 0.129, 0.116, 0.099, 0.084, 0.083, 0.098, 0.101, 0.109, 0.304, 0.084, 0.07, 0.085, 0.105, 0.1, 0.074, 0.077, 0.079, 0.12, 0.077, 0.09, 0.09, 0.093, 0.108, 0.088, 0.116, 0.09, 0.084, 0.154, 0.13, 0.082, 0.067, 0.068, 0.114, 0.072, 0.099, 0.079, 0.105, 0.079, 0.075, 0.097, 0.145, 0.135, 0.067, 0.068, 0.081, 0.079, 0.073, 0.084, 0.102, 0.072, 0.089, 0.095, 0.378, 0.105, 0.112, 0.096, 0.081, 0.083, 0.081, 0.073, 0.074, 0.075, 0.108, 0.105, 0.091, 0.074, 0.076, 0.112, 0.215, 0.093, 0.122, 0.077, 0.11, 0.077, 0.096, 0.129, 0.102, 0.084, 0.088, 0.083, 0.07, 0.099, 0.067, 0.323, 0.085, 0.071, 0.083, 0.075, 0.141, 0.084, 0.145, 0.104, 0.116, 0.098, 0.07, 0.073, 0.093, 0.076, 0.072, 0.094, 0.061, 0.116, 0.068, 0.061, 0.08, 0.839, 0.129, 0.085, 0.316, 0.097, 0.088, 0.071, 0.125, 0.07, 0.084, 0.099, 0.111, 0.164, 0.071, 0.127, 0.096, 0.1, 0.093, 0.094, 0.073, 0.112, 0.112, 0.22, 0.089, 0.093, 0.09, 0.129, 0.112, 0.113, 0.089, 0.072, 0.088, 0.151, 0.075, 0.079, 0.11, 0.083, 0.137, 0.091, 0.08, 0.086, 0.126, 0.122, 0.099, 0.102, 0.084, 0.114, 0.098, 0.156, 0.079, 0.073, 0.083, 0.09, 0.114, 0.134, 0.137, 0.067, 0.111, 0.099, 0.07, 0.079, 0.128, 0.068, 0.08, 0.071, 0.077, 0.093, 0.084, 0.114, 0.07, 0.09, 0.083, 0.077, 0.067, 0.069, 0.076, 0.082, 0.117, 0.09, 0.1, 0.096, 0.074, 0.076, 0.079, 0.118, 0.083, 0.112, 0.109, 0.083, 0.077, 0.075, 0.104, 0.098, 0.272, 0.214, 0.069, 0.119, 0.09, 0.079, 0.071, 0.075, 0.105, 0.089, 0.086, 0.092, 0.082, 0.097, 0.07, 0.103, 0.102, 0.07, 0.08, 0.072, 0.069, 0.089, 0.064, 0.502, 0.091, 0.127, 0.075, 0.089, 0.099, 0.139, 0.11, 0.093, 0.087, 0.073, 0.065, 0.136, 0.063, 0.082, 0.072, 0.064, 0.079, 0.074, 0.069, 0.108, 0.107, 0.109, 0.123, 0.061, 0.079, 0.07, 0.071, 0.11, 0.076, 0.07, 0.126, 0.098, 0.091, 0.07, 0.089, 0.092, 0.086, 0.093, 0.187, 0.073, 0.098, 0.085, 0.2, 0.097, 0.15, 0.074, 0.097, 0.142, 0.081, 0.101, 0.204, 0.092, 0.085, 0.159, 0.087, 0.085, 0.089, 0.083, 0.097, 0.091, 0.068, 0.088, 0.096, 0.071, 0.071, 0.089, 0.074, 0.091, 0.094, 0.09, 0.074, 0.1, 0.129, 0.074, 0.083, 0.092, 0.087, 0.07, 0.101, 0.068, 0.079, 0.085, 0.105, 0.087, 0.08, 0.067, 0.08, 0.072, 0.087, 0.09, 0.218, 0.076, 0.076, 0.079, 0.065, 0.068, 0.163, 0.068, 0.068, 0.088, 0.098, 0.083, 0.089, 0.072, 0.099, 3.036, 0.061, 0.104, 0.065, 0.076, 0.07, 0.118, 0.083, 0.082, 0.095, 0.125, 0.092, 0.086, 0.091, 0.108, 0.08, 0.156, 0.068, 0.103, 0.326, 0.079, 0.096, 0.069, 0.094, 0.16, 0.074, 0.063, 0.112, 0.073, 0.085, 0.076, 0.084, 0.077, 0.078, 0.099, 0.065, 1.296, 0.109, 0.071, 0.112, 1.457, 0.077, 0.135, 0.084, 0.067, 0.094, 0.155, 0.071, 0.141, 0.07, 0.082, 0.076, 0.124, 0.127, 0.08, 0.092, 0.07, 0.078, 0.079, 0.08, 0.062, 0.078, 0.122, 0.083, 0.083, 0.069, 0.074, 0.074, 0.072, 0.079, 0.075, 0.083, 0.089, 0.099, 0.083, 0.095, 0.116, 0.081, 0.085, 0.081, 0.095, 0.121, 0.113, 0.089, 0.105, 0.084, 0.091, 0.115, 0.077, 0.072, 0.069, 0.106, 0.129, 0.107, 0.112, 0.11, 0.08, 0.083, 0.069, 0.1, 0.111, 0.079, 0.103, 0.272, 0.079, 0.114, 0.083, 0.103, 0.119, 0.088, 0.113, 0.068, 0.135, 0.144, 0.146, 0.074, 0.102, 0.067, 0.065, 0.164, 0.08, 0.08, 0.11, 0.066, 0.19, 0.076, 0.076, 0.093, 0.065, 0.077, 0.09, 0.074, 0.067, 0.093, 0.096, 0.098, 0.074, 0.106, 0.085, 0.106, 0.085, 0.076, 0.108, 0.117, 0.14, 0.085, 0.084, 0.127, 0.07, 0.071, 0.078, 0.096, 0.101, 0.108, 0.07, 0.261, 0.074, 0.076, 0.066, 0.587, 0.148, 0.086, 0.14, 0.128, 0.07, 0.075, 0.086, 0.094, 0.087, 0.284, 0.088, 0.101, 0.088, 0.098, 0.093, 0.098, 0.092, 0.08, 0.079, 0.093, 0.088, 0.102, 0.08, 0.07, 0.082, 0.079, 0.126, 0.066, 0.076, 0.07, 0.168, 0.076, 0.097, 0.091, 0.077, 0.069, 0.1, 0.083, 0.078, 0.081, 0.091, 0.06, 0.077, 0.104, 0.096, 0.088, 0.091, 0.085, 0.103, 0.073, 0.064, 0.074, 0.076, 0.111, 0.078, 0.216, 0.076, 0.109, 0.228, 0.075, 0.131, 0.129, 0.226, 0.09, 0.072, 0.09, 0.065, 0.085, 0.065, 0.07, 0.081, 0.087, 0.076, 0.107, 0.068, 0.077, 0.075, 0.138, 0.082, 0.08, 0.101, 0.203, 0.087, 0.086, 0.066, 0.069, 0.073, 0.126, 0.08, 0.153, 0.09, 0.083, 0.086, 0.077, 0.075, 0.09, 0.133, 0.067, 0.119, 0.134, 0.089, 0.075, 0.128, 0.086, 0.081, 0.084, 0.069, 0.106, 0.067, 0.061, 0.16, 0.066, 0.093, 0.082, 0.076, 0.168, 0.087, 0.084, 0.1, 0.074, 0.131, 0.074, 0.077, 0.096, 0.09, 0.098, 0.166, 0.082, 0.081, 0.124, 0.25, 0.095, 0.07, 0.064, 0.065, 0.128, 0.084, 0.083, 0.079, 0.105, 0.07, 0.065, 0.121, 0.104, 0.079, 0.149, 0.096, 0.093, 0.091, 0.094, 0.099, 0.068, 0.066, 0.09, 0.083, 0.07, 0.083, 0.103, 0.091, 0.681, 0.079, 0.073, 0.1, 0.069, 0.101, 0.074, 0.089, 0.091, 0.075, 0.11, 0.07, 0.1, 0.082, 0.086, 0.092, 0.086, 0.111, 0.072, 0.132, 0.109, 0.075, 0.093, 0.093, 0.076, 0.093, 0.076, 0.074, 0.1, 0.084, 0.076, 0.156, 0.087, 0.414, 0.078, 0.105, 0.094, 0.066, 0.071, 0.099, 0.105, 0.083, 0.071, 0.128, 0.065, 0.18, 0.16, 0.082, 0.078, 0.066, 0.066, 0.076, 0.067, 0.103, 0.087, 0.079, 0.075, 0.091, 0.105, 0.074, 0.095, 0.098, 0.082, 0.079, 0.069, 0.08, 0.062, 0.074, 0.1, 0.083, 0.078, 0.068, 0.095, 0.075, 0.105, 0.131, 0.099, 0.074, 0.073, 0.062, 0.063, 0.104, 0.08, 0.1, 0.089, 0.075, 0.102, 0.107, 0.093, 0.067, 0.085, 0.063, 0.118, 0.112, 0.068, 0.085, 0.088, 0.065, 0.073, 0.067, 0.064, 0.067, 0.081, 0.271, 0.118, 0.099, 0.077, 0.117, 0.091, 0.07, 0.061, 0.068, 0.073, 0.07, 0.09, 0.096, 0.105, 0.106, 0.09, 0.078, 0.074, 0.083, 0.124, 0.075, 0.093, 0.068, 0.105, 0.076, 0.071, 0.076, 0.066, 0.276, 0.088, 0.065, 0.074, 0.082, 0.063, 0.104, 0.095, 0.091, 0.086, 0.078, 0.059, 0.084, 0.074, 0.069, 0.069, 0.087, 0.096, 0.074, 0.094, 0.066, 0.07, 0.09, 0.097, 0.087, 0.065, 0.09, 0.067, 0.098, 0.078, 0.087, 0.064, 0.096, 0.105, 0.071, 0.078, 0.096, 0.126, 0.089, 0.116, 0.099, 0.084, 0.069, 0.071, 0.096, 0.06, 0.071, 0.082, 0.126, 0.081, 0.074, 0.096, 0.085, 0.073, 0.148, 0.081, 0.074, 0.079, 0.073, 0.091, 0.089, 0.095, 0.089, 0.069, 0.075, 0.093, 0.082, 0.084, 0.071, 0.072, 0.171, 0.069, 0.103, 0.101, 0.088, 0.126, 0.1, 0.087, 0.083, 0.063, 0.093, 0.094, 0.069, 0.093, 0.074, 0.062, 0.096, 0.094, 0.102, 0.132, 0.073, 0.071, 0.06, 0.065, 0.121, 0.105, 0.084, 0.062, 0.094, 0.109, 0.066, 0.117, 0.085, 0.083, 0.07, 0.072, 0.069, 0.083, 0.104, 0.068, 0.077, 0.08, 0.084, 0.073, 0.076, 0.065, 0.102, 0.069, 0.105, 0.119, 0.152, 0.082, 0.081, 0.078, 0.088, 0.069, 0.086, 0.075, 0.067, 0.094, 0.082, 0.073, 0.086, 0.188, 0.08, 0.072, 0.079, 0.09, 0.088, 0.066, 1.078, 0.082, 0.104, 0.142, 0.12, 0.13, 0.104, 0.082, 0.125, 0.094, 0.114, 0.073, 0.088, 0.071, 0.097, 0.079, 0.07, 0.066, 0.293, 0.086, 0.116, 0.122, 0.085, 0.08, 0.156, 0.109, 0.075, 0.104, 0.102, 0.141, 0.075, 0.087, 0.068, 0.119, 0.083, 0.076, 0.098, 0.113, 0.09, 0.207, 0.112, 0.07, 0.089, 0.077, 0.084, 0.092, 0.077, 0.074, 0.081, 0.082, 0.094, 0.074, 0.078, 0.133, 0.084, 0.097, 0.207, 0.085, 0.09, 0.078, 0.135, 0.081, 0.357, 0.089, 0.238, 0.102, 0.068, 0.124, 0.091, 0.083, 0.063, 0.084, 0.087, 0.073, 0.075, 0.07, 0.084, 0.125, 0.068, 0.066, 0.077, 0.087, 0.066, 0.068, 0.096, 0.094, 0.208, 0.115, 0.126, 0.096, 0.125, 0.095, 0.074, 0.109, 0.058, 0.061, 0.072, 0.06, 0.063, 0.058, 0.077, 0.068, 0.08, 0.078, 0.116, 0.126, 0.089, 0.082, 0.108, 0.128, 0.127, 0.105, 0.109, 0.07, 0.139, 0.09, 0.131, 0.143, 0.144, 0.076, 0.084, 0.097, 0.144, 0.094, 0.136, 0.081, 0.083, 0.084, 0.111, 0.092, 0.083, 0.099, 0.11, 0.074, 0.092, 0.073, 0.074, 0.095, 0.083, 0.078, 0.084, 0.074, 0.092, 0.121, 0.077, 0.115, 0.078, 0.103, 0.135, 0.101, 0.099, 0.084, 0.08, 0.107, 0.093, 0.11, 0.082, 0.137, 0.08, 0.094, 0.069, 0.114, 0.09, 0.083, 0.083, 0.12, 0.163, 0.097, 0.132, 0.096, 0.076, 0.059, 0.069, 0.095, 0.092, 0.108, 0.086, 0.083, 0.146, 0.085, 0.11, 0.082, 0.081, 0.15, 0.145, 0.08, 0.09, 0.105, 0.086, 0.072, 0.058, 0.091, 0.074, 0.105, 0.134, 0.11, 0.086, 0.105, 0.134, 0.111, 0.077, 2.943, 0.084, 0.093, 0.085, 0.086, 0.085, 0.082, 0.074, 0.091, 0.103, 0.067, 0.089, 0.084, 0.078, 0.072, 0.298, 0.08, 0.064, 0.07, 0.068, 0.081, 0.089, 0.06, 0.063, 0.075, 0.143, 0.086, 0.077, 0.081, 0.09, 0.133, 0.138, 0.089, 0.287, 0.098, 0.085, 0.137, 0.095, 0.078, 0.084, 0.102, 0.096, 0.07, 0.213, 0.174, 0.068, 0.121, 0.129, 0.1, 0.088, 0.134, 0.108, 0.086, 0.097, 0.082, 0.084, 0.075, 0.085, 0.08, 0.073, 0.117, 0.085, 0.063, 0.071, 0.069, 0.101, 0.071, 0.106, 0.091, 0.093, 0.077, 0.121, 0.082, 0.107, 0.08, 0.079, 0.074, 0.144, 0.088, 0.072, 0.134, 0.104, 0.113, 0.086, 0.13, 0.13, 0.207, 0.095, 0.074, 0.081, 0.1, 0.099, 0.108, 0.092, 0.074, 0.071, 0.086, 0.088, 0.088, 0.082, 0.092, 0.093, 0.136, 0.109, 0.075, 0.103, 0.077, 0.087, 0.08, 0.102, 0.065, 0.086, 0.096, 0.087, 0.086, 0.088, 0.1, 0.071, 0.101, 0.102, 0.102, 0.084, 0.075, 0.088, 0.661, 0.116, 0.091, 0.121, 0.081, 0.136, 0.112, 0.084, 0.077, 0.1, 0.092, 0.13, 0.087, 0.09, 0.094, 0.075, 0.123, 0.091, 0.089, 0.082, 0.077, 0.083, 0.079, 0.065, 0.118, 0.079, 1.189, 0.094, 0.07, 0.067, 0.071, 0.075, 0.085, 0.088, 0.078, 0.094, 0.074, 0.08, 0.064, 0.068, 0.067, 0.078, 0.077, 0.068, 0.121, 0.069, 0.088, 0.082, 0.088, 0.13, 0.098, 0.08, 0.142, 0.12, 0.07, 0.153, 0.078, 0.15, 0.075, 0.076, 0.081, 0.103, 0.079, 0.072, 0.154, 0.111, 0.089, 0.157, 0.115, 0.104, 0.11, 0.171, 0.104, 0.118, 0.088, 0.095, 0.095, 0.084, 0.103, 0.069, 0.073, 0.116, 0.075, 0.066, 0.085, 0.082, 0.112, 0.108, 0.121, 0.089, 0.165, 0.091, 0.103, 0.064, 0.073, 0.074, 0.06, 0.173, 0.082, 0.096, 0.221, 0.086, 0.073, 0.088, 0.09, 0.136, 0.097, 0.085, 0.122, 0.086, 0.08, 0.081, 0.09, 0.08, 0.095, 0.076, 0.113, 0.093, 0.073, 0.073, 0.064, 0.063, 0.072, 0.079, 0.069, 0.093, 0.074, 0.081, 0.105, 0.087, 0.097, 0.093, 0.072, 0.213, 0.079, 0.081, 0.104, 0.082, 0.104, 0.073, 0.071, 0.075, 0.09, 0.096, 0.069, 0.105, 0.074, 0.062, 0.096, 0.084, 0.081, 0.127, 0.105, 0.084, 0.075, 0.2, 0.106, 0.201, 0.101, 0.061, 0.08, 0.084, 0.081, 0.081, 0.076, 0.095, 0.085, 0.099, 0.086, 0.09, 0.093, 0.08, 0.104, 0.089, 0.134, 0.089, 0.087, 0.102, 0.089, 0.089, 0.092, 0.11, 0.094, 0.091, 0.114, 0.093, 0.09, 0.111, 0.213, 0.095, 0.067, 0.078, 0.098, 0.077, 0.087, 0.104, 0.092, 0.084, 0.086, 0.072, 0.085, 0.084, 0.106, 0.077, 0.104, 0.123, 0.093, 0.081, 0.085, 0.085, 0.097, 0.102, 0.071, 0.071, 0.08, 0.068, 0.086, 0.12, 0.144, 0.08, 0.067, 0.075, 0.107, 0.085, 0.079, 0.082, 0.067, 0.073, 0.201, 0.077, 0.071, 0.086, 0.074, 0.387, 0.082, 0.124, 0.109, 0.084, 0.294, 0.403, 0.073, 0.084, 0.075, 0.067, 0.074, 0.084, 0.13, 0.112, 0.076, 0.115, 0.083, 0.072, 0.072, 0.098, 0.067, 0.106, 0.104, 0.082, 0.105, 0.165, 0.087, 0.078, 0.114, 0.132, 0.067, 0.067, 0.069, 0.057, 0.084, 0.074, 0.102, 0.09, 0.087, 0.151, 0.096, 0.089, 0.071, 0.078, 0.077, 0.093, 0.086, 0.081, 0.079, 0.128, 0.088, 0.069, 0.077, 0.073, 0.081, 0.084, 0.083, 0.147, 0.081, 0.078, 0.093, 0.078, 0.077, 0.081, 0.089, 0.087, 0.086, 0.083, 0.064, 0.069, 0.062, 0.09, 0.078, 0.099, 0.114, 0.108, 0.076, 0.084, 0.082, 0.076, 0.062, 0.063, 0.069, 0.08, 0.093, 0.091, 0.1, 0.091, 0.074, 0.081, 0.084, 0.138, 0.09, 0.093, 0.073, 0.079, 0.086, 0.092, 0.094, 0.096, 0.101, 0.074, 0.086, 0.073, 0.081, 0.069, 0.079, 0.113, 0.128, 0.072, 0.098, 0.093, 0.078, 0.065, 0.079, 0.082, 0.1, 0.084, 0.077, 0.073, 0.106, 0.09, 0.09, 0.112, 0.08, 0.083, 0.09, 0.097, 0.075, 0.077, 0.085, 0.083, 0.077, 0.073, 0.083, 0.094, 0.079, 0.077, 0.094, 0.134, 0.068, 0.069, 0.066, 0.091, 0.084, 0.095, 0.086, 0.068, 0.072, 0.071, 0.07, 0.071, 0.061, 0.089, 0.124, 0.117, 0.093, 0.063, 0.103, 0.111, 0.095, 0.128, 0.101, 0.081, 0.079, 0.107, 0.086, 0.099, 0.079, 0.084, 0.071, 0.102, 0.073, 0.098, 0.095, 0.078, 0.068, 0.068, 0.084, 0.064, 0.072, 0.075, 0.082, 0.081, 0.063, 0.16, 0.079, 0.109, 0.08, 0.071, 0.085, 0.448, 0.086, 0.08, 0.098, 0.107, 0.095, 0.08, 0.09, 0.089, 0.098, 0.129, 0.09, 0.086, 0.12, 0.073, 0.275, 0.132, 0.083, 0.088, 0.139, 0.097, 0.095, 0.08, 0.07, 0.107, 0.1, 0.096, 0.101, 0.088, 0.072, 0.079, 0.066, 0.085, 0.082, 0.103, 0.078, 0.07, 0.09, 0.088, 0.085, 0.081, 0.088, 0.085, 0.075, 0.062, 0.125, 0.081, 0.093, 0.108, 0.08, 0.08, 0.069, 0.087, 0.066, 0.28, 0.079, 0.078, 0.264, 0.084, 0.071, 0.185, 0.084, 0.101, 0.06, 0.071, 0.111, 0.073, 0.274, 0.075, 0.076, 0.08, 0.062, 0.079, 0.082, 0.097, 0.081, 0.086, 0.1, 0.095, 0.079, 0.104, 0.076, 0.076, 0.13, 0.084, 0.093, 0.092, 0.101, 0.204, 0.086, 0.079, 0.061, 0.123, 0.092, 0.101, 0.096, 0.098, 0.094, 0.095, 0.084, 0.093, 0.147, 0.094, 0.098, 0.066, 0.111, 0.131, 0.086, 0.098, 0.103, 0.133, 0.093, 0.098, 0.116, 1.033, 0.078, 0.079, 0.135, 0.15, 0.081, 0.086, 0.089, 0.169, 0.102, 0.086, 0.097, 0.102, 0.172, 0.161, 0.061, 0.065, 0.083, 0.079, 0.081, 0.062, 0.102, 0.162, 0.088, 0.064, 0.107, 0.115, 0.084, 0.127, 0.096, 0.238, 1.517, 0.072, 0.083, 0.093, 0.065, 0.085, 0.083, 0.077, 0.106, 0.093, 0.82, 0.139, 0.087, 0.107, 0.093, 0.111, 0.121, 0.124, 0.104, 0.092, 0.083, 0.088, 0.128, 0.085, 0.077, 0.087, 0.094, 0.076, 0.301, 0.073, 0.07, 0.072, 0.113, 0.088, 0.075, 0.083, 0.075, 0.078, 0.085, 0.084, 0.082, 0.154, 0.112, 0.085, 0.095, 0.081, 0.088, 0.154, 0.098, 0.083, 0.095, 0.09, 0.072, 0.083, 0.101, 0.068, 0.071, 0.077, 0.081, 0.072, 0.096, 0.086, 0.107, 0.073, 0.095, 0.092, 0.086, 0.086, 0.075, 0.069, 0.088, 0.13, 0.122, 0.085, 0.077, 0.067, 0.084, 0.08, 0.067, 0.082, 0.076, 0.112, 0.337, 0.137, 0.075, 0.085, 0.079, 0.093, 0.75, 0.114, 0.084, 0.083, 0.084, 0.121, 0.11, 0.09, 0.074, 0.089, 0.102, 0.197, 0.112, 0.091, 0.09, 0.068, 0.073, 0.076, 0.086, 0.124, 0.093, 0.095, 0.076, 0.087, 0.086, 0.098, 0.089, 0.081, 0.104, 0.073, 0.078, 0.228, 0.087, 0.185, 0.087, 0.081, 0.095, 0.088, 0.104, 0.093, 0.111, 0.098, 0.078, 0.101, 0.094, 0.125, 0.085, 0.122, 0.095, 0.242, 0.075, 0.09, 0.08, 0.087, 0.097, 0.096, 0.103, 0.098, 0.124, 0.085, 0.068, 0.085, 0.095, 0.136, 0.06, 0.068, 0.123, 0.084, 0.167, 0.097, 0.089, 0.073, 0.1, 0.109, 0.09, 0.089, 0.075, 0.104, 0.121, 0.089, 0.104, 0.085, 0.096, 0.085, 0.082, 0.09, 0.089, 0.102, 0.098, 0.091, 0.093, 0.096, 0.083, 0.066, 0.108, 0.079, 0.111, 0.094, 0.079, 0.083, 0.084, 0.088, 0.102, 0.12, 0.078, 0.109, 0.088, 0.182, 0.083, 0.088, 0.077, 0.072, 0.11, 0.071, 0.081, 0.074, 0.093, 0.104, 0.109, 0.068, 0.065, 0.063, 0.078, 0.245, 0.071, 0.075, 0.088, 0.082, 0.092, 0.082, 0.087, 0.088, 0.124, 0.118, 0.239, 0.084, 0.13, 0.125, 0.061, 0.103, 0.089, 0.115, 0.083, 0.082, 0.098, 0.114, 0.073, 0.077, 0.08, 0.079, 0.097, 0.08, 0.117, 0.113, 0.094, 0.071, 0.089, 0.071, 0.072, 0.069, 0.117, 0.133, 0.085, 0.076, 0.085, 0.076, 0.101, 0.082, 0.09, 0.089, 0.066, 0.086, 0.123, 0.073, 0.077, 0.072, 0.083, 0.093, 0.085, 0.076, 0.072, 0.088, 0.075, 0.066, 0.079, 0.077, 0.095, 0.074, 0.228, 0.082, 0.116, 0.078, 0.19, 0.069, 0.081, 0.083, 0.106, 0.082, 0.1, 0.152, 0.105, 0.216, 0.082, 0.072, 0.09, 0.092, 0.085, 0.062, 0.073, 0.124, 0.096, 0.093, 0.097, 0.076, 0.102, 0.134, 0.073, 0.109, 0.084, 0.079, 0.082, 0.098, 0.113, 0.097, 0.139, 0.086, 0.088, 0.082, 0.115, 0.089, 0.108, 0.083, 0.098, 0.077, 0.085, 0.075, 0.101, 0.134, 0.09, 0.079, 0.086, 0.111, 0.102, 0.087, 0.116, 0.129, 0.115, 0.091, 0.074, 0.091, 0.135, 0.097, 0.117, 0.128, 0.16, 0.119, 0.093, 0.141, 0.144, 0.123, 0.12, 0.122, 0.099, 0.077, 0.081, 0.084
            ]
        ], 
        [#filter or not
            [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
                0.173, 0.151, 0.172, 0.212, 0.17, 0.164, 0.223, 0.231, 0.152, 0.256, 0.157, 0.152, 0.166, 0.61, 0.159, 0.151, 0.157, 0.192, 0.139, 0.15, 0.128, 0.192, 0.17, 0.162, 0.143, 0.125, 0.21, 0.148, 0.254, 0.136, 0.195, 0.19, 0.142, 0.137, 0.231, 0.212, 0.126, 0.16, 0.122, 0.126, 0.119, 0.211, 0.121, 0.421, 0.161, 0.192, 0.178, 0.182, 0.189, 0.203, 0.14, 0.136, 0.231, 0.124, 0.111, 0.274, 0.206, 0.122, 0.153, 0.14, 0.191, 0.128, 0.151, 0.161, 0.327, 0.159, 0.142, 0.145, 0.126, 0.134, 0.143, 0.194, 0.126, 0.169, 0.141, 0.134, 0.096, 0.148, 0.2, 0.21, 0.177, 0.178, 0.283, 0.141, 0.177, 0.201, 0.186, 0.163, 0.15, 0.125, 0.111, 0.155, 0.138, 0.175, 0.188, 0.134, 0.155, 0.17, 0.234, 0.271, 0.178, 0.203, 0.166, 0.132, 0.144, 0.155, 0.156, 0.186, 0.195, 0.211, 0.118, 0.187, 0.217, 0.128, 0.182, 0.226, 0.198, 0.525, 0.185, 0.155, 0.132, 0.137, 0.204, 0.177, 0.14, 0.195, 0.177, 0.158, 0.152, 0.144, 2.159, 0.143, 0.224, 0.215, 0.138, 0.175, 0.145, 0.143, 0.21, 0.16, 0.156, 0.14, 0.166, 0.142, 0.28, 0.158, 0.149, 0.121, 0.238, 0.195, 0.141, 0.192, 0.241, 0.136, 0.18, 0.226, 0.208, 0.208, 0.195, 0.155, 0.199, 0.167, 0.21, 0.185, 0.26, 0.14, 0.134, 0.165, 0.14, 0.274, 0.201, 0.21, 0.162, 0.227, 0.159, 0.148, 0.152, 0.14, 0.155, 1.205, 0.159, 0.122, 0.138, 0.2, 0.129, 0.221, 0.215, 0.224, 0.164, 0.13, 0.149, 0.148, 0.243, 0.235, 0.193, 0.143, 0.167, 0.133, 0.179, 0.192, 0.134, 0.145, 0.202, 0.15, 0.167, 0.169, 0.218, 0.21, 0.17, 0.152, 0.183, 0.24, 0.145, 0.13, 0.144, 0.123, 0.144, 0.147, 0.143, 0.176, 0.202, 0.231, 0.238, 0.253, 0.217, 0.143, 0.189, 0.158, 0.139, 0.457, 0.224, 0.133, 0.209, 0.151, 0.22, 0.176, 0.141, 0.149, 0.242, 0.133, 0.12, 0.114, 0.155, 0.12, 0.168, 0.165, 0.122, 0.122, 0.12, 0.123, 0.094, 0.123, 0.105, 0.194, 0.119, 0.201, 0.123, 0.17, 0.125, 0.102, 0.155, 0.157, 0.141, 0.298, 0.18, 0.131, 0.123, 0.124, 0.163, 0.374, 0.126, 0.185, 0.157, 0.191, 0.182, 0.169, 0.111, 0.135, 0.21, 0.217, 0.181, 0.124, 0.126, 0.108, 0.13, 0.143, 0.174, 0.205, 0.205, 0.218, 0.189, 0.164, 0.152, 0.15, 0.183, 0.189, 0.152, 0.18, 0.136, 0.112, 0.357, 0.158, 0.182, 0.165, 0.173, 0.177, 0.156, 0.167, 0.173, 0.204, 0.125, 0.151, 0.148, 0.127, 0.108, 0.113, 0.13, 0.262, 0.141, 0.187, 0.13, 0.122, 0.108, 0.097, 0.11, 0.129, 0.185, 0.103, 0.147, 0.184, 0.129, 0.148, 0.115, 0.138, 0.122, 0.134, 0.152, 0.153, 0.103, 0.147, 0.117, 0.124, 0.177, 0.114, 0.13, 0.124, 0.196, 0.19, 0.217, 0.176, 0.118, 0.202, 0.138, 0.138, 0.166, 0.227, 0.179, 0.103, 0.243, 0.939, 0.115, 0.18, 0.171, 0.182, 0.143, 0.186, 0.125, 0.218, 0.144, 0.2, 0.197, 0.155, 0.127, 0.113, 0.293, 0.248, 0.114, 0.136, 0.151, 0.167, 0.15, 0.949, 0.186, 0.132, 0.207, 0.168, 0.17, 0.151, 0.134, 0.142, 0.164, 0.209, 0.169, 0.1, 0.175, 0.209, 0.203, 0.152, 0.191, 0.137, 0.17, 0.144, 0.146, 0.193, 0.141, 0.15, 0.182, 0.201, 0.122, 0.179, 0.161, 0.235, 0.199, 0.133, 0.187, 0.156, 0.136, 0.134, 0.362, 0.128, 0.241, 0.236, 0.187, 0.139, 0.154, 0.213, 0.192, 0.202, 0.13, 0.121, 0.127, 0.194, 0.133, 0.16, 0.115, 0.155, 0.167, 0.14, 0.126, 0.218, 0.114, 0.181, 0.16, 0.178, 0.21, 0.128, 0.159, 0.186, 0.156, 0.139, 0.125, 0.119, 0.121, 0.123, 0.17, 0.102, 0.161, 0.182, 0.187, 0.183, 0.108, 0.117, 0.142, 0.146, 0.12, 0.171, 0.139, 0.144, 0.143, 0.12, 0.124, 0.094, 0.104, 0.177, 0.196, 0.239, 0.128, 0.122, 0.108, 0.096, 0.1, 0.726, 0.155, 0.153, 0.124, 0.163, 0.202, 0.147, 0.15, 0.122, 0.119, 0.204, 0.169, 0.319, 0.128, 0.085, 0.098, 0.11, 0.117, 0.179, 0.152, 0.121, 0.164, 0.143, 0.156, 0.137, 0.217, 0.191, 0.128, 0.135, 0.12, 0.134, 0.199, 0.128, 0.167, 0.12, 0.11, 0.156, 0.176, 0.124, 0.129, 0.187, 0.136, 0.118, 0.176, 0.097, 0.278, 0.147, 0.355, 0.141, 0.599, 0.314, 0.122, 0.118, 0.116, 0.106, 0.125, 0.167, 0.104, 0.106, 0.209, 0.133, 0.178, 0.143, 0.198, 0.167, 0.141, 0.167, 0.102, 0.103, 0.109, 0.14, 0.106, 0.148, 0.113, 0.141, 0.13, 0.104, 0.156, 0.159, 0.144, 0.152, 0.146, 0.188, 0.102, 0.114, 0.163, 0.175, 0.115, 0.216, 0.162, 0.146, 0.133, 0.123, 0.131, 0.13, 0.11, 0.141, 0.124, 0.195, 0.363, 0.134, 0.12, 0.181, 0.185, 0.148, 0.163, 0.136, 0.109, 0.129, 0.1, 0.118, 1.186, 0.119, 0.164, 0.166, 0.194, 0.145, 0.166, 0.146, 0.114, 0.182, 0.205, 0.134, 0.145, 0.134, 0.138, 0.151, 0.161, 0.137, 0.154, 0.225, 0.103, 0.086, 0.107, 0.11, 0.136, 0.116, 0.144, 0.176, 0.155, 0.141, 0.128, 0.148, 0.144, 0.145, 0.116, 0.144, 0.129, 0.125, 0.171, 0.17, 0.215, 0.199, 0.141, 0.112, 0.124, 0.108, 0.142, 0.126, 0.135, 0.197, 0.186, 0.187, 0.18, 0.142, 0.134, 0.158, 0.115, 0.239, 0.15, 0.123, 0.143, 0.129, 0.139, 0.314, 0.129, 0.153, 0.151, 0.186, 0.185, 0.167, 0.136, 0.117, 0.294, 0.12, 0.139, 0.133, 0.128, 0.16, 0.175, 0.22, 0.166, 0.113, 0.129, 0.138, 0.169, 0.187, 0.143, 0.158, 0.115, 0.106, 0.223, 0.171, 0.264, 0.176, 0.163, 0.125, 0.115, 0.164, 0.159, 0.162, 0.121, 0.11, 0.123, 0.128, 0.97, 0.138, 0.11, 0.109, 0.115, 0.113, 0.104, 0.257, 0.107, 0.145, 0.161, 0.121, 0.178, 0.137, 0.154, 0.166, 0.205, 0.189, 0.236, 0.2, 0.228, 0.177, 0.151, 0.193, 0.147, 0.16, 0.141, 0.217, 0.104, 0.099, 0.116, 0.152, 0.122, 0.168, 0.135, 0.099, 0.163, 0.16, 0.427, 0.158, 0.183, 0.126, 0.952, 0.16, 0.141, 0.21, 0.155, 0.139, 0.242, 0.148, 0.083, 0.275, 0.124, 0.105, 0.115, 0.114, 0.13, 0.128, 0.178, 0.203, 0.11, 0.102, 0.117, 0.131, 0.115, 0.111, 0.134, 0.178, 0.208, 0.111, 0.163, 0.863, 0.159, 0.185, 0.227, 0.123, 0.172, 0.101, 0.106, 0.128, 0.177, 0.132, 0.145, 0.112, 0.197, 0.145, 0.235, 0.134, 0.135, 0.134, 0.134, 0.152, 0.126, 0.106, 0.098, 0.128, 0.15, 0.198, 0.148, 0.226, 0.124, 0.115, 0.108, 0.106, 0.145, 0.19, 0.135, 0.114, 0.116, 0.152, 0.125, 0.142, 0.117, 0.158, 0.101, 0.157, 0.084, 0.141, 0.118, 0.168, 0.149, 0.12, 0.144, 0.149, 0.161, 0.082, 0.136, 0.125, 0.111, 0.184, 0.168, 0.141, 0.129, 0.111, 0.153, 0.117, 0.131, 0.392, 0.132, 0.103, 0.117, 0.118, 0.2, 0.157, 0.139, 0.133, 0.169, 0.199, 0.119, 0.149, 0.116, 0.181, 0.162, 0.148, 0.113, 0.125, 0.207, 0.165, 0.147, 0.187, 0.165, 0.174, 0.223, 0.164, 0.151, 0.178, 0.165, 0.132, 0.165, 0.271, 0.209, 0.143, 0.131, 0.155, 0.134, 0.131, 0.123, 0.146, 0.139, 0.548, 0.121, 0.174, 0.143, 0.127, 0.26, 0.132, 0.115, 0.113, 0.179, 0.16, 0.107, 0.116, 0.221, 0.101, 0.12, 0.165, 0.098, 0.174, 0.161, 0.164, 0.181, 0.118, 0.151, 0.183, 0.186, 0.164, 0.167, 0.195, 0.306, 0.084, 0.117, 0.108, 0.114, 0.152, 0.149, 0.126, 0.205, 0.101, 0.145, 0.161, 0.199, 0.239, 0.128, 0.186, 0.142, 0.169, 0.128, 0.158, 0.204, 0.285, 0.151, 0.112, 0.194, 0.127, 0.186, 0.144, 0.149, 0.134, 0.204, 0.144, 0.186, 0.169, 0.131, 0.119, 0.126, 0.107, 0.152, 0.107, 0.208, 0.128, 0.172, 0.138, 0.217, 0.195, 0.17, 0.188, 0.165, 0.157, 0.124, 0.145, 0.217, 0.11, 0.102, 0.109, 0.159, 0.203, 0.103, 0.268, 0.127, 0.136, 0.137, 0.224, 0.15, 0.16, 0.179, 0.145, 0.116, 0.141, 0.147, 0.168, 0.169, 0.153, 2.091, 0.093, 0.092, 0.123, 0.19, 0.167, 0.256, 0.12, 0.244, 0.202, 0.16, 0.117, 0.137, 0.177, 0.17, 0.133, 0.18, 0.115, 0.1, 0.155, 0.188, 0.114, 0.162, 0.102, 0.484, 0.186, 0.125, 0.166, 0.173, 0.143, 0.155, 0.124, 0.173, 0.111, 0.109, 0.149, 0.138, 0.099, 0.108, 0.208, 0.187, 0.151, 0.135, 0.149, 0.122, 0.157, 0.134, 0.169, 0.152, 0.21, 0.159, 0.171, 0.126, 0.117, 0.1, 0.114, 0.088, 0.096, 0.105, 0.18, 0.203, 0.124, 0.108, 0.097, 0.161, 0.141, 0.188, 0.198, 0.143, 0.125, 1.031, 0.112, 0.155, 0.202, 0.133, 0.191, 0.226, 0.203, 0.105, 0.201, 0.141, 0.16, 0.209, 0.124, 0.13, 0.154, 0.15, 0.203, 0.205, 0.22, 0.174, 0.133, 0.228, 0.166, 0.157, 0.104, 0.143, 0.11, 0.186, 0.219, 0.161, 0.141, 0.127, 0.171, 0.201, 0.133, 0.124, 0.274, 0.133, 0.182, 0.124, 0.148, 0.111, 0.134, 0.161, 0.168, 0.287, 0.152, 0.126, 0.182, 0.107, 0.112, 0.104, 0.193, 0.132, 0.145, 0.172, 0.29, 0.104, 0.132, 0.12, 0.103, 0.121, 0.123, 0.108, 0.319, 0.137, 0.211, 0.18, 0.109, 0.141, 0.184, 0.163, 0.177, 0.251, 0.146, 0.141, 0.213, 0.213, 0.153, 0.716, 0.178, 0.106, 0.16, 0.121, 0.109, 0.107, 0.114, 0.158, 0.179, 0.192, 0.193, 0.134, 0.178, 0.149, 0.221, 0.117, 0.147, 0.133, 0.192, 0.122, 0.156, 0.148, 0.175, 0.12, 0.115, 0.168, 0.159, 0.151, 0.157, 0.213, 0.121, 0.187, 0.206, 0.112, 0.127, 0.111, 2.406, 0.164, 0.175, 0.18, 0.145, 0.227, 0.096, 0.095, 0.137, 0.165, 0.107, 0.106, 0.177, 0.105, 0.092, 0.218, 0.212, 0.124, 0.172, 0.194, 0.155, 1.178, 0.12, 0.11, 0.193, 0.148, 0.128, 0.256, 0.12, 0.099, 0.126, 0.099, 0.108, 0.133, 0.197, 0.188, 0.15, 0.126, 0.18, 0.159, 0.106, 0.13, 0.143, 0.219, 0.135, 0.677, 0.255, 0.174, 0.188, 0.178, 0.188, 0.12, 0.244, 0.248, 0.114, 0.167, 0.214, 0.127, 0.205, 0.137, 0.165, 0.139, 0.096, 0.143, 0.133, 0.116, 0.292, 0.105, 0.11, 0.124, 0.118, 0.132, 0.136, 0.146, 0.18, 0.12, 0.104, 0.148, 0.11, 0.171, 0.179, 0.175, 0.156, 0.121, 0.213, 0.105, 0.444, 0.201, 0.211, 0.119, 0.144, 0.273, 0.121, 0.114, 0.117, 0.128, 0.149, 0.197, 0.149, 0.208, 0.168, 0.138, 0.128, 0.141, 0.124, 0.149, 0.145, 0.152, 0.154, 0.154, 0.136, 0.151, 0.154, 0.164, 0.18, 0.122, 0.143, 0.164, 0.187, 0.174, 0.196, 0.232, 0.211, 0.154, 0.137, 0.185, 0.213, 0.14, 0.147, 0.097, 0.089, 0.124, 0.196, 0.126, 0.131, 0.135, 0.123, 0.117, 0.311, 0.131, 0.188, 0.178, 0.157, 0.172, 0.17, 0.164, 0.149, 0.16, 0.154, 0.144, 0.1, 0.195, 0.207, 0.308, 0.158, 0.131, 0.134, 0.239, 0.181, 0.122, 0.229, 0.211, 0.166, 0.171, 0.143, 0.139, 0.117, 0.127, 0.156, 0.12, 0.175, 0.179, 0.13, 0.174, 0.188, 0.172, 0.135, 0.109, 0.164, 0.347, 0.153, 0.154, 0.133, 0.108, 0.119, 0.141, 0.172, 0.172, 0.134, 0.161, 0.14, 0.128, 0.132, 0.195, 0.171, 0.206, 0.201, 0.226, 0.174, 0.154, 0.104, 0.179, 0.142, 0.133, 0.118, 0.137, 0.148, 0.128, 0.145, 0.142, 0.151, 0.125, 0.117, 0.132, 0.121, 0.132, 0.124, 0.14, 0.137, 0.178, 0.173, 0.155, 0.133, 0.129, 0.19, 0.114, 0.125, 0.181, 0.178, 0.188, 0.164, 0.144, 0.133, 0.188, 0.106, 0.129, 0.15, 0.167, 0.18, 0.963, 0.12, 0.128, 0.165, 0.336, 0.145, 0.134, 0.103, 0.123, 0.167, 0.1, 0.13, 0.162, 0.152, 0.128, 0.128, 0.119, 0.096, 0.098, 0.198, 0.136, 0.111, 0.222, 0.106, 0.147, 0.135, 0.107, 0.095, 0.126, 0.146, 0.117, 0.123, 0.145, 0.1, 0.155, 0.122, 0.205, 0.2, 0.248, 0.147, 0.131, 0.122, 0.13, 0.173, 0.123, 0.118, 0.128, 0.135, 0.161, 0.19, 0.174, 0.17, 0.13, 0.201, 0.127, 0.171, 0.145, 0.144, 0.149, 0.221, 0.147, 0.141, 0.295, 0.129, 0.138, 0.148, 0.191, 0.121, 0.17, 0.116, 0.272, 0.128, 0.127, 0.166, 0.117, 0.114, 0.122, 0.174, 0.11, 0.225, 0.214, 0.189, 0.425, 0.191, 0.108, 0.137, 0.115, 0.145, 0.159, 0.208, 0.101, 0.107, 0.102, 0.116, 0.146, 0.128, 0.162, 0.149, 0.133, 0.139, 0.111, 0.183, 0.09, 0.191, 0.133, 0.105, 0.11, 0.152, 0.091, 0.158, 0.135, 0.115, 0.096, 0.092, 0.162, 0.147, 0.121, 0.137, 0.31, 0.101, 0.13, 0.146, 0.158, 0.111, 0.151, 0.127, 0.148, 0.154, 0.181, 0.114, 0.189, 0.149, 0.106, 0.132, 0.205, 0.103, 0.106, 0.151, 0.202, 0.132, 0.347, 0.146, 0.113, 0.116, 0.125, 0.156, 0.092, 0.158, 0.192, 0.127, 0.112, 0.119, 0.133, 0.109, 0.103, 0.315, 0.123, 0.131, 0.164, 0.199, 0.157, 0.116, 0.1, 0.115, 0.134, 0.083, 0.679, 0.126, 0.278, 0.087, 0.12, 0.11, 0.189, 0.128, 0.096, 0.154, 0.157, 0.204, 0.095, 0.135, 0.119, 0.097, 0.139, 0.125, 0.14, 0.157, 0.098, 0.159, 0.129, 0.138, 0.155, 0.11, 0.138, 0.195, 0.164, 0.149, 0.115, 0.171, 0.099, 0.119, 0.154, 0.103, 0.131, 0.102, 0.128, 0.191, 0.114, 0.122, 0.199, 0.159, 0.2, 0.102, 0.124, 0.355, 0.105, 0.116, 0.102, 0.128, 0.101, 0.118, 0.139, 0.102, 0.136, 0.107, 0.434, 0.16, 0.138, 0.174, 0.141, 0.118, 0.18, 0.15, 0.139, 0.127, 0.118, 0.202, 0.113, 0.096, 0.119, 0.135, 0.151, 0.108, 0.106, 0.105, 0.179, 0.115, 0.208, 0.113, 0.16, 0.11, 0.205, 0.172, 0.105, 0.113, 0.121, 0.104, 0.103, 0.126, 0.12, 0.124, 0.101, 0.139, 0.127, 0.112, 0.197, 0.131, 0.134, 0.14, 0.144, 0.119, 0.233, 0.118, 0.106, 0.145, 0.117, 0.132, 0.115, 2.214, 0.156, 0.105, 0.149, 0.098, 0.158, 0.106, 0.151, 0.177, 0.151, 0.287, 0.111, 0.18, 0.121, 0.144, 0.135, 0.112, 0.173, 0.973, 0.15, 1.176, 0.144, 0.105, 0.147, 0.134, 0.103, 0.086, 0.165, 0.149, 0.123, 0.139, 0.146, 0.131, 0.127, 0.111, 0.101, 0.181, 0.112, 0.131, 0.101, 0.123, 0.201, 0.211, 0.129, 0.105, 0.09, 0.176, 0.129, 0.112, 0.089, 0.144, 0.121, 0.392, 0.133, 0.193, 0.168, 0.156, 0.142, 0.121, 0.097, 0.166, 0.131, 0.163, 0.109, 0.123, 0.094, 0.104, 0.088, 0.101, 0.096, 0.098, 0.127, 0.135, 0.117, 0.129, 0.087, 0.106, 0.101, 0.254, 0.116, 0.543, 0.14, 0.127, 0.105, 0.149, 0.291, 0.102, 0.111, 0.109, 0.094, 0.103, 0.119, 0.096, 0.135, 0.081, 0.168, 0.092, 0.103, 0.082, 0.101, 0.149, 0.108, 0.172, 0.113, 0.153, 0.099, 0.125, 0.131, 0.202, 0.208, 0.13, 0.259, 0.123, 0.121, 0.101, 0.102, 0.107, 0.106, 0.102, 0.14, 0.096, 0.197, 0.118, 0.099, 0.106, 0.151, 0.091, 0.091, 0.12, 0.126, 0.216, 0.202, 0.1, 0.129, 0.147, 0.162, 0.101, 0.089, 0.15, 0.095, 0.176, 0.094, 0.103, 0.154, 0.093, 0.255, 0.141, 0.094, 0.13, 0.118, 0.138, 0.212, 0.158, 0.196, 0.129, 0.109, 0.141, 0.192, 0.152, 0.193, 0.576, 0.134, 0.17, 0.127, 0.17, 0.13, 0.123, 0.101, 0.223, 0.204, 0.168, 0.128, 0.131, 0.149, 0.132, 0.204, 0.39, 0.121, 0.121, 0.141, 0.102, 0.173, 0.226, 0.19, 0.128, 0.125, 0.126, 0.136, 0.128, 0.137, 0.1, 0.118, 0.096, 0.087, 0.11, 0.089, 0.149, 0.183, 0.152, 0.115, 0.151, 0.209, 0.221, 0.227, 0.138, 0.16, 0.152, 0.127, 0.117, 0.106, 0.094, 0.265, 0.139, 0.126, 0.151, 0.105, 0.108, 0.107, 0.115, 0.103, 0.114, 0.139, 0.137, 0.176, 0.107, 0.289, 0.172, 0.15, 0.127, 0.126, 0.12, 0.124, 0.112, 0.126, 0.115, 0.16, 0.155, 0.127, 0.106, 0.127, 0.132, 0.134, 0.133, 0.11, 0.124, 0.139, 0.145, 0.158, 0.137, 0.147, 0.116, 0.186, 0.171, 0.124, 0.097, 0.128, 0.108, 0.095, 0.092, 0.107, 0.188, 0.126, 0.127, 0.137, 0.097, 0.099, 0.111, 0.109, 0.134, 0.114, 0.146, 0.109, 0.128, 0.204, 0.125, 0.172, 0.158, 0.139, 0.139, 0.154, 0.117, 0.138, 0.176, 0.136, 0.146, 0.216, 0.161, 0.146, 0.123, 0.095, 0.116, 0.105, 0.186, 0.098, 0.136, 0.926, 0.189, 0.162, 0.195, 0.173, 0.159, 0.112, 0.206, 0.108, 0.294, 0.194, 0.17, 0.192, 0.121, 0.227, 0.171, 0.136, 0.16, 0.172, 0.194, 0.233, 0.153, 0.132, 0.199, 0.122, 0.087, 0.091, 0.129, 0.219, 0.1, 0.151, 0.303, 0.212, 0.117, 0.182, 0.092, 0.121, 0.098, 0.121, 0.156, 0.144, 0.13, 0.156, 0.225, 0.165, 0.187, 0.126, 0.215, 0.139, 0.118, 0.134, 0.109, 0.161, 0.289, 0.169, 0.161, 0.167, 0.188, 0.195, 0.234, 0.15, 0.214, 0.211, 0.114, 0.144, 0.107, 0.157, 0.16, 0.108, 0.171, 0.135, 0.128, 0.162, 0.159, 0.147, 0.152, 0.122, 0.113, 0.139, 0.188, 0.178, 0.172, 0.155, 0.221, 0.172, 0.135, 0.137, 0.144, 0.151, 0.147, 0.137, 0.12, 0.174, 0.116, 0.155, 0.112, 0.131, 0.167, 0.166, 0.162, 0.11, 2.138, 0.105, 0.112, 0.114, 0.141, 0.147, 0.151, 0.305, 0.116, 0.138, 0.222, 0.109, 0.165, 0.121, 0.152, 0.194, 0.306, 0.123, 0.192, 0.144, 0.22, 0.216, 0.192, 0.222, 0.24, 0.147, 0.103, 0.175, 0.147, 0.115, 0.192, 0.116, 0.134, 0.126, 0.141, 0.152, 0.15, 0.124, 0.148, 0.11, 0.107, 0.097, 0.124, 0.218, 0.115, 0.126, 0.19, 0.113, 0.089, 0.124, 0.113, 0.174, 0.168, 0.129, 0.177, 0.15, 0.142, 0.14, 0.143, 0.121, 0.124, 0.094, 0.523, 0.151, 0.164, 0.121, 0.115, 0.189, 0.109, 0.162, 0.144, 0.147, 0.119, 0.159, 0.159, 0.936, 0.133, 0.127, 0.117, 0.144, 0.091, 0.116, 0.127, 0.102, 0.121, 0.143, 0.158, 0.138, 0.164, 0.175, 0.161, 0.101, 0.191, 0.121, 0.216, 0.214, 0.225, 0.234, 0.23, 0.138, 0.128, 0.14, 0.203, 0.117, 0.114, 0.188, 0.163, 0.181, 0.166, 0.11, 0.197, 0.123, 0.254, 0.109, 0.168, 0.144, 0.153, 0.119, 0.122, 0.153, 0.139, 0.133, 0.148, 0.144, 0.186, 0.153, 0.204, 0.2, 0.217, 0.15, 0.132, 0.13, 0.126, 0.141, 0.143, 0.139, 0.119, 0.153, 0.127, 0.225, 0.199, 0.111, 0.142, 0.135, 0.165, 0.142, 0.135, 0.102, 0.177, 0.18, 0.128, 0.123, 0.173, 0.107, 0.136, 0.14, 0.221, 0.108, 0.151, 0.12, 0.203, 0.113, 0.12, 0.123, 0.16, 0.136, 0.126, 0.143, 0.107, 0.103, 0.153, 0.171, 0.107, 0.168, 0.104, 0.113, 0.204, 0.124, 0.38, 0.169, 0.181, 0.514, 0.142, 0.128, 0.12, 0.194, 0.163, 0.168, 0.202, 0.154, 0.167, 0.158, 0.15, 0.179, 0.103, 0.139, 0.122, 0.163, 0.185, 0.147, 0.095, 0.147, 0.149, 0.156, 0.108, 0.106, 0.118, 0.187, 0.129, 0.142, 0.112, 0.094, 0.095, 0.127, 0.252, 0.152, 0.155, 0.125, 0.11, 0.118, 0.111, 0.125, 0.134, 0.124, 0.195, 0.154, 0.146, 0.219, 0.144, 0.2, 0.111, 0.147, 0.239, 0.195, 0.232, 0.095, 0.125, 0.16, 0.133, 0.15, 0.145, 0.143, 0.14, 0.126, 0.132, 0.112, 0.133, 0.098, 0.178, 0.109, 0.158, 0.152, 0.143, 0.125, 0.118, 0.137, 0.156, 0.117, 0.158, 0.157, 0.138, 0.165, 0.163, 0.122, 0.204, 0.165, 0.222, 0.12, 0.118, 0.123, 0.18, 0.198, 0.158, 0.116, 0.435, 0.142, 0.15, 0.154, 0.151, 0.22, 0.146, 0.188, 0.32, 0.125, 0.201, 0.117, 0.116, 0.126, 0.116, 0.105, 0.113, 0.125, 0.104, 0.124, 0.103, 0.108, 0.12, 0.152, 0.168, 0.141, 0.172, 0.254, 0.117, 0.276, 0.148, 0.115, 0.086, 0.123, 0.394, 0.119, 0.12, 0.177, 0.107, 0.14, 0.187, 0.111, 0.188, 0.14, 0.198, 0.129, 0.151, 0.116, 0.13, 0.148, 0.131, 0.169, 0.158, 0.156, 0.108, 0.207, 0.139, 0.942, 0.132, 0.181, 0.197, 0.192, 0.179, 0.181, 0.266, 0.114, 0.141, 0.12, 0.269, 0.12, 0.181, 0.228, 0.241, 1.176, 0.162, 0.14, 0.152, 0.177, 0.727, 0.131, 0.137, 0.196, 0.119, 0.12, 0.18, 0.126, 0.144, 0.323, 0.154, 0.153, 0.132, 0.125, 0.113, 0.203, 0.145, 0.252, 0.219, 0.181, 0.166, 0.143, 0.238, 0.148, 0.128, 0.165, 0.151, 0.121, 0.09, 0.117, 0.165, 0.262, 0.142, 0.137, 0.124, 0.149, 0.343, 0.127, 0.162, 0.587, 0.179, 0.151, 0.157, 0.128, 0.203, 0.142, 0.156, 0.119, 0.156, 0.119, 0.136, 0.145, 0.172, 0.163, 0.24, 0.23, 0.156, 0.107, 0.128, 0.179, 0.14, 0.22, 0.134, 0.247, 0.142, 0.13, 0.184, 0.179, 0.173, 0.107, 0.161, 0.118, 0.176, 0.185, 0.1, 0.149, 0.105, 0.122, 0.207, 0.141, 0.104, 0.131, 0.119, 0.117, 0.144, 0.131, 0.133, 0.115, 0.125, 0.12, 0.18, 0.161, 0.2, 0.117, 0.099, 0.173, 0.118, 0.151, 0.212, 0.115, 0.267, 0.147, 0.146, 0.13, 0.179, 0.201, 0.263, 0.215, 0.167, 0.115, 0.132, 0.143, 0.113, 0.128, 0.21, 0.172, 0.141, 0.101, 0.121, 0.169, 0.139, 0.139, 0.145, 0.122, 0.133, 0.166, 0.132, 0.184, 0.171, 0.138, 0.116, 0.15, 0.13, 0.217, 0.132, 0.205, 0.103, 0.177, 0.178, 0.242, 0.083, 0.128, 0.114, 0.137, 0.147, 0.139, 0.168, 0.107, 0.128, 0.151, 0.126, 0.151, 0.102, 0.133, 0.143, 0.15, 0.104, 0.182, 0.144, 0.163, 0.132, 0.131, 0.129, 0.11, 0.146, 0.149, 0.158, 0.18, 0.184, 0.157, 0.114, 0.115, 2.078, 0.154, 0.209, 0.105, 0.115, 0.188, 0.135, 0.11, 0.134, 0.708, 0.153, 0.299, 0.164, 0.124, 0.167, 0.164, 0.164, 0.116, 0.123, 0.108, 0.159, 0.191, 0.345, 0.137, 0.116, 0.085, 0.131, 0.105, 0.117, 0.122, 0.134, 0.104, 0.101, 0.127, 0.13, 0.154, 0.14, 0.143, 0.115, 0.137, 0.137, 0.103, 0.287, 0.181, 0.17, 0.212, 0.112, 0.1, 0.124, 0.158, 0.193, 0.139, 0.111, 0.092, 0.094, 0.147, 0.167, 0.188, 0.118, 0.116, 0.112, 0.23, 0.184, 0.159, 0.107, 0.147, 0.142, 0.115, 0.163
            ],
            [
                0.206, 0.139, 0.151, 0.253, 0.213, 0.239, 0.23, 0.242, 0.135, 0.212, 0.154, 0.161, 0.174, 0.582, 0.142, 0.158, 0.175, 0.173, 0.161, 0.188, 0.156, 0.19, 0.176, 0.181, 0.178, 0.142, 0.207, 0.165, 0.189, 0.12, 0.247, 0.238, 0.176, 0.122, 0.281, 0.201, 0.164, 0.225, 0.148, 0.143, 0.131, 0.179, 0.137, 0.412, 0.149, 0.216, 0.185, 0.175, 0.222, 0.225, 0.152, 0.115, 0.235, 0.146, 0.165, 0.287, 0.195, 0.131, 0.137, 0.114, 0.198, 0.185, 0.236, 0.171, 0.367, 0.133, 0.157, 0.14, 0.184, 0.12, 0.156, 0.142, 0.125, 0.191, 0.17, 0.142, 0.145, 0.172, 0.149, 0.124, 0.126, 0.111, 0.251, 0.133, 0.164, 0.229, 0.186, 0.16, 0.222, 0.135, 0.129, 0.172, 0.173, 0.198, 0.149, 0.15, 0.162, 0.157, 0.23, 0.264, 0.225, 0.188, 0.226, 0.196, 0.16, 0.152, 0.148, 0.184, 0.162, 0.214, 0.164, 0.202, 0.236, 0.147, 0.199, 0.223, 0.17, 0.713, 0.148, 0.19, 0.137, 0.152, 0.189, 0.217, 0.155, 0.215, 0.193, 0.195, 0.144, 0.136, 2.191, 0.122, 0.206, 0.219, 0.136, 0.214, 0.134, 0.149, 0.186, 0.157, 0.189, 0.163, 0.18, 0.136, 0.276, 0.153, 0.112, 0.127, 0.179, 0.227, 0.147, 0.217, 0.249, 0.151, 0.252, 0.227, 0.177, 0.226, 0.184, 0.18, 0.211, 0.174, 0.261, 0.171, 0.208, 0.128, 0.151, 0.158, 0.157, 0.31, 0.193, 0.191, 0.16, 0.216, 0.229, 0.165, 0.241, 0.149, 0.146, 1.297, 0.176, 0.18, 0.139, 0.206, 0.132, 0.165, 0.148, 0.211, 0.141, 0.14, 0.171, 0.13, 0.305, 0.144, 0.163, 0.179, 0.15, 0.135, 0.139, 0.124, 0.105, 0.117, 0.155, 0.142, 0.158, 0.193, 0.202, 0.179, 0.139, 0.138, 0.216, 0.134, 0.157, 0.119, 0.127, 0.181, 0.115, 0.14, 0.154, 0.188, 0.137, 0.136, 0.128, 0.132, 0.206, 0.1, 0.188, 0.144, 0.141, 0.423, 0.23, 0.136, 0.207, 0.143, 0.202, 0.197, 0.135, 0.138, 0.271, 0.179, 0.182, 0.163, 0.245, 0.164, 0.162, 0.241, 0.165, 0.211, 0.146, 0.122, 0.164, 0.182, 0.174, 0.186, 0.15, 0.224, 0.141, 0.192, 0.115, 0.16, 0.206, 0.2, 0.177, 0.312, 0.249, 0.159, 0.133, 0.164, 0.166, 0.546, 0.145, 0.185, 0.152, 0.201, 0.234, 0.173, 0.112, 0.126, 0.238, 0.186, 0.185, 0.224, 0.154, 0.166, 0.161, 0.162, 0.227, 0.244, 0.159, 0.24, 0.214, 0.119, 0.119, 0.183, 0.162, 0.193, 0.151, 0.24, 0.088, 0.16, 0.494, 0.216, 0.144, 0.171, 0.156, 0.16, 0.129, 0.149, 0.167, 0.201, 0.204, 0.195, 0.199, 0.184, 0.172, 0.165, 0.223, 0.343, 0.168, 0.224, 0.172, 0.141, 0.169, 0.168, 0.155, 0.241, 0.207, 0.138, 0.194, 0.185, 0.125, 0.131, 0.113, 0.158, 0.119, 0.137, 0.166, 0.175, 0.166, 0.192, 0.14, 0.194, 0.223, 0.153, 0.152, 0.145, 0.222, 0.176, 0.233, 0.211, 0.149, 0.239, 0.144, 0.133, 0.173, 0.312, 0.22, 0.144, 0.186, 0.995, 0.145, 0.193, 0.146, 0.16, 0.16, 0.173, 0.167, 0.218, 0.185, 0.189, 0.239, 0.145, 0.147, 0.106, 0.295, 0.163, 0.155, 0.13, 0.148, 0.117, 0.137, 1.485, 0.145, 0.1, 0.167, 0.157, 0.213, 0.146, 0.12, 0.159, 0.197, 0.2, 0.225, 0.114, 0.25, 0.268, 0.169, 0.18, 0.215, 0.182, 0.217, 0.176, 0.142, 0.193, 0.193, 0.185, 0.219, 0.181, 0.129, 0.153, 0.155, 0.173, 0.155, 0.131, 0.168, 0.205, 0.166, 0.157, 0.366, 0.118, 0.345, 0.271, 0.228, 0.209, 0.148, 0.253, 0.167, 0.171, 0.12, 0.121, 0.157, 0.157, 0.192, 0.217, 0.132, 0.189, 0.167, 0.15, 0.194, 0.212, 0.169, 0.224, 0.194, 0.207, 0.178, 0.144, 0.194, 0.181, 0.195, 0.177, 0.15, 0.135, 0.106, 0.109, 0.137, 0.107, 0.159, 0.129, 0.146, 0.124, 0.119, 0.159, 0.201, 0.196, 0.165, 0.194, 0.199, 0.184, 0.173, 0.167, 0.155, 0.145, 0.157, 0.238, 0.266, 0.252, 0.144, 0.138, 0.18, 0.13, 0.117, 1.034, 0.201, 0.178, 0.151, 0.17, 0.19, 0.178, 0.188, 0.163, 0.135, 0.216, 0.219, 0.361, 0.137, 0.138, 0.14, 0.173, 0.154, 0.226, 0.189, 0.158, 0.178, 0.179, 0.175, 0.194, 0.208, 0.206, 0.156, 0.135, 0.156, 0.159, 0.167, 0.161, 0.213, 0.279, 0.162, 0.188, 0.214, 0.161, 0.138, 0.223, 0.138, 0.161, 0.162, 0.113, 0.353, 0.214, 0.401, 0.16, 0.591, 0.366, 0.159, 0.171, 0.19, 0.155, 0.174, 0.222, 0.148, 0.167, 0.259, 0.143, 0.193, 0.183, 0.193, 0.167, 0.14, 0.17, 0.162, 0.182, 0.18, 0.199, 0.154, 0.179, 0.19, 0.154, 0.16, 0.129, 0.17, 0.182, 0.166, 0.167, 0.175, 0.188, 0.136, 0.141, 0.224, 0.205, 0.09, 0.202, 0.237, 0.173, 0.145, 0.181, 0.161, 0.158, 0.18, 0.228, 0.236, 0.242, 0.594, 0.194, 0.147, 0.187, 0.234, 0.144, 0.224, 0.234, 0.163, 0.186, 0.154, 0.159, 1.267, 0.126, 0.161, 0.175, 0.22, 0.188, 0.222, 0.165, 0.113, 0.147, 0.155, 0.174, 0.194, 0.174, 0.169, 0.156, 0.149, 0.143, 0.181, 0.199, 0.196, 0.149, 0.228, 0.206, 0.219, 0.175, 0.182, 0.203, 0.181, 0.198, 0.233, 0.241, 0.227, 0.166, 0.145, 0.119, 0.109, 0.107, 0.182, 0.217, 0.254, 0.216, 0.177, 0.135, 0.162, 0.127, 0.162, 0.158, 0.183, 0.205, 0.235, 0.183, 0.201, 0.16, 0.139, 0.155, 0.148, 0.185, 0.158, 0.14, 0.151, 0.231, 0.175, 0.301, 0.145, 0.225, 0.203, 0.171, 0.141, 0.17, 0.217, 0.153, 0.318, 0.131, 0.183, 0.189, 0.202, 0.229, 0.183, 0.268, 0.12, 0.091, 0.137, 0.139, 0.177, 0.208, 0.199, 0.112, 0.094, 0.096, 0.114, 0.191, 0.243, 0.148, 0.145, 0.143, 0.149, 0.189, 0.166, 0.191, 0.168, 0.162, 0.147, 0.162, 0.989, 0.098, 0.109, 0.142, 0.144, 0.157, 0.166, 0.292, 0.129, 0.168, 0.19, 0.19, 0.204, 0.159, 0.161, 0.16, 0.187, 0.169, 0.16, 0.188, 0.196, 0.189, 0.19, 0.16, 0.151, 0.202, 0.176, 0.244, 0.165, 0.128, 0.13, 0.195, 0.146, 0.202, 0.15, 0.147, 0.17, 0.157, 0.421, 0.191, 0.188, 0.135, 1.005, 0.186, 0.183, 0.221, 0.173, 0.149, 0.179, 0.156, 0.136, 0.274, 0.151, 0.158, 0.134, 0.138, 0.143, 0.119, 0.14, 0.176, 0.169, 0.139, 0.153, 0.216, 0.146, 0.18, 0.166, 0.226, 0.171, 0.161, 0.195, 1.174, 0.148, 0.182, 0.189, 0.203, 0.223, 0.187, 0.154, 0.119, 0.174, 0.144, 0.131, 0.18, 0.192, 0.137, 0.307, 0.113, 0.171, 0.168, 0.157, 0.174, 0.194, 0.145, 0.145, 0.13, 0.168, 0.174, 0.205, 0.281, 0.172, 0.147, 0.151, 0.153, 0.177, 0.196, 0.141, 0.134, 0.115, 0.13, 0.106, 0.164, 0.109, 0.177, 0.129, 0.172, 0.135, 0.196, 0.157, 0.183, 0.175, 0.165, 0.18, 0.173, 0.159, 0.132, 0.194, 0.14, 0.119, 0.184, 0.161, 0.105, 0.159, 0.117, 0.148, 0.18, 0.176, 0.458, 0.213, 0.168, 0.214, 0.204, 0.308, 0.209, 0.162, 0.169, 0.197, 0.19, 0.127, 0.203, 0.145, 0.201, 0.156, 0.169, 0.13, 0.166, 0.183, 0.172, 0.151, 0.186, 0.173, 0.182, 0.24, 0.198, 0.177, 0.209, 0.219, 0.176, 0.215, 0.282, 0.155, 0.116, 0.124, 0.148, 0.125, 0.126, 0.127, 0.16, 0.144, 0.784, 0.141, 0.234, 0.184, 0.192, 0.282, 0.213, 0.167, 0.163, 0.197, 0.191, 0.157, 0.142, 0.245, 0.116, 0.136, 0.146, 0.135, 0.188, 0.183, 0.198, 0.165, 0.15, 0.199, 0.23, 0.179, 0.182, 0.191, 0.203, 0.321, 0.119, 0.145, 0.138, 0.192, 0.182, 0.174, 0.158, 0.21, 0.141, 0.192, 0.204, 0.254, 0.198, 0.142, 0.197, 0.188, 0.219, 0.198, 0.208, 0.206, 0.319, 0.193, 0.158, 0.135, 0.114, 0.155, 0.14, 0.138, 0.132, 0.179, 0.165, 0.194, 0.157, 0.115, 0.119, 0.142, 0.13, 0.179, 0.126, 0.154, 0.121, 0.171, 0.145, 0.245, 0.215, 0.16, 0.17, 0.137, 0.155, 0.131, 0.148, 0.16, 0.143, 0.15, 0.134, 0.198, 0.225, 0.136, 0.299, 0.187, 0.147, 0.179, 0.325, 0.212, 0.219, 0.185, 0.199, 0.155, 0.184, 0.17, 0.203, 0.213, 0.187, 2.187, 0.142, 0.111, 0.116, 0.207, 0.174, 0.361, 0.16, 0.297, 0.276, 0.183, 0.133, 0.166, 0.195, 0.21, 0.114, 0.144, 0.127, 0.109, 0.194, 0.154, 0.152, 0.158, 0.121, 0.663, 0.229, 0.188, 0.155, 0.178, 0.211, 0.234, 0.152, 0.207, 0.157, 0.157, 0.224, 0.154, 0.151, 0.206, 0.298, 0.211, 0.212, 0.147, 0.166, 0.168, 0.224, 0.209, 0.249, 0.126, 0.159, 0.183, 0.221, 0.185, 0.161, 0.131, 0.18, 0.167, 0.126, 0.142, 0.158, 0.186, 0.098, 0.155, 0.166, 0.193, 0.21, 0.224, 0.233, 0.22, 0.217, 1.579, 0.153, 0.221, 0.281, 0.158, 0.172, 0.217, 0.174, 0.138, 0.23, 0.139, 0.151, 0.217, 0.151, 0.156, 0.176, 0.162, 0.181, 0.199, 0.27, 0.183, 0.119, 0.236, 0.22, 0.193, 0.141, 0.148, 0.144, 0.186, 0.188, 0.165, 0.157, 0.18, 0.209, 0.254, 0.236, 0.196, 0.34, 0.142, 0.228, 0.215, 0.18, 0.11, 0.121, 0.135, 0.221, 0.334, 0.208, 0.167, 0.18, 0.141, 0.159, 0.145, 0.193, 0.143, 0.165, 0.19, 0.301, 0.142, 0.173, 0.159, 0.127, 0.114, 0.113, 0.127, 0.34, 0.123, 0.213, 0.216, 0.148, 0.152, 0.171, 0.192, 0.175, 0.175, 0.179, 0.155, 0.182, 0.206, 0.152, 1.042, 0.213, 0.112, 0.202, 0.132, 0.127, 0.107, 0.138, 0.193, 0.177, 0.194, 0.174, 0.124, 0.216, 0.223, 0.317, 0.134, 0.176, 0.14, 0.166, 0.189, 0.195, 0.18, 0.232, 0.184, 0.159, 0.203, 0.233, 0.187, 0.159, 0.237, 0.157, 0.194, 0.245, 0.146, 0.162, 0.156, 2.25, 0.212, 0.27, 0.228, 0.152, 0.21, 0.148, 0.141, 0.254, 0.246, 0.14, 0.18, 0.197, 0.135, 0.135, 0.181, 0.253, 0.126, 0.181, 0.208, 0.191, 1.29, 0.183, 0.214, 0.297, 0.231, 0.225, 0.32, 0.144, 0.152, 0.192, 0.137, 0.17, 0.159, 0.211, 0.227, 0.169, 0.161, 0.171, 0.235, 0.164, 0.146, 0.135, 0.195, 0.176, 0.594, 0.2, 0.207, 0.2, 0.212, 0.171, 0.15, 0.256, 0.262, 0.152, 0.19, 0.184, 0.123, 0.216, 0.144, 0.194, 0.208, 0.134, 0.237, 0.223, 0.166, 0.329, 0.146, 0.144, 0.163, 0.15, 0.138, 0.156, 0.158, 0.214, 0.196, 0.151, 0.177, 0.145, 0.206, 0.191, 0.201, 0.211, 0.153, 0.25, 0.194, 0.479, 0.177, 0.15, 0.16, 0.178, 0.305, 0.204, 0.143, 0.182, 0.131, 0.143, 0.232, 0.177, 0.205, 0.234, 0.124, 0.122, 0.137, 0.125, 0.126, 0.144, 0.124, 0.122, 0.162, 0.149, 0.211, 0.207, 0.182, 0.184, 0.165, 0.182, 0.18, 0.183, 0.189, 0.171, 0.172, 0.157, 0.148, 0.159, 0.244, 0.307, 0.213, 0.177, 0.148, 0.14, 0.15, 0.196, 0.156, 0.139, 0.158, 0.141, 0.139, 0.323, 0.143, 0.208, 0.183, 0.191, 0.237, 0.215, 0.23, 0.146, 0.165, 0.147, 0.16, 0.12, 0.175, 0.206, 0.499, 0.149, 0.15, 0.165, 0.203, 0.259, 0.144, 0.17, 0.21, 0.197, 0.223, 0.2, 0.192, 0.121, 0.114, 0.174, 0.134, 0.194, 0.21, 0.171, 0.19, 0.185, 0.206, 0.15, 0.168, 0.147, 0.568, 0.206, 0.235, 0.168, 0.141, 0.159, 0.179, 0.186, 0.224, 0.199, 0.209, 0.128, 0.172, 0.171, 0.188, 0.2, 0.183, 0.176, 0.245, 0.2, 0.189, 0.132, 0.207, 0.203, 0.139, 0.172, 0.164, 0.138, 0.128, 0.18, 0.158, 0.177, 0.16, 0.155, 0.17, 0.132, 0.133, 0.133, 0.157, 0.183, 0.182, 0.205, 0.192, 0.149, 0.188, 0.203, 0.137, 0.147, 0.191, 0.188, 0.171, 0.178, 0.189, 0.156, 0.185, 0.148, 0.134, 0.153, 0.191, 0.205, 1.022, 0.108, 0.15, 0.212, 0.517, 0.222, 0.173, 0.148, 0.159, 0.174, 0.144, 0.139, 0.188, 0.155, 0.185, 0.194, 0.177, 0.165, 0.155, 0.197, 0.216, 0.167, 0.251, 0.125, 0.191, 0.234, 0.129, 0.143, 0.188, 0.203, 0.113, 0.117, 0.162, 0.113, 0.153, 0.127, 0.209, 0.185, 0.262, 0.151, 0.135, 0.126, 0.178, 0.181, 0.161, 0.144, 0.135, 0.138, 0.221, 0.192, 0.202, 0.167, 0.131, 0.244, 0.159, 0.171, 0.173, 0.218, 0.236, 0.24, 0.183, 0.141, 0.336, 0.168, 0.165, 0.217, 0.205, 0.173, 0.185, 0.135, 0.296, 0.165, 0.169, 0.141, 0.139, 0.132, 0.18, 0.224, 0.132, 0.152, 0.163, 0.174, 0.428, 0.226, 0.157, 0.224, 0.157, 0.225, 0.188, 0.196, 0.133, 0.142, 0.146, 0.154, 0.188, 0.214, 0.125, 0.123, 0.137, 0.101, 0.096, 0.264, 0.147, 0.218, 0.182, 0.137, 0.178, 0.177, 0.139, 0.231, 0.214, 0.215, 0.163, 0.204, 0.224, 0.233, 0.142, 0.208, 0.324, 0.113, 0.182, 0.125, 0.193, 0.109, 0.197, 0.129, 0.18, 0.166, 0.199, 0.132, 0.155, 0.209, 0.191, 0.247, 0.233, 0.096, 0.101, 0.1, 0.117, 0.171, 0.507, 0.146, 0.127, 0.148, 0.162, 0.175, 0.118, 0.184, 0.221, 0.209, 0.186, 0.172, 0.195, 0.15, 0.179, 0.333, 0.139, 0.152, 0.202, 0.201, 0.188, 0.186, 0.17, 0.208, 0.192, 0.127, 1.054, 0.217, 0.337, 0.152, 0.14, 0.119, 0.195, 0.186, 0.146, 0.207, 0.221, 0.332, 0.208, 0.191, 0.177, 0.129, 0.202, 0.147, 0.194, 0.247, 0.178, 0.211, 0.24, 0.227, 0.252, 0.123, 0.29, 0.26, 0.225, 0.224, 0.167, 0.251, 0.169, 0.223, 0.24, 0.16, 0.181, 0.15, 0.192, 0.236, 0.191, 0.19, 0.169, 0.171, 0.132, 0.109, 0.166, 0.367, 0.173, 0.13, 0.158, 0.163, 0.137, 0.184, 0.206, 0.174, 0.159, 0.172, 0.422, 0.169, 0.21, 0.192, 0.199, 0.12, 0.172, 0.164, 0.148, 0.19, 0.176, 0.197, 0.205, 0.168, 0.188, 0.168, 0.187, 0.128, 0.14, 0.149, 0.216, 0.181, 0.257, 0.182, 0.223, 0.132, 0.232, 0.143, 0.117, 0.16, 0.155, 0.146, 0.152, 0.165, 0.156, 0.146, 0.13, 0.158, 0.114, 0.121, 0.213, 0.183, 0.219, 0.159, 0.221, 0.142, 0.333, 0.138, 0.126, 0.184, 0.144, 0.209, 0.192, 2.172, 0.204, 0.159, 0.186, 0.151, 0.202, 0.163, 0.191, 0.213, 0.211, 0.3, 0.16, 0.22, 0.114, 0.176, 0.213, 0.135, 0.15, 0.994, 0.251, 1.184, 0.198, 0.13, 0.23, 0.222, 0.195, 0.202, 0.214, 0.207, 0.165, 0.163, 0.214, 0.179, 0.14, 0.129, 0.166, 0.18, 0.141, 0.18, 0.171, 0.205, 0.192, 0.16, 0.126, 0.137, 0.154, 0.204, 0.179, 0.18, 0.137, 0.208, 0.206, 0.426, 0.21, 0.201, 0.193, 0.238, 0.193, 0.2, 0.143, 0.238, 0.251, 0.254, 0.161, 0.15, 0.157, 0.108, 0.143, 0.147, 0.218, 0.22, 0.206, 0.181, 0.199, 0.231, 0.159, 0.193, 0.224, 0.317, 0.151, 0.833, 0.297, 0.239, 0.157, 0.223, 0.308, 0.147, 0.186, 0.215, 0.163, 0.177, 0.224, 0.146, 0.189, 0.116, 0.186, 0.12, 0.142, 0.12, 0.138, 0.157, 0.109, 0.181, 0.133, 0.179, 0.124, 0.154, 0.274, 0.252, 0.231, 0.193, 0.304, 0.209, 0.14, 0.182, 0.162, 0.169, 0.185, 0.155, 0.236, 0.203, 0.26, 0.141, 0.146, 0.182, 0.204, 0.157, 0.17, 0.164, 0.205, 0.163, 0.199, 0.121, 0.175, 0.147, 0.201, 0.169, 0.16, 0.194, 0.163, 0.204, 0.136, 0.182, 0.192, 0.147, 0.255, 0.16, 0.144, 0.2, 0.146, 0.189, 0.202, 0.218, 0.212, 0.2, 0.197, 0.161, 0.181, 0.169, 0.215, 0.631, 0.21, 0.21, 0.159, 0.174, 0.22, 0.175, 0.144, 0.186, 0.174, 0.202, 0.174, 0.176, 0.178, 0.164, 0.215, 0.43, 0.169, 0.19, 0.211, 0.152, 0.236, 0.251, 0.242, 0.151, 0.146, 0.222, 0.191, 0.156, 0.167, 0.186, 0.187, 0.173, 0.169, 0.255, 0.192, 0.264, 0.231, 0.164, 0.154, 0.207, 0.284, 0.217, 0.213, 0.167, 0.248, 0.216, 0.171, 0.213, 0.159, 0.134, 0.308, 0.235, 0.193, 0.201, 0.147, 0.161, 0.22, 0.176, 0.168, 0.161, 0.179, 0.176, 0.201, 0.2, 0.316, 0.169, 0.169, 0.201, 0.201, 0.173, 0.181, 0.154, 0.173, 0.185, 0.226, 0.199, 0.189, 0.18, 0.267, 0.239, 0.213, 0.215, 0.194, 0.216, 0.212, 0.199, 0.217, 0.168, 0.194, 0.157, 0.145, 0.217, 0.141, 0.165, 0.175, 0.151, 0.165, 0.157, 0.211, 0.219, 0.21, 0.164, 0.211, 0.155, 0.158, 0.133, 0.133, 0.184, 0.143, 0.19, 0.133, 0.218, 0.194, 0.163, 0.197, 0.203, 0.195, 0.191, 0.206, 0.187, 0.203, 0.213, 0.182, 0.233, 0.304, 0.16, 0.183, 0.168, 0.113, 0.22, 0.14, 0.215, 0.148, 0.138, 1.021, 0.207, 0.204, 0.169, 0.202, 0.192, 0.144, 0.21, 0.128, 0.329, 0.199, 0.176, 0.189, 0.179, 0.147, 0.206, 0.153, 0.171, 0.179, 0.198, 0.291, 0.175, 0.199, 0.224, 0.165, 0.121, 0.153, 0.162, 0.24, 0.149, 0.215, 0.344, 0.298, 0.224, 0.246, 0.158, 0.226, 0.14, 0.15, 0.206, 0.15, 0.192, 0.241, 0.275, 0.221, 0.217, 0.166, 0.168, 0.15, 0.154, 0.116, 0.118, 0.184, 0.213, 0.21, 0.235, 0.21, 0.199, 0.235, 0.238, 0.147, 0.207, 0.174, 0.123, 0.209, 0.131, 0.203, 0.204, 0.149, 0.193, 0.125, 0.156, 0.201, 0.192, 0.201, 0.19, 0.124, 0.164, 0.153, 0.203, 0.178, 0.179, 0.158, 0.18, 0.183, 0.126, 0.149, 0.207, 0.168, 0.206, 0.201, 0.146, 0.204, 0.115, 0.178, 0.173, 0.203, 0.218, 0.22, 0.217, 0.168, 2.235, 0.141, 0.116, 0.137, 0.156, 0.245, 0.196, 0.343, 0.14, 0.135, 0.171, 0.137, 0.209, 0.145, 0.144, 0.229, 0.307, 0.136, 0.167, 0.152, 0.213, 0.246, 0.258, 0.242, 0.194, 0.189, 0.158, 0.186, 0.158, 0.126, 0.21, 0.142, 0.181, 0.197, 0.121, 0.164, 0.146, 0.144, 0.174, 0.118, 0.193, 0.181, 0.187, 0.277, 0.141, 0.177, 0.19, 0.144, 0.14, 0.17, 0.158, 0.149, 0.147, 0.135, 0.188, 0.15, 0.197, 0.175, 0.171, 0.184, 0.144, 0.145, 0.809, 0.186, 0.165, 0.174, 0.14, 0.222, 0.172, 0.195, 0.228, 0.151, 0.134, 0.164, 0.2, 1.513, 0.148, 0.145, 0.144, 0.176, 0.161, 0.138, 0.157, 0.171, 0.193, 0.171, 0.227, 0.166, 0.166, 0.246, 0.2, 0.141, 0.203, 0.134, 0.193, 0.22, 0.223, 0.251, 0.158, 0.157, 0.141, 0.157, 0.194, 0.133, 0.133, 0.203, 0.19, 0.263, 0.194, 0.14, 0.201, 0.139, 0.267, 0.13, 0.143, 0.135, 0.138, 0.109, 0.133, 0.17, 0.146, 0.169, 0.14, 0.156, 0.173, 0.142, 0.183, 0.186, 0.302, 0.132, 0.152, 0.146, 0.098, 0.201, 0.189, 0.1, 0.17, 0.167, 0.155, 0.278, 0.217, 0.128, 0.128, 0.158, 0.222, 0.193, 0.217, 0.152, 0.184, 0.2, 0.172, 0.173, 0.198, 0.142, 0.23, 0.177, 0.255, 0.131, 0.192, 0.167, 0.206, 0.179, 0.164, 0.175, 0.193, 0.186, 0.192, 0.197, 0.138, 0.14, 0.221, 0.192, 0.164, 0.211, 0.182, 0.135, 0.215, 0.131, 0.534, 0.157, 0.182, 0.878, 0.165, 0.173, 0.149, 0.194, 0.219, 0.21, 0.184, 0.214, 0.192, 0.181, 0.179, 0.194, 0.161, 0.164, 0.165, 0.22, 0.223, 0.237, 0.137, 0.151, 0.197, 0.185, 0.153, 0.148, 0.168, 0.203, 0.138, 0.202, 0.132, 0.141, 0.156, 0.148, 0.194, 0.208, 0.156, 0.147, 0.171, 0.135, 0.133, 0.167, 0.205, 0.14, 0.164, 0.132, 0.123, 0.193, 0.158, 0.151, 0.117, 0.138, 0.178, 0.201, 0.224, 0.15, 0.164, 0.181, 0.201, 0.174, 0.211, 0.151, 0.17, 0.148, 0.18, 0.139, 0.161, 0.134, 0.187, 0.143, 0.19, 0.184, 0.196, 0.154, 0.137, 0.164, 0.173, 0.136, 0.16, 0.174, 0.158, 0.147, 0.193, 0.144, 0.17, 0.201, 0.208, 0.14, 0.142, 0.137, 0.22, 0.245, 0.176, 0.124, 0.452, 0.159, 0.197, 0.165, 0.154, 0.214, 0.184, 0.217, 0.347, 0.15, 0.172, 0.14, 0.167, 0.176, 0.162, 0.147, 0.151, 0.173, 0.134, 0.177, 0.145, 0.146, 0.138, 0.205, 0.155, 0.174, 0.175, 0.296, 0.181, 0.303, 0.227, 0.22, 0.149, 0.199, 0.46, 0.169, 0.165, 0.148, 0.138, 0.156, 0.187, 0.145, 0.163, 0.19, 0.284, 0.158, 0.217, 0.169, 0.187, 0.194, 0.165, 0.215, 0.2, 0.22, 0.153, 0.207, 0.182, 1.04, 0.159, 0.24, 0.242, 0.217, 0.222, 0.203, 0.307, 0.142, 0.149, 0.154, 0.218, 0.12, 0.195, 0.231, 0.282, 1.187, 0.186, 0.159, 0.141, 0.219, 0.827, 0.147, 0.154, 0.233, 0.154, 0.203, 0.208, 0.16, 0.161, 0.346, 0.161, 0.213, 0.179, 0.156, 0.165, 0.233, 0.2, 0.197, 0.229, 0.2, 0.158, 0.156, 0.182, 0.155, 0.151, 0.162, 0.194, 0.166, 0.13, 0.11, 0.187, 0.168, 0.121, 0.147, 0.137, 0.234, 0.373, 0.143, 0.186, 0.673, 0.21, 0.195, 0.195, 0.196, 0.296, 0.174, 0.163, 0.147, 0.165, 0.151, 0.143, 0.156, 0.175, 0.203, 0.339, 0.223, 0.196, 0.169, 0.17, 0.194, 0.171, 0.186, 0.193, 0.275, 0.197, 0.129, 0.234, 0.244, 0.221, 0.135, 0.227, 0.094, 0.123, 0.197, 0.097, 0.136, 0.092, 0.163, 0.173, 0.13, 0.101, 0.12, 0.134, 0.162, 0.129, 0.102, 0.157, 0.164, 0.099, 0.152, 0.143, 0.143, 0.207, 0.103, 0.134, 0.151, 0.13, 0.156, 0.142, 0.118, 0.27, 0.112, 0.11, 0.113, 0.117, 0.123, 0.256, 0.184, 0.158, 0.125, 0.114, 0.16, 0.128, 0.127, 0.135, 0.142, 0.132, 0.096, 0.125, 0.186, 0.123, 0.12, 0.187, 0.149, 0.127, 0.191, 0.142, 0.155, 0.13, 0.129, 0.155, 0.128, 0.166, 0.309, 0.173, 0.229, 0.115, 0.176, 0.207, 0.299, 0.141, 0.138, 0.124, 0.168, 0.169, 0.184, 0.197, 0.208, 0.116, 0.18, 0.183, 0.173, 0.127, 0.15, 0.139, 0.137, 0.122, 0.158, 0.121, 0.152, 0.136, 0.149, 0.193, 0.116, 0.18, 0.156, 0.19, 0.143, 0.14, 0.131, 0.157, 0.137, 2.169, 0.131, 0.181, 0.104, 0.125, 0.199, 0.213, 0.155, 0.171, 1.113, 0.181, 0.31, 0.167, 0.169, 0.222, 0.215, 0.16, 0.121, 0.109, 0.117, 0.194, 0.202, 0.521, 0.157, 0.11, 0.131, 0.152, 0.176, 0.146, 0.169, 0.164, 0.192, 0.161, 0.188, 0.132, 0.182, 0.152, 0.167, 0.145, 0.232, 0.169, 0.118, 0.281, 0.148, 0.156, 0.222, 0.144, 0.125, 0.166, 0.192, 0.15, 0.184, 0.147, 0.11, 0.139, 0.156, 0.128, 0.152, 0.106, 0.185, 0.176, 0.228, 0.19, 0.221, 0.111, 0.199, 0.128, 0.177, 0.193, 0.189, 0.167, 0.191, 0.119, 0.12, 0.201, 0.147, 0.729, 0.125, 0.122, 0.136, 0.14, 0.098, 0.145, 0.109, 0.166, 0.195, 0.168, 0.147, 0.189, 0.152, 0.143, 0.216, 0.208, 0.139, 0.244, 0.164, 0.166, 0.133, 0.194, 0.162, 0.204, 0.104, 0.22, 0.294, 0.172, 0.227, 0.135, 0.146, 0.224, 0.204, 0.162, 0.17, 0.172, 0.13, 0.1, 0.127, 0.286, 0.168, 0.184, 0.159, 0.186, 0.14, 0.118, 0.197, 0.113, 0.116, 0.166, 0.163, 0.227, 0.187, 0.19, 0.973, 0.129, 0.15, 0.188, 0.179, 0.186, 0.199, 0.212, 0.209, 0.161, 0.136, 0.214, 0.169, 0.157, 0.14, 0.23, 0.197, 0.14, 0.348, 0.615, 0.189, 0.172, 0.23, 0.192, 0.179, 0.196, 0.138, 1.168, 0.179, 0.17, 0.148, 0.149, 0.185, 0.182, 0.22, 0.183, 0.158, 0.134, 0.134, 0.148, 0.204, 0.11, 0.171, 0.169, 0.199, 0.288, 0.18, 0.175, 0.232, 0.184, 0.283, 0.213, 0.191, 0.157, 0.151, 0.125, 0.118, 0.109, 0.125, 0.115, 0.212, 0.139, 0.146, 0.147, 0.165, 0.164, 0.139, 0.125, 0.109, 0.108, 0.204, 0.178, 0.206, 0.149, 0.15, 0.199, 0.276, 0.178, 0.128, 0.147, 0.157, 0.232, 0.15, 0.146, 0.205, 0.202, 0.176, 0.109, 0.154, 0.105, 0.186, 0.115, 0.115, 0.144, 0.159, 0.157, 0.123, 0.169, 0.128, 0.143, 0.178, 0.159, 0.299, 0.174, 0.171, 0.145, 0.157, 0.114, 0.122, 0.19, 0.123, 0.148, 0.12, 0.185, 0.125, 0.134, 0.112, 0.178, 0.16, 0.136, 0.123, 0.141, 0.111, 0.172, 0.138, 0.165, 0.126, 0.148, 0.191, 0.188, 0.129, 0.208, 0.113, 0.14, 0.196, 0.126, 0.111, 0.181, 0.227, 0.164, 0.15, 0.372, 0.162, 0.17, 0.14, 0.119, 0.465, 0.152, 0.164, 0.172, 0.122, 0.175, 0.171, 0.161, 0.143, 0.106, 0.284, 0.175, 0.123, 0.195, 0.147, 0.109, 0.152, 0.195, 0.182, 0.16, 0.151, 0.126, 0.159, 0.128, 0.162, 0.152, 0.118, 0.143, 0.203, 0.217, 0.126, 0.123, 0.108, 0.109, 0.137, 0.149, 0.141, 0.162, 0.302, 0.165, 0.111, 0.201, 0.145, 0.181, 0.426, 0.12, 0.129, 0.146, 0.164, 0.287, 0.399, 0.164, 0.184, 0.995, 0.187, 0.12, 0.126, 0.112, 0.153, 0.318, 0.238, 0.197, 0.144, 0.161, 0.123, 0.166, 0.192, 0.224, 0.149, 0.149, 0.192, 0.145, 0.108, 0.108, 0.113, 0.126, 0.14, 0.134, 0.162, 0.138, 0.101, 0.115, 0.132, 0.179, 0.126, 0.139, 0.152, 0.153, 0.152, 0.174, 0.22, 0.121, 0.155, 0.094, 0.121, 0.103, 0.212, 0.087, 0.093, 0.13, 0.122, 0.179, 0.157, 0.162, 0.15, 0.157, 0.146, 0.141, 0.219, 0.187, 0.191, 0.183, 0.207, 0.119, 0.274, 0.214, 0.198, 0.181, 0.128, 0.335, 0.251, 0.208, 0.108, 0.144, 0.149, 0.155, 0.274, 0.124, 0.103, 0.146, 0.119, 0.201, 0.189, 0.224, 0.11, 0.162, 0.163, 0.2, 0.181, 0.204, 0.096, 0.096, 0.117, 0.236, 0.18, 0.152, 0.178, 0.166, 0.187, 0.248, 0.25, 0.165, 0.143, 0.148, 0.169, 0.113, 0.187, 1.001, 0.154, 0.214, 0.221, 0.216, 0.343, 0.111, 0.724, 0.148, 0.191, 0.133, 0.266, 0.147, 0.143, 0.105, 0.116, 0.126, 0.476, 0.2, 0.126, 0.165, 0.164, 0.19, 0.132, 0.163, 0.201, 0.123, 0.147, 0.107, 0.194, 0.182, 0.151, 0.154, 0.121, 0.156, 0.194, 0.137, 0.21, 0.193, 0.137, 0.156, 0.204, 0.197, 0.209, 0.155, 0.148, 0.141, 0.168, 0.131, 0.175, 0.204, 0.218, 0.241, 0.15, 0.21, 0.168, 0.214, 0.148, 0.209, 0.167, 0.172, 0.175, 0.134, 0.175, 0.161, 0.21, 0.192, 0.162, 0.183, 0.115, 0.19, 0.165, 0.128, 0.111, 0.089, 0.103, 0.09, 0.221, 0.19, 0.17, 0.111, 0.111, 0.135, 0.117, 0.144, 0.123, 0.139, 0.161, 0.121, 0.136, 0.121, 0.11, 0.139, 0.161, 0.153, 0.128, 0.15, 0.152, 0.117, 0.256, 0.787, 0.145, 0.172, 0.175, 2.362, 0.145, 0.115, 0.145, 0.156, 0.122, 0.145, 0.187, 0.318, 0.142, 0.125, 0.108, 0.141, 0.177, 0.201, 0.16, 0.171, 0.128, 0.115, 0.137, 0.115, 0.155, 0.153, 0.141, 0.204, 0.142, 0.206, 0.114, 0.156, 0.124, 0.102, 0.14, 0.173, 0.165, 0.19, 0.173, 0.18, 0.112, 0.137, 0.114, 0.337, 1.006, 0.179, 0.136, 0.211, 0.187, 0.175, 0.192, 0.284, 0.171, 0.211, 0.23, 0.268, 0.186, 0.201, 0.167, 0.199, 0.15, 0.252, 0.204, 0.244, 0.206, 0.274, 0.187, 0.207, 0.247, 0.17, 0.179, 0.13, 0.153, 0.155, 0.187, 0.252, 0.345, 0.236, 0.213, 0.446, 0.179, 0.204, 0.159, 0.364, 0.209, 0.231, 0.168, 0.215, 0.227, 0.263, 0.214, 0.21, 0.124, 0.127, 0.157, 0.201, 0.131, 0.163, 0.171, 0.356, 0.151, 0.16, 0.169, 0.213, 0.166, 0.241, 0.199, 0.223, 0.141, 0.182, 0.191, 0.164, 0.169, 0.14, 0.19, 0.226, 0.221, 0.224, 0.177, 0.201, 0.192, 0.158, 0.192, 0.127, 0.124, 0.177, 0.141, 0.123, 0.188, 0.147, 0.202, 0.217, 0.198, 0.17, 0.204, 0.157, 0.167, 0.181, 0.145, 0.267, 0.169, 0.208, 0.233, 0.219, 0.207, 0.216, 0.184, 0.152, 0.209, 0.226, 0.454, 0.121, 0.196, 0.169, 0.143, 0.183, 0.226, 0.153, 0.218, 0.196, 0.19, 0.146, 0.148, 0.154, 0.225, 0.21, 0.196, 0.152, 0.19, 0.2, 0.168, 0.246, 0.245, 0.17, 0.226, 0.218, 0.189, 0.23, 0.129, 0.168, 0.167, 0.119, 0.113, 0.146, 0.18, 0.158, 0.197, 0.209, 0.216, 0.142, 0.17, 0.147, 0.194, 0.182, 0.184, 0.238, 0.238, 0.23, 0.237, 0.227, 0.138, 0.195, 0.209, 0.174, 0.161, 0.19, 0.211, 0.145, 0.134, 0.159, 0.194, 0.173, 0.257, 0.146, 0.334, 0.136, 0.149, 0.097, 0.117, 0.146, 0.144, 0.174, 0.154, 0.141, 0.163, 0.182, 0.187, 0.135, 0.155, 0.222, 0.18, 0.156, 0.228, 0.15, 0.222, 0.237, 0.146, 0.19, 0.162, 0.152, 0.241, 0.174, 0.168, 1.202, 0.195, 0.134, 0.227, 0.169, 0.227, 0.113, 0.17, 0.222, 0.138, 0.19, 0.185, 0.218, 0.243, 0.142, 0.157, 0.113, 0.263, 0.175, 0.171, 0.252, 0.226, 0.196, 0.143, 0.179, 0.327, 0.176, 0.138, 0.173, 0.138, 0.193, 0.164, 0.175, 0.299, 0.221, 0.205, 0.233, 0.124, 0.191, 0.211, 0.213, 0.136, 0.153, 0.141, 0.15, 0.188, 0.186, 0.176, 0.175, 0.22, 0.197, 0.212, 0.195, 0.2, 0.179, 0.154, 0.221, 0.189, 0.156, 0.243, 0.151, 0.206, 0.342, 0.208, 0.225, 0.152, 0.205, 0.246, 0.221, 0.23, 0.161, 0.154, 0.225, 0.234, 0.199, 0.153, 0.194, 0.134, 0.155, 0.16, 0.305, 0.12, 0.193, 0.208, 0.154, 0.217, 0.551, 0.151, 0.205, 0.2, 0.157, 0.214, 0.193, 0.219, 0.218, 0.229, 0.201, 0.195, 0.202, 0.204, 1.104, 0.288, 0.184, 0.152, 0.158, 0.187, 0.199, 0.215, 0.208, 0.204, 0.206, 0.225, 0.173, 0.155, 0.182, 0.153, 0.14, 0.216, 0.197, 0.246, 0.144, 0.114, 0.1, 0.149, 0.123, 0.119, 0.18, 0.12, 0.289, 0.159, 0.167, 0.184, 0.157, 0.129, 0.123, 0.122, 0.119, 0.148, 0.139, 0.151, 0.133, 0.176, 0.198, 0.176, 0.155, 0.158, 0.158, 0.19, 0.246, 0.122, 0.167, 0.145, 0.157, 0.36, 0.107, 0.143, 0.12, 0.134, 0.142, 0.179, 0.188, 0.155, 0.175, 0.161, 0.122, 0.147, 0.204, 0.114, 0.182, 0.166, 0.15, 0.122, 0.121, 0.141, 0.098, 0.218, 0.13, 0.114, 0.114, 0.122, 0.104, 0.096, 0.135, 0.12, 0.205, 0.322, 0.116, 0.13, 0.575, 0.139, 0.148, 0.196, 0.16, 0.14, 0.106, 1.077, 0.173, 0.108, 0.101, 0.142, 0.133, 0.125, 0.132, 0.165, 0.093, 0.123, 0.133, 0.169, 0.131, 0.169, 0.13, 0.131, 0.186, 0.134, 0.156, 0.224, 0.115, 0.151, 0.132, 0.171, 0.112, 0.156, 0.13, 0.173, 0.094, 0.146, 0.119, 0.149, 0.128, 0.171, 0.321, 0.142, 0.174, 0.162, 0.132, 0.155, 0.153, 0.289, 0.197, 0.178, 0.165, 0.168, 0.112, 0.154, 0.165, 0.107, 0.099, 0.445, 0.158, 0.116, 0.137, 0.178, 0.224, 0.152, 0.173, 0.124, 0.205, 0.139, 0.109, 0.191, 0.159, 0.148, 0.108, 0.156, 0.119, 0.123, 0.117, 0.181, 0.11, 0.165, 0.141, 0.157, 0.149, 0.159, 0.288, 0.154, 1.048, 0.122, 0.169, 0.2, 0.117, 0.19, 0.15, 0.097, 0.142, 0.145, 0.106, 0.166, 0.189, 0.168, 0.145, 0.139, 0.117, 0.156, 0.157, 0.132, 0.546, 0.161, 1.017, 0.203, 0.147, 0.147, 0.176, 0.132, 0.192, 0.144, 0.296, 0.176, 0.169, 0.196, 0.154, 0.125, 0.271, 0.096, 0.198, 0.137, 0.152, 0.172, 0.115, 0.128, 0.279, 0.11, 0.154, 0.137, 0.113, 0.137, 0.158, 0.133, 0.125, 0.129, 0.141, 0.116, 0.15, 0.123, 0.123, 0.263, 0.344, 0.166, 0.119, 0.115, 0.213, 0.212, 0.178, 0.108, 0.126, 0.115, 0.184, 0.148, 0.14, 0.15, 0.173, 0.133, 0.153, 0.17, 0.195, 0.154, 0.182, 0.189, 0.174, 0.206, 0.279, 0.218, 0.15, 0.155, 0.174, 0.214, 0.157, 0.246, 0.203, 0.171, 0.141, 0.207, 0.231, 0.204, 0.222, 0.194, 0.242, 0.142, 0.208, 0.218, 0.131, 0.115, 0.163, 0.145, 0.165, 0.126, 0.115, 0.149, 0.169, 0.199, 0.177, 0.144, 0.201, 0.148, 0.137, 0.138, 0.22, 0.154, 0.158, 0.161, 0.319, 0.582, 0.18, 0.143, 0.157, 0.178, 0.203, 0.121, 0.179, 0.154, 0.177, 0.155, 0.154, 0.273, 0.157, 0.184, 0.118, 0.191, 0.159, 0.159, 0.582, 0.131, 0.158, 0.127, 0.128, 0.111, 0.219, 0.192, 0.152, 0.208, 0.157, 0.256, 0.143, 0.518, 0.147, 0.162, 0.193, 0.208, 0.179, 0.117, 0.13, 0.152, 0.176, 0.248, 0.198, 0.221, 0.218, 0.183, 0.176, 0.182, 0.281, 0.141, 0.283, 0.291, 0.144, 0.243, 0.173, 0.123, 0.109, 0.104, 0.174, 0.179, 0.24, 0.163, 0.211, 0.171, 0.235, 0.226, 0.163, 0.136, 0.251, 0.157, 0.128, 0.118, 0.15, 0.147, 0.135, 0.132, 0.153, 0.219, 0.176, 0.173, 0.168, 0.206, 0.227, 0.173, 0.165, 0.211, 0.122, 0.187, 0.236, 0.176, 0.134, 0.149, 0.123, 0.13, 0.173, 0.175, 0.154, 0.225, 0.16, 0.215, 0.24, 0.153, 0.186, 0.22, 0.123, 0.2, 0.259, 0.169, 0.181, 0.246, 0.136, 0.181, 0.226, 0.214, 0.201, 0.145, 0.186, 0.193, 0.152, 0.127, 0.123, 0.206, 0.207, 0.136, 0.194, 0.217, 0.175, 0.18, 0.272, 0.211, 0.208, 0.165, 0.227, 0.15, 0.11, 0.184, 0.156, 0.166, 0.171, 0.288, 0.202, 0.211, 0.217, 0.269, 0.116, 0.162, 0.137, 0.167, 0.21, 0.177, 0.209, 0.119, 0.129, 0.186, 0.163, 0.151, 0.15, 0.159, 0.293, 0.166, 0.169, 0.141, 0.196, 0.14, 0.289, 0.225, 0.319, 0.149, 0.191, 0.153, 0.144, 0.226, 0.237, 0.137, 0.14, 0.166, 1.2, 0.301, 0.183, 0.18, 0.158, 0.18, 0.267, 0.131, 0.167, 0.149, 0.211, 0.13, 0.216, 0.266, 0.181, 0.216, 0.14, 2.137, 0.203, 0.275, 0.231, 0.139, 0.184, 0.205, 0.202, 0.265, 0.145, 0.13, 0.187, 0.214, 0.183, 0.205, 0.206, 0.125, 0.179, 0.192, 0.19, 0.131, 0.172, 0.234, 0.28, 0.182, 0.19, 0.177, 0.195, 0.131, 0.165, 0.171, 0.155, 0.287, 0.227, 0.183, 0.172, 0.253, 0.158, 0.155, 0.204, 0.185, 0.148, 0.152, 0.248, 0.149, 0.184, 0.211, 0.22, 0.19, 0.16, 0.197, 0.169, 0.195, 0.125, 0.223, 0.153, 0.598, 0.233, 0.206, 0.153, 0.238, 0.186, 0.322, 0.259, 0.189, 0.212, 0.212, 0.147, 0.157, 0.086, 0.164, 0.15, 0.174, 0.164, 0.214, 0.117, 0.206, 0.176, 0.221, 0.129, 0.15, 0.191, 0.217, 0.15, 0.185, 0.152, 0.158, 0.149, 0.27, 0.096, 0.095, 0.126, 0.093, 0.151, 0.137, 0.188, 0.184, 0.15, 0.163, 0.165, 0.252, 0.201, 0.208, 0.149, 0.2, 0.157, 0.205, 0.202, 0.27, 0.194, 0.258, 0.214, 0.146, 0.142, 0.238, 0.175, 0.239, 0.188, 0.213, 0.217, 0.272, 0.253, 0.304, 0.253, 0.194, 0.149, 0.298, 0.179, 0.178, 0.139, 0.212, 0.212, 0.246, 0.97, 0.178, 0.263, 0.163, 0.145, 0.215, 0.203, 0.194, 0.137, 0.175, 0.12, 0.302, 0.187, 0.129, 0.325, 0.15, 0.115, 0.174, 0.117, 0.173, 0.171, 0.154, 0.144, 0.284, 0.178, 0.136, 1.001, 0.197, 0.252, 0.148, 0.202, 0.169, 0.224, 0.53, 0.118, 0.111, 0.182, 0.193, 0.169, 0.126, 0.157, 0.142, 0.218, 0.184, 0.163, 0.175, 0.192, 0.139, 0.277, 0.12, 0.202, 0.193, 0.147, 0.197, 0.189, 0.568, 0.228, 0.145, 0.236, 0.181, 0.195, 0.23, 0.208, 0.147, 0.351, 0.15, 0.135, 0.204, 0.193, 0.239, 0.362, 0.385, 0.155, 0.142, 0.121, 0.204, 0.214, 0.195, 0.181, 0.197, 0.211, 0.15, 0.151, 0.192, 0.137, 0.224, 0.137, 0.198, 0.145, 0.231, 0.227, 0.181, 0.216, 0.16, 0.194, 0.197, 0.187, 0.145, 0.324, 0.109, 0.118, 0.141, 0.109, 0.14, 0.207, 0.114, 0.19, 0.132, 0.209, 0.213, 0.163, 0.177, 0.193, 0.164, 0.141, 0.21, 0.17, 0.144, 0.138, 0.164, 0.135, 0.14, 0.14, 0.193, 0.18, 0.188, 0.196, 0.191, 0.115, 0.2, 1.264, 0.2, 0.235, 0.238, 0.24, 0.23, 0.156, 0.154, 0.15, 0.143, 0.165, 0.125, 0.141, 0.136, 0.132, 0.153, 0.211, 0.192, 0.251, 0.195, 0.147, 0.155, 0.198, 0.149, 0.253, 0.174, 0.275, 0.156, 0.117, 0.152, 0.188, 0.166, 0.218, 0.185, 0.145, 0.168, 0.212, 0.483, 0.209, 0.146, 0.146, 0.161, 0.228, 0.24, 0.207, 0.175, 0.127, 0.291, 0.179, 0.148, 0.159, 0.15, 0.161, 0.173, 0.354, 0.154, 0.179, 0.21, 0.133, 0.125, 0.17, 0.154, 0.208, 0.147, 0.175, 0.212, 0.214, 0.127, 0.224, 0.15, 0.155, 0.154, 0.143, 0.141, 0.212, 0.171, 0.157, 0.158, 0.164, 0.191, 0.152, 0.243, 0.149, 0.22, 0.127, 0.224, 0.128, 0.188, 0.156, 0.135, 0.163, 0.159, 0.132, 0.176, 0.197, 0.178, 0.19, 0.188, 0.228, 0.148, 0.152, 0.141, 0.184, 1.08, 0.146, 0.223, 0.226, 0.196, 0.173, 0.17, 0.169, 0.171, 0.149, 0.214, 0.208, 0.138, 0.158, 0.159, 0.124, 0.189, 0.138, 0.144, 0.223, 0.245, 0.229, 0.129, 0.267, 0.174, 0.152, 0.147, 0.206, 0.228, 0.213, 0.208, 0.21, 0.164, 0.15, 0.192, 0.183, 0.129, 0.172, 0.149, 0.156, 0.165, 0.192, 0.192, 0.21, 0.224, 0.138, 0.223, 0.186, 0.217, 0.181, 0.133, 0.183, 0.147, 0.113, 0.202, 0.218, 0.28, 0.159, 0.169, 0.149, 0.123, 0.095, 0.166, 0.171, 0.136, 0.157, 0.146, 0.147, 0.137, 0.201, 0.12, 0.208, 0.169, 0.155, 0.202, 0.227, 0.178, 0.194, 0.165, 0.176, 0.21, 0.124, 0.196, 0.43, 0.172, 0.164, 0.106, 0.115, 0.149, 0.152, 0.138, 0.136, 0.295, 0.133, 0.148, 0.728, 0.22, 0.244, 0.193, 0.218, 0.129, 0.143, 0.133, 0.146, 0.136, 0.151, 0.194, 0.147, 0.151, 0.144, 0.15, 0.204, 0.196, 0.162, 0.166, 0.184, 0.184, 0.162, 0.182, 0.785, 0.144, 0.167, 0.169, 0.138, 0.138, 0.202, 0.234, 0.218, 0.233, 0.248, 0.158, 0.164, 0.267, 0.239, 0.155, 0.218, 4.321, 0.125, 0.158, 0.189, 0.16, 0.163, 0.124, 0.17, 0.224, 0.142, 0.185, 0.204, 0.14, 0.213, 0.153, 0.189, 0.142, 0.43, 0.138, 0.2, 0.16, 0.14, 0.183, 0.14
            ]
        ], 
        [#filter or not
            [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
                2.2599546909332275, 5.860959053039551, 1.6872971057891846, 2.6122658252716064, 4.224048376083374, 3.1590418815612793, 2.907451868057251, 2.0609350204467773, 3.811128616333008, 2.843451976776123, 1.7924714088439941, 7.901972055435181, 2.549543619155884, 25.790019512176514, 2.4383609294891357, 2.5613629817962646, 2.9312632083892822, 11.067089080810547, 2.8109025955200195, 2.2598752975463867, 1.507671594619751, 1.8136401176452637, 4.9552130699157715, 2.7204174995422363, 1.191046953201294, 1.3465023040771484, 4.996950626373291, 2.223444938659668, 2.430529832839966, 1.9955921173095703, 5.195051670074463, 4.321598768234253, 1.450653314590454, 1.4451072216033936, 3.0488173961639404, 9.63210678100586, 3.1119027137756348, 3.0273654460906982, 8.725103378295898, 2.001119375228882, 1.987593173980713, 3.24078369140625, 4.490218162536621, 2.048307418823242, 1.7175371646881104, 1.6202187538146973, 1.9018332958221436, 3.0471739768981934, 7.027266263961792, 3.4920365810394287, 1.4151079654693604, 1.7739901542663574, 6.574313402175903, 7.2341461181640625, 2.52790904045105, 1.6330852508544922, 2.4601688385009766, 2.594205141067505, 4.011118173599243, 12.476887226104736, 1.3071203231811523, 1.7192978858947754, 1.3867526054382324, 1.1940364837646484, 1.4321284294128418, 2.7555723190307617, 3.397642135620117, 3.07456374168396, 2.723553419113159, 12.072330951690674, 2.5957090854644775, 1.9653785228729248, 2.632096767425537, 16.58332133293152, 2.5625085830688477, 1.2746713161468506, 7.9742467403411865, 2.013183355331421, 2.822597026824951, 2.3698976039886475, 2.3928160667419434, 1.733212947845459, 1.9153573513031006, 5.855409145355225, 2.336411952972412, 2.9932925701141357, 3.297962188720703, 4.622767448425293, 3.920417547225952, 1.6661336421966553, 3.523688554763794, 2.380187511444092, 3.295067071914673, 1.60904860496521, 2.5821096897125244, 1.4745557308197021, 5.585092306137085, 20.97913670539856, 4.552108526229858, 2.0911858081817627, 5.592394590377808, 2.2671191692352295, 2.221144676208496, 2.431992769241333, 12.67451786994934, 3.0452308654785156, 2.4200527667999268, 2.176527738571167, 4.31308126449585, 3.024693489074707, 2.6994237899780273, 3.546691656112671, 7.816696882247925, 1.7417786121368408, 2.504668712615967, 2.0009267330169678, 22.713515996932983, 1.849358081817627, 13.131017208099365, 2.694868326187134, 1.6493914127349854, 8.04440689086914, 1.846400260925293, 2.6465139389038086, 2.4964141845703125, 5.606354475021362, 1.374962568283081, 2.4478044509887695, 1.7065563201904297, 3.20174241065979, 3.335329055786133, 3.1884353160858154, 1.761347770690918, 1.8728711605072021, 4.272232294082642, 1.878187656402588, 2.7297518253326416, 1.3073787689208984, 1.8305552005767822, 1.4419715404510498, 11.398545503616333, 1.5516881942749023, 2.0531225204467773, 1.7128283977508545, 2.940253257751465, 1.935607671737671, 3.1719861030578613, 2.8807215690612793, 6.517936944961548, 2.0086989402770996, 3.635679244995117, 2.862213611602783, 2.96767520904541, 2.3308441638946533, 6.237794637680054, 4.765473127365112, 2.085383653640747, 9.235119342803955, 3.060056686401367, 3.3023860454559326, 2.067816734313965, 4.202597379684448, 4.04735803604126, 2.2851321697235107, 2.3030331134796143, 3.5813546180725098, 1.9908230304718018, 2.6079909801483154, 20.655632972717285, 11.244138717651367, 11.319575786590576, 1.7166235446929932, 1.9869699478149414, 5.181312084197998, 2.373763084411621, 3.494164228439331, 6.741464853286743, 2.176649570465088, 2.296430826187134, 3.828728437423706, 3.066828966140747, 2.9470303058624268, 3.033853530883789, 1.7390413284301758, 6.359750747680664, 6.271398305892944, 2.399401903152466, 1.7561333179473877, 1.618661642074585, 2.8118152618408203, 3.0912954807281494, 1.3493566513061523, 1.8864893913269043, 1.5923662185668945, 2.27101469039917, 2.5717666149139404, 2.466367721557617, 9.452656984329224, 3.616274118423462, 2.903324842453003, 5.49184775352478, 3.2717180252075195, 1.5857253074645996, 2.6761319637298584, 1.6628589630126953, 1.6988422870635986, 2.19343900680542, 29.81986117362976, 3.46502947807312, 4.834465026855469, 1.8307440280914307, 1.8238985538482666, 2.778069496154785, 5.465042352676392, 1.529329538345337, 9.387434720993042, 2.9309237003326416, 2.711479425430298, 3.4741837978363037, 1.387272596359253, 2.478907585144043, 3.340143918991089, 1.8284506797790527, 2.001462936401367, 1.5948615074157715, 10.518564701080322, 2.769918918609619, 2.4559309482574463, 1.6506545543670654, 1.472743272781372, 1.977832555770874, 1.8241267204284668, 1.5341596603393555, 1.8340163230895996, 1.981715202331543, 5.863634347915649, 1.4078128337860107, 3.096395254135132, 5.852593183517456, 2.0218849182128906, 10.270245552062988, 6.371631383895874, 19.095728397369385, 3.0375590324401855, 2.3823983669281006, 1.5518813133239746, 7.522383451461792, 2.3336899280548096, 3.53759503364563, 3.4114651679992676, 1.745192527770996, 1.356360912322998, 2.9354255199432373, 2.6630711555480957, 1.7665503025054932, 1.301314115524292, 4.236664295196533, 1.4465277194976807, 1.4753856658935547, 2.5660979747772217, 25.263699531555176, 9.10377025604248, 3.6376559734344482, 2.3944780826568604, 2.9652628898620605, 1.8953649997711182, 2.9823124408721924, 5.369048595428467, 1.3329124450683594, 1.887129306793213, 4.014279365539551, 3.1729013919830322, 1.8781147003173828, 11.500060796737671, 2.2453789710998535, 21.22187566757202, 2.41127872467041, 2.4608218669891357, 2.4877312183380127, 2.7677688598632812, 2.770029067993164, 3.1694750785827637, 1.5349533557891846, 2.9968252182006836, 1.5262537002563477, 1.63771390914917, 1.309401512145996, 5.464269638061523, 3.647977113723755, 1.4788908958435059, 1.3220984935760498, 3.0490427017211914, 7.691647052764893, 11.312275171279907, 1.1631267070770264, 1.146833896636963, 2.2484400272369385, 2.168473482131958, 2.76548433303833, 5.693224668502808, 3.0898900032043457, 2.1239173412323, 4.65432333946228, 10.29594612121582, 8.092661142349243, 4.5204973220825195, 1.7837650775909424, 2.4528894424438477, 2.2294819355010986, 2.0689730644226074, 1.8986601829528809, 2.6367452144622803, 1.5533020496368408, 24.563863039016724, 2.9435362815856934, 2.26489520072937, 2.452577590942383, 2.3989999294281006, 10.627686023712158, 2.7425687313079834, 1.9375488758087158, 8.03170895576477, 1.1269941329956055, 2.2656776905059814, 1.599402666091919, 1.7671597003936768, 1.4003808498382568, 2.4737491607666016, 3.662033796310425, 1.5424461364746094, 4.338785648345947, 1.4810278415679932, 1.6218407154083252, 1.532149076461792, 1.8729877471923828, 3.2219326496124268, 2.0163094997406006, 10.656807899475098, 2.086851119995117, 3.2151122093200684, 2.9912540912628174, 3.7224137783050537, 1.6295077800750732, 2.085989475250244, 3.909738063812256, 2.655244827270508, 3.4070539474487305, 7.222890615463257, 1.699054479598999, 1.3105967044830322, 2.6688177585601807, 1.7494125366210938, 2.5277106761932373, 3.1980795860290527, 1.3965787887573242, 1.7186872959136963, 5.67152738571167, 7.555086374282837, 1.168966293334961, 1.420475959777832, 3.6396477222442627, 3.6549320220947266, 4.078430891036987, 3.0651373863220215, 1.364961862564087, 9.887195348739624, 1.1240999698638916, 11.815392971038818, 2.178435802459717, 3.740210771560669, 1.3151092529296875, 4.6517791748046875, 2.5573337078094482, 1.9388880729675293, 1.8658714294433594, 2.3940534591674805, 1.7784230709075928, 2.1665525436401367, 6.451530694961548, 3.780392646789551, 1.1438837051391602, 5.304408550262451, 2.370227575302124, 4.3176867961883545, 2.684074878692627, 1.399301290512085, 2.0763766765594482, 1.3178224563598633, 1.7172164916992188, 2.3463408946990967, 2.026559591293335, 1.6395478248596191, 3.6522696018218994, 2.761030435562134, 3.6479129791259766, 12.4206862449646, 2.286123514175415, 22.083027362823486, 1.6587700843811035, 1.6161584854125977, 3.216477394104004, 1.430241346359253, 1.3101491928100586, 6.470303535461426, 1.3478927612304688, 1.5927257537841797, 2.5660130977630615, 1.5203306674957275, 2.1664540767669678, 5.069245100021362, 10.37515115737915, 3.059972047805786, 3.2614665031433105, 9.983915567398071, 4.003943920135498, 2.2027041912078857, 5.335612535476685, 6.05609130859375, 1.6690750122070312, 2.839592456817627, 2.6677865982055664, 1.9599547386169434, 1.1530044078826904, 11.52375316619873, 1.404404640197754, 1.441281795501709, 2.1566853523254395, 4.429488897323608, 2.4609475135803223, 2.877492666244507, 1.567617654800415, 1.326289415359497, 1.3895792961120605, 1.6838321685791016, 7.172287464141846, 2.4687438011169434, 2.013502359390259, 1.7708337306976318, 3.1939568519592285, 2.580177068710327, 1.7158050537109375, 1.229781150817871, 2.613921642303467, 6.974794626235962, 1.5917649269104004, 5.160931587219238, 1.900024175643921, 19.46753215789795, 1.635099172592163, 4.251370906829834, 8.029897212982178, 1.8520338535308838, 2.9993555545806885, 4.317518949508667, 3.0020484924316406, 24.30865478515625, 1.543515920639038, 5.56501841545105, 2.1103663444519043, 2.5562400817871094, 1.8484623432159424, 3.4936327934265137, 2.448371171951294, 1.8872718811035156, 3.4887402057647705, 2.329653263092041, 2.762343645095825, 4.188585042953491, 2.166377067565918, 2.05721116065979, 1.7323427200317383, 1.7802622318267822, 1.6114583015441895, 10.166800498962402, 1.3878538608551025, 5.745956897735596, 3.366044044494629, 2.179743766784668, 5.492403030395508, 3.0637047290802, 3.8144330978393555, 1.8706269264221191, 2.7987864017486572, 3.4232969284057617, 2.350620746612549, 5.86482310295105, 2.204941749572754, 1.928124189376831, 25.03522562980652, 5.0886313915252686, 2.3949830532073975, 3.1468429565429688, 7.223953723907471, 3.5864460468292236, 1.8653831481933594, 1.7990589141845703, 1.5829079151153564, 1.6141078472137451, 1.7352488040924072, 3.7669928073883057
            ],
            [
                3.226569175720215, 5.982784032821655, 1.9701085090637207, 3.032407760620117, 4.527009963989258, 3.8743948936462402, 3.50927472114563, 2.677292823791504, 4.335613489151001, 3.414398193359375, 2.0065033435821533, 8.184272289276123, 2.9701120853424072, 21.06943964958191, 2.633127212524414, 3.118410348892212, 3.3311233520507812, 11.922610759735107, 3.1431896686553955, 2.3967366218566895, 1.7876904010772705, 2.0278847217559814, 5.699926853179932, 3.008568286895752, 1.5537550449371338, 1.7761790752410889, 5.64853048324585, 2.6901581287384033, 2.694645404815674, 2.5208606719970703, 5.667191982269287, 4.986819744110107, 1.7711310386657715, 1.3488538265228271, 3.6499686241149902, 10.72648024559021, 3.3643958568573, 3.370333671569824, 10.104805946350098, 2.277083396911621, 2.471320390701294, 3.785860776901245, 5.732381343841553, 2.5253732204437256, 2.093459367752075, 2.1224565505981445, 2.254085063934326, 3.3625426292419434, 7.208090543746948, 3.6442997455596924, 1.9530158042907715, 2.3703043460845947, 6.056962490081787, 8.52448558807373, 3.5469865798950195, 2.403681755065918, 2.8796868324279785, 3.2335784435272217, 4.5732505321502686, 13.93368148803711, 1.536959171295166, 2.0244598388671875, 1.8061490058898926, 1.4609763622283936, 1.8059256076812744, 3.23529314994812, 4.084223508834839, 3.4529359340667725, 3.327188730239868, 9.336952209472656, 2.695162534713745, 2.3974688053131104, 3.064743757247925, 13.853090286254883, 2.8403549194335938, 1.3674781322479248, 7.731144189834595, 2.55210280418396, 3.572673797607422, 2.996328353881836, 2.7907321453094482, 1.751215934753418, 1.8256738185882568, 6.276418685913086, 2.4774646759033203, 3.5832912921905518, 3.8301315307617188, 5.065784692764282, 4.012378215789795, 2.387399911880493, 3.8170580863952637, 2.8697850704193115, 4.071581602096558, 1.744720220565796, 3.0242674350738525, 1.7823967933654785, 5.879639148712158, 24.547972917556763, 5.906580924987793, 2.8471150398254395, 7.237337589263916, 2.923729419708252, 3.2607595920562744, 3.182188034057617, 12.968800783157349, 4.450224876403809, 3.041780948638916, 2.9431169033050537, 5.948149919509888, 3.8112025260925293, 3.6511285305023193, 4.43986701965332, 10.026690244674683, 2.3629767894744873, 3.6225173473358154, 2.9665184020996094, 25.2521550655365, 2.946197509765625, 16.58014702796936, 3.624880075454712, 2.4448084831237793, 10.032482147216797, 2.5545201301574707, 3.3850998878479004, 3.3735744953155518, 7.221105337142944, 1.709122657775879, 2.8187472820281982, 2.0752432346343994, 4.2992188930511475, 4.680186986923218, 4.4926838874816895, 2.629633665084839, 2.3839104175567627, 4.567923307418823, 2.8964240550994873, 3.7846264839172363, 1.8847534656524658, 2.5864386558532715, 1.8860526084899902, 14.128082275390625, 1.9567313194274902, 2.673036813735962, 2.0270156860351562, 3.816462516784668, 2.8590219020843506, 3.8950374126434326, 3.5556387901306152, 6.41163969039917, 2.669989824295044, 3.298614740371704, 3.053804636001587, 3.637814998626709, 3.109035015106201, 4.121803283691406, 5.05661678314209, 2.5268406867980957, 10.276760816574097, 4.05029821395874, 4.173299789428711, 2.0285017490386963, 5.328871965408325, 4.994354963302612, 3.0266330242156982, 2.7745981216430664, 4.511628150939941, 1.8338658809661865, 3.1012322902679443, 26.681898832321167, 14.594772577285767, 14.26132845878601, 1.995199203491211, 2.461890935897827, 6.5650954246521, 3.268434524536133, 4.2060441970825195, 8.45395016670227, 2.8197619915008545, 2.824021100997925, 4.60947585105896, 3.6529834270477295, 3.782123327255249, 3.807180166244507, 2.3492212295532227, 6.7202112674713135, 4.629856824874878, 3.397583246231079, 2.619842052459717, 2.4866831302642822, 3.8346059322357178, 4.135109186172485, 2.172165870666504, 2.6655116081237793, 2.2219064235687256, 2.7836496829986572, 2.75079607963562, 3.09893536567688, 11.885525941848755, 4.617025375366211, 3.9609475135803223, 6.343640565872192, 3.5635645389556885, 2.434690475463867, 3.690046548843384, 2.4331655502319336, 2.245938539505005, 3.208864450454712, 22.217233419418335, 4.152047157287598, 6.094391584396362, 4.009148836135864, 2.7883856296539307, 2.7181999683380127, 6.047606945037842, 2.372530698776245, 10.307952880859375, 3.7432639598846436, 3.5592474937438965, 4.428303480148315, 2.396566390991211, 3.136463165283203, 4.347481727600098, 3.127610445022583, 2.8171231746673584, 3.058488130569458, 10.9069664478302, 3.455932378768921, 3.8812968730926514, 2.464705467224121, 2.601331949234009, 2.6908490657806396, 2.4372851848602295, 2.51108980178833, 3.2087206840515137, 2.6414003372192383, 7.141713380813599, 2.024770975112915, 3.756810426712036, 7.22942590713501, 3.051934242248535, 11.288331747055054, 5.544332265853882, 22.226015329360962, 4.23491907119751, 3.5404467582702637, 2.2811131477355957, 9.436755418777466, 3.1247425079345703, 4.186832904815674, 4.37584662437439, 2.601454257965088, 1.9079179763793945, 3.5722267627716064, 3.6360011100769043, 2.4991979598999023, 2.203608274459839, 5.094527721405029, 2.3948402404785156, 2.2433457374572754, 3.696302652359009, 21.244051694869995, 9.886967658996582, 4.295060157775879, 3.040428876876831, 3.770206928253174, 2.7317745685577393, 4.020162343978882, 6.1071155071258545, 2.267995595932007, 3.4510884284973145, 4.818058967590332, 4.743032455444336, 2.817681312561035, 11.856585264205933, 2.9538612365722656, 20.069509267807007, 2.933124542236328, 3.586066246032715, 3.5244905948638916, 3.81673264503479, 3.356081008911133, 3.854369640350342, 2.000272512435913, 4.088430881500244, 2.4061052799224854, 2.6249265670776367, 2.8160104751586914, 6.19146728515625, 4.396425485610962, 2.152390241622925, 2.2514290809631348, 3.6696431636810303, 8.483054161071777, 12.865769863128662, 1.7590110301971436, 1.703787088394165, 2.925896644592285, 2.8264248371124268, 3.724090337753296, 6.970319747924805, 3.8728673458099365, 2.7886266708374023, 5.101907730102539, 12.066317319869995, 9.63175630569458, 5.157976388931274, 2.9254202842712402, 3.0645010471343994, 3.0904433727264404, 2.594270706176758, 2.4056293964385986, 3.3073716163635254, 2.3358826637268066, 27.50315809249878, 4.198135614395142, 2.9856202602386475, 3.9775805473327637, 4.080864667892456, 12.957553625106812, 3.885246515274048, 3.5879569053649902, 10.017712831497192, 2.241238594055176, 3.3601012229919434, 2.8672640323638916, 2.9763524532318115, 2.6906280517578125, 3.685997724533081, 5.126179456710815, 2.660921573638916, 5.666288137435913, 2.9772214889526367, 2.9546682834625244, 2.7060770988464355, 2.8368113040924072, 4.043755531311035, 3.272067070007324, 13.036189317703247, 2.750335216522217, 4.454191446304321, 4.208281517028809, 4.8391547203063965, 2.7210752964019775, 3.35547137260437, 5.135641098022461, 3.6737568378448486, 4.344902038574219, 8.839090585708618, 2.5087196826934814, 2.3645520210266113, 3.4499471187591553, 2.102369546890259, 3.2305498123168945, 3.9473235607147217, 2.301114082336426, 2.562741279602051, 6.896066665649414, 8.757238388061523, 2.0831661224365234, 2.4401769638061523, 4.759253740310669, 4.844159841537476, 5.036044597625732, 4.2335474491119385, 2.671398878097534, 11.178825855255127, 2.337381601333618, 13.401407718658447, 3.2558693885803223, 4.8146586418151855, 1.9856586456298828, 5.926246881484985, 3.7196712493896484, 2.9402389526367188, 3.0925629138946533, 3.2143936157226562, 2.6716227531433105, 2.886078119277954, 7.7203991413116455, 5.26439094543457, 2.3969533443450928, 6.654831171035767, 3.387582302093506, 6.002479791641235, 4.017857074737549, 2.8216097354888916, 2.9592669010162354, 2.2618279457092285, 2.6621525287628174, 3.280254364013672, 2.94134259223938, 2.8412985801696777, 5.145834445953369, 3.723693370819092, 4.956719636917114, 15.399207592010498, 3.395986795425415, 25.10458779335022, 2.436471700668335, 2.290140151977539, 4.125765562057495, 2.6029446125030518, 2.3480374813079834, 7.6432013511657715, 2.4136645793914795, 2.6441683769226074, 4.6232404708862305, 2.948376417160034, 3.261303186416626, 6.687075614929199, 13.128108501434326, 4.2361063957214355, 4.422879457473755, 11.839470148086548, 5.19425368309021, 3.067579984664917, 6.9753124713897705, 7.779293537139893, 2.963545560836792, 4.088619232177734, 3.5719308853149414, 3.331266403198242, 2.2895867824554443, 13.678380012512207, 2.6589882373809814, 2.70815372467041, 3.0947940349578857, 5.6077351570129395, 4.117727041244507, 3.795450448989868, 2.767569065093994, 1.860962152481079, 1.7097930908203125, 2.3911187648773193, 8.688595533370972, 3.350907325744629, 2.901883363723755, 3.183152914047241, 4.420107126235962, 3.3808388710021973, 2.310075521469116, 2.2694106101989746, 3.595465660095215, 8.797299861907959, 2.763789653778076, 7.052568674087524, 2.7598774433135986, 25.16569471359253, 2.8839361667633057, 5.347482919692993, 9.478008508682251, 2.3179259300231934, 3.657592535018921, 5.302065134048462, 3.2988991737365723, 22.522145986557007, 2.0646934509277344, 6.305030345916748, 2.3860979080200195, 2.9182498455047607, 2.309379816055298, 4.132100343704224, 2.864154100418091, 2.0755231380462646, 2.3331401348114014, 2.023345947265625, 2.2552123069763184, 4.385568618774414, 2.4723222255706787, 2.4546244144439697, 1.9659671783447266, 1.837012529373169, 2.1470179557800293
            ]
        ], 
        [
            [
                14.13504672050476, 6.643536806106567, 14.322987794876099, 8.727133750915527, 12.074774980545044, 17.016431093215942, 44.39469814300537, 8.43496561050415, 27.15203094482422, 8.397366285324097, 5.285809516906738, 13.988829135894775, 3.899996280670166, 13.238822937011719, 6.799224376678467, 17.039714336395264, 3.6864144802093506, 24.246922492980957, 10.468846321105957, 22.01151180267334, 9.954501867294312, 12.545536041259766, 5.470430135726929, 8.235721111297607, 19.940320014953613, 5.170547962188721, 24.292343854904175, 7.546392917633057, 8.034991025924683, 37.488040924072266, 4.406641483306885, 4.03205680847168, 7.204914808273315, 11.604877948760986, 22.19936966896057, 7.246811151504517, 32.23373460769653, 6.195426940917969, 16.955864906311035, 9.225871086120605, 5.638361930847168, 12.152792692184448, 8.373802900314331, 14.933627367019653, 9.702550411224365, 10.230079889297485, 8.107486724853516, 6.437952995300293, 52.44209122657776, 12.71657419204712, 14.45408320426941, 8.178836107254028, 29.807032823562622, 7.393904209136963, 14.076227903366089, 10.853855848312378, 18.87202286720276, 8.331816673278809, 47.13361597061157, 32.850250482559204, 19.14024043083191, 7.813594102859497, 15.411895036697388, 5.1977269649505615, 7.398233652114868, 12.166958093643188, 5.546251535415649, 10.18563985824585, 6.24114990234375, 4.451425790786743, 22.9970600605011, 5.281791925430298, 8.193644762039185, 9.788020133972168, 12.636177062988281, 9.77734375, 9.267190933227539, 15.348628282546997, 21.909423112869263, 11.393722772598267, 9.421780586242676, 10.656216144561768, 9.411010503768921, 5.46008038520813, 73.00767636299133, 23.062660694122314, 11.868800401687622, 9.133431434631348, 15.33626675605774, 9.43037223815918, 9.095588684082031, 7.356077671051025, 16.794620037078857, 7.5953686237335205, 7.45907998085022, 7.300816297531128, 5.719620943069458, 6.599687814712524, 22.10853862762451, 11.49854040145874, 15.143710613250732, 7.3828442096710205, 5.220373868942261, 41.24876952171326, 14.467401266098022, 6.005532264709473, 12.064475059509277, 18.088552713394165, 9.692595481872559, 8.227149248123169, 9.754254341125488, 6.275760173797607, 22.59534454345703, 8.577623128890991, 5.367448806762695, 4.945881366729736, 4.627644300460815, 14.638313055038452, 7.2214391231536865, 15.600471496582031, 26.41933822631836, 57.235706090927124, 6.402780055999756, 18.519588470458984, 11.474486351013184, 5.1155686378479, 9.90021276473999, 4.773776292800903, 9.50310206413269, 7.060441017150879, 65.42549681663513, 10.06359601020813, 7.651517868041992, 16.87304711341858, 4.0902605056762695, 12.722256183624268, 24.121120929718018, 60.06872224807739, 10.083392858505249, 9.487313270568848, 10.033523321151733, 6.466915607452393, 4.7743330001831055, 11.366303443908691, 7.5815112590789795, 8.06456971168518, 35.33736205101013, 3.46042799949646, 7.631725788116455, 24.312726736068726, 8.957527160644531, 43.30180525779724, 23.515421867370605, 7.723651170730591, 6.1501946449279785, 6.455656051635742, 55.793768644332886, 8.857685804367065, 8.353749990463257, 26.803433179855347, 31.9404239654541, 5.716303825378418, 5.723100900650024, 6.689754486083984, 9.11918592453003, 11.988826513290405, 5.636993646621704, 9.569688320159912, 24.79384732246399, 9.252457857131958, 11.81212592124939, 5.872482538223267, 12.100241422653198, 20.221774339675903, 4.912020444869995, 8.101531982421875, 10.46786642074585, 4.582698822021484, 31.278342723846436, 3.835265874862671, 15.77814507484436, 13.608526706695557, 22.646175384521484, 25.34614086151123, 12.149401426315308, 11.549139738082886, 8.579358577728271, 6.765780448913574, 6.201290845870972, 19.539942026138306, 11.650189399719238, 12.774480104446411, 6.994599342346191, 5.601522445678711, 9.785366773605347, 7.73382043838501, 12.03802752494812, 46.828033208847046, 55.428248167037964, 6.173834562301636, 9.130842685699463, 14.632440328598022, 4.338165760040283, 6.971630811691284, 13.199448585510254, 26.563375234603882, 26.401800870895386, 10.68200135231018, 22.554494619369507, 8.44787883758545, 8.626760482788086, 25.226454257965088, 3.9463956356048584, 11.61643362045288, 9.438043117523193, 3.69893479347229, 4.3438193798065186, 17.42571520805359, 6.252614259719849, 10.064390897750854, 4.219004154205322, 18.72703981399536, 12.895825862884521, 48.29000449180603, 10.612698793411255, 18.007678031921387, 13.13792085647583, 43.98447227478027, 13.824566125869751, 8.409380912780762, 10.627373456954956, 6.762234926223755, 5.926272869110107, 10.184895038604736, 7.364484548568726, 8.508596420288086, 19.9880428314209, 12.262983322143555, 9.821865558624268, 15.575934171676636, 9.754586696624756, 10.76632809638977, 14.096184492111206, 6.940730094909668, 55.76835536956787, 9.805315732955933, 18.441522359848022, 5.908677339553833, 6.19050669670105, 9.465275526046753
            ],
            [
                17.0601909160614, 8.523519039154053, 15.317062854766846, 10.50206732749939, 14.342082738876343, 20.103845596313477, 48.02868318557739, 11.567522048950195, 30.511226177215576, 10.03878664970398, 6.453806400299072, 16.24085307121277, 5.773916959762573, 16.5120530128479, 9.876771450042725, 21.57613253593445, 5.673012018203735, 30.893014669418335, 12.802958726882935, 23.7434823513031, 11.943033218383789, 14.817287921905518, 7.126970052719116, 10.129679918289185, 21.28436851501465, 6.909835338592529, 27.953467845916748, 10.389947175979614, 11.586497068405151, 37.22792172431946, 6.589996337890625, 6.2124834060668945, 9.392419338226318, 14.992175340652466, 25.967051029205322, 9.462016105651855, 37.35657000541687, 7.549102067947388, 19.48299789428711, 11.863858699798584, 7.769118785858154, 14.941891193389893, 11.155472755432129, 17.171849966049194, 13.145987033843994, 12.458761215209961, 10.556135177612305, 8.742898225784302, 59.7716588973999, 16.386197090148926, 17.905104875564575, 10.698440313339233, 31.172932147979736, 9.425827741622925, 16.04270076751709, 13.422945261001587, 21.870399713516235, 10.629071712493896, 46.14730215072632, 33.707194805145264, 20.106887578964233, 9.519555568695068, 17.04540777206421, 6.618764400482178, 9.603165864944458, 15.203354597091675, 7.102583408355713, 12.270995140075684, 8.597406387329102, 6.5416624546051025, 27.62533473968506, 7.012095928192139, 10.60265326499939, 12.320058822631836, 15.479598760604858, 12.075124979019165, 12.05717420578003, 17.62878966331482, 24.829162120819092, 15.137894868850708, 11.969702959060669, 13.201308250427246, 11.624084234237671, 6.964832067489624, 76.68933868408203, 27.052295207977295, 14.484448909759521, 11.743532419204712, 17.859731197357178, 11.576428890228271, 11.591573238372803, 9.454928874969482, 17.96996569633484, 8.703932523727417, 8.99894642829895, 9.218722581863403, 7.238810777664185, 7.896920442581177, 23.977555513381958, 13.920378923416138, 17.781859636306763, 9.323963403701782, 7.020031213760376, 54.72940397262573, 18.637074947357178, 8.459012985229492, 15.050019025802612, 20.487958431243896, 12.691168546676636, 10.075062274932861, 12.79081416130066, 8.595545530319214, 24.774277687072754, 10.031963348388672, 5.669772148132324, 6.786661624908447, 6.266855716705322, 16.950127840042114, 8.537511587142944, 17.345942735671997, 28.93264937400818, 47.866795778274536, 7.424095869064331, 20.103856563568115, 13.377108573913574, 6.605891466140747, 12.593493938446045, 6.21387243270874, 12.07964539527893, 8.102169513702393, 71.45141220092773, 12.887939691543579, 9.630345582962036, 17.546321392059326, 6.041355848312378, 16.427870273590088, 28.417968273162842, 48.49124598503113, 10.635781288146973, 11.378876447677612, 12.613463640213013, 8.78909182548523, 6.258424758911133, 13.81572675704956, 10.259360074996948, 9.70791482925415, 41.421066999435425, 4.72163987159729, 9.941158771514893, 20.596582889556885, 11.701518774032593, 33.044219732284546, 28.791518211364746, 8.325964212417603, 7.410181283950806, 8.179991960525513, 58.75763773918152, 11.355474948883057, 10.907352685928345, 31.702977418899536, 23.21888279914856, 7.729116201400757, 6.975305080413818, 8.823009967803955, 13.089093685150146, 13.745083332061768, 7.473447322845459, 10.84105110168457, 27.628311157226562, 11.400563955307007, 15.410266160964966, 7.752861738204956, 14.95525574684143, 24.306840658187866, 6.109312295913696, 9.147010087966919, 11.575978994369507, 5.405757665634155, 28.796201705932617, 4.9641594886779785, 16.899033546447754, 16.601762294769287, 24.31104350090027, 27.635575532913208, 13.70483112335205, 12.820080995559692, 10.421739101409912, 8.671821594238281, 8.187026500701904, 23.46467900276184, 14.043275117874146, 16.911259651184082, 9.747852563858032, 7.724069595336914, 8.568644762039185, 8.582400798797607, 14.876900672912598, 36.811240911483765, 53.399152994155884, 6.998392820358276, 10.788227081298828, 17.331482887268066, 6.165582656860352, 8.69462251663208, 16.764945030212402, 35.247414112091064, 29.847418308258057, 13.56543779373169, 26.478355169296265, 10.495213270187378, 10.20238184928894, 29.239012002944946, 6.023600816726685, 13.930301904678345, 12.262597560882568, 5.61452579498291, 5.558778285980225, 22.047395706176758, 8.96989917755127, 13.329753875732422, 5.7898571491241455, 22.590572595596313, 15.79676604270935, 51.81870150566101, 13.019252061843872, 21.73551034927368, 16.390055179595947, 51.364989042282104, 15.52095651626587, 9.632445335388184, 11.848720788955688, 8.536629676818848, 7.4250829219818115, 11.56647801399231, 8.188414573669434, 6.15496563911438, 22.775827407836914, 15.524687767028809, 14.456343412399292, 18.873639822006226, 12.328993558883667, 12.708192110061646, 17.7517249584198, 8.886136054992676, 67.65368247032166, 10.857194900512695, 21.7303626537323, 7.2757408618927, 6.59699559211731, 11.79249358177185
            ]
        ],   
        [
            [
                67.31773042678833, 59.97956371307373, 160.1257803440094, 103.31810593605042, 49.250431537628174, 55.843337535858154, 64.43385028839111, 122.00954675674438, 56.71690225601196, 68.62684750556946, 86.6029121875763, 103.58272242546082, 22.32465887069702, 88.85153031349182, 95.9472222328186, 65.36881303787231, 49.49083757400513, 70.07261943817139, 54.579429149627686, 153.26697731018066, 106.72267460823059, 67.05953693389893, 81.23925185203552, 182.87208914756775, 68.88101077079773, 53.85119080543518, 57.34074640274048, 30.86008048057556, 78.27890586853027, 60.63566279411316, 60.266440868377686, 99.96439027786255, 55.30855345726013, 177.19287204742432, 91.67611193656921, 74.26545071601868, 62.65848684310913, 45.95880389213562, 33.729467153549194, 83.36678385734558, 57.488648414611816, 142.91337418556213, 45.093963384628296, 82.30222630500793, 42.758819818496704, 63.246208906173706, 25.782946825027466, 74.9639642238617, 168.66990685462952, 76.9375352859497, 37.73823690414429, 38.2355899810791, 175.10894012451172, 50.09345030784607, 99.0332179069519, 147.25709128379822, 41.96045923233032, 51.99401116371155, 109.60917735099792, 62.10821580886841, 135.9530429840088, 46.74380683898926, 161.176029920578, 119.31006383895874, 67.77096152305603, 46.324801206588745, 42.44867658615112, 103.10152816772461, 59.84921360015869, 81.44150304794312, 43.75065994262695, 79.71525764465332, 90.08837532997131, 129.34906363487244, 48.897741079330444, 73.98879981040955, 71.18097043037415, 31.5597722530365, 59.01558041572571, 185.33672738075256, 59.720964431762695, 52.06255626678467, 144.65125966072083, 79.39013910293579, 82.8301420211792, 55.201791286468506, 54.96039366722107, 51.418497800827026, 59.26886248588562, 158.68510818481445, 112.09624099731445, 159.6753900051117, 51.45852327346802, 40.04783082008362, 59.180492639541626, 86.82043838500977, 53.088594913482666, 163.41428995132446, 69.6328444480896, 36.7096643447876
            ],
            [
                83.78962016105652, 76.82368803024292, 181.0612587928772, 124.03245806694031, 60.098273277282715, 70.68021726608276, 84.4526596069336, 146.3571171760559, 77.22227787971497, 89.33310508728027, 105.20238184928894, 137.77591514587402, 34.63622045516968, 110.81378054618835, 115.73984289169312, 84.5052695274353, 62.61405396461487, 86.99343824386597, 67.94790840148926, 186.70507383346558, 141.5990002155304, 87.00840091705322, 104.0967366695404, 218.00158286094666, 86.08132982254028, 66.87951326370239, 71.03195285797119, 45.346476316452026, 96.20641779899597, 80.64815306663513, 81.35776710510254, 123.67409205436707, 70.3810453414917, 204.96035814285278, 110.82065725326538, 89.40079379081726, 78.82569026947021, 60.08606672286987, 46.69007229804993, 102.46454977989197, 83.4853241443634, 165.04657101631165, 60.441789388656616, 99.08323860168457, 58.16794991493225, 82.38488245010376, 39.32291316986084, 90.71974611282349, 208.18652963638306, 93.8502745628357, 55.36384320259094, 54.68475413322449, 198.8036503791809, 61.248743295669556, 123.74823260307312, 158.16608953475952, 55.47226643562317, 67.79673266410828, 127.65112662315369, 81.74372029304504, 153.4009211063385, 59.70505619049072, 177.1966531276703, 115.03999590873718, 81.5710129737854, 63.207497119903564, 61.27553701400757, 115.40037870407104, 79.37888407707214, 88.25241780281067, 56.94569396972656, 87.92313122749329, 90.2315022945404, 155.14581036567688, 68.40500497817993, 92.12454795837402, 89.05607223510742, 44.14599633216858, 77.82099866867065, 202.99726629257202, 71.63643217086792, 69.534832239151, 169.22394108772278, 103.8071072101593, 105.02691531181335, 73.24324607849121, 66.65484595298767, 67.4938337802887, 76.14901113510132, 174.22008061408997, 111.78954148292542, 158.95690441131592, 57.11946749687195, 53.436670780181885, 74.10971546173096, 107.38695096969604, 68.82295083999634, 185.7761685848236, 84.83388781547546, 49.74272155761719
            ]
        ],  
        [
            [
                9313.321469068527, 9513.348496198654, 10081.760856628418, 9697.71790933609, 9849.607594490051, 8427.687427520752, 7819.219457864761, 9075.831291913986, 9303.58086180687, 8877.326451778412
            ],
            [
                9908.079588413239, 9998.970449924469, 9756.591591596603, 9917.700372219086, 10426.1523168087, 11946.905452728271, 11762.42085313797, 11679.036692857742
            ]
        ],
        [
            [
                66.713757, 27.303638, 28.933013, 15.040427, 31.832221, 15.822427, 39.659982, 16.17639, 49.957405, 16.892539, 71.813707, 59.22021, 40.204244, 89.076626, 66.949182, 22.410824, 21.787291, 22.674498, 91.928393, 46.050556, 45.436041, 46.135238, 46.214144, 24.212086, 47.954019, 49.161428, 24.774572, 543.030172, 50.92655, 25.253184, 26.008995, 52.089157, 27.438542, 59.124583, 54.253089, 53.13916, 52.876159, 53.474895, 27.498166, 81.529547, 27.517216, 54.645572, 55.073375, 55.718001, 56.197316, 55.545122, 56.367325, 55.324673, 55.631132, 58.011412, 29.192948, 29.434539, 58.581264, 42.27576, 58.834052, 59.455832, 63.181528, 59.88227, 30.029715, 30.670623, 60.469143, 90.384191, 62.116117, 91.009873, 61.972065, 62.10329, 62.037815, 63.112592, 127.465099, 62.127594, 63.912351, 49.210021, 62.929781, 64.763315, 111.806609, 64.146391, 63.642399, 65.067513, 32.834886, 32.783628, 32.907109, 33.435734, 67.354955, 65.163417, 33.81026, 66.891651, 336.836146, 66.299415, 66.625926, 67.025504, 34.377081, 100.488107, 69.035865, 34.529896, 34.158856, 102.658906, 68.734358, 67.207508, 102.430754, 34.479178, 68.926058, 68.762973, 68.847611, 69.293594, 125.490163, 69.670868, 69.482525, 70.222211, 35.737868, 69.314755, 171.349481, 105.317721, 70.12058, 104.820062, 36.196355, 70.268987, 70.714814, 70.275466, 35.310807, 37.169552, 71.092015, 70.173878, 36.220102, 71.067662, 71.065286, 71.027194, 70.902011, 70.463353, 237.613465, 36.718967, 36.402745, 71.905121, 36.968681, 71.312711, 72.028328, 71.502168, 71.982348, 71.231912, 36.615173, 36.704, 72.393682, 36.839928, 36.750586, 108.988475, 71.871456, 72.832602, 196.87902, 72.712106, 72.462307, 72.962539, 36.959872, 73.665186, 37.652796, 37.014514, 172.832798, 73.079304, 155.028575, 74.114117, 75.998182, 73.654732, 87.880411, 75.03358, 74.302367, 117.183801, 74.75444, 189.703566, 73.118068, 37.512824, 74.925125, 74.089314, 74.425734, 63.355518, 112.322403, 37.786912, 73.362124, 74.542727, 110.312629, 74.122876, 75.525088, 74.205304, 38.071936, 37.776551, 37.062789, 75.160551, 73.691666, 74.687334, 97.13263, 38.248381, 125.632069, 74.680612, 38.427063, 75.147329, 76.199641, 75.377472, 38.717832, 74.708955, 123.486298, 38.199919, 38.638698, 103.227113, 76.06351, 77.280838, 76.25736, 75.785727, 75.703777, 76.113636, 38.727361, 76.471439, 76.197064, 39.407531, 39.194357, 76.080404, 76.100145, 77.151177, 108.04195, 76.206087, 76.996669, 114.270728, 80.6434, 38.978655, 39.181544, 76.494713, 50.735464, 41.684434, 77.170943, 69.348997, 77.598529, 38.582697, 127.366524, 39.516122, 75.876952, 77.92682, 128.475328, 39.525023, 39.878575, 324.180485, 79.949708, 79.719327, 80.881544, 57.76456, 77.470235, 39.596038, 41.227166, 78.107912, 127.80863, 119.494056, 78.380629, 67.091887, 77.94742, 78.013164, 77.77475, 55.168014, 49.24549, 123.843258, 78.029063, 77.661388, 79.008292, 39.569581, 77.19768, 77.726212, 1133.255177, 78.166559, 78.477081, 79.244246, 89.686172, 78.717798, 129.193391, 79.120047, 39.821531, 79.609262, 79.566871, 78.368102, 40.720032, 78.094254, 78.476153, 79.348635, 39.463069, 121.35294, 79.072339, 79.25479, 79.06358, 40.251953, 40.241444, 40.003901, 80.349713, 41.036068, 78.504932, 40.78523, 40.369834, 274.330949, 80.436071, 40.721706, 79.447138, 40.655898, 40.845606, 40.647547, 40.870384, 43.225411, 40.913119, 120.718427, 81.822727, 41.404454, 81.501698, 41.116529, 103.038085, 163.474075, 41.398907, 41.596297, 81.047188, 80.956592, 213.852896, 40.406971, 108.48261, 40.852201, 83.128386, 82.127013, 81.374926, 183.223125, 41.000612, 42.032379, 82.160727, 124.131868, 83.122767, 41.079359, 41.892745, 65.408521, 82.017948, 42.144266, 125.02262, 81.534171, 81.633011, 82.242208, 41.564043, 41.823882, 81.498716, 41.906614, 41.877378, 82.451207, 278.919459, 81.838683, 125.122128, 84.574828, 125.268392, 82.437383, 83.318291, 81.945805, 42.469404, 49.189312, 42.257321, 83.18552, 41.805967, 42.039089, 42.546135, 136.028361, 82.546001, 82.660854, 83.307875, 41.708755, 208.686743, 751.419697, 42.451352, 42.360238, 83.200869, 42.268444, 82.502676, 42.251266, 62.209919, 125.910007, 42.25959, 82.802381, 83.418793, 53.971815, 92.107618, 126.601657, 42.098094, 283.77618, 82.657851, 81.913344, 42.462012, 41.540281, 82.627653, 83.64133, 84.295825, 42.679684, 85.529099, 98.336605, 42.422308, 85.439021, 82.407727, 84.865541, 82.416464, 84.160984, 42.956339, 84.351053, 83.999117, 42.505868, 42.752769, 124.842071, 83.800278, 84.762552, 82.768162, 42.453274, 84.278681, 84.286084, 42.484763, 85.398688, 42.582923, 84.128597, 84.757037, 85.607728, 84.263131, 84.670191, 171.682096, 43.021438, 83.232996, 127.29775, 85.073353, 84.709025, 83.425694, 42.977644, 236.118506, 84.364649, 131.21293, 43.091418, 84.847899, 43.055565, 83.821867, 85.31438, 84.539636, 84.496853, 43.012511, 84.995355, 43.619355, 85.636472, 84.998302, 85.18621, 43.108799, 84.054441, 85.075593, 85.686936, 109.748295, 84.657322, 85.257538, 131.429853, 89.480384, 83.982965, 190.644954, 84.859968, 257.738793, 85.624993, 84.403099, 43.261113, 44.119645, 43.731463, 85.91148, 85.815451, 43.694477, 85.193725, 133.972425, 132.089985, 43.866147, 156.863719, 85.4262, 43.936632, 84.952353, 54.977668, 84.36631, 85.792475, 192.297877, 107.391962, 43.099183, 45.640424, 43.033624, 85.213094, 85.456077, 44.004802, 43.530174, 128.801028, 87.061416, 85.781104, 44.411654, 85.351723, 85.485404, 87.951457, 43.889436, 86.896698, 86.138195, 86.584472, 135.553232, 86.371567, 85.725497, 85.120807, 84.786604, 85.256454, 85.4034, 85.619678, 43.385827, 44.244304, 43.530937, 84.987281, 44.867717, 43.745726, 85.421575, 44.196163, 85.162945, 86.535738, 44.035272, 143.221359, 44.042619, 86.551179, 86.288466, 133.865566, 86.029882, 44.140498, 87.471962, 99.890382, 44.226022, 44.352523, 87.482866, 44.616035, 87.737413, 87.620566, 147.058259, 86.414521, 129.841128, 43.974903, 86.366122, 194.785927, 131.066746, 44.415524, 44.69832, 86.128853, 43.935658, 43.922133, 86.483004, 87.783421, 44.184387, 87.725785, 87.351792, 174.520182, 86.414953, 85.951607, 87.853843, 44.453355, 44.427136, 87.864874, 43.753312, 55.928378, 88.542917, 44.002256, 87.489991, 43.914896, 45.294568, 44.051134, 87.170183, 44.429414, 44.570531, 93.562119, 134.356898, 86.514711, 67.681642, 88.113893, 43.947618, 89.468989, 43.66146, 88.247773, 89.912108, 44.727448, 87.94474, 44.545046, 89.949322, 86.685467, 44.835805, 184.230038, 82.0003, 45.022281, 88.926271, 132.281761, 46.231257, 45.548515, 87.248042, 89.129903, 44.460474, 87.93096, 182.851536, 88.601861, 45.132324, 87.612324, 88.409741, 88.519623, 87.264771, 131.730431, 44.092482, 87.210122, 71.444787, 144.98817, 43.97733, 44.759032, 87.291294, 44.915594, 236.837057, 88.441342, 87.689911, 44.579153, 88.908918, 136.461134, 131.905189, 45.850509, 89.014673, 162.141542, 88.518189, 88.029493, 44.87327, 88.793981, 131.387328, 150.13017, 133.351865, 90.769532, 90.425248, 127.476954, 91.67609, 44.579687, 65.360815, 45.500159, 45.03859, 92.461691, 145.437636, 45.066094, 88.31065, 88.2984, 91.838556, 44.348023, 45.094143, 91.013345, 88.180833, 135.704687, 88.719671, 89.669771, 144.95943, 89.13188, 45.713421, 44.651707, 89.028747, 45.078857, 89.522621, 89.024619, 45.059007, 45.102056, 44.951649, 89.35762, 143.555043, 133.379848, 134.248595, 45.522591, 89.349819, 89.5242, 45.350031, 101.556952, 89.039098, 92.047133, 88.804842, 88.97735, 45.505438, 89.524835, 45.593193, 45.216027, 45.677691, 88.064723, 88.855418, 89.617802, 45.962319, 45.34211, 91.029252, 89.891928, 133.13554, 45.495275, 88.952363, 89.650522, 89.621723, 45.901407, 45.224776, 44.739195, 45.900826, 45.736698, 56.919374, 184.703459, 89.348325, 89.59971, 90.973746, 45.240572, 89.230502, 90.381023, 94.094599, 45.319457, 145.373824, 89.956725, 153.488662, 89.399511, 45.506687, 90.343112, 45.987479, 45.766716, 139.683526, 45.158676, 45.253869, 90.669727, 45.480976, 89.383511, 185.883089, 90.069485, 209.223333, 90.092001, 100.868751, 45.560075, 45.402616, 45.152845, 139.009184, 89.048108, 755.065929, 89.653401, 46.211217, 45.99126, 45.554375, 137.093416, 93.301991, 92.792485, 115.24227, 90.541191, 89.834898, 90.175815, 90.475667, 134.676555, 90.248697, 46.067756, 89.6518, 190.227383, 91.194691, 90.057443, 151.818727, 137.743483, 136.351115, 46.180616, 92.006987, 90.205523, 90.8689, 45.740673, 45.97964, 45.935519, 46.681639, 131.433554, 142.044572, 46.322141, 89.584428, 46.683903, 89.337708, 46.676133, 46.041123, 247.599752, 89.872382, 90.052084, 46.176728, 197.796776, 482.558087, 90.967778, 91.504552, 90.832535, 93.147354, 45.902807, 141.888179, 47.626295, 91.680468, 46.999436, 138.81739, 90.492805, 92.621346, 46.749901, 46.795951, 91.077987, 91.442992, 46.104046, 92.193083, 94.416689, 139.870863, 92.722111, 137.944494, 46.746843, 47.77905, 91.859031, 92.590896, 46.105342, 46.999895, 137.556408, 91.898069, 164.628375, 45.541328, 91.760664, 91.65391, 93.713244, 93.527157, 92.504534, 140.091486, 46.665132, 93.479052, 92.899861, 46.920306, 46.664031, 54.742769, 47.29509, 90.918197, 91.579336, 91.452632, 46.304044, 91.410086, 129.820072, 92.22536, 94.397071, 46.805697, 91.627497, 94.31765, 95.134614, 93.628171, 91.326928, 97.101085, 46.453335, 153.140756, 46.723949, 91.400212, 92.010416, 91.498381, 113.83929, 52.45629, 100.758786, 112.279287, 94.307017, 47.114942, 91.926522, 141.069123, 121.776767, 92.390385, 95.361372, 109.744698, 91.693717, 47.78111, 231.259774, 67.802159, 95.794351, 101.221251, 93.795449, 47.43927, 94.406226, 201.314465, 48.596535, 145.891384, 92.313905, 114.10112, 95.226556, 48.75766, 48.36167, 48.60395, 50.225746, 48.451972, 96.324459, 49.201782, 144.295512, 48.782471, 95.196768, 121.588209, 95.872603, 49.038592, 95.367644, 48.982979, 58.855872, 96.004627, 103.885395, 48.325732, 95.992926, 94.837659, 96.527022, 48.580488, 97.975987, 47.330459, 96.344848, 95.735838, 139.346712, 49.279831, 97.494802, 95.409549, 212.019933, 142.774046, 49.565535, 49.447254, 97.160424, 49.224574, 100.249271, 95.163381, 109.804456, 94.869917, 48.908309, 97.171386, 96.814189, 48.384334, 94.226537, 93.997504, 48.040954, 94.408005, 94.73421, 91.548637, 47.726458, 138.14682, 91.96105, 93.246831, 92.280501, 101.998814, 47.318336, 92.71193, 93.513156, 148.295716, 94.449524, 102.949458, 47.303112, 47.357177, 92.979858, 92.828688, 48.043317, 95.595589, 94.14516, 166.849136, 93.488669, 93.643794, 94.579789, 92.291782, 94.587506, 47.304602, 154.71618, 92.94248, 92.477909, 94.3259, 143.781634, 96.592627, 51.942326, 103.370185, 100.713888, 101.837237, 51.726309, 51.518912, 103.62765, 101.793373, 102.409624, 101.017369, 91.638514, 116.64703, 100.840015, 101.018337, 51.294129, 51.935383, 101.510679, 51.467388, 101.17447, 51.644209, 51.070291, 51.227925, 51.61632, 356.621141, 51.739739, 101.769576, 100.470574, 51.12466, 100.771773, 51.529595, 101.223234, 51.248169, 167.899297, 51.543892, 152.565922, 51.386336, 101.292925, 51.048394, 167.755422, 100.472413, 101.846515, 51.983355, 51.514055, 101.461408, 103.347919, 101.837715, 115.650021, 100.61766, 160.094142, 100.174788, 51.369717, 101.022528, 51.189568, 51.641091, 51.34715, 100.833418, 101.154303, 101.103924, 51.818392, 109.371802, 101.886867,
                2.064632, 13.897698, 8.175998, 4.452423, 8.970353, 19.352669, 13.659489, 18.213639, 16.863995, 82.593065, 28.415293, 27.160618, 27.442423, 42.374424, 33.837799, 30.403061, 29.245424, 31.153731, 16.674541, 16.509296, 32.237468, 18.057135, 17.148432, 34.884817, 45.413078, 40.673843, 35.28101, 35.347249, 48.244873, 39.978783, 20.657704, 46.550522, 39.107512, 38.701856, 50.90647, 86.305564, 38.120477, 210.929576, 39.247538, 39.732839, 40.345053, 20.53701, 40.094937, 261.608498, 21.23978, 41.97542, 42.0561, 43.043164, 44.073908, 83.758083, 43.84687, 22.999035, 45.382462, 715.795131, 50.869615, 45.3082, 1613.43959, 44.949273, 24.075769, 46.229213, 1745.439102, 46.968234, 857.460771, 24.652799, 24.332831, 50.343865, 50.194381, 25.881387, 50.818538, 50.861149, 51.209645, 26.053925, 53.150365, 51.467007, 209.844044, 52.810534, 26.851263, 27.021168, 27.266647, 54.199375, 644.742676, 70.231576, 27.645285, 54.535459, 130.464942, 57.559808, 179.676081, 54.721097, 28.399859, 136.751992, 60.646892, 57.710749, 28.739275, 55.986686, 58.178115, 28.933249, 57.695267, 57.923947, 60.927511, 56.69873, 58.170751, 88.229174, 58.406197, 60.562184, 58.378488, 29.276068, 77.447808, 58.36571, 58.975856, 61.943305, 58.922369, 63.482996, 59.427372, 59.240384, 57.88804, 58.522309, 33.378958, 66.227487, 62.552844, 84.60547, 30.151375, 62.216124, 30.377027, 62.162726, 61.173059, 30.550941, 122.467335, 65.676857, 30.578318, 59.671175, 31.125318, 31.281929, 116.914087, 110.36886, 109.39567, 30.938746, 61.043915, 31.566788, 61.963205, 334.71325, 278.927918, 69.108251, 32.554389, 112.3094, 63.187418, 68.274018, 63.964841, 65.350432, 32.790411, 64.999737, 33.035032, 66.017012, 33.70161, 34.144202, 70.667754, 33.424859, 65.917777, 70.43545, 34.695694, 421.255813, 1045.870461, 33.326299, 65.959765, 34.977667, 67.917144, 66.14938, 105.1235, 33.992265, 83.284971, 66.510385, 67.627505, 34.568509, 34.501059, 444.514549, 78.622274, 67.606561, 68.481323, 68.832065, 67.612047, 90.552208, 68.358446, 68.479427, 71.505055, 35.321882, 89.72953, 5797.757577, 68.434982, 69.862904, 134.936089, 71.152359, 35.574357, 208.610842, 35.671099, 669.780704, 36.553608, 75.806698, 72.161432, 344.066899, 89.144169, 71.00266, 35.840958, 35.875245, 73.748276, 76.770145, 74.799543, 76.882246, 73.628485, 36.401509, 71.484921, 78.951068, 36.160012, 73.479281, 36.081847, 38.907757, 37.503495, 71.211135, 71.887087, 36.55565, 39.888201, 77.823424, 37.089025, 73.076715, 36.915938, 84.895377, 38.008847, 74.382316, 37.008677, 37.333939, 74.663132, 74.404083, 74.8939, 73.840648, 73.294326, 214.441832, 75.430904, 73.476657, 37.604886, 72.96329, 38.440028, 120.653424, 74.631877, 38.511215, 290.780962, 37.644506, 73.713423, 77.158621, 76.240605, 76.850592, 78.956447, 73.860593, 73.64461, 76.466696, 37.597917, 74.456984, 73.342101, 76.298117, 38.409054, 74.296646, 74.155746, 74.694658, 77.369937, 105.930811, 37.796101, 79.842599, 83.651568, 38.708006, 38.729266, 79.685267, 76.257566, 75.053381, 74.78697, 38.901122, 74.702419, 38.935258, 38.157168, 38.7071, 40.744373, 75.383106, 74.831009, 77.416289, 77.353716, 77.206912, 93.47784, 40.007197, 76.714944, 81.148021, 42.393202, 96.820792, 111.440406, 76.024642, 39.128535, 77.39078, 39.077953, 77.847697, 78.238495, 77.248389, 39.332949, 77.822124, 40.22121, 94.613455, 80.508403, 39.500431, 39.329169, 39.472895, 40.200899, 77.804682, 85.798269, 39.856333, 81.817371, 77.307109, 78.526438, 745.055547, 78.512303, 78.648767, 87.293395, 79.938758, 84.305332, 40.206954, 78.580528, 83.556352, 78.585588, 102.642493, 40.659116, 109.410624, 79.188393, 87.779562, 40.407735, 40.632556, 80.960064, 810.489332, 79.935843, 40.18016, 80.638283, 78.972297, 42.863525, 40.421602, 126.183323, 78.794268, 40.294266, 241.211816, 324.503817, 78.898027, 112.064839, 540.422284, 40.308134, 80.453103, 40.685225, 40.471297, 80.164052, 112.000002, 80.983475, 41.376355, 41.506608, 127.476848, 78.458895, 265.133454, 46.148539, 40.55101, 43.431624, 80.703406, 80.078916, 79.320847, 80.041656, 40.676866, 80.10318, 93.619997, 114.743352, 146.799702, 310.526034, 321.035742, 92.548912, 79.080014, 84.044563, 80.266303, 41.183809, 82.703195, 82.530692, 41.15346, 84.651849, 82.721172, 41.968588, 82.582045, 108.121141, 81.375023, 81.532312, 82.066058, 80.966906, 80.812769, 41.611181, 41.554635, 83.162766, 41.755149, 81.173098, 2980.277605, 42.192816, 81.317396, 41.962078, 41.455844, 41.969445, 41.84896, 41.966722, 82.054265, 42.28359, 82.106324, 82.613188, 42.081127, 573.962319, 89.732736, 82.62494, 82.571789, 84.907887, 42.150245, 109.146629, 109.539476, 83.547005, 84.363341, 82.503479, 90.314768, 82.545295, 44.262729, 86.232167, 42.263003, 83.838719, 91.584318, 84.667907, 90.208076, 43.243946, 154.779602, 83.42722, 106.399129, 46.288789, 84.099093, 186.259409, 42.762261, 82.601438, 92.76667, 42.737617, 88.37318, 95.161407, 83.473293, 84.73406, 42.919716, 83.886353, 217.46784, 92.720917, 131.240367, 824.785658, 85.483934, 85.469085, 85.108305, 84.667514, 43.335652, 42.541154, 85.166423, 89.414788, 43.093705, 84.576002, 84.062208, 42.470825, 142.155602, 86.734421, 84.127932, 42.913665, 42.947909, 43.352485, 100.178145, 84.932998, 95.729863, 1271.746639, 84.770633, 85.091392, 93.124173, 84.619665, 331.145629, 42.583308, 43.487181, 5518.666288, 83.703192, 85.333123, 84.554718, 85.359256, 84.269949, 87.164132, 110.024928, 44.242233, 85.732301, 43.356246, 85.185313, 43.190723, 108.550292, 43.207819, 86.61046, 43.123186, 43.675255, 674.321123, 83.701443, 43.43784, 86.250137, 85.97901, 85.163926, 43.320863, 85.672317, 85.781931, 85.005584, 86.789762, 44.126879, 43.39245, 84.011177, 86.696917, 85.676431, 44.11326, 113.762343, 85.020795, 88.163869, 84.489756, 84.75742, 86.37105, 86.0388, 87.068721, 92.197453, 85.690054, 44.616951, 84.732778, 96.743404, 43.941967, 87.698316, 86.805621, 300.891064, 44.431457, 229.940961, 44.127139, 45.554126, 88.03284, 88.916336, 2828.531173, 89.852274, 44.773153, 43.537793, 44.270462, 88.939357, 87.447076, 102.795027, 94.618484, 87.015946, 651.600216, 87.542564, 91.098904, 87.897756, 85.371731, 91.476218, 44.340617, 86.878346, 123.810205, 86.645257, 87.694929, 43.995387, 45.045434, 86.5654, 45.191437, 45.006457, 87.338817, 270.771703, 89.894468, 89.549949, 89.520763, 859.531724, 44.352807, 87.169661, 90.861555, 45.101661, 89.197526, 87.216427, 86.416281, 45.296454, 86.91046, 226.697365, 88.756218, 89.287565, 87.666581, 87.151067, 44.277519, 87.968611, 88.798467, 44.83917, 87.879786, 90.362204, 256.550279, 86.454091, 89.491182, 90.949333, 733.771059, 86.949335, 89.161989, 44.191228, 88.36207, 87.572974, 87.961974, 44.75385, 87.247446, 88.824037, 45.643262, 57.555361, 356.944251, 87.649242, 87.96198, 90.217924, 88.487844, 44.763044, 44.254681, 86.912216, 186.484666, 45.787405, 88.2031, 45.506735, 89.650792, 89.665439, 88.277721, 44.945838, 162.821579, 89.289873, 44.932547, 88.173827, 89.199371, 88.742573, 87.878249, 45.044117, 46.16641, 92.299209, 44.743596, 90.164185, 142.512339, 88.180557, 44.856384, 94.148087, 88.521809, 91.097407, 45.988165, 47.07744, 89.439516, 88.239157, 97.809639, 88.066097, 87.732934, 44.788143, 112.881715, 89.287624, 88.131944, 88.578193, 45.09487, 88.700105, 89.449509, 93.577233, 90.899397, 89.635338, 88.908978, 45.178971, 154.277773, 89.648278, 45.030797, 45.382141, 45.414136, 186.62864, 91.649928, 88.72147, 45.266743, 100.401233, 903.502366, 95.246688, 89.322155, 91.931467, 45.368675, 89.885459, 136.541355, 87.655066, 149.073806, 88.272658, 94.898428, 667.042308, 90.172599, 117.152358, 88.810845, 91.085752, 91.355147, 45.168036, 45.480282, 303.045082, 94.697747, 292.263176, 88.871695, 45.241804, 89.461754, 160.696861, 45.654397, 45.705047, 89.916534, 95.017635, 45.564501, 107.592362, 89.677085, 95.298025, 89.498746, 45.41191, 91.997732, 89.493036, 100.23763, 92.030949, 118.555999, 122.564159, 93.670614, 45.426678, 93.303165, 46.021398, 93.527193, 94.537693, 91.344835, 129.713678, 862.429757, 46.07122, 232.903923, 90.141225, 89.297755, 92.338143, 89.992374, 96.637707, 89.469295, 232.602861, 90.744961, 89.02822, 88.727796, 133.272239, 726.692755, 46.078343, 95.666262, 172.32373, 90.151852, 45.785121, 46.087406, 45.508339, 90.839543, 90.3024, 89.543839, 90.060743, 90.534534, 45.82872, 46.021921, 89.339961, 48.043095, 45.721271, 89.483085, 92.157455, 1914.220237, 94.233175, 46.515897, 90.733012, 45.796082, 110.320009, 45.697814, 107.810856, 92.700577, 90.082533, 89.810539, 588.098991, 48.054799, 93.315165, 90.805503, 92.250634, 91.774196, 46.106527, 90.319914, 120.977462, 46.673775, 153.141828, 46.354175, 46.455069, 46.091865, 46.447028, 123.736851, 590.482286, 89.719362, 46.156406, 46.050539, 92.662285, 92.379369, 101.908442, 46.221248, 92.429815, 45.720495, 121.891149, 94.818122, 91.035336, 93.056189, 46.428459, 46.052549, 100.412673, 91.552748, 90.269396, 91.828053, 94.745275, 89.977321, 339.02415, 91.352101, 181.161864, 46.259625, 101.807607, 96.027833, 46.869473, 96.3764, 221.26285, 582.845426, 92.554847, 46.886153, 46.269587, 90.691499, 91.525216, 47.248618, 46.650461, 61.76688, 46.450033, 91.726466, 47.246392, 95.923944, 47.634408, 93.200346, 50.505338, 319.61822, 94.567637, 46.542154, 46.401375, 46.996424, 101.58165, 97.048565, 46.988948, 47.033005, 563.341597, 93.091944, 121.366488, 47.261467, 91.851932, 92.860225, 109.492229, 46.869118, 96.306218, 49.427531, 207.979108, 46.732714, 93.167119, 145.657814, 95.933865, 95.110296, 283.276529, 676.510867, 97.683609, 95.904569, 46.780857, 91.547201, 46.830218, 105.836423, 101.073102, 92.734127, 92.131777, 47.046048, 98.891685, 47.446062, 48.888184, 47.588869, 91.261336, 91.825565, 46.985377, 94.55655, 98.324217, 94.990701, 91.041447, 94.305858, 160.836286, 46.589553, 100.759029, 47.204925, 92.373656, 46.544367, 92.545741, 94.796853, 47.211429, 47.293466, 91.91095, 46.983797, 97.551021, 47.373605, 47.029468, 98.848891, 162.704818, 47.617632, 47.417868, 92.935987, 49.395816, 47.867924, 91.505779, 46.93956, 374.139156, 566.178656, 93.925708, 121.598418, 107.634737, 101.400135, 47.13911, 95.106836, 96.511205, 98.27241, 91.538619, 93.69825, 47.836629, 47.007948, 94.9818, 48.193446, 105.039807, 47.302324, 47.514319, 92.228012, 92.963711, 47.119025, 47.364752, 162.766147, 92.443944, 91.9382, 444.005093, 94.095655, 47.425347, 115.444313, 848.893755, 92.675779, 94.612133, 47.637565, 47.346658, 47.09145, 94.671731, 776.873399, 94.153023, 94.052842, 180.217479, 93.804709, 180.986455, 103.771313, 47.615792, 48.295993, 124.970207, 47.345699, 94.11115, 98.315169, 94.316947, 95.217304, 92.984565, 93.064323, 99.905599, 134.410401, 94.899552, 193.547561, 47.363085, 92.727701, 6770.431421, 48.042637, 48.096192, 93.114544, 47.984706, 94.006872, 47.959252, 94.293421, 100.608875, 348.50169, 49.089751, 898.075068, 341.846087, 95.246525, 47.900507, 95.052267, 1044.007409, 365.816741, 153.661645, 47.919267, 101.392522, 47.703236, 47.57426, 93.328653, 97.674042, 48.255573, 127.390638, 179.940532, 99.269994, 95.343759, 49.271174, 168.728621, 94.339346, 48.259884, 47.952879, 47.735963, 47.93292, 47.784124, 345.494122, 183.296558, 47.895655, 96.241742, 93.633729
            ],
            [
                75.678666, 40.315424, 28.045789, 14.367179, 47.975924, 16.086629, 51.188264, 31.962981, 49.494796, 32.750834, 53.148805, 37.882628, 38.263466, 105.690049, 60.693504, 38.417247, 19.473744, 39.318537, 69.253935, 39.168172, 40.09744, 40.586181, 40.881421, 41.525616, 42.902821, 43.134277, 21.729024, 334.342987, 67.46461, 45.190763, 23.668568, 68.700342, 45.967513, 80.163963, 100.534459, 47.067297, 47.155886, 47.597054, 48.115567, 97.353999, 47.831647, 48.475999, 48.268105, 76.602074, 49.070508, 72.403153, 49.256515, 49.541184, 48.627753, 49.429113, 25.260736, 49.758585, 50.593801, 39.910717, 74.304407, 49.736393, 80.831098, 51.1056, 26.025361, 51.136212, 52.145443, 76.962412, 50.44878, 78.294174, 51.867302, 26.089259, 52.009257, 53.289167, 83.835104, 52.178042, 26.961946, 47.516123, 53.451227, 52.91267, 95.321397, 53.736757, 27.319438, 53.776115, 27.293112, 28.009075, 54.331136, 28.031742, 88.158263, 27.721178, 27.708173, 55.169479, 249.039767, 55.316096, 55.196592, 56.318305, 56.442026, 84.480945, 83.925266, 56.540859, 29.303904, 86.987554, 88.077469, 56.88398, 88.764028, 57.298018, 30.022709, 58.243402, 56.718488, 57.708193, 80.428657, 59.173819, 58.28058, 59.557641, 58.043032, 59.345218, 245.833242, 60.335531, 92.924063, 91.946135, 59.144373, 58.70197, 59.854915, 59.612433, 29.804809, 30.757892, 60.462268, 61.467186, 59.485632, 60.161573, 60.630911, 61.087315, 60.246232, 61.013253, 189.42042, 59.81736, 30.493429, 60.686388, 59.967873, 30.907108, 60.048267, 60.35508, 62.641249, 60.600717, 60.854097, 61.44783, 60.464478, 60.360122, 61.223594, 91.466264, 60.391782, 31.227167, 58.66247, 91.319651, 61.085793, 60.999795, 30.489986, 61.989625, 60.186568, 30.947914, 80.04003, 61.003152, 163.658136, 31.935679, 67.408252, 91.940105, 216.63707, 64.395531, 61.355104, 101.089678, 61.917125, 215.869675, 61.418758, 31.426507, 62.921478, 61.498046, 62.067361, 60.843659, 95.357751, 31.198258, 62.0872, 61.581908, 126.422347, 61.414231, 62.646466, 61.329319, 31.955953, 31.161865, 32.146832, 93.270299, 62.920583, 62.688049, 93.118227, 31.528344, 107.584936, 31.583887, 62.499888, 62.391973, 63.2593, 62.601776, 62.77851, 62.145712, 39.455783, 32.491959, 32.182267, 153.84649, 63.59001, 63.421372, 94.130343, 94.326256, 64.436702, 62.888442, 63.036525, 64.1113, 32.869347, 32.148935, 62.624524, 63.324815, 62.68725, 63.000218, 104.806094, 32.708584, 95.030825, 95.261124, 99.051091, 63.2254, 32.198349, 64.103606, 81.635833, 63.761237, 64.406701, 65.758958, 32.026476, 63.805415, 107.124952, 63.52954, 114.753063, 64.37498, 145.101767, 63.689749, 63.714868, 318.989057, 71.983298, 63.612406, 102.832407, 94.866651, 63.861699, 64.500787, 63.238271, 64.51244, 42.415343, 111.73988, 64.753712, 71.242709, 63.790673, 64.970013, 64.986533, 53.251951, 44.775501, 137.4232, 64.093425, 96.144335, 64.343707, 64.014605, 64.899159, 64.419985, 1163.461394, 65.032887, 33.264755, 65.63366, 77.297646, 32.563183, 144.351601, 64.88002, 33.423779, 64.972178, 65.124683, 97.68205, 64.808178, 65.013018, 65.067442, 66.642557, 64.874947, 108.288298, 65.064001, 65.804299, 65.230164, 67.091298, 64.748445, 65.680022, 98.398252, 64.613536, 64.472912, 65.055664, 33.787893, 242.414613, 33.672539, 66.045234, 65.369414, 65.194765, 66.527999, 33.188914, 33.706793, 102.689266, 65.699903, 67.547646, 67.159928, 65.873212, 101.679018, 65.636602, 89.51293, 149.607675, 66.348288, 33.714616, 99.961929, 66.569185, 156.782845, 66.034095, 95.692869, 34.277778, 99.780401, 66.974158, 34.097854, 164.890085, 66.551497, 68.644449, 100.730051, 109.075293, 67.601133, 33.479392, 67.205523, 99.28577, 67.62042, 66.314327, 105.764379, 67.743393, 34.637657, 67.63229, 67.452281, 34.355174, 68.048829, 68.309844, 34.371247, 68.492862, 119.894834, 67.641928, 102.863951, 68.112471, 145.277735, 67.514597, 69.221068, 34.510084, 68.610817, 84.36531, 35.820086, 102.446913, 68.096574, 68.917894, 35.296761, 112.206722, 69.405357, 35.173003, 69.534511, 68.91571, 97.182006, 1063.794632, 71.134772, 68.125803, 34.742099, 69.26315, 68.946115, 68.795325, 55.57428, 71.896961, 67.835069, 68.706423, 34.431709, 83.718945, 43.787782, 102.811316, 69.045294, 157.688792, 69.566234, 68.478926, 35.085847, 68.082068, 34.747772, 69.252252, 35.323026, 34.966619, 105.737275, 146.836843, 68.39599, 103.015833, 75.363766, 105.292119, 35.384901, 68.194772, 34.576727, 103.184519, 68.196592, 35.162417, 68.593309, 69.790251, 68.699677, 104.733454, 34.909493, 69.151388, 36.041033, 35.518407, 69.157531, 104.80681, 69.928399, 69.379249, 71.765087, 108.783255, 70.576319, 71.198244, 76.788208, 69.033836, 69.756553, 107.466822, 69.336915, 70.004081, 70.297022, 35.215059, 204.59589, 69.503882, 114.463601, 68.977976, 105.81632, 35.252885, 69.665178, 35.886863, 35.44739, 70.221011, 69.852798, 70.616337, 70.058325, 68.918585, 35.036295, 106.319617, 69.384419, 69.769325, 70.301517, 69.886035, 133.796141, 69.713959, 69.723006, 112.333315, 113.94003, 106.009352, 162.361507, 70.332903, 113.379663, 71.36712, 69.80255, 70.484768, 70.683272, 69.668872, 106.058932, 69.870955, 70.001588, 70.434904, 335.788504, 111.277294, 35.375066, 147.449247, 70.207028, 35.955964, 70.751674, 50.755005, 70.839118, 70.113297, 49.68123, 53.918231, 37.36708, 71.337124, 35.790361, 70.50472, 70.300862, 36.203923, 70.227173, 107.026889, 70.382824, 70.678308, 35.705544, 69.766447, 70.839189, 71.452601, 35.397219, 75.078572, 70.90169, 70.354354, 42.98032, 70.750309, 105.465754, 70.685139, 70.53399, 35.333621, 70.478458, 70.590447, 69.533868, 69.910705, 70.349447, 70.535354, 35.858258, 35.498053, 70.429015, 71.126003, 35.701485, 70.419485, 70.71222, 164.974141, 70.192895, 70.227429, 69.994315, 78.058793, 70.802875, 70.511408, 71.281358, 86.097535, 70.04936, 69.315009, 70.178074, 70.226351, 106.644445, 71.089606, 169.280131, 70.151239, 72.96877, 70.097756, 71.024557, 128.776951, 109.783259, 36.119885, 71.106775, 70.358635, 36.415954, 70.814515, 70.608985, 71.387024, 70.887421, 36.252098, 73.269616, 168.491917, 70.97773, 71.960317, 37.259733, 35.87976, 71.22716, 71.761979, 36.283922, 91.904963, 145.468709, 71.102721, 106.798272, 72.266397, 35.901244, 71.209586, 71.423431, 71.207617, 71.526167, 155.803553, 40.853245, 36.753164, 59.791236, 110.087449, 35.638028, 106.87612, 36.512647, 71.249743, 71.536675, 71.169422, 72.603615, 36.352967, 71.800449, 72.500792, 71.035383, 155.194818, 77.129532, 70.645447, 107.772703, 109.264512, 71.515363, 37.451978, 109.52763, 72.158276, 71.967558, 72.378774, 119.094568, 107.373431, 36.357257, 106.942235, 107.725057, 37.064512, 71.532088, 77.142112, 37.041527, 71.771635, 70.438949, 87.137571, 71.098894, 73.834112, 71.773494, 71.420617, 269.708191, 36.23424, 72.826252, 71.713017, 37.345114, 152.623833, 110.965971, 36.552516, 72.364732, 187.026248, 72.113656, 72.589044, 36.857813, 73.016523, 108.897804, 168.074342, 112.09991, 115.510267, 111.201615, 121.177824, 116.019876, 36.494446, 60.984501, 72.244933, 37.095252, 117.06617, 166.168609, 72.568542, 72.157718, 108.32132, 120.02125, 72.162236, 72.156986, 40.081383, 36.478831, 139.905715, 108.153986, 73.781737, 126.289125, 73.0956, 72.553382, 72.076594, 72.008626, 36.544153, 37.540421, 72.54665, 72.406005, 72.463934, 37.110244, 72.195255, 120.777639, 75.73348, 114.161029, 37.099003, 36.602972, 72.506015, 72.347086, 85.949716, 73.759102, 73.678937, 72.88554, 73.221233, 72.458225, 72.357373, 71.792292, 36.241245, 72.628331, 73.002739, 72.800231, 37.466467, 73.390459, 72.058167, 72.348113, 72.827981, 110.066027, 72.477604, 72.683184, 73.051212, 107.917377, 72.581102, 37.672657, 72.341967, 36.862811, 109.392638, 55.007155, 154.528143, 72.823686, 72.481247, 74.527732, 36.921832, 73.641798, 73.218305, 139.487429, 72.181026, 123.619627, 72.976243, 139.4052, 73.741378, 73.57821, 74.527697, 37.535521, 73.087532, 123.065823, 37.673584, 73.999592, 72.99227, 72.944914, 73.453685, 83.869331, 74.76582, 97.508113, 73.63179, 123.216218, 74.177497, 74.014, 37.00139, 155.840381, 73.994008, 901.393873, 73.420884, 37.783755, 72.705286, 73.43605, 113.1636, 116.353933, 39.547033, 101.881349, 74.302063, 111.654676, 37.917327, 75.792342, 110.078495, 38.242017, 73.036113, 74.241847, 208.117735, 112.14593, 73.916222, 166.271561, 77.910904, 149.543039, 74.013844, 74.691317, 75.6064, 73.792355, 37.850724, 74.385194, 73.228621, 74.975736, 328.864594, 46.823156, 74.14361, 73.789341, 74.269244, 74.043853, 74.538132, 74.198808, 48.486005, 38.408573, 74.971806, 37.383605, 137.626899, 997.93602, 75.441852, 75.067868, 75.05424, 74.598901, 38.221395, 123.086392, 74.944853, 74.874202, 75.59565, 113.421366, 74.910502, 75.256773, 74.665586, 74.188196, 74.613157, 75.61844, 38.167459, 74.305872, 42.063493, 84.508126, 75.267343, 116.935519, 38.224625, 37.604296, 74.425077, 77.753685, 74.337394, 74.231529, 153.237683, 74.896388, 96.272379, 74.497042, 112.08446, 113.904497, 75.159342, 76.015192, 75.396871, 117.670144, 38.153677, 74.636597, 74.295855, 38.872867, 40.037913, 87.079918, 75.537191, 75.748571, 77.33301, 76.354826, 75.679262, 37.717015, 74.301645, 74.93292, 159.405289, 75.515964, 75.974129, 114.369599, 118.851507, 114.561771, 76.258502, 43.791085, 75.098763, 96.797921, 74.870708, 38.806722, 76.506302, 76.576867, 74.420285, 75.423847, 112.368019, 76.913192, 76.034104, 76.744873, 75.231106, 132.61332, 160.744977, 75.359538, 38.790577, 107.08393, 77.640055, 75.073678, 136.64373, 59.443404, 117.852529, 84.906005, 111.798997, 76.558391, 76.53512, 150.052349, 75.454036, 45.658652, 112.787899, 56.6199, 74.962518, 75.625599, 75.678882, 75.251574, 75.572802, 75.971058, 76.047126, 75.505671, 119.690266, 74.987814, 75.823212, 64.902713, 75.609837, 74.993132, 76.692307, 100.334357, 58.857642, 83.30553, 49.113456, 53.175503, 78.108682, 79.073942, 79.385489, 76.854676, 124.772919, 38.775889, 77.725239, 79.24933, 117.168917, 77.769362, 117.192579, 77.183309, 94.330708, 163.333297, 40.799819, 39.588403, 77.969582, 78.631181, 43.338885, 117.991019, 89.324126, 78.356495, 116.713388, 77.822786, 77.756993, 77.965993, 78.35812, 79.72552, 77.855024, 77.985466, 79.61181, 80.83018, 40.276621, 120.145317, 77.42992, 78.731712, 78.849657, 51.734188, 40.612797, 80.047159, 80.014107, 55.127742, 79.277668, 52.692019, 40.228201, 41.017318, 79.753231, 79.565692, 79.413214, 118.42433, 120.790633, 123.434375, 77.438115, 79.420855, 79.896205, 40.239874, 79.36029, 79.017315, 244.290066, 64.550498, 79.475868, 79.031691, 126.587131, 80.314153, 80.22323, 79.057344, 79.488953, 78.158425, 80.471683, 78.867473, 78.238017, 79.189232, 79.185566, 78.198165, 90.005677, 168.769342, 78.387409, 78.030843, 114.515341, 75.583036, 76.402494, 76.35405, 76.261626, 39.395726, 38.523019, 77.057957, 38.568905, 534.319067, 38.942376, 77.568389, 77.067894, 77.960476, 114.995858, 77.541984, 76.547143, 38.921052, 49.049956, 77.914564, 120.054585, 40.173127, 77.002893, 77.798188, 53.929337, 78.085139, 77.51608, 77.069232, 76.662168, 76.939959, 116.124383, 154.999415, 55.461589, 76.400352, 220.76933, 85.222285, 43.009236, 84.109094, 83.923117, 42.892813, 84.402374, 91.508075, 84.338041, 84.127733, 84.005515, 52.93529, 83.624434,
                3.058573, 12.293336, 4.900088, 2.887298, 5.444768, 13.750949, 5.886262, 8.515226, 7.149313, 65.119724, 10.194052, 7.202299, 9.388727, 28.945797, 18.431972, 11.656631, 9.004633, 10.960115, 10.800149, 10.968385, 11.529094, 12.365875, 11.746205, 13.476285, 39.359413, 22.717339, 14.246977, 12.458554, 40.123806, 16.734802, 13.56268, 23.463137, 15.453047, 14.70991, 35.110643, 66.59867, 14.277803, 181.736151, 15.535314, 15.447897, 15.059939, 15.611423, 16.115072, 297.082465, 9.008978, 9.692646, 17.467143, 17.850744, 18.431703, 65.543417, 17.419359, 9.628074, 10.010934, 754.122581, 25.58887, 20.120993, 1618.986906, 18.722211, 20.578599, 19.980509, 1750.959168, 20.137712, 861.000309, 20.735199, 10.693467, 22.457645, 21.751029, 20.996381, 21.059339, 21.229923, 21.937236, 10.819856, 22.935139, 20.924677, 206.952639, 22.653439, 21.2214, 20.593242, 21.027517, 22.025062, 765.346375, 59.792003, 21.946424, 21.457071, 72.784831, 24.591411, 165.270916, 21.465553, 21.760074, 114.704653, 24.156895, 24.428259, 21.132092, 22.129595, 27.356196, 21.831998, 23.84232, 24.215498, 27.920022, 23.536582, 23.988432, 76.156017, 24.58002, 31.815349, 24.294443, 21.747093, 64.75689, 24.317613, 23.538182, 30.510501, 24.99216, 40.094173, 25.020357, 24.970556, 22.091523, 22.717396, 16.006107, 40.911474, 27.333491, 64.323641, 22.658488, 31.450236, 22.866847, 28.406095, 26.380863, 11.883795, 94.214219, 33.109046, 22.883847, 22.60252, 23.514911, 24.639122, 103.271984, 81.049951, 128.923028, 12.496484, 23.798326, 23.874891, 24.848573, 437.526899, 260.630293, 46.821024, 12.953768, 106.164851, 25.821928, 32.003192, 25.526044, 28.581312, 12.995599, 26.439093, 13.342447, 15.772372, 26.251852, 27.054049, 34.327466, 13.562462, 26.942384, 36.070267, 15.142162, 452.046246, 1014.934408, 26.470747, 28.576471, 28.959009, 27.441001, 26.302638, 93.669966, 14.078243, 54.5375, 27.242287, 28.47229, 14.206928, 27.459944, 426.512112, 75.119579, 29.385915, 29.431573, 29.924063, 15.465191, 65.842029, 28.948282, 27.879867, 32.497802, 27.812682, 65.322129, 4189.504462, 28.596017, 29.161825, 75.430866, 31.620722, 28.75745, 174.639434, 28.592528, 720.909063, 29.389479, 47.110511, 31.914365, 456.359377, 58.583736, 30.726022, 15.409964, 28.760075, 36.094469, 35.786545, 35.533134, 48.263742, 33.630102, 15.686863, 30.538938, 71.24057, 29.361365, 33.698366, 29.297742, 18.697672, 17.395862, 15.973891, 32.750841, 30.218908, 31.543364, 30.727585, 31.729489, 19.628669, 16.628837, 48.315353, 32.3056, 35.980422, 31.514702, 32.990074, 36.676747, 35.365746, 35.872021, 31.433121, 32.743981, 211.424586, 33.597348, 17.64434, 33.164709, 31.786288, 34.087793, 85.458973, 33.646816, 33.398328, 366.636491, 32.695893, 32.033368, 40.145823, 36.444916, 36.290242, 39.077269, 32.03296, 33.006138, 36.021693, 32.521999, 33.312177, 17.288041, 36.090577, 17.524533, 33.894092, 33.181732, 35.154139, 35.880997, 77.285504, 33.081061, 41.39458, 56.672373, 33.739395, 33.430511, 40.334634, 35.531855, 17.622298, 33.221262, 33.573652, 33.193256, 18.687583, 33.414725, 33.28251, 20.124245, 33.968019, 34.124343, 37.178254, 37.750399, 34.802163, 60.895368, 36.018296, 34.79125, 43.671522, 40.363501, 71.142387, 73.023394, 33.858831, 33.69381, 34.484438, 33.662814, 35.249859, 36.37561, 33.670125, 17.985003, 35.909864, 34.802027, 63.91473, 37.714064, 18.186513, 35.559984, 34.484725, 18.419854, 19.002328, 57.072627, 36.82928, 42.084323, 35.476163, 35.335409, 730.530131, 37.062309, 36.086512, 51.529766, 39.821897, 21.220598, 35.788667, 36.308793, 44.231131, 35.830928, 69.483731, 35.480105, 86.987431, 36.501318, 58.191536, 35.479478, 35.978816, 37.993126, 805.61476, 37.977261, 18.695537, 40.479481, 36.230206, 23.085651, 35.91369, 109.601606, 36.592823, 37.593334, 219.976384, 366.40528, 36.135191, 87.65648, 481.928464, 36.569539, 38.895163, 19.220884, 37.250494, 40.760404, 98.777853, 40.630766, 38.688897, 19.44022, 89.261439, 36.993519, 289.478471, 32.434647, 36.811568, 42.485515, 39.191476, 37.809336, 37.103419, 38.95715, 37.937973, 37.336572, 70.071146, 91.409113, 193.886446, 314.881212, 314.45601, 78.057886, 37.933813, 45.413895, 38.394514, 20.134959, 43.505254, 42.820983, 20.093203, 47.313449, 43.668148, 40.338711, 43.62631, 130.819927, 39.668124, 40.424092, 41.748412, 40.937589, 40.417409, 39.544043, 40.428968, 41.516975, 38.739571, 39.935333, 3049.143142, 39.256336, 39.553348, 40.278048, 39.583111, 39.69715, 41.34152, 39.75399, 40.648647, 40.581088, 40.393382, 42.212562, 39.636569, 543.90183, 58.264683, 21.077059, 21.097598, 44.571011, 40.525271, 80.657318, 89.10815, 42.392841, 45.99608, 21.556805, 56.183765, 41.036509, 24.089832, 47.451736, 41.052197, 44.337954, 67.228216, 44.066941, 50.44253, 42.482544, 131.434377, 40.801547, 76.693977, 49.310939, 44.615837, 200.734238, 22.265359, 21.797491, 64.387457, 43.338355, 54.049734, 70.114615, 42.41766, 24.415067, 43.399724, 43.481103, 258.51973, 57.553765, 91.599036, 853.977148, 44.431917, 44.529481, 45.313532, 42.830481, 41.632279, 41.698665, 44.09473, 52.541709, 23.117746, 42.709053, 43.169169, 41.691906, 80.070296, 46.006205, 42.642322, 42.924161, 42.922873, 42.686037, 79.007792, 44.043914, 76.837443, 982.497003, 44.251263, 22.842214, 69.033706, 42.50351, 312.568463, 42.520681, 42.455744, 6966.191335, 43.228873, 46.644616, 44.022581, 46.663055, 43.860202, 48.732123, 80.991356, 44.025875, 44.257287, 43.174713, 44.074508, 43.196886, 82.637609, 42.89068, 46.533134, 43.235878, 43.744752, 672.20494, 44.149573, 43.495369, 46.361655, 44.791354, 44.473946, 43.851764, 44.859059, 22.786149, 45.8702, 47.468158, 23.667942, 44.144457, 45.021166, 45.844604, 44.752054, 44.284849, 90.936501, 23.422124, 50.077311, 44.470492, 44.525378, 46.272756, 23.335063, 48.078082, 53.714603, 45.332018, 44.348561, 44.559585, 118.0086, 23.211559, 48.069928, 45.47876, 260.665611, 45.496861, 227.180086, 44.629947, 47.092551, 47.087692, 48.203091, 1908.852399, 50.051614, 46.893698, 23.458064, 44.959405, 50.791708, 46.662643, 69.996376, 71.654586, 46.896631, 710.948467, 46.862672, 53.082821, 45.237949, 45.775228, 24.560019, 24.082798, 46.514809, 93.878676, 47.318748, 49.689429, 23.802766, 24.988012, 46.183959, 47.868997, 49.072652, 48.182953, 266.389545, 50.280816, 49.928664, 49.93375, 1130.803777, 46.681664, 46.538247, 59.612356, 47.46445, 50.583297, 47.787286, 47.558177, 48.521234, 47.519987, 231.043077, 50.679178, 52.811719, 48.038729, 24.271019, 47.754827, 48.992476, 53.149967, 47.686499, 51.278992, 51.70386, 223.774719, 48.372123, 50.589327, 55.705438, 788.523912, 47.44421, 52.64515, 46.83769, 49.525004, 48.077441, 47.920706, 47.863252, 47.776102, 50.114265, 47.999895, 39.462671, 371.293242, 48.36287, 48.502905, 51.973146, 50.381178, 25.352791, 46.784327, 48.576725, 152.264229, 49.064173, 48.350353, 51.028658, 51.537457, 53.996911, 48.515522, 24.512959, 128.141555, 50.235887, 48.446166, 48.227922, 49.661742, 50.869755, 25.0656, 48.104434, 50.001249, 53.412908, 24.85478, 50.512405, 112.838388, 48.558666, 48.015935, 54.25324, 49.643011, 49.751941, 49.904193, 50.786242, 53.008014, 49.964519, 52.941236, 48.337175, 48.533398, 48.107163, 90.978999, 50.487422, 47.931775, 50.953122, 49.124168, 49.877846, 51.721169, 55.484394, 56.920957, 49.808209, 51.011741, 25.347348, 131.629573, 51.05647, 25.492554, 50.023602, 49.283318, 153.688199, 53.000222, 50.907079, 49.263959, 85.133654, 724.339538, 57.081561, 52.739518, 55.150117, 50.083789, 52.466217, 196.653541, 26.15656, 126.215825, 50.348368, 60.835769, 762.144213, 53.479171, 93.839749, 50.952146, 51.991794, 53.622001, 49.93237, 49.499982, 264.931569, 57.794356, 248.071055, 50.167994, 50.552358, 52.306481, 175.765159, 50.705484, 51.252788, 50.721685, 63.017055, 26.708075, 89.904756, 51.999863, 59.867982, 51.685974, 51.044445, 55.695214, 50.922818, 73.090832, 57.15613, 90.826635, 101.801285, 63.695096, 50.423012, 59.510895, 51.907322, 58.145163, 50.981972, 55.611386, 128.725293, 863.618987, 51.846601, 233.093454, 51.806643, 52.015085, 56.193477, 52.05034, 60.244761, 51.977746, 221.484666, 56.257721, 26.782391, 26.78157, 109.21446, 750.104222, 52.843505, 73.838603, 149.479655, 53.808517, 50.909861, 51.862006, 50.940446, 54.452569, 53.766243, 51.805104, 51.192812, 51.555925, 51.546306, 52.241646, 51.432109, 57.425569, 53.234652, 51.677143, 55.359256, 1259.512636, 58.12187, 52.352619, 54.65489, 52.454771, 79.881276, 27.230057, 98.371629, 59.959433, 53.352087, 55.281515, 613.196529, 54.715665, 62.725709, 27.607677, 56.396937, 55.101028, 53.297341, 53.062023, 110.939124, 27.572929, 127.69305, 27.251828, 53.829668, 53.1884, 53.689042, 56.835365, 579.721428, 54.731986, 53.696323, 27.935784, 59.077333, 57.52133, 71.590017, 53.768572, 56.010919, 54.764083, 121.29473, 60.944622, 54.40172, 61.079067, 55.493421, 53.963802, 84.452568, 55.16805, 53.874805, 55.081077, 65.958436, 28.931896, 336.196549, 56.524792, 206.49741, 27.978721, 69.475939, 61.381559, 54.137011, 69.580882, 195.378596, 743.841905, 58.364833, 27.895177, 54.039255, 54.884557, 55.449499, 54.516334, 54.544396, 47.247877, 28.162905, 55.660523, 56.666804, 59.20472, 29.985973, 57.742734, 54.209112, 308.682512, 59.869293, 55.197767, 54.922979, 28.46995, 75.724286, 68.152405, 28.355423, 55.949106, 676.407488, 54.900957, 101.5005, 55.398066, 55.215062, 59.145334, 80.765471, 55.237749, 59.834042, 59.702658, 249.555519, 55.547479, 57.637315, 133.42874, 61.665188, 61.48286, 265.794572, 702.473877, 64.355804, 64.323912, 55.525689, 28.711365, 56.008, 75.112149, 75.189809, 57.506413, 55.414684, 55.570913, 64.694663, 55.632075, 58.029211, 29.88509, 56.567698, 55.801746, 54.84376, 58.070358, 72.879912, 60.186183, 29.159195, 62.217162, 141.611305, 55.039264, 67.735784, 28.587788, 56.844621, 55.332639, 56.74658, 59.552608, 28.777184, 55.947405, 56.954172, 28.990554, 62.840522, 55.913921, 29.058815, 64.62809, 151.017525, 56.295904, 29.38974, 58.528047, 60.634403, 57.948212, 56.072387, 56.020291, 377.488878, 567.559964, 59.989751, 96.885277, 83.889851, 78.172782, 56.316181, 63.298179, 63.249303, 68.900702, 56.170906, 58.195101, 57.851533, 56.418839, 64.549132, 58.665009, 83.111673, 57.357528, 56.96817, 56.5795, 57.127958, 57.313437, 57.248232, 206.191787, 30.250419, 56.839591, 459.224022, 58.785945, 57.720803, 97.716464, 845.933939, 57.795846, 59.809237, 57.945014, 57.217003, 57.91898, 61.029874, 403.233174, 61.08213, 57.575697, 158.970055, 59.997514, 242.013381, 86.663627, 59.339015, 59.455842, 102.623026, 57.635979, 61.096974, 64.343341, 57.528838, 61.359069, 58.349216, 58.617672, 76.247888, 104.205038, 61.076816, 239.378667, 57.531189, 58.303066, 10184.284211, 59.465758, 60.589143, 30.277421, 58.88027, 31.168128, 30.409903, 60.159622, 77.748296, 344.453683, 30.925341, 834.234294, 316.60008, 61.583957, 59.479154, 60.465544, 592.830426, 355.306699, 204.081087, 59.493377, 81.099298, 59.634403, 30.241627, 60.160241, 65.847818, 59.936714, 113.519886, 252.6413, 67.349062, 60.910886, 62.353581, 234.433436, 62.897344, 59.506271, 59.827722, 31.078959, 31.17346, 59.951942, 303.236671, 223.970364, 59.373168, 66.567007, 61.728294
            ]
        ],
        [
            # [
            #     83720.33528900002, 129494.22880700014, 80329.52590799995, 118830.82944199987, 403545.20581299975
            # ],
            # [
            #     79335.71080400002, 108984.9144119999, 79091.35687100007, 106109.76268500005, 447087.925176
            # ]
            [
                83720.33528900002, 129494.22880700014, 118830.82944199987
            ],
            [
                79335.71080400002, 108984.9144119999, 106109.76268500005
            ]
        ]
    ]

    encoder_times = [
        [
            [
                9.425, 6.307, 6.03, 7.262, 6.554, 6.146, 10.599, 5.732, 6.425, 5.956, 6.812, 6.881, 6.976, 7.139, 6.396, 6.07, 5.83, 5.95, 6.892, 5.953, 6.79, 6.288, 5.787, 5.85, 6.123, 6.464, 5.789, 42.069, 6.214, 6.377, 5.875, 5.923, 5.812, 7.19, 7.059, 5.954, 5.839, 6.091, 6.065, 6.727, 6.011, 6.546, 6.76, 6.569, 6.012, 5.806, 6.308, 6.16, 6.983, 6.126, 5.808, 5.633, 6.739, 7.791, 6.327, 6.622, 6.543, 5.854, 6.574, 6.104, 7.037, 6.142, 6.174, 7.044, 5.815, 5.686, 5.823, 5.845, 13.168, 6.106, 5.793, 8.737, 6.624, 5.757, 7.511, 6.103, 5.846, 6.702, 6.197, 5.928, 6.061, 5.996, 6.725, 5.744, 5.902, 5.92, 28.203, 6.657, 5.912, 6.731, 5.963, 6.384, 6.219, 5.748, 6.644, 6.346, 6.998, 5.906, 6.558, 6.133, 5.689, 6.301, 6.802, 6.116, 12.428, 7.488, 6.741, 7.057, 6.137, 7.477, 16.979, 6.397, 6.465, 7.35, 6.041, 5.926, 6.449, 6.025, 5.962, 5.863, 6.06, 6.836, 5.888, 6.258, 6.395, 6.67, 6.674, 6.541, 21.559, 7.378, 5.883, 5.789, 5.945, 6.017, 5.875, 6.723, 5.925, 5.813, 5.983, 5.922, 6.466, 5.687, 6.339, 6.438, 6.292, 5.85, 9.327, 6.131, 5.932, 5.895, 5.968, 5.781, 5.774, 6.803, 8.565, 6.013, 7.344, 6.697, 6.533, 6.55, 7.94, 6.791, 6.142, 7.086, 6.019, 18.047, 6.837, 5.829, 6.36, 6.183, 6.782, 9.539, 6.669, 6.858, 6.11, 6.11, 6.415, 6.049, 6.643, 6.556, 6.569, 8.17, 5.822, 6.158, 5.96, 6.768, 8.918, 7.557, 7.726, 5.91, 5.869, 6.035, 6.44, 6.169, 5.902, 6.03, 7.145, 5.822, 5.739, 16.138, 6.079, 6.429, 6.521, 6.004, 6.875, 5.87, 6.081, 6.845, 6.126, 5.841, 5.951, 6.054, 5.931, 6.491, 9.615, 5.965, 7.114, 6.547, 7.227, 6.54, 5.902, 6.156, 8.492, 6.354, 6.245, 10.497, 6.417, 5.958, 11.893, 6.697, 12.671, 6.511, 7.897, 5.977, 6.01, 37.009, 7.713, 6.311, 6.891, 9.377, 6.317, 6.635, 5.937, 5.782, 7.543, 7.134, 6.12, 10.67, 5.956, 5.907, 5.871, 8.606, 7.581, 7.008, 6.187, 6.368, 6.033, 5.862, 6.133, 6.063, 174.154, 7.542, 6.488, 6.858, 7.887, 6.534, 7.719, 6.446, 7.405, 6.753, 6.84, 6.82, 6.62, 6.473, 6.368, 6.646, 6.588, 7.671, 7.96, 7.063, 6.838, 6.706, 6.686, 6.657, 6.988, 6.415, 6.36, 6.428, 6.359, 17.756, 6.582, 6.729, 6.491, 6.373, 6.578, 6.325, 6.466, 8.256, 6.68, 6.784, 7.604, 6.348, 7.387, 6.438, 9.185, 10.162, 6.583, 6.457, 7.103, 7.172, 8.374, 7.256, 9.67, 6.467, 6.942, 6.62, 6.564, 8.5, 6.342, 6.705, 6.906, 7.569, 6.864, 6.75, 7.46, 10.05, 6.833, 6.584, 7.467, 6.902, 6.576, 6.624, 6.252, 6.505, 6.967, 6.294, 6.65, 6.578, 19.337, 6.437, 7.178, 6.372, 7.618, 6.679, 6.633, 6.54, 6.649, 8.113, 6.414, 6.922, 7.106, 6.573, 6.403, 8.171, 6.67, 6.502, 7.405, 6.717, 9.686, 91.62, 7.032, 6.569, 6.915, 7.216, 6.639, 6.432, 9.857, 7.738, 6.472, 6.614, 7.333, 9.126, 8.115, 6.932, 6.403, 14.334, 6.837, 6.475, 6.763, 6.512, 6.727, 6.922, 6.524, 6.474, 7.461, 15.261, 6.613, 7.117, 6.879, 7.075, 7.126, 6.648, 6.518, 6.682, 6.63, 6.351, 6.45, 7.42, 6.61, 7.131, 6.461, 6.46, 6.603, 6.48, 6.46, 7.264, 6.833, 6.466, 7.386, 7.51, 6.892, 6.83, 7.674, 6.663, 6.807, 7.241, 6.957, 6.987, 6.996, 6.519, 11.728, 7.586, 7.72, 6.772, 7.465, 6.465, 6.77, 6.888, 6.552, 7.838, 6.659, 7.014, 6.489, 6.419, 6.589, 8.197, 6.801, 6.66, 7.21, 6.787, 9.332, 6.854, 7.775, 7.37, 7.732, 7.19, 8.623, 6.614, 9.808, 7.171, 6.635, 6.55, 7.073, 6.669, 6.931, 6.362, 6.727, 7.608, 19.964, 9.562, 6.845, 13.933, 7.752, 6.417, 8.364, 8.891, 6.683, 6.836, 8.336, 8.925, 6.6, 7.037, 7.158, 6.654, 6.699, 7.0, 6.692, 7.459, 6.668, 8.277, 6.819, 6.485, 6.858, 6.695, 6.819, 7.691, 6.379, 7.1, 8.15, 6.904, 7.112, 7.019, 6.664, 6.639, 6.853, 6.686, 6.742, 6.547, 7.978, 6.828, 6.691, 6.349, 7.69, 6.936, 7.158, 7.676, 6.722, 8.197, 6.672, 6.879, 7.003, 8.226, 7.223, 6.593, 7.549, 8.334, 6.603, 6.869, 6.88, 8.121, 7.737, 6.612, 8.47, 6.584, 7.311, 6.761, 6.689, 20.075, 7.403, 6.371, 6.512, 7.055, 7.003, 6.847, 6.832, 6.727, 6.74, 6.496, 8.248, 26.96, 6.407, 7.137, 6.956, 6.557, 6.369, 7.104, 6.242, 8.896, 7.283, 6.433, 6.907, 6.635, 7.229, 7.842, 7.265, 6.706, 6.685, 14.087, 7.348, 6.644, 9.927, 7.397, 6.905, 6.819, 6.402, 6.527, 6.683, 6.389, 6.645, 7.059, 6.984, 7.753, 6.662, 8.656, 13.05, 7.773, 7.108, 6.97, 6.768, 6.924, 7.292, 6.631, 6.291, 6.686, 7.938, 6.821, 6.454, 6.833, 6.873, 6.407, 6.571, 7.145, 6.692, 6.764, 10.849, 8.332, 6.703, 6.488, 7.308, 6.7, 25.413, 6.579, 7.505, 6.764, 6.117, 7.667, 7.44, 6.365, 7.528, 9.623, 6.67, 6.68, 6.783, 6.699, 7.114, 8.579, 7.321, 7.608, 7.142, 11.063, 7.672, 6.516, 9.867, 6.627, 6.404, 7.658, 8.206, 6.569, 6.419, 6.84, 7.197, 6.569, 6.597, 7.634, 6.568, 20.776, 6.865, 7.047, 12.227, 6.873, 6.506, 6.439, 6.706, 6.239, 6.454, 6.679, 6.396, 6.682, 6.584, 6.852, 7.897, 7.351, 7.673, 6.519, 6.612, 7.213, 6.833, 8.286, 6.932, 6.715, 6.752, 6.873, 6.477, 7.107, 6.443, 8.209, 6.712, 6.758, 6.66, 6.497, 6.83, 6.488, 6.988, 6.346, 8.343, 6.48, 6.483, 6.529, 6.967, 6.454, 6.47, 6.782, 6.713, 6.921, 8.832, 7.706, 6.226, 6.559, 6.555, 6.807, 6.707, 6.874, 13.701, 6.446, 7.791, 6.522, 13.279, 6.527, 6.595, 6.996, 7.371, 6.523, 8.639, 6.25, 7.066, 6.982, 6.408, 7.595, 8.078, 7.187, 15.015, 6.904, 7.649, 6.615, 7.108, 6.574, 7.844, 6.599, 64.632, 6.464, 8.217, 6.801, 6.602, 7.687, 7.493, 8.037, 9.89, 6.876, 7.204, 6.826, 7.094, 7.246, 7.378, 6.779, 7.39, 14.6, 7.443, 7.672, 8.272, 7.749, 7.604, 7.275, 7.036, 7.134, 6.97, 6.575, 6.668, 8.209, 7.689, 19.97, 9.124, 6.92, 7.793, 6.771, 6.729, 7.004, 7.05, 8.343, 7.364, 6.684, 6.646, 9.039, 70.814, 7.337, 7.764, 6.867, 6.63, 7.909, 7.86, 6.732, 7.979, 7.27, 7.367, 6.854, 8.042, 6.815, 7.261, 7.075, 7.237, 6.582, 6.658, 7.516, 7.963, 7.83, 7.566, 6.717, 7.186, 6.637, 7.645, 6.97, 6.826, 7.523, 7.031, 10.26, 7.204, 7.835, 7.742, 7.462, 7.421, 6.77, 7.837, 6.85, 7.106, 6.779, 6.988, 6.891, 8.399, 6.964, 7.956, 7.17, 7.277, 6.866, 6.448, 11.403, 6.745, 7.823, 7.024, 7.05, 7.54, 7.871, 7.273, 6.923, 7.779, 6.862, 8.918, 6.691, 6.984, 7.001, 7.317, 6.794, 6.983, 7.33, 6.926, 6.996, 6.699, 7.313, 19.768, 10.509, 7.359, 7.042, 15.965, 6.644, 7.033, 13.306, 9.621, 8.043, 7.987, 7.306, 7.078, 6.977, 14.598, 6.85, 8.046, 7.977, 9.834, 6.792, 6.947, 7.132, 6.605, 6.832, 6.897, 8.001, 7.341, 8.358, 7.074, 7.287, 10.894, 7.021, 6.487, 6.901, 6.641, 9.012, 6.668, 8.079, 7.451, 6.643, 7.997, 6.717, 6.532, 7.841, 6.674, 7.142, 6.95, 8.699, 7.743, 7.284, 7.985, 9.133, 7.639, 6.63, 6.71, 6.709, 6.588, 7.803, 7.259, 8.285, 6.492, 7.068, 6.853, 7.315, 7.046, 6.972, 8.244, 6.826, 6.856, 6.92, 7.085, 6.704, 7.511, 6.812, 6.734, 6.996, 9.081, 6.823, 7.021, 7.956, 8.605, 6.672, 8.301, 7.498, 6.825, 7.116, 7.37, 6.669, 9.229, 8.611, 9.845, 6.712, 6.881, 6.74, 6.563, 7.517, 6.921, 8.455, 7.266, 8.292, 7.153, 7.864, 6.912, 6.856, 6.888, 7.166, 6.96, 6.77, 6.89, 7.1, 6.929, 7.357, 7.017, 13.372, 16.659, 6.656, 6.858, 7.078, 6.717, 7.141, 6.659, 8.55, 6.907, 8.859, 7.683, 8.449, 52.743, 6.907, 6.832, 7.219, 6.571, 7.076, 7.075, 6.585, 6.737, 8.878, 6.932, 7.635, 6.653, 7.159, 6.823, 10.156, 8.115, 6.699, 6.899, 7.214, 7.26, 7.498, 7.495, 9.443, 6.691, 22.97, 6.46, 7.212, 6.475, 6.854, 7.228, 6.561, 6.869, 6.869, 6.933, 7.268, 8.28, 6.793, 6.557, 10.072, 6.823, 6.747, 6.806, 6.956, 6.631, 6.693, 6.962, 8.143, 8.689, 8.763, 6.98, 9.042, 7.386, 6.86, 6.76, 6.845, 7.904, 6.781, 6.578, 6.884, 6.553, 7.357, 7.597, 7.841, 6.749, 6.604, 7.529, 6.917, 6.666, 7.22, 6.76, 6.521, 7.228, 7.939, 6.543, 9.911, 6.521, 6.633, 6.728, 6.759, 6.571, 10.306, 6.487, 6.505, 6.851, 6.683, 6.569, 8.127, 6.55, 6.556, 6.619, 22.433, 7.048, 7.114, 27.977, 6.789, 6.655, 6.642, 46.761, 7.028, 24.903, 7.006, 6.698, 6.86, 6.646, 6.386, 7.852, 6.469, 6.758, 6.501, 6.656, 7.534, 9.329, 6.811, 6.68, 6.562, 6.586, 6.38, 14.837, 7.482, 6.614, 6.771, 8.33, 7.061, 9.02, 6.404, 6.461, 8.622, 6.581, 6.698, 6.93, 6.62, 6.92, 6.538, 6.668, 7.548, 7.11, 8.823, 6.883, 8.788, 7.149, 6.78, 6.824, 6.504, 7.766, 9.27, 6.588, 6.944, 7.163, 6.969, 8.048, 8.163, 8.067, 7.424, 7.003, 9.439, 6.87, 8.555, 6.476, 6.855, 8.289, 7.085, 6.744, 6.523, 8.043, 6.942, 6.977, 6.436, 7.189, 6.659, 8.224, 7.972, 8.312, 7.495, 6.621, 6.699, 7.48, 11.757, 11.08, 7.146, 6.338, 8.109, 6.823, 6.995, 6.716, 6.862, 6.674, 8.034, 6.698, 6.587, 6.558, 6.979, 6.888, 6.529, 6.461, 7.179, 7.712, 14.977, 28.764, 8.057, 6.626, 8.94, 7.528, 6.654, 9.252, 6.536, 7.334, 6.395, 7.917, 6.444, 7.075, 11.236, 7.495, 6.641, 7.814, 7.139, 6.604, 7.571, 6.804, 6.423, 7.943, 6.475, 7.451, 94.772, 7.372, 6.778, 8.483, 7.815, 6.59, 9.731, 8.491, 14.079, 6.843, 7.494, 6.981, 12.071, 7.827, 7.829, 6.628, 8.05, 7.171, 7.138, 7.445, 7.702, 7.1, 6.778, 6.832, 8.312, 6.671, 7.307, 6.757, 7.594, 6.652, 6.66, 6.98, 6.761, 6.825, 6.696, 7.177, 7.109, 6.674, 7.39, 6.638, 7.198, 6.555, 8.084, 7.029, 7.019, 7.17, 6.602, 6.814, 10.226, 6.767, 6.908, 6.96, 6.531, 7.08, 7.788, 6.886, 7.294, 10.893, 6.622, 8.295, 7.235, 6.709, 7.232, 7.194, 6.411, 6.645, 6.97, 8.002, 6.721, 6.864, 7.436, 6.757, 6.671, 6.723, 6.856, 7.023, 7.893, 6.875, 7.11, 7.698, 7.768, 6.585, 9.358, 8.324, 6.666, 6.758, 7.208, 6.78, 9.232, 7.869, 6.834, 6.885, 6.728, 6.773, 7.306, 7.288, 7.721, 7.699, 9.079, 7.074, 7.291, 7.281, 7.928, 8.009, 6.581, 6.778, 6.804, 7.138, 7.025, 7.212, 7.027, 6.934, 8.338, 6.72, 7.66, 8.772, 9.013, 6.947, 7.014, 8.95, 7.048, 7.63, 6.637, 6.973, 7.132, 6.668, 21.409, 6.833, 7.206, 7.536, 7.228, 6.692, 9.225, 9.216, 7.401, 6.892, 8.477, 6.882, 8.006, 6.798, 7.647, 8.057, 8.835, 7.009, 22.866, 6.86, 6.833, 6.909, 6.816, 7.438, 6.553, 9.815, 8.562, 6.6, 10.294, 10.453, 6.682, 8.221, 12.969, 6.717, 7.712, 6.701, 6.887, 7.055, 8.192, 9.001, 7.027, 6.995, 9.792, 6.678, 10.611, 7.453, 7.46, 7.356, 7.192, 7.206, 6.912, 7.637, 6.802, 6.941, 8.398, 8.163, 9.053, 13.135, 12.085, 8.013, 8.747, 7.478, 6.858, 6.757, 7.309, 6.937, 6.961, 7.471, 7.007, 8.234, 7.371, 8.872, 8.396, 6.808, 7.221, 6.815, 6.971, 8.104, 6.868, 7.377, 6.821, 6.833, 68.454, 6.886, 6.594, 8.217, 6.748, 6.927, 7.576, 8.592, 6.872, 6.829, 6.684, 7.232, 6.935, 17.692, 7.584, 6.668, 6.867, 9.047, 8.135, 8.25, 9.55, 7.263, 7.366, 6.918, 7.596, 6.583, 8.714, 7.557, 6.884, 7.101, 7.497, 7.203, 7.606, 6.824, 8.797, 6.78, 7.718, 7.271, 7.069, 8.959, 6.88, 7.546, 7.661, 6.962, 7.686, 9.518, 6.903, 8.522, 6.996, 7.343, 9.778, 7.491, 7.914, 15.337, 7.012, 6.989, 8.389, 8.503, 7.054, 6.685, 7.281, 7.443, 6.968, 6.663, 6.728, 7.932, 8.614, 7.297, 7.77, 6.884, 6.952, 7.0, 8.121, 7.078, 10.047, 32.132, 7.182, 7.428, 7.773, 7.017, 12.3, 7.331, 6.975, 75.247, 6.814, 8.359, 7.183, 7.187, 8.564, 7.608, 8.228, 8.8, 7.351, 6.893, 8.259, 6.983, 8.384, 7.219, 7.109, 6.805, 7.993, 19.666, 6.924, 6.672, 7.383, 6.816, 7.899, 6.982, 6.912, 7.633, 7.058, 6.971, 7.249, 6.676, 7.034, 6.925, 6.789, 7.088, 7.951, 7.106, 7.39, 6.702, 7.953, 6.928, 6.938, 7.011, 7.11, 8.907, 6.77, 6.868, 8.674, 6.757, 7.164, 8.236, 9.875, 7.02, 11.646, 6.763, 7.034, 7.354, 8.894, 56.177, 8.235, 6.962, 6.986, 6.744, 8.417, 7.561, 7.785, 7.916, 6.671, 14.194, 6.834, 7.36, 6.862, 7.151, 6.756, 7.419, 7.137, 8.293, 6.846, 7.127, 7.083, 7.493, 6.925, 6.952, 7.36, 7.128, 11.664, 7.26, 7.09, 7.468, 17.225, 6.983, 7.036, 9.831, 7.312, 7.425, 7.143, 7.968, 7.11, 6.939, 10.851, 7.32, 7.461, 8.559, 6.907, 6.895, 6.956, 7.568, 6.799, 7.949, 8.4, 10.134, 7.295, 8.279, 7.66, 15.886, 6.93, 7.243, 6.684, 7.16, 7.004, 7.035, 7.99, 6.827, 6.966, 6.827, 9.404, 13.459, 8.949, 6.892, 7.158, 6.996, 6.697, 8.564, 7.392, 8.97, 7.668, 6.963, 7.223, 7.809, 9.2, 6.985, 6.802, 8.554, 7.819, 6.699, 6.946, 7.037, 9.306, 7.428, 6.739, 7.182, 7.362, 6.891, 8.427, 8.749, 6.955, 7.208, 7.111, 8.942, 7.142, 7.013, 6.915, 7.922, 6.965, 7.222, 6.968, 6.74, 6.836, 8.004, 6.897, 7.457, 6.976, 6.68, 8.637, 7.809, 7.399, 7.939, 6.917, 9.06, 8.611, 8.711, 6.911, 6.739, 6.847, 7.027, 9.272, 7.33, 7.86, 6.843, 7.97, 21.586, 8.124, 6.865, 7.34, 7.325, 7.006, 9.015, 8.629, 8.925, 6.918, 7.861, 14.818, 7.041, 8.433, 6.898, 7.258, 7.166, 8.468, 8.741, 10.269, 7.662, 9.483, 6.873, 8.228, 7.198, 9.545, 9.089, 7.583, 6.788, 8.711, 7.067, 8.084, 6.827, 7.461, 6.987, 6.769, 7.43, 6.851, 7.822, 7.439, 7.925, 9.754, 7.696, 7.362, 9.306, 7.512, 8.232, 7.545, 7.489, 8.611, 16.045, 7.939, 10.472, 6.796, 8.464, 7.173, 7.89, 7.554, 8.525, 9.494, 7.684, 6.865, 7.101, 8.34, 22.229, 6.957, 7.895, 8.909, 6.963, 6.922, 6.701, 6.923, 7.115, 7.186, 6.833, 8.616, 6.935, 6.937, 6.917, 6.841, 7.593, 7.125, 6.823, 9.082, 41.614, 7.508, 6.843, 7.319, 8.472, 7.803, 6.557, 8.152, 7.368, 6.793, 7.547, 18.912, 6.753, 8.382, 6.867, 7.128, 7.219, 9.134, 8.129, 9.898, 6.859, 8.512, 6.899, 6.897, 7.146, 6.924, 7.755, 15.511, 8.408, 7.054, 6.898, 8.38, 7.79, 7.426, 6.841, 7.0, 6.795, 9.788, 8.017, 7.939, 7.613, 7.144, 8.093, 7.852, 7.215, 8.685, 6.953, 7.367, 7.039, 11.028, 6.995, 9.484, 7.612, 7.572, 7.548, 6.883, 8.522, 10.248, 22.187, 7.069, 6.799, 6.765, 8.575, 7.069, 6.729, 8.079, 7.769, 8.145, 7.021, 7.176, 7.064, 7.007, 7.895, 6.762, 10.453, 7.952, 6.978, 6.933, 6.825, 7.897, 7.482, 6.931, 7.328, 14.227, 6.704, 8.268, 6.834, 6.727, 7.223, 7.866, 6.848, 7.146, 7.227, 9.584, 6.672, 6.987, 8.734, 7.349, 7.23, 9.854, 20.654, 7.534, 7.428, 7.729, 6.767, 7.07, 7.921, 7.435, 7.511, 6.892, 9.347, 8.346, 6.942, 7.184, 7.07, 6.958, 6.843, 8.219, 8.462, 7.672, 7.283, 6.877, 7.342, 8.621, 6.898, 7.54, 6.82, 7.025, 6.898, 6.816, 7.175, 6.869, 9.088, 6.705, 7.052, 7.167, 6.968, 6.736, 7.631, 8.862, 6.777, 7.006, 7.454, 7.203, 8.213, 6.742, 6.686, 12.962, 12.957, 7.012, 7.854, 7.633, 7.619, 6.774, 9.331, 7.585, 7.48, 6.805, 9.689, 8.213, 7.053, 7.27, 7.418, 7.566, 7.051, 8.468, 6.725, 6.99, 6.762, 6.872, 9.158, 7.964, 6.817, 15.306, 6.882, 8.466, 9.344, 19.892, 6.691, 6.98, 8.443, 6.79, 6.765, 7.157, 16.31, 7.675, 7.609, 8.701, 7.011, 9.464, 7.848, 6.977, 7.273, 8.262, 7.241, 7.162, 9.175, 6.945, 7.115, 6.998, 6.94, 9.134, 9.825, 7.066, 9.474, 6.916, 7.99, 175.916, 6.963, 8.329, 9.015, 7.049, 7.225, 7.006, 7.359, 8.0, 10.85, 7.306, 16.738, 12.516, 7.293, 6.95, 7.331, 18.492, 12.903, 9.45, 7.015, 8.051, 9.06, 7.344, 7.426, 9.714, 7.44, 8.311, 10.094, 8.01, 8.529, 7.334, 9.303, 7.588, 7.236, 7.304, 7.055, 9.681, 6.95, 10.349, 9.464, 7.059, 7.595, 7.182, 8.424, 6.753, 7.336, 7.173, 41.401, 7.175, 9.17, 7.902, 7.464, 6.984, 6.987, 8.657, 6.858, 8.811, 7.962, 7.44, 11.181, 7.543, 7.234, 7.008, 7.283, 9.438, 7.248, 7.095, 7.239, 7.029, 7.906, 7.139, 7.17, 6.971, 7.763, 7.038, 7.13, 7.521, 14.425, 8.387, 7.783, 7.416, 7.811, 7.404, 7.068, 7.168, 7.158, 7.539, 7.091, 8.547, 9.266, 7.374, 7.678, 6.989, 12.538, 7.335, 7.472, 7.368, 8.223, 7.367, 7.412, 10.859, 7.425, 7.335, 7.398, 8.127, 7.042, 7.419, 7.149, 7.188, 7.671, 7.244, 7.255, 7.251, 7.274, 7.565, 7.193, 8.308, 7.28, 10.788, 14.646, 7.825, 7.161, 6.872, 7.002, 7.057, 7.31, 6.942, 9.74, 6.819, 7.303, 7.333, 10.783, 7.167, 7.356, 14.11, 6.923, 8.039, 7.785, 8.316, 79.049, 7.66, 8.935, 7.719, 9.855, 7.274, 7.167, 16.487, 7.507, 7.11, 8.258, 7.241, 7.368, 13.807, 7.176, 8.577, 8.31, 7.172, 9.709, 8.614, 7.421, 7.265, 8.548, 8.087, 7.932, 9.19, 9.123, 7.203, 7.313, 8.309, 7.394, 7.214, 7.379, 7.771, 7.172, 9.042, 7.935, 7.824, 7.41, 15.972, 7.604, 9.293, 8.597, 7.294, 7.5, 15.569, 7.142, 7.771, 7.578, 7.402, 7.222, 7.264, 7.37, 7.981, 7.454, 6.818, 7.556, 8.217, 8.35, 7.041, 7.16, 7.521, 7.437, 7.232, 7.679, 8.233, 8.179, 7.443, 16.33, 7.206, 8.206, 7.898, 7.751, 9.421, 7.275, 23.963, 7.292, 8.818, 7.706, 9.672, 7.367, 7.307, 7.04, 10.957, 7.202, 6.967, 7.248, 7.171, 7.607, 6.899, 10.565, 9.534, 22.95, 7.315, 7.455, 8.332, 9.077, 7.716, 7.656, 7.267, 7.257, 7.236, 7.779, 10.023, 8.533, 8.624, 8.072, 9.152, 7.678, 8.111, 7.643, 8.405, 8.252, 10.073, 7.241, 21.569, 7.363, 9.303, 9.787, 9.05, 8.778, 7.395, 7.618, 8.763, 7.262, 7.183, 9.578, 7.762, 8.02, 7.41, 26.744, 7.357, 7.375, 7.704, 8.76, 10.564, 7.349, 7.984, 7.864, 8.141, 9.603, 7.646, 7.326, 9.448, 8.209, 11.052, 7.599, 7.871, 9.076, 8.825, 8.55, 7.657, 7.494, 8.473, 13.416, 7.256, 8.274, 10.781, 7.66, 7.5, 7.152, 59.13, 9.186, 11.26, 7.104, 7.498, 8.261, 7.541, 8.57, 7.308, 7.974, 8.891, 8.331, 7.994, 9.048, 9.252, 8.05, 9.17, 10.119, 8.088, 8.847, 10.175, 7.942, 7.536, 8.162, 7.303, 7.242, 8.123, 7.596, 9.843, 8.325, 17.921, 7.391, 7.113, 7.487, 7.6, 7.368, 7.263, 10.966, 7.617, 8.403, 8.212, 9.966, 9.283, 8.681, 7.456, 8.708, 8.995, 8.093, 7.573, 8.262, 7.362, 8.473, 7.443, 9.647, 10.864, 7.709, 7.516, 7.221, 8.096, 12.396, 7.22, 8.801, 7.077, 8.894, 8.119, 7.309, 9.606, 7.183, 8.857, 9.642, 7.537, 7.678, 7.169, 8.406, 186.501, 10.534, 9.009, 8.532, 9.496, 11.242, 8.204, 9.559, 8.209, 9.161, 9.108, 7.712, 9.204, 7.525, 9.435, 11.547, 7.919, 7.935, 13.098, 9.273, 9.066, 9.788, 7.872, 8.859, 9.603, 8.532, 9.001, 7.913, 8.016, 7.965, 8.771, 17.132, 8.976, 8.779, 7.665, 7.856, 8.148, 7.703, 10.239, 7.979, 8.964, 102.636, 9.059, 8.608, 8.165, 8.671, 10.03, 8.284, 17.019, 8.442, 12.015, 9.948, 9.308, 7.819, 22.833, 9.24, 9.968, 8.879, 7.866, 7.998, 8.419, 8.654, 8.814, 9.3, 7.751, 8.727, 8.564, 7.931, 8.052, 11.248, 7.83, 8.083, 7.823, 8.569, 7.757, 8.954, 8.321, 9.017, 8.497, 9.05, 8.163, 8.42, 8.583, 8.874, 9.473, 10.875, 7.75, 9.496, 9.623, 49.364, 8.089, 8.225, 8.174, 8.411, 7.592, 9.444, 8.18, 7.898, 8.37, 8.238, 7.634, 7.957, 7.318, 8.366, 19.029, 18.473, 8.021, 8.586, 9.29, 7.538, 9.623, 7.963, 8.677, 8.232, 7.358, 8.329, 7.702, 7.621, 7.616, 8.614, 7.995, 9.44, 8.711, 7.363, 7.907, 7.875, 7.886, 8.478, 8.572, 7.44, 7.912, 8.056, 24.878, 7.375, 8.881, 7.435, 8.381, 7.287, 7.303, 8.46, 7.881, 7.509, 7.46, 7.188, 7.575, 7.374, 7.424, 7.461, 7.888, 7.591, 7.329, 7.673, 7.024, 7.538, 7.739, 7.241, 7.779, 8.56, 7.155, 8.174, 7.322, 10.42, 7.436, 7.794, 7.805, 9.671, 7.552, 9.552, 13.301, 7.885, 8.13, 7.535, 22.666, 10.542, 7.061, 7.451, 8.108, 9.139, 8.187, 8.099, 7.04, 20.326, 7.55, 9.252, 8.766, 7.517, 7.149, 7.103, 8.863, 7.416, 7.064, 7.402, 7.588, 8.293, 7.519, 7.674, 7.595, 8.747, 7.297, 7.673, 7.942, 8.128, 7.138, 7.264, 7.431, 7.227, 9.313, 7.475, 7.358, 7.45, 7.675, 7.329, 7.711, 7.474, 7.785, 7.394, 7.588, 7.737, 7.497, 7.207, 7.391, 8.395, 8.75, 8.076, 8.503, 8.737, 7.258, 7.565, 13.158, 7.534, 7.721, 8.256, 7.575, 7.603, 7.976, 7.636, 7.385, 7.56, 8.288, 7.672, 9.218, 11.103, 8.736, 9.009, 7.216, 8.334, 7.599, 7.558, 7.402, 11.977, 7.64, 17.404, 7.538, 7.128, 8.493, 13.194, 7.346, 8.347, 7.396, 7.193, 7.77, 7.415, 7.29, 8.627, 7.627, 7.627, 7.446, 7.236, 7.87, 7.657, 8.292, 7.662, 7.316, 7.215, 7.312, 8.26, 22.331, 7.134, 7.533, 7.373, 7.927, 13.424, 7.551, 9.86, 7.478, 7.345, 9.001, 7.808, 7.039, 8.122, 7.434, 8.764, 7.735, 8.999, 7.785, 8.861, 7.843, 7.52, 8.347, 7.709, 8.445, 7.94, 7.723, 8.968, 8.04, 17.671, 15.621, 8.649, 7.816, 7.187, 8.067, 7.236, 7.091, 8.467, 8.796, 7.715, 10.02, 7.245, 7.18, 9.566, 7.331, 8.123, 7.211, 10.939, 7.389, 7.888, 7.127, 8.124, 8.206, 7.809, 7.203, 7.219, 7.435, 7.327, 7.281, 8.399, 7.7, 7.386, 7.318, 8.112, 9.429, 8.841, 11.158, 7.524, 7.631, 7.906, 7.773, 8.192, 7.74, 10.388, 8.054, 7.386, 7.259, 7.387, 7.634, 9.517, 8.438, 7.424, 30.774, 7.34, 8.161, 8.163, 7.769, 8.706, 8.466, 9.069, 9.025, 7.656, 9.254, 9.496, 8.529, 8.3, 8.521, 8.546, 8.227, 10.962, 9.212, 9.774, 12.105, 8.779, 9.016, 8.475, 9.133, 8.691, 7.675, 10.849, 9.445, 8.351, 8.272, 9.653, 8.901, 9.642, 8.87, 7.561, 13.081, 12.855, 7.275, 8.466, 7.2, 7.466, 7.089, 9.18, 8.913, 7.463, 8.411, 7.827, 8.79, 7.466, 9.143, 7.816, 7.762, 7.637, 7.612, 7.593, 9.076, 8.312, 7.828, 8.976, 7.522, 9.296, 8.625, 8.815, 8.042, 7.953, 7.662, 7.704, 7.383, 7.442, 7.325, 7.853, 9.195, 8.657, 10.293, 7.963, 7.292, 6.955, 8.4, 9.543, 11.394, 8.282, 8.45, 7.941, 7.694, 7.263, 8.585, 7.729, 7.333, 10.832, 7.805, 7.421, 7.623, 7.608, 7.336, 8.342, 9.688, 8.07, 9.283, 8.144, 8.071, 7.965, 7.812, 8.259, 7.82, 7.528, 7.975, 8.05, 7.865, 9.287, 7.576, 8.095, 8.32, 8.494, 10.286, 7.716, 9.194, 10.811, 9.989, 70.668, 9.082, 8.855, 8.291, 8.388, 7.986, 9.917, 9.647, 8.193, 29.605, 9.977, 10.109, 10.333, 8.678, 8.843, 9.119, 9.629, 8.773, 9.812, 10.042, 8.099, 9.107, 9.04, 9.018, 9.858, 9.936, 9.733, 9.965, 9.732, 10.373, 9.843, 10.481, 9.36, 9.401, 10.291, 9.296, 9.488, 10.801, 10.105, 9.599, 9.152, 10.696, 8.529, 9.487, 13.177, 9.952, 9.352, 8.177, 9.164, 9.403, 8.912, 10.697, 9.471, 9.537, 9.641, 9.535, 9.996, 9.473, 12.702, 9.583, 9.849, 9.945, 8.863, 9.285, 10.96, 9.225, 9.395, 9.109, 9.494, 8.553, 9.033, 9.549, 11.031, 9.924, 9.329, 10.469, 15.718, 15.14, 12.042, 10.573, 10.052, 9.427, 8.761, 8.713, 9.824, 9.116, 9.591, 9.208, 9.739, 9.385, 9.224, 9.629, 8.344, 8.472, 9.692, 9.08, 9.25, 10.701, 10.014, 12.02, 12.013, 10.219, 10.057, 10.351, 9.322, 9.04, 9.181, 9.824, 9.271, 9.678, 8.112, 10.077, 9.06, 8.846, 9.304, 9.688, 9.009, 11.06, 10.162, 8.816, 10.067, 10.051, 9.491, 8.913, 8.694, 26.532, 9.952, 9.841, 8.981, 9.369, 7.673, 8.523, 8.328, 9.816, 9.915, 7.736, 7.823, 8.605, 8.217, 7.811, 20.78, 10.294, 9.58, 7.983, 9.229, 10.456, 8.104, 7.524, 9.226, 9.025, 8.212, 9.963, 9.077, 8.387, 7.599, 9.673, 9.259, 7.794, 8.113, 8.505, 10.662, 10.296, 9.276, 9.223, 35.289, 8.605, 17.095, 9.676, 9.798, 9.676, 10.648, 10.529, 9.903, 10.318, 10.076, 10.29, 9.625, 9.163, 11.384, 9.914, 9.726, 10.478, 10.319, 10.429, 10.12, 9.703, 9.339, 10.15, 9.525, 11.845, 10.182, 12.013
            ], 
            [
                4.413, 0.767, 0.361, 0.149, 0.653, 0.115, 5.775, 0.149, 0.806, 0.12, 1.03, 0.789, 0.473, 1.401, 0.928, 0.216, 0.149, 0.236, 1.419, 0.199, 0.188, 0.242, 0.279, 0.211, 0.345, 0.256, 0.153, 38.945, 0.395, 0.18, 0.182, 0.47, 0.16, 1.645, 1.236, 0.21, 0.211, 0.24, 0.139, 0.827, 0.125, 0.485, 0.214, 0.954, 0.481, 0.473, 0.463, 0.358, 0.291, 0.487, 0.19, 0.162, 0.447, 2.616, 0.414, 0.157, 1.119, 0.512, 0.123, 0.13, 0.56, 0.703, 0.337, 0.843, 0.213, 0.294, 0.227, 0.234, 8.853, 0.249, 0.168, 3.41, 0.246, 0.164, 2.072, 0.208, 0.162, 0.224, 0.132, 0.247, 0.153, 0.12, 1.273, 0.133, 0.18, 0.186, 25.416, 0.27, 0.298, 0.489, 0.293, 0.863, 0.663, 0.227, 0.118, 0.768, 1.038, 0.152, 1.077, 0.235, 0.198, 0.249, 0.206, 0.172, 7.172, 0.78, 0.163, 0.284, 0.137, 0.265, 11.726, 0.838, 0.852, 0.97, 0.277, 0.176, 0.204, 0.471, 0.167, 0.133, 0.522, 0.668, 0.136, 0.463, 0.504, 0.541, 0.516, 0.482, 16.269, 0.144, 0.142, 0.188, 0.292, 0.283, 0.195, 0.211, 0.271, 0.22, 0.162, 0.183, 0.434, 0.189, 0.244, 0.663, 0.185, 0.194, 3.962, 0.648, 0.372, 0.288, 0.183, 0.46, 0.217, 0.159, 2.817, 0.314, 1.542, 0.135, 1.177, 0.575, 2.391, 0.895, 0.448, 1.334, 0.487, 12.795, 0.302, 0.131, 0.474, 0.474, 0.332, 4.182, 0.96, 0.449, 0.382, 0.43, 0.953, 0.209, 0.521, 0.467, 0.196, 0.17, 0.149, 0.565, 0.492, 0.41, 3.51, 0.239, 1.878, 0.157, 0.204, 0.272, 0.134, 0.396, 0.309, 0.202, 1.512, 0.137, 0.134, 10.814, 0.444, 0.638, 0.683, 0.507, 0.591, 0.317, 0.178, 0.476, 0.32, 0.148, 0.225, 0.253, 0.175, 0.517, 4.385, 0.162, 0.667, 0.862, 1.218, 0.196, 0.156, 0.45, 2.613, 0.441, 0.438, 4.788, 0.202, 0.213, 5.343, 0.453, 6.395, 0.422, 1.955, 0.139, 0.192, 32.117, 1.309, 0.431, 1.118, 3.525, 0.216, 0.211, 0.188, 0.268, 2.096, 1.474, 0.514, 5.291, 0.399, 0.376, 0.296, 3.364, 2.159, 1.405, 0.504, 0.565, 0.268, 0.229, 0.477, 0.221, 164.131, 0.603, 0.157, 0.508, 2.087, 0.338, 1.504, 0.28, 0.181, 0.209, 0.616, 0.544, 0.406, 0.204, 0.169, 0.371, 0.199, 1.393, 0.248, 0.294, 0.47, 0.288, 0.218, 0.259, 0.585, 0.158, 0.278, 0.227, 0.233, 12.814, 0.182, 0.422, 0.239, 0.161, 0.175, 0.154, 0.154, 0.9, 0.219, 0.796, 0.214, 0.215, 0.959, 0.16, 3.357, 4.392, 0.185, 0.215, 0.623, 0.563, 2.01, 0.215, 3.7, 0.166, 0.575, 0.405, 0.145, 2.654, 0.156, 0.294, 0.641, 1.562, 0.637, 0.151, 0.169, 4.244, 0.433, 0.225, 1.151, 0.559, 0.157, 0.413, 0.15, 0.199, 0.522, 0.193, 0.146, 0.217, 13.399, 0.393, 0.771, 0.174, 1.215, 0.225, 0.455, 0.187, 0.356, 1.994, 0.179, 0.65, 0.314, 0.314, 0.225, 1.754, 0.245, 0.193, 0.491, 0.249, 3.91, 86.712, 0.508, 0.191, 0.278, 0.292, 0.204, 0.154, 3.516, 0.954, 0.176, 0.375, 0.179, 2.51, 1.93, 0.786, 0.207, 8.443, 0.37, 0.256, 0.154, 0.176, 0.145, 0.467, 0.242, 0.182, 0.987, 9.59, 0.155, 0.814, 0.244, 0.673, 0.228, 0.365, 0.177, 0.538, 0.344, 0.149, 0.14, 0.794, 0.331, 0.71, 0.167, 0.17, 0.168, 0.158, 0.21, 0.907, 0.215, 0.274, 0.83, 1.068, 0.526, 0.494, 1.351, 0.32, 0.433, 0.983, 0.465, 0.529, 0.513, 0.191, 5.78, 0.318, 1.381, 0.201, 0.601, 0.22, 0.167, 0.221, 0.157, 0.248, 0.15, 0.464, 0.186, 0.171, 0.159, 0.654, 0.226, 0.261, 0.47, 0.47, 3.45, 0.353, 0.428, 1.284, 1.568, 0.638, 2.37, 0.479, 3.88, 0.689, 0.205, 0.163, 0.59, 0.241, 0.519, 0.199, 0.238, 0.283, 14.254, 1.374, 0.168, 8.261, 0.245, 0.165, 0.303, 2.64, 0.273, 0.444, 2.418, 2.896, 0.166, 0.625, 0.169, 0.245, 0.211, 0.277, 0.229, 0.955, 0.351, 0.372, 0.493, 0.236, 0.488, 0.265, 0.159, 1.062, 0.181, 0.593, 1.679, 0.343, 0.673, 0.587, 0.413, 0.25, 0.267, 0.479, 0.243, 0.2, 0.16, 0.348, 0.338, 0.192, 0.398, 0.424, 0.164, 0.205, 0.235, 2.023, 0.15, 0.267, 0.514, 1.336, 0.377, 0.191, 0.763, 1.997, 0.229, 0.162, 0.244, 0.234, 0.767, 0.21, 2.36, 0.256, 0.836, 0.21, 0.366, 14.279, 1.071, 0.154, 0.215, 0.328, 0.212, 0.221, 0.22, 0.413, 0.246, 0.183, 0.918, 22.059, 0.299, 0.321, 0.755, 0.152, 0.15, 0.625, 0.174, 2.933, 0.976, 0.355, 0.698, 0.491, 0.249, 0.187, 0.323, 0.183, 0.245, 8.46, 1.332, 0.289, 3.515, 1.025, 0.208, 0.707, 0.19, 0.416, 0.43, 0.184, 0.458, 0.17, 0.482, 0.361, 0.189, 1.639, 6.241, 0.215, 0.71, 0.816, 0.155, 0.637, 0.911, 0.369, 0.158, 0.551, 1.609, 0.549, 0.192, 0.607, 0.677, 0.194, 0.234, 0.978, 0.454, 0.509, 4.916, 2.076, 0.172, 0.186, 0.242, 0.187, 21.21, 0.199, 0.686, 0.185, 0.211, 1.404, 0.944, 0.227, 0.52, 3.664, 0.442, 0.535, 0.165, 0.445, 0.845, 2.376, 1.105, 1.185, 0.927, 5.204, 1.364, 0.159, 3.593, 0.381, 0.324, 1.261, 2.015, 0.318, 0.208, 0.567, 1.206, 0.31, 0.202, 1.191, 0.198, 16.111, 0.688, 0.749, 6.848, 0.598, 0.467, 0.175, 0.404, 0.195, 0.192, 0.348, 0.177, 0.372, 0.2, 0.355, 1.481, 0.938, 1.161, 0.173, 0.193, 0.219, 0.334, 2.265, 0.704, 0.57, 0.438, 0.406, 0.232, 0.539, 0.228, 0.166, 0.203, 0.388, 0.388, 0.177, 0.175, 0.408, 0.561, 0.197, 0.971, 0.239, 0.236, 0.426, 0.581, 0.277, 0.172, 0.273, 0.2, 0.703, 2.859, 1.404, 0.318, 0.21, 0.435, 0.183, 0.257, 0.28, 7.899, 0.232, 1.659, 0.387, 7.591, 0.389, 0.29, 0.72, 0.337, 0.291, 1.445, 0.202, 0.2, 0.426, 0.342, 0.382, 1.556, 0.669, 9.153, 0.497, 1.403, 0.189, 0.241, 0.177, 1.317, 0.238, 59.446, 0.316, 0.282, 0.223, 0.15, 0.909, 1.122, 0.918, 3.508, 0.685, 0.679, 0.488, 0.508, 0.717, 0.44, 0.214, 0.486, 9.285, 0.694, 0.325, 1.93, 1.139, 1.011, 0.226, 0.357, 0.372, 0.406, 0.183, 0.184, 0.172, 0.682, 14.351, 1.829, 0.188, 0.317, 0.245, 0.235, 0.554, 0.414, 1.969, 0.655, 0.299, 0.234, 2.369, 66.334, 0.696, 0.68, 0.562, 0.288, 0.181, 1.483, 0.354, 0.372, 0.621, 0.898, 0.347, 0.432, 0.466, 0.235, 0.306, 0.562, 0.192, 0.185, 1.172, 1.476, 0.661, 1.129, 0.177, 0.153, 0.267, 0.992, 0.297, 0.293, 1.079, 0.369, 3.119, 0.216, 0.722, 0.825, 0.556, 0.771, 0.305, 1.203, 0.21, 0.452, 0.321, 0.367, 0.185, 1.961, 0.391, 0.216, 0.706, 0.585, 0.366, 0.187, 5.777, 0.203, 1.375, 0.182, 0.373, 0.895, 1.282, 0.845, 0.332, 1.465, 0.327, 2.575, 0.171, 0.268, 0.289, 0.626, 0.222, 0.365, 0.763, 0.421, 0.274, 0.205, 0.331, 14.479, 4.497, 0.322, 0.172, 10.193, 0.344, 0.349, 7.515, 3.359, 1.078, 1.435, 0.585, 0.201, 0.434, 8.987, 0.206, 1.56, 0.7, 2.952, 0.296, 0.299, 0.38, 0.312, 0.197, 0.319, 0.622, 0.676, 1.217, 0.191, 0.524, 3.921, 0.471, 0.242, 0.468, 0.184, 2.882, 0.308, 1.7, 0.213, 0.303, 0.637, 0.395, 0.215, 1.42, 0.165, 0.431, 0.427, 0.814, 0.318, 0.722, 0.285, 2.396, 1.271, 0.218, 0.188, 0.319, 0.186, 1.285, 0.73, 1.938, 0.342, 0.505, 0.377, 0.471, 0.277, 0.367, 0.231, 0.187, 0.35, 0.379, 0.598, 0.186, 0.988, 0.476, 0.302, 0.415, 1.812, 0.163, 0.573, 0.497, 2.307, 0.544, 1.985, 0.178, 0.219, 0.552, 0.349, 0.189, 0.811, 1.125, 3.534, 0.231, 0.395, 0.372, 0.21, 0.85, 0.435, 2.191, 0.225, 0.736, 0.434, 1.411, 0.442, 0.381, 0.286, 0.523, 0.388, 0.202, 0.233, 0.294, 0.44, 0.752, 0.21, 7.324, 10.557, 0.277, 0.315, 0.499, 0.195, 0.469, 0.298, 0.534, 0.301, 0.196, 0.217, 0.174, 47.718, 0.26, 0.433, 0.518, 0.218, 0.611, 0.277, 0.281, 0.214, 1.994, 0.395, 1.026, 0.184, 0.584, 0.277, 2.516, 0.446, 0.287, 0.27, 0.266, 0.409, 0.872, 1.01, 2.731, 0.198, 17.619, 0.189, 0.181, 0.277, 0.371, 0.353, 0.209, 0.433, 0.391, 0.421, 0.287, 1.975, 0.237, 0.354, 1.169, 0.448, 0.369, 0.365, 1.027, 0.364, 0.629, 0.439, 2.146, 0.665, 0.411, 0.479, 1.373, 1.089, 0.671, 0.389, 0.559, 0.416, 0.374, 0.386, 0.447, 0.379, 0.491, 1.421, 1.131, 0.564, 0.4, 1.498, 0.802, 0.42, 1.099, 0.578, 0.412, 1.355, 2.086, 0.396, 3.626, 0.473, 0.472, 0.383, 0.358, 0.37, 4.296, 0.376, 0.455, 0.422, 0.473, 0.446, 1.783, 0.369, 0.348, 0.485, 15.531, 0.955, 0.517, 20.413, 0.373, 0.51, 0.479, 38.574, 0.41, 17.716, 0.467, 0.358, 0.576, 0.523, 0.472, 0.47, 0.477, 0.509, 0.353, 0.557, 0.364, 3.519, 0.548, 0.417, 0.398, 0.425, 0.455, 7.686, 1.445, 0.448, 0.392, 2.222, 0.655, 2.751, 0.374, 0.396, 2.553, 0.624, 0.655, 0.395, 0.434, 0.908, 0.506, 0.639, 0.636, 0.933, 0.571, 0.6, 1.77, 0.644, 0.952, 0.662, 0.408, 1.559, 0.629, 0.582, 0.996, 0.618, 1.095, 0.605, 0.586, 0.367, 0.421, 0.829, 1.17, 0.851, 1.559, 0.416, 0.98, 0.427, 0.898, 0.712, 0.323, 2.088, 0.967, 0.432, 0.34, 0.394, 0.502, 2.456, 1.907, 2.141, 0.337, 0.351, 0.432, 0.484, 5.48, 3.946, 1.23, 0.354, 2.217, 0.467, 0.914, 0.462, 0.695, 0.351, 0.539, 0.497, 0.712, 0.531, 0.611, 1.015, 0.351, 0.486, 1.028, 0.621, 8.533, 21.386, 0.371, 0.589, 0.727, 0.572, 0.44, 2.006, 0.387, 1.31, 0.457, 0.506, 0.351, 0.382, 4.87, 1.556, 0.515, 0.513, 0.592, 0.435, 1.408, 0.492, 0.392, 0.849, 0.447, 1.498, 84.751, 0.397, 0.443, 2.212, 0.719, 0.46, 3.501, 0.344, 7.202, 0.404, 1.127, 0.67, 5.615, 1.37, 0.594, 0.4, 0.382, 0.933, 0.961, 0.875, 1.184, 0.805, 0.424, 0.48, 2.009, 0.376, 0.748, 0.367, 0.669, 0.568, 0.442, 0.657, 0.492, 0.542, 0.438, 0.48, 0.717, 0.441, 1.073, 0.475, 0.737, 0.414, 0.539, 0.739, 0.684, 0.74, 0.386, 0.508, 3.856, 0.56, 0.405, 0.55, 0.418, 0.589, 1.652, 0.54, 0.503, 4.518, 0.463, 0.369, 0.978, 0.708, 0.698, 0.887, 0.398, 0.454, 0.72, 0.389, 0.402, 0.376, 0.679, 0.38, 0.42, 0.413, 0.52, 0.603, 1.529, 0.422, 0.949, 1.231, 0.441, 0.393, 0.877, 0.566, 0.359, 0.466, 0.487, 0.523, 0.484, 0.381, 0.404, 0.634, 0.525, 0.441, 0.672, 0.709, 0.483, 1.471, 0.611, 0.481, 0.994, 0.882, 1.499, 1.562, 0.395, 0.417, 0.447, 0.387, 0.494, 0.698, 0.461, 0.409, 0.572, 0.462, 1.359, 0.682, 0.344, 0.436, 0.362, 0.375, 0.459, 1.271, 0.512, 0.871, 0.442, 0.459, 14.333, 0.505, 0.435, 1.084, 0.761, 0.625, 0.414, 0.474, 0.818, 0.43, 1.476, 0.367, 1.776, 0.444, 1.208, 0.365, 0.536, 0.657, 15.78, 0.56, 0.475, 0.79, 0.459, 0.922, 0.447, 2.107, 0.428, 0.47, 3.969, 4.145, 0.404, 1.725, 6.443, 0.347, 0.686, 0.371, 0.43, 0.636, 1.86, 0.684, 0.531, 0.401, 1.683, 0.434, 4.16, 1.078, 0.374, 0.837, 0.562, 0.426, 0.376, 0.504, 0.435, 0.344, 1.375, 1.745, 2.659, 5.395, 5.407, 1.468, 0.358, 0.884, 0.376, 0.379, 0.787, 0.75, 0.346, 0.941, 0.767, 0.465, 0.786, 2.699, 0.488, 0.574, 0.68, 0.531, 0.512, 0.38, 0.508, 0.593, 0.386, 0.478, 58.401, 0.347, 0.394, 0.505, 0.42, 0.375, 0.589, 0.409, 0.497, 0.436, 0.421, 0.577, 0.34, 10.878, 1.083, 0.349, 0.36, 0.643, 0.347, 1.533, 1.643, 0.53, 0.796, 0.364, 1.061, 0.378, 0.624, 0.84, 0.37, 0.707, 1.268, 0.602, 1.076, 0.533, 2.33, 0.363, 1.394, 0.764, 0.691, 2.689, 0.395, 0.374, 1.278, 0.472, 1.137, 1.362, 0.439, 0.62, 0.485, 0.481, 3.378, 1.092, 1.604, 8.582, 0.612, 0.582, 0.636, 0.468, 0.335, 0.362, 0.522, 0.977, 0.581, 0.524, 0.576, 0.465, 2.327, 0.853, 0.579, 0.445, 0.491, 0.46, 1.48, 0.516, 1.401, 25.66, 0.52, 0.457, 1.31, 0.505, 5.582, 0.433, 0.423, 67.95, 0.425, 0.705, 0.57, 0.724, 0.553, 0.898, 1.516, 0.498, 0.504, 0.43, 0.482, 0.375, 1.499, 0.382, 0.641, 0.383, 0.402, 12.339, 0.432, 0.374, 0.628, 0.456, 0.474, 0.404, 0.456, 0.383, 0.545, 0.645, 0.461, 0.391, 0.443, 0.563, 0.476, 0.425, 1.711, 0.415, 0.878, 0.464, 0.418, 0.532, 0.391, 0.638, 0.951, 0.479, 0.378, 0.423, 2.074, 0.444, 0.693, 0.455, 3.465, 0.443, 3.721, 0.365, 0.546, 0.554, 0.695, 47.279, 0.775, 0.54, 0.363, 0.425, 0.815, 0.473, 1.332, 1.297, 0.52, 7.422, 0.595, 1.018, 0.355, 0.397, 0.479, 0.413, 0.461, 1.838, 0.491, 0.677, 0.383, 0.477, 0.431, 0.502, 0.649, 0.623, 4.759, 0.732, 0.683, 0.685, 10.107, 0.461, 0.436, 1.044, 0.455, 0.697, 0.443, 0.512, 0.552, 0.449, 3.84, 0.722, 0.906, 0.58, 0.435, 0.508, 0.551, 0.845, 0.386, 0.755, 0.811, 3.882, 0.51, 0.72, 1.085, 8.955, 0.483, 0.885, 0.444, 0.662, 0.485, 0.487, 0.526, 0.436, 0.6, 0.443, 1.108, 6.606, 0.436, 0.523, 0.774, 0.663, 0.479, 0.402, 0.513, 2.597, 0.497, 0.436, 0.69, 0.73, 0.872, 0.474, 0.375, 2.151, 0.627, 0.486, 0.496, 0.596, 0.624, 0.415, 0.466, 0.57, 0.842, 0.373, 0.598, 2.187, 0.501, 0.385, 0.89, 0.547, 0.563, 0.614, 0.606, 0.765, 0.539, 0.702, 0.433, 0.443, 0.419, 1.599, 0.58, 0.434, 0.607, 0.393, 0.417, 0.613, 0.859, 0.78, 0.487, 0.637, 0.377, 2.293, 0.521, 0.397, 0.459, 0.389, 2.556, 0.738, 0.548, 0.475, 1.448, 14.474, 0.941, 0.584, 0.898, 0.506, 0.665, 2.553, 0.491, 2.23, 0.453, 1.076, 8.064, 0.659, 1.583, 0.483, 0.588, 0.632, 0.427, 0.357, 3.637, 0.96, 3.019, 0.412, 0.443, 0.548, 2.898, 0.398, 0.436, 0.405, 1.059, 0.43, 1.444, 0.465, 0.976, 0.44, 0.448, 0.865, 0.436, 1.194, 1.032, 1.549, 1.748, 1.102, 0.35, 0.975, 0.512, 0.97, 0.455, 0.826, 2.169, 8.723, 0.461, 3.672, 0.523, 0.564, 0.817, 0.487, 1.012, 0.478, 2.768, 0.746, 0.425, 0.451, 1.824, 14.41, 0.553, 1.299, 2.471, 0.583, 0.4, 0.432, 0.37, 0.689, 0.631, 0.476, 0.475, 0.396, 0.422, 0.477, 0.398, 0.9, 0.431, 0.412, 0.672, 31.79, 0.88, 0.395, 0.555, 0.439, 1.387, 0.429, 1.657, 0.896, 0.423, 0.462, 11.317, 0.547, 1.058, 0.421, 0.836, 0.622, 0.452, 0.439, 1.895, 0.378, 2.122, 0.362, 0.478, 0.401, 0.511, 1.488, 9.028, 0.47, 0.415, 0.367, 0.819, 0.76, 1.18, 0.423, 0.584, 0.413, 1.975, 1.09, 0.571, 0.935, 0.511, 0.412, 1.351, 0.531, 0.446, 0.622, 1.077, 0.534, 4.307, 0.603, 2.558, 0.375, 1.096, 0.941, 0.403, 1.082, 3.263, 14.143, 0.697, 0.404, 0.5, 0.449, 0.518, 0.505, 0.415, 1.426, 0.423, 0.566, 0.634, 0.77, 0.57, 0.661, 0.391, 3.954, 0.812, 0.531, 0.528, 0.451, 1.234, 1.085, 0.382, 0.459, 7.25, 0.476, 1.725, 0.498, 0.441, 0.757, 1.299, 0.451, 0.848, 0.765, 3.193, 0.484, 0.692, 2.242, 0.94, 0.893, 3.321, 13.7, 1.055, 0.993, 0.461, 0.461, 0.603, 1.319, 1.144, 0.647, 0.402, 0.423, 0.981, 0.445, 0.637, 0.543, 0.517, 0.495, 0.48, 0.716, 1.213, 0.816, 0.426, 0.894, 2.253, 0.404, 1.063, 0.476, 0.547, 0.418, 0.515, 0.677, 0.37, 0.434, 0.513, 0.398, 0.879, 0.558, 0.465, 1.102, 2.662, 0.42, 0.477, 0.609, 0.754, 0.54, 0.439, 0.538, 5.283, 6.694, 0.811, 1.628, 1.481, 1.369, 0.529, 1.048, 1.003, 1.168, 0.507, 0.646, 0.603, 0.475, 1.029, 0.661, 1.39, 0.549, 0.541, 0.505, 0.582, 0.493, 0.482, 2.665, 0.573, 0.491, 8.141, 0.516, 0.438, 1.514, 13.694, 0.471, 0.608, 0.455, 0.401, 0.446, 0.755, 9.82, 0.727, 0.44, 2.542, 0.605, 3.005, 1.364, 0.556, 0.645, 1.668, 0.437, 0.705, 0.953, 0.443, 0.712, 0.49, 0.494, 1.164, 1.755, 0.675, 3.08, 0.401, 0.421, 163.22, 0.431, 0.514, 0.41, 0.498, 0.506, 0.486, 0.537, 1.204, 4.192, 0.487, 9.766, 3.747, 0.712, 0.471, 0.577, 11.191, 5.855, 2.4, 0.457, 1.276, 0.406, 0.542, 0.558, 1.007, 0.645, 1.805, 2.981, 0.996, 0.544, 0.631, 2.916, 0.63, 0.463, 0.447, 0.45, 0.429, 0.434, 3.744, 2.853, 0.49, 0.882, 0.583, 2.446, 0.375, 0.554, 0.445, 32.365, 0.402, 2.595, 1.558, 0.943, 0.403, 0.489, 2.231, 0.479, 1.435, 0.9, 0.918, 4.227, 0.447, 0.464, 0.443, 0.628, 3.256, 0.53, 0.457, 0.4, 0.44, 1.066, 0.42, 0.466, 0.494, 0.493, 0.408, 0.435, 0.753, 7.779, 1.813, 1.01, 0.445, 0.501, 0.936, 0.403, 0.445, 0.604, 0.385, 0.412, 0.675, 3.051, 0.761, 1.182, 0.426, 5.719, 0.58, 0.582, 0.496, 1.225, 0.648, 0.792, 3.93, 0.631, 0.623, 0.866, 0.399, 0.386, 0.648, 0.436, 0.449, 1.511, 0.472, 0.429, 0.795, 0.55, 0.868, 0.494, 1.935, 0.516, 4.26, 7.361, 0.405, 0.473, 0.586, 0.358, 0.679, 0.429, 0.473, 3.294, 0.479, 0.799, 0.749, 3.948, 0.514, 0.956, 7.255, 0.443, 1.175, 1.023, 1.236, 64.964, 0.9, 0.486, 0.469, 3.084, 0.796, 0.552, 9.041, 0.831, 0.436, 1.356, 0.418, 0.543, 6.525, 0.504, 1.627, 0.471, 0.412, 2.944, 0.763, 0.465, 0.482, 0.563, 0.703, 1.106, 2.21, 0.409, 0.476, 0.453, 0.423, 0.737, 0.44, 0.616, 0.758, 0.622, 0.883, 1.011, 0.827, 0.493, 8.535, 0.749, 0.913, 0.45, 0.422, 0.545, 7.974, 0.392, 1.051, 0.775, 0.524, 0.458, 0.527, 0.478, 0.846, 0.549, 0.391, 0.895, 1.427, 1.643, 0.372, 0.383, 0.807, 0.707, 0.463, 0.886, 0.5, 1.244, 0.796, 8.572, 0.687, 1.425, 0.954, 0.841, 0.686, 0.396, 16.045, 0.44, 0.423, 1.032, 2.985, 0.791, 0.715, 0.528, 2.182, 0.475, 0.544, 0.468, 0.618, 0.778, 0.464, 3.805, 0.502, 14.525, 0.401, 0.449, 1.592, 0.495, 0.511, 0.923, 0.637, 0.452, 0.5, 0.511, 0.685, 0.598, 0.475, 0.492, 1.411, 0.466, 0.52, 0.596, 0.595, 1.363, 3.459, 0.464, 12.92, 0.447, 0.433, 0.663, 0.518, 0.528, 0.93, 0.681, 0.49, 0.479, 0.566, 0.509, 0.438, 0.498, 0.608, 17.92, 0.455, 0.394, 0.539, 1.804, 3.847, 0.41, 1.315, 0.452, 0.636, 0.525, 0.48, 0.549, 1.283, 0.993, 3.835, 0.541, 0.966, 2.079, 0.743, 0.623, 0.755, 0.776, 0.473, 4.156, 0.407, 1.769, 2.685, 0.767, 0.459, 0.462, 48.401, 0.395, 4.351, 0.363, 0.37, 1.626, 0.541, 0.618, 0.493, 0.525, 0.44, 0.505, 0.459, 0.493, 0.641, 0.709, 2.333, 1.672, 0.804, 0.84, 2.528, 1.068, 0.476, 0.41, 0.526, 0.487, 1.16, 0.475, 2.805, 0.727, 9.585, 0.371, 0.412, 0.411, 0.815, 0.49, 0.549, 3.911, 0.703, 0.467, 0.883, 1.337, 0.475, 1.811, 0.613, 0.557, 1.871, 0.58, 0.494, 0.535, 0.401, 1.381, 0.459, 2.185, 2.474, 0.489, 0.746, 0.498, 1.069, 5.078, 0.483, 0.42, 0.527, 1.309, 0.947, 0.463, 1.308, 0.56, 0.608, 0.814, 0.512, 0.598, 0.39, 0.679, 162.465, 2.005, 0.523, 0.931, 0.857, 3.912, 0.674, 0.8, 0.509, 1.873, 0.916, 0.456, 0.449, 0.41, 0.384, 4.13, 0.477, 0.595, 5.52, 0.44, 0.392, 0.479, 0.571, 0.433, 1.531, 0.473, 0.429, 0.393, 0.466, 0.963, 1.384, 9.012, 0.882, 0.446, 0.511, 0.713, 0.662, 0.436, 2.615, 0.948, 0.497, 87.132, 1.26, 0.614, 0.707, 0.564, 1.005, 0.54, 8.759, 0.912, 2.88, 1.188, 0.504, 0.553, 13.776, 0.535, 0.491, 0.421, 0.498, 0.65, 0.843, 0.416, 0.449, 0.638, 0.572, 0.437, 0.648, 0.799, 1.072, 3.801, 0.757, 0.828, 0.499, 0.537, 0.544, 1.544, 1.142, 0.871, 0.833, 0.555, 0.633, 0.391, 0.471, 0.445, 0.449, 2.246, 0.485, 0.581, 0.375, 39.035, 0.787, 0.995, 1.033, 1.042, 0.424, 2.376, 0.767, 0.535, 1.05, 1.223, 0.597, 0.541, 0.483, 0.416, 11.756, 10.843, 0.559, 0.541, 0.45, 0.565, 2.689, 0.561, 1.567, 0.421, 0.445, 1.12, 0.788, 0.524, 0.479, 1.605, 1.089, 2.168, 1.208, 0.437, 0.449, 0.918, 0.928, 1.164, 0.511, 0.411, 0.771, 0.739, 15.571, 0.427, 0.404, 0.408, 0.451, 0.442, 0.724, 0.545, 0.56, 0.638, 0.459, 0.445, 0.517, 0.422, 0.51, 0.434, 1.105, 0.906, 0.544, 0.528, 0.446, 0.744, 0.754, 0.48, 0.487, 1.715, 0.501, 1.25, 0.4, 3.533, 0.53, 0.781, 0.837, 0.559, 0.637, 2.646, 5.899, 0.526, 0.878, 0.57, 14.411, 3.498, 0.431, 0.536, 1.503, 0.944, 0.468, 1.186, 0.53, 12.579, 0.457, 0.722, 0.529, 0.491, 0.458, 0.5, 0.747, 0.504, 0.403, 0.464, 0.795, 1.35, 0.431, 0.657, 0.46, 1.712, 0.429, 0.75, 0.94, 0.569, 0.406, 0.401, 0.537, 0.564, 0.669, 0.443, 0.47, 0.696, 0.65, 0.482, 0.692, 0.462, 0.824, 0.433, 0.663, 0.901, 0.539, 0.551, 0.586, 1.153, 0.506, 1.235, 1.897, 2.098, 0.394, 0.668, 5.639, 0.458, 0.691, 0.667, 0.918, 0.714, 0.702, 0.813, 0.793, 0.924, 0.884, 1.046, 0.963, 1.617, 0.428, 1.609, 0.495, 0.518, 0.913, 0.612, 0.467, 4.995, 0.425, 9.739, 0.47, 0.522, 1.857, 4.921, 0.474, 0.525, 0.582, 0.477, 0.508, 0.611, 0.596, 1.981, 0.941, 0.567, 0.422, 0.435, 0.578, 0.774, 0.563, 0.514, 0.556, 0.465, 0.439, 0.551, 14.484, 0.42, 0.601, 0.493, 1.395, 5.509, 0.866, 2.508, 0.447, 0.433, 2.284, 0.864, 0.45, 1.165, 0.571, 0.46, 0.838, 0.691, 0.618, 0.477, 0.608, 0.668, 0.465, 0.443, 0.552, 1.095, 0.738, 2.065, 0.606, 10.245, 8.025, 1.39, 0.589, 0.42, 0.421, 0.566, 0.422, 0.456, 1.554, 1.006, 0.799, 0.477, 0.491, 2.044, 0.632, 1.06, 0.607, 3.906, 0.434, 1.091, 0.515, 0.937, 1.223, 1.025, 0.419, 0.452, 0.5, 0.476, 0.494, 1.783, 0.806, 0.482, 0.575, 1.348, 0.765, 0.692, 2.698, 0.503, 0.68, 0.947, 0.876, 1.177, 0.849, 1.042, 0.536, 0.591, 0.424, 0.524, 0.478, 2.599, 0.774, 0.786, 21.546, 0.404, 1.147, 1.126, 0.482, 0.729, 0.4, 0.514, 0.46, 0.504, 0.744, 0.785, 0.493, 1.432, 0.511, 0.594, 1.27, 2.174, 0.533, 1.069, 2.954, 0.523, 0.643, 0.744, 0.558, 0.497, 0.773, 2.536, 0.47, 0.788, 0.892, 0.865, 1.659, 0.589, 1.251, 0.454, 6.439, 4.573, 0.408, 1.724, 0.42, 0.394, 0.379, 2.31, 1.465, 0.478, 1.531, 0.626, 0.561, 0.574, 0.583, 0.946, 0.514, 0.644, 0.439, 0.514, 0.674, 1.06, 0.569, 0.428, 0.552, 2.302, 0.554, 0.562, 0.903, 0.499, 0.452, 0.74, 0.538, 0.73, 0.44, 0.867, 0.414, 0.61, 0.451, 0.463, 0.432, 0.438, 1.608, 0.501, 4.301, 1.652, 1.724, 0.647, 0.64, 0.482, 0.522, 0.826, 0.439, 1.602, 0.601, 0.431, 0.46, 0.535, 0.448, 0.958, 0.578, 0.405, 1.656, 0.962, 0.888, 0.787, 0.605, 0.799, 0.844, 0.587, 0.411, 0.97, 0.468, 0.481, 0.452, 0.402, 0.432, 1.217, 0.624, 0.49, 0.939, 1.731, 0.741, 59.499, 0.567, 0.614, 0.387, 0.453, 0.448, 0.762, 1.11, 0.548, 20.468, 0.923, 0.702, 0.741, 0.479, 0.478, 0.434, 0.668, 0.58, 1.386, 1.198, 0.491, 0.429, 0.431, 0.403, 0.782, 0.484, 0.567, 0.445, 0.392, 1.547, 0.611, 2.32, 0.411, 0.744, 0.676, 0.497, 0.457, 0.559, 1.372, 0.582, 0.602, 2.843, 0.405, 0.71, 4.372, 1.458, 0.45, 0.53, 0.897, 0.581, 0.456, 1.196, 0.441, 0.602, 0.409, 0.467, 0.459, 0.712, 3.416, 0.67, 0.491, 0.493, 0.454, 0.558, 2.532, 0.709, 0.409, 0.409, 0.651, 0.7, 0.513, 0.416, 1.569, 0.662, 0.485, 1.076, 6.631, 5.532, 3.053, 0.449, 0.936, 0.586, 0.436, 0.455, 0.578, 0.71, 1.792, 0.752, 0.529, 0.548, 0.519, 0.478, 0.462, 0.431, 0.444, 0.498, 0.64, 2.208, 0.456, 3.832, 2.352, 1.832, 0.941, 1.545, 0.445, 0.515, 1.508, 0.94, 0.472, 0.543, 0.625, 0.611, 0.696, 0.405, 0.635, 0.848, 0.612, 1.787, 1.392, 0.403, 0.561, 0.607, 0.453, 0.446, 1.151, 14.379, 0.672, 0.377, 0.439, 0.52, 0.604, 1.703, 1.667, 0.49, 0.593, 0.7, 0.964, 0.53, 0.427, 0.484, 11.466, 0.861, 2.085, 0.467, 0.686, 1.001, 1.122, 0.468, 0.839, 0.505, 0.535, 0.7, 0.773, 0.553, 0.578, 2.296, 0.488, 0.441, 1.095, 1.01, 1.247, 1.014, 1.169, 1.238, 23.894, 0.417, 7.727, 0.474, 0.629, 0.557, 0.944, 0.615, 0.4, 0.797, 0.878, 0.897, 0.794, 0.642, 2.634, 1.158, 0.437, 0.494, 0.649, 0.493, 0.576, 0.535, 0.486, 0.501, 0.47, 3.397, 0.506, 3.09, 1.143, 0.435, 1.278, 0.717, 0.777, 0.768, 0.719, 0.779, 0.473, 0.526, 0.427, 8.028, 0.473, 0.392, 7.651, 0.641, 0.371, 1.128, 0.488, 0.512, 0.69, 0.647, 0.524, 1.333, 0.521, 0.369, 1.346, 3.693, 1.515, 2.245, 0.722, 1.811, 0.509, 0.35, 0.665, 0.66, 2.587, 2.55, 1.109, 0.575, 0.456, 0.531, 0.773, 0.861, 16.989, 0.494, 0.392, 0.42, 0.829, 0.705, 0.547, 0.396, 0.39, 2.484, 0.41, 0.423, 0.864, 0.761, 0.54, 0.501, 2.168, 0.508, 0.486, 1.462, 3.219, 0.433, 0.405, 0.453, 1.43, 0.575, 1.049, 0.617, 0.862, 0.508, 0.504, 1.309, 4.731, 3.997, 0.421, 0.387, 0.382, 0.494, 0.593, 0.46, 1.651, 0.413, 0.526, 0.792, 22.117, 0.986, 1.958, 0.653, 0.393, 0.459, 0.397, 0.388, 0.483, 0.58, 1.033, 0.413, 0.453, 0.463, 0.618, 1.061, 8.506, 0.554, 3.007, 0.663, 1.204, 0.421, 1.628, 1.068, 1.392, 0.625, 0.551, 0.477, 0.433, 0.785, 0.394, 19.882, 0.57, 0.458, 0.711, 0.511, 3.892, 0.45, 3.522, 0.447, 0.776, 1.036, 0.406, 0.988, 0.887, 0.445, 0.413, 1.352, 0.45, 1.83, 0.374, 0.386, 0.762, 50.273, 1.445, 0.517, 17.007, 0.534, 0.511, 0.42, 2.675, 0.429, 0.631, 0.475, 0.703, 6.261, 0.446, 1.795, 0.597, 0.6, 0.499, 0.946, 0.439, 1.824, 1.103, 10.385, 0.615, 0.664, 0.76, 1.661, 1.318, 1.055, 0.453, 0.452, 0.432, 2.923, 0.607, 0.445, 0.877, 0.406, 4.496, 0.82, 0.514, 0.557, 0.967, 1.826, 1.043, 0.542, 0.571, 2.64, 0.656, 5.895, 0.441, 0.44, 0.815, 1.073, 2.343, 4.22, 4.173, 0.505, 1.851, 0.945, 0.383, 0.484, 2.733, 0.417, 0.563, 0.462, 0.542, 0.851, 0.455, 1.849, 0.437, 0.482, 0.641, 0.505, 0.412, 0.461, 0.609, 0.57, 1.721, 0.533, 0.704, 0.449, 0.672, 0.425, 0.509, 2.709, 0.571, 3.255, 3.003, 0.573, 0.487, 0.418, 1.747, 0.876, 12.621, 10.713, 0.447, 0.984, 0.503, 0.433, 0.455, 0.653, 0.442, 0.641, 0.426, 0.469, 0.719, 0.518, 0.475, 0.946, 0.711, 0.475, 0.496, 0.485, 0.383, 0.625, 0.457, 27.508, 0.793, 2.16, 0.702, 0.911, 0.779, 4.837, 1.079, 0.641, 0.58, 0.403, 0.412, 4.044, 0.469, 1.108, 0.722, 0.412, 0.984, 0.454, 0.462, 0.743, 1.407, 0.676, 1.023, 0.503, 0.477, 0.542, 0.469, 1.515, 0.52, 0.457, 3.342, 0.52, 0.771, 0.401, 0.451, 0.55, 0.595, 0.506, 7.496, 0.417, 0.651, 0.451, 9.603, 0.885, 3.171, 0.439, 0.974, 4.076, 0.382, 0.39, 9.113, 0.525, 0.388, 1.433, 0.425, 0.5, 0.511, 0.476, 0.668, 0.625, 0.422, 0.533, 0.526, 0.443, 0.462, 0.608, 0.594, 0.589, 0.561, 0.683, 0.383, 0.703, 1.36, 0.586, 0.499, 0.482, 0.492, 0.495, 2.17, 0.395, 0.71, 0.47, 0.801, 0.847, 0.387, 0.59, 0.765, 0.743, 0.713, 0.548, 11.243, 0.471, 0.585, 0.461, 0.452, 0.383, 1.03, 0.452, 0.367, 0.543, 0.904, 0.474, 0.627, 0.456, 1.73, 181.005, 0.421, 1.529, 0.468, 0.485, 0.63, 1.247, 0.551, 0.412, 0.504, 1.685, 0.648, 0.466, 0.64, 0.901, 0.398, 5.657, 0.41, 1.02, 16.12, 0.747, 0.625, 0.541, 1.248, 5.301, 0.584, 0.569, 2.695, 0.539, 1.859, 0.616, 0.473, 0.534, 0.661, 1.208, 0.494, 69.313, 1.199, 0.447, 2.127, 90.39, 0.376, 2.619, 0.486, 0.537, 0.462, 1.314, 0.397, 1.502, 0.451, 0.679, 0.423, 0.923, 2.769, 0.39, 1.23, 0.434, 0.623, 0.621, 0.798, 0.396, 0.59, 2.89, 0.701, 0.553, 0.413, 0.547, 0.39, 0.488, 0.454, 0.597, 0.762, 0.847, 0.657, 0.388, 0.712, 1.464, 0.588, 0.795, 0.655, 0.798, 1.263, 0.923, 0.6, 2.251, 0.449, 0.531, 0.739, 0.528, 0.483, 0.534, 1.718, 2.244, 0.73, 0.732, 0.825, 0.404, 0.425, 0.465, 1.641, 1.769, 0.455, 0.893, 14.962, 0.504, 2.313, 0.529, 0.884, 1.718, 0.563, 1.538, 0.399, 3.814, 1.046, 2.951, 0.591, 0.979, 0.516, 0.428, 5.763, 0.579, 0.713, 0.88, 0.451, 7.792, 0.487, 0.675, 1.019, 0.453, 0.417, 0.88, 0.469, 0.462, 0.516, 0.658, 0.486, 0.445, 1.031, 0.554, 0.908, 0.768, 0.563, 2.251, 0.64, 1.552, 0.768, 0.628, 3.195, 0.419, 0.395, 0.45, 0.617, 0.805, 1.033, 0.395, 13.664, 0.506, 0.418, 0.491, 34.229, 2.763, 0.504, 1.321, 1.603, 0.462, 0.423, 0.684, 0.899, 0.651, 14.883, 0.618, 0.455, 0.448, 0.643, 0.604, 0.576, 0.73, 0.432, 0.568, 0.508, 0.505, 0.894, 0.906, 0.411, 0.904, 0.464, 4.099, 0.485, 0.515, 0.415, 5.807, 0.497, 0.821, 0.713, 0.433, 0.528, 0.752, 0.61, 0.521, 0.718, 0.873, 0.412, 0.549, 1.057, 0.731, 0.567, 0.487, 0.497, 0.825, 0.463, 0.419, 0.581, 0.453, 1.185, 0.526, 8.999, 0.561, 0.892, 9.251, 0.456, 1.981, 0.963, 11.867, 0.892, 0.536, 0.586, 0.638, 0.669, 0.447, 0.497, 0.47, 0.482, 0.485, 0.714, 0.403, 0.579, 0.413, 3.708, 0.503, 0.527, 0.706, 9.053, 0.465, 0.473, 0.61, 0.428, 0.761, 1.107, 0.615, 4.356, 0.763, 0.52, 0.55, 0.453, 0.485, 0.684, 0.424, 0.41, 1.411, 3.667, 0.538, 0.472, 2.302, 0.475, 0.506, 0.93, 0.425, 1.544, 0.499, 0.411, 5.7, 0.472, 0.678, 0.576, 0.477, 5.484, 0.649, 0.466, 0.577, 0.57, 4.132, 0.43, 0.449, 0.608, 0.735, 0.897, 2.365, 0.615, 0.656, 1.803, 11.783, 0.731, 0.604, 0.435, 0.453, 1.369, 0.474, 0.398, 0.605, 0.866, 0.443, 0.508, 1.465, 0.914, 0.444, 4.649, 0.532, 0.502, 0.947, 0.816, 0.606, 0.421, 0.493, 0.821, 0.667, 0.488, 0.638, 1.58, 0.711, 40.61, 0.638, 0.455, 0.927, 0.488, 0.731, 0.456, 0.521, 0.515, 0.654, 0.958, 0.464, 0.664, 0.529, 0.421, 0.53, 0.581, 1.461, 0.422, 1.437, 1.305, 0.547, 0.685, 0.489, 0.396, 0.793, 0.569, 0.657, 0.623, 0.471, 0.42, 1.41, 0.727, 22.657, 0.434, 0.606, 0.797, 0.384, 0.48, 0.972, 0.527, 0.467, 0.482, 1.691, 0.395, 6.481, 4.248, 0.585, 0.423, 0.462, 0.405, 0.472, 0.419, 2.374, 0.804, 0.618, 0.872, 0.487, 2.314, 0.563, 0.737, 0.451, 0.55, 0.689, 0.476, 0.694, 0.43, 0.507, 1.816, 0.623, 0.691, 0.405, 1.278, 0.551, 1.029, 2.755, 1.526, 0.466, 0.585, 0.439, 0.462, 0.886, 0.688, 1.186, 1.651, 0.417, 1.573, 0.514, 0.673, 0.423, 1.178, 0.484, 1.518, 2.111, 0.555, 0.571, 0.902, 0.482, 0.51, 0.498, 0.416, 0.462, 0.588, 14.737, 1.786, 2.473, 0.454, 0.774, 0.676, 0.45, 0.39, 0.461, 0.479, 0.553, 0.649, 0.926, 0.68, 0.568, 0.419, 0.631, 0.425, 0.728, 1.403, 0.433, 1.07, 0.428, 3.186, 0.684, 0.522, 0.723, 0.395, 13.187, 0.844, 0.408, 0.467, 0.692, 0.464, 2.146, 1.52, 0.48, 0.764, 0.5, 0.43, 0.756, 0.449, 0.508, 0.474, 0.699, 1.016, 0.468, 1.244, 0.456, 0.607, 0.98, 0.627, 1.648, 0.482, 0.491, 0.553, 1.036, 0.484, 0.939, 0.456, 1.09, 1.3, 0.425, 0.751, 0.679, 2.724, 0.504, 2.389, 1.248, 0.779, 0.548, 0.534, 1.322, 0.457, 0.511, 0.63, 4.387, 0.437, 0.617, 1.097, 0.664, 0.432, 3.36, 0.56, 0.465, 0.457, 0.451, 0.495, 0.479, 0.439, 0.517, 0.536, 0.543, 0.419, 0.421, 0.734, 0.565, 0.523, 6.487, 0.465, 1.154, 0.622, 0.925, 1.656, 0.957, 0.623, 0.476, 0.412, 0.495, 0.575, 0.407, 0.461, 0.464, 0.461, 1.132, 0.606, 0.461, 3.463, 0.515, 0.491, 0.395, 0.523, 0.823, 1.935, 0.63, 0.392, 0.541, 2.029, 0.371, 2.582, 0.402, 0.628, 0.474, 0.554, 0.545, 1.661, 0.907, 0.512, 0.656, 0.448, 0.717, 0.702, 0.505, 0.437, 0.822, 0.472, 1.172, 3.728, 4.586, 0.726, 0.708, 0.706, 0.456, 0.554, 0.807, 0.41, 0.421, 0.954, 0.437, 0.608, 0.582, 7.369, 0.395, 0.422, 0.524, 0.493, 0.787, 0.453, 60.948, 0.503, 0.986, 1.643, 1.372, 1.048, 0.746, 0.715, 1.208, 0.38, 0.899, 0.398, 0.675, 0.537, 1.107, 0.545, 0.468, 0.499, 14.878, 0.753, 1.314, 3.634, 0.566, 0.555, 3.752, 0.585, 0.479, 2.346, 0.81, 2.2, 0.491, 0.459, 0.518, 1.305, 0.585, 0.407, 1.474, 1.228, 0.561, 8.658, 0.945, 0.457, 0.748, 0.613, 0.829, 1.399, 0.702, 0.875, 0.645, 0.659, 0.449, 0.542, 0.47, 1.998, 0.529, 0.749, 9.028, 0.457, 0.638, 0.513, 1.877, 0.503, 17.796, 0.639, 9.459, 1.015, 0.602, 4.307, 1.979, 0.593, 0.438, 0.77, 0.729, 0.549, 0.442, 0.498, 0.544, 2.186, 0.441, 0.418, 0.479, 0.832, 0.468, 0.499, 0.944, 0.909, 7.702, 1.031, 2.111, 0.589, 1.071, 0.579, 0.448, 2.555, 0.435, 0.47, 0.506, 0.407, 0.585, 0.442, 0.451, 0.474, 0.595, 0.449, 0.753, 1.538, 0.687, 0.462, 0.796, 1.21, 1.16, 1.164, 2.17, 0.609, 2.969, 0.549, 2.786, 2.826, 1.259, 0.467, 0.458, 0.782, 2.918, 0.555, 2.477, 0.446, 0.435, 0.477, 0.875, 0.449, 0.7, 0.952, 0.888, 0.483, 0.955, 0.491, 0.444, 1.488, 0.547, 0.461, 0.581, 0.423, 0.719, 3.692, 0.453, 2.713, 0.47, 0.918, 3.375, 0.715, 0.774, 0.458, 0.587, 0.477, 0.546, 0.72, 0.516, 1.091, 0.454, 0.836, 0.451, 0.775, 0.486, 0.74, 0.609, 1.16, 1.384, 0.606, 1.808, 0.499, 0.397, 0.4, 0.503, 1.236, 0.554, 1.478, 0.434, 0.595, 2.771, 0.83, 0.887, 0.594, 0.517, 1.418, 3.458, 0.427, 0.414, 2.617, 1.173, 0.775, 0.41, 0.808, 0.509, 0.695, 0.8, 0.997, 0.503, 0.751, 1.369, 0.809, 0.444, 165.098, 0.446, 0.46, 0.486, 0.498, 0.486, 0.478, 0.499, 1.057, 2.556, 0.608, 1.179, 1.564, 0.479, 0.541, 14.397, 0.522, 0.418, 0.486, 0.46, 0.688, 1.249, 0.429, 0.512, 0.717, 3.277, 0.578, 0.616, 0.56, 0.721, 2.262, 1.973, 0.746, 14.392, 0.577, 0.429, 2.797, 0.612, 0.537, 0.584, 0.968, 0.838, 0.421, 8.496, 6.12, 0.5, 1.435, 3.724, 1.454, 0.536, 2.039, 0.652, 0.654, 0.582, 0.617, 0.791, 0.485, 0.523, 0.455, 0.429, 2.183, 0.55, 0.482, 0.511, 0.451, 1.527, 0.426, 1.178, 0.48, 1.111, 0.508, 1.282, 0.557, 2.34, 0.621, 0.66, 0.453, 3.051, 0.591, 0.55, 1.098, 0.489, 0.868, 0.482, 0.971, 1.661, 7.327, 0.607, 0.504, 0.71, 0.497, 1.06, 1.232, 0.549, 0.427, 0.543, 0.459, 0.492, 0.568, 0.863, 0.58, 0.54, 1.363, 0.875, 0.673, 0.934, 0.464, 0.729, 0.589, 1.697, 0.435, 0.872, 0.758, 0.672, 0.688, 0.508, 0.622, 0.544, 0.771, 0.762, 0.577, 0.439, 0.482, 0.512, 32.17, 2.653, 0.658, 0.962, 0.471, 1.0, 0.924, 0.479, 0.454, 0.456, 0.591, 1.295, 0.501, 0.82, 0.823, 0.711, 1.215, 0.503, 0.664, 0.668, 0.608, 0.585, 0.8, 0.509, 1.548, 0.705, 65.762, 1.31, 0.605, 0.635, 0.713, 0.678, 0.754, 0.581, 0.53, 1.187, 0.626, 0.656, 0.559, 0.461, 0.633, 0.477, 0.934, 0.516, 2.528, 0.484, 0.766, 0.689, 0.962, 3.997, 0.588, 0.71, 2.685, 1.496, 0.534, 5.043, 0.49, 3.812, 0.519, 0.558, 0.534, 1.155, 0.571, 0.468, 3.769, 1.073, 0.709, 3.897, 0.97, 0.912, 1.581, 4.361, 0.814, 1.126, 0.682, 0.713, 0.81, 0.468, 0.614, 0.504, 0.488, 2.082, 0.457, 0.416, 0.535, 0.539, 1.592, 0.884, 1.143, 0.487, 5.144, 0.594, 0.933, 0.477, 0.577, 0.505, 0.499, 6.651, 0.455, 0.447, 11.015, 0.405, 0.494, 0.536, 0.553, 2.179, 0.645, 0.81, 1.508, 0.492, 0.469, 0.455, 0.511, 0.597, 0.67, 0.57, 0.521, 0.677, 0.471, 0.875, 0.437, 0.51, 0.728, 0.616, 0.462, 0.996, 0.592, 0.499, 1.557, 0.51, 0.576, 1.479, 0.622, 9.683, 0.614, 0.823, 0.742, 0.739, 0.985, 0.526, 0.511, 0.452, 1.045, 1.139, 0.676, 2.261, 0.496, 0.534, 0.731, 0.776, 0.593, 3.622, 0.786, 0.561, 0.476, 8.9, 0.846, 8.107, 0.605, 0.551, 0.67, 0.729, 0.714, 0.69, 0.68, 1.27, 1.025, 1.643, 0.907, 0.748, 0.583, 0.59, 0.887, 0.626, 4.256, 2.292, 0.723, 0.736, 0.618, 0.695, 0.697, 1.013, 0.49, 0.463, 0.974, 0.762, 0.475, 0.866, 8.587, 0.739, 0.468, 0.531, 0.997, 0.583, 0.61, 0.835, 0.94, 0.635, 1.001, 0.516, 0.601, 0.717, 0.972, 0.544, 0.992, 1.866, 1.558, 0.678, 0.736, 0.62, 1.575, 0.649, 0.533, 0.546, 0.45, 0.451, 0.562, 1.615, 1.604, 0.415, 0.455, 0.626, 2.463, 0.829, 0.474, 0.818, 0.517, 0.568, 8.014, 0.593, 0.504, 0.484, 0.682, 21.59, 0.519, 2.042, 1.619, 0.447, 14.408, 20.524, 0.523, 0.737, 0.501, 0.509, 0.609, 0.673, 3.521, 0.948, 0.542, 2.935, 1.995, 0.807, 0.647, 2.26, 0.613, 1.101, 1.114, 0.613, 0.779, 4.303, 0.802, 0.506, 1.638, 3.888, 0.612, 0.715, 0.659, 0.471, 0.744, 0.536, 1.512, 0.767, 1.006, 4.541, 1.009, 0.767, 0.536, 0.549, 0.501, 0.634, 0.506, 0.867, 0.701, 1.196, 0.526, 0.495, 0.435, 0.472, 0.53, 0.606, 0.49, 1.345, 0.477, 0.475, 2.634, 0.483, 0.456, 0.439, 0.465, 0.425, 0.449, 0.505, 0.49, 0.516, 0.501, 1.582, 0.802, 0.852, 1.327, 1.305, 0.771, 0.692, 0.491, 0.701, 0.428, 0.483, 0.418, 0.456, 0.78, 0.45, 0.779, 0.651, 0.444, 0.436, 0.684, 4.239, 0.629, 0.474, 0.573, 0.488, 0.794, 1.18, 0.927, 0.611, 1.583, 0.565, 0.638, 0.522, 0.619, 0.627, 0.718, 1.344, 3.874, 0.537, 1.246, 0.844, 0.552, 0.534, 0.632, 0.555, 0.924, 0.692, 0.802, 0.682, 0.708, 0.622, 0.654, 1.255, 0.577, 0.62, 0.569, 0.834, 0.479, 0.507, 0.894, 0.553, 0.444, 0.499, 0.479, 0.801, 0.517, 0.472, 0.759, 2.528, 0.417, 0.541, 0.58, 1.952, 0.517, 0.841, 0.945, 0.56, 0.435, 0.614, 0.543, 0.485, 0.4, 0.656, 1.037, 1.348, 0.481, 0.43, 1.015, 1.301, 0.706, 2.123, 0.771, 0.484, 0.643, 1.726, 0.748, 0.996, 0.504, 0.522, 0.54, 1.358, 0.444, 1.145, 1.506, 0.752, 0.477, 0.421, 0.517, 0.43, 0.441, 0.457, 0.564, 1.199, 0.522, 5.622, 0.544, 0.97, 0.432, 0.378, 0.507, 23.888, 0.947, 0.585, 0.671, 0.805, 0.737, 0.574, 0.624, 0.617, 0.565, 2.37, 0.72, 0.633, 3.106, 0.503, 13.675, 2.618, 0.503, 0.522, 1.052, 1.051, 0.708, 0.559, 0.575, 0.786, 0.789, 0.837, 0.769, 0.478, 0.45, 0.604, 0.463, 0.677, 0.642, 1.581, 0.682, 0.517, 0.612, 0.764, 0.648, 0.573, 0.585, 0.646, 0.541, 0.617, 2.987, 0.615, 1.225, 0.776, 1.004, 1.038, 0.657, 1.69, 0.503, 12.529, 0.417, 0.641, 12.954, 1.03, 0.467, 5.729, 0.642, 1.821, 0.46, 0.466, 1.301, 0.487, 14.278, 0.456, 0.552, 0.728, 0.458, 0.671, 0.59, 0.948, 0.589, 0.718, 0.77, 0.599, 0.799, 1.655, 0.59, 0.708, 1.768, 0.749, 0.801, 0.875, 0.914, 7.505, 0.798, 0.486, 0.503, 1.772, 0.674, 0.765, 0.611, 0.712, 0.557, 0.924, 0.487, 0.599, 4.567, 0.753, 1.505, 0.605, 1.334, 1.108, 0.716, 0.531, 0.796, 1.285, 0.645, 0.73, 1.42, 60.117, 0.548, 0.757, 1.289, 4.17, 0.945, 0.787, 0.51, 5.799, 2.152, 0.77, 0.804, 0.79, 7.147, 5.634, 0.437, 0.449, 0.517, 0.636, 0.587, 0.451, 1.369, 5.542, 0.507, 0.437, 1.074, 1.219, 0.522, 2.277, 0.466, 11.116, 93.648, 0.494, 0.521, 1.163, 0.503, 0.878, 0.636, 0.495, 1.804, 1.068, 49.836, 2.442, 0.549, 0.761, 0.548, 0.633, 1.281, 2.217, 0.733, 0.652, 0.566, 1.133, 1.318, 0.514, 0.471, 0.787, 0.671, 0.466, 16.078, 0.555, 0.62, 0.634, 1.066, 0.979, 0.61, 0.667, 0.507, 0.583, 0.644, 0.723, 0.553, 5.587, 1.575, 0.926, 1.686, 0.824, 0.733, 3.458, 1.09, 0.799, 0.89, 0.662, 0.731, 0.672, 2.362, 0.882, 0.773, 0.596, 0.768, 0.642, 0.854, 0.724, 1.153, 0.52, 0.705, 0.742, 0.615, 0.498, 0.455, 0.54, 0.551, 1.719, 1.72, 0.514, 0.584, 0.564, 0.566, 0.481, 0.517, 0.551, 0.629, 1.145, 16.481, 3.929, 0.629, 0.592, 0.561, 0.955, 39.106, 2.071, 0.81, 0.753, 0.888, 0.867, 1.937, 0.893, 0.642, 1.916, 0.777, 8.601, 0.98, 0.662, 0.977, 0.497, 0.582, 0.559, 0.754, 0.653, 0.661, 0.588, 0.625, 0.575, 0.703, 0.653, 0.635, 0.846, 1.764, 0.585, 0.735, 10.288, 0.56, 7.493, 0.624, 1.056, 0.829, 0.498, 0.774, 0.602, 0.94, 0.761, 0.607, 0.865, 0.753, 1.493, 0.827, 1.139, 0.805, 11.739, 0.465, 1.055, 0.581, 0.553, 0.966, 1.054, 1.051, 1.054, 3.796, 0.868, 0.58, 0.564, 0.549, 3.647, 0.46, 0.558, 1.2, 0.458, 4.171, 1.552, 0.408, 0.634, 0.835, 0.964, 0.521, 0.509, 0.527, 0.646, 2.51, 0.505, 0.711, 0.58, 0.514, 0.5, 0.826, 0.524, 0.569, 0.84, 0.761, 0.52, 0.451, 0.643, 0.437, 0.42, 0.892, 0.557, 0.774, 0.805, 0.533, 0.433, 0.834, 0.516, 1.405, 1.248, 0.635, 0.877, 0.929, 6.46, 0.454, 0.424, 0.478, 0.559, 1.187, 0.425, 0.543, 0.473, 0.593, 0.576, 1.487, 0.449, 0.434, 0.507, 0.56, 10.881, 0.469, 0.619, 0.733, 0.517, 0.563, 0.73, 0.719, 0.597, 1.565, 1.129, 10.664, 0.509, 1.822, 1.745, 0.412, 0.695, 0.439, 0.729, 0.453, 0.553, 1.465, 1.047, 0.603, 0.42, 0.682, 0.48, 1.443, 0.683, 0.943, 1.571, 0.52, 0.568, 0.405, 0.443, 0.756, 0.48, 2.306, 1.202, 0.55, 0.56, 0.584, 0.428, 0.934, 0.457, 0.462, 0.613, 0.442, 0.532, 3.754, 0.501, 0.484, 0.477, 0.538, 0.806, 0.541, 0.592, 0.488, 0.719, 0.553, 0.437, 0.432, 0.708, 0.925, 0.422, 9.689, 0.446, 0.8, 0.461, 7.421, 0.508, 0.528, 0.544, 1.023, 0.504, 1.044, 3.641, 0.671, 8.93, 0.449, 0.474, 0.667, 0.884, 0.787, 0.482, 0.569, 1.342, 0.836, 0.654, 0.857, 0.511, 0.857, 1.148, 0.568, 1.01, 0.498, 0.473, 0.541, 0.881, 0.974, 0.532, 1.45, 0.43, 0.55, 0.489, 1.957, 0.599, 0.782, 0.458, 0.691, 0.418, 0.511, 0.513, 0.831, 1.318, 0.775, 0.483, 0.42, 0.9, 0.718, 0.503, 1.007, 2.744, 1.781, 0.601, 0.58, 0.567, 4.063, 0.648, 0.957, 1.638, 2.741, 0.659, 0.524, 1.237, 1.224, 1.0, 0.816, 1.044, 0.58, 0.791, 0.471, 0.482
            ]
        ], # Example encoder times for each category
        [
            [
                14.888, 12.605, 10.967, 16.196, 12.83, 13.625, 12.778, 12.656, 11.875, 12.628, 11.294, 11.585, 11.487, 47.161, 10.739, 10.985, 12.157, 12.018, 11.904, 10.818, 10.835, 11.232, 11.264, 10.726, 10.879, 10.387, 13.078, 10.595, 11.618, 10.342, 11.271, 11.413, 10.755, 11.139, 18.117, 13.638, 10.7, 12.877, 11.006, 11.194, 10.73, 12.39, 10.952, 33.626, 10.756, 11.759, 13.961, 11.691, 11.475, 11.466, 11.28, 10.874, 17.732, 10.571, 11.909, 22.256, 13.034, 10.713, 11.785, 12.557, 11.216, 11.934, 11.864, 11.85, 25.65, 11.336, 11.586, 12.48, 11.413, 10.75, 11.262, 10.751, 10.851, 14.666, 10.914, 11.354, 11.841, 14.473, 12.354, 13.608, 13.251, 11.555, 22.825, 11.617, 12.184, 15.03, 11.729, 12.353, 13.409, 12.387, 11.083, 11.534, 12.488, 13.89, 13.417, 10.983, 10.815, 11.38, 12.697, 20.744, 11.152, 12.206, 11.554, 12.222, 12.795, 10.539, 12.076, 14.204, 11.55, 12.437, 10.973, 12.929, 15.234, 10.579, 15.571, 17.627, 12.61, 40.992, 11.825, 14.611, 10.929, 10.577, 13.555, 15.619, 10.742, 14.218, 14.248, 12.559, 10.893, 12.934, 177.015, 11.547, 13.187, 12.746, 11.176, 12.581, 11.501, 11.406, 12.721, 11.734, 11.433, 11.508, 12.183, 11.509, 23.157, 11.857, 11.963, 12.628, 13.243, 12.269, 12.619, 12.2, 18.277, 11.561, 13.456, 13.522, 14.682, 12.457, 14.233, 11.218, 13.25, 12.048, 15.199, 11.521, 14.792, 11.952, 11.328, 12.647, 11.803, 24.907, 12.447, 12.779, 11.63, 13.564, 12.225, 11.791, 12.834, 11.643, 11.793, 100.063, 11.606, 12.541, 11.644, 15.427, 11.869, 13.703, 15.022, 19.483, 12.521, 11.37, 11.585, 11.496, 20.658, 12.233, 12.248, 12.128, 12.108, 12.177, 12.887, 13.143, 11.508, 11.434, 12.222, 11.655, 13.077, 12.122, 12.837, 13.068, 12.668, 11.938, 17.25, 12.874, 12.324, 11.671, 11.649, 11.842, 11.937, 12.495, 12.671, 12.109, 14.425, 12.659, 13.506, 14.122, 15.521, 11.953, 12.128, 13.061, 11.636, 25.949, 18.682, 11.767, 13.676, 11.935, 16.066, 12.067, 11.532, 11.811, 12.457, 11.963, 12.394, 12.492, 14.829, 11.902, 13.195, 14.346, 12.389, 12.009, 11.911, 11.563, 11.713, 12.081, 11.45, 13.682, 11.464, 12.982, 11.828, 13.949, 12.027, 11.835, 12.213, 13.811, 12.433, 25.218, 12.401, 11.989, 11.405, 12.108, 11.734, 32.58, 11.669, 12.153, 12.096, 13.871, 12.433, 12.626, 11.986, 11.863, 19.831, 12.607, 16.065, 12.369, 12.152, 12.014, 11.875, 12.596, 13.008, 17.196, 13.119, 12.145, 12.605, 12.063, 13.268, 11.85, 12.488, 12.505, 12.474, 17.477, 11.813, 11.82, 30.939, 12.155, 12.478, 12.392, 15.682, 12.239, 11.925, 14.949, 13.722, 17.693, 12.758, 15.039, 12.828, 13.22, 12.037, 12.626, 13.121, 26.1, 12.525, 18.16, 11.603, 11.926, 11.496, 11.942, 11.659, 14.205, 12.418, 11.544, 13.686, 13.168, 12.535, 12.096, 11.658, 12.023, 12.959, 12.019, 11.842, 12.098, 12.411, 13.37, 11.444, 12.425, 15.348, 12.209, 12.019, 11.656, 18.896, 13.342, 19.047, 12.118, 11.692, 13.095, 12.012, 11.909, 13.679, 20.465, 12.804, 11.669, 12.982, 69.678, 11.879, 12.434, 13.43, 15.478, 12.952, 12.609, 11.891, 20.123, 12.49, 14.159, 12.523, 12.146, 12.246, 11.713, 25.332, 13.178, 12.085, 12.11, 14.165, 12.43, 13.507, 76.731, 12.533, 12.002, 12.987, 12.489, 12.923, 12.593, 12.102, 12.345, 12.764, 13.483, 12.786, 12.249, 12.807, 13.075, 14.328, 13.274, 14.914, 13.603, 12.962, 13.049, 13.955, 13.684, 12.849, 12.24, 16.899, 12.958, 12.138, 13.747, 12.686, 13.395, 13.886, 12.118, 12.86, 12.548, 13.074, 12.29, 29.546, 12.003, 21.071, 18.715, 15.615, 13.6, 12.199, 19.768, 13.712, 14.909, 11.873, 11.635, 12.72, 13.407, 13.39, 15.705, 12.486, 13.715, 13.542, 11.993, 12.562, 12.898, 11.943, 12.476, 12.252, 13.956, 13.016, 12.139, 13.112, 14.077, 12.238, 14.273, 12.123, 11.976, 11.855, 12.318, 12.872, 12.229, 13.006, 12.829, 14.241, 13.652, 12.463, 11.969, 13.228, 14.933, 12.12, 12.421, 14.063, 12.759, 13.165, 12.476, 11.991, 12.103, 13.088, 13.36, 18.452, 21.955, 12.19, 12.068, 12.523, 11.859, 11.914, 58.179, 12.802, 12.552, 11.977, 13.391, 13.271, 12.219, 15.558, 12.144, 12.001, 12.625, 14.694, 27.67, 11.385, 11.803, 12.323, 12.408, 11.997, 13.156, 13.995, 11.104, 11.424, 11.351, 13.315, 11.488, 12.131, 11.654, 11.13, 11.355, 11.256, 11.556, 12.382, 11.498, 12.078, 12.024, 11.803, 13.301, 15.66, 12.885, 10.996, 15.322, 10.943, 11.079, 12.442, 12.158, 27.161, 11.727, 32.1, 11.477, 50.993, 30.904, 11.184, 11.713, 13.341, 11.21, 11.646, 14.432, 11.195, 11.193, 19.516, 13.108, 13.207, 13.695, 13.293, 11.282, 11.459, 11.38, 12.262, 12.019, 12.612, 11.885, 11.317, 12.47, 13.999, 12.022, 11.44, 11.135, 12.269, 13.176, 11.945, 11.59, 11.556, 13.786, 12.151, 11.894, 15.541, 13.466, 11.561, 16.579, 18.126, 13.563, 11.927, 12.148, 11.309, 11.947, 11.375, 11.899, 13.338, 19.957, 33.693, 11.319, 11.381, 12.593, 12.035, 11.497, 18.259, 12.406, 13.293, 14.825, 11.59, 11.443, 103.533, 13.804, 13.76, 16.228, 20.193, 13.959, 18.978, 13.026, 14.654, 12.764, 12.759, 14.342, 13.7, 12.1, 12.44, 11.6, 11.864, 11.675, 11.793, 12.076, 12.222, 11.93, 12.395, 11.708, 15.038, 14.116, 11.509, 13.217, 11.696, 15.835, 12.726, 15.193, 12.313, 12.102, 14.6, 12.746, 14.064, 11.521, 13.325, 12.277, 12.328, 12.02, 11.661, 12.028, 11.424, 14.111, 15.04, 12.297, 11.92, 13.033, 12.534, 14.513, 13.695, 11.694, 12.09, 12.02, 13.634, 12.702, 11.773, 12.105, 11.736, 13.124, 14.441, 28.188, 11.443, 14.224, 14.566, 11.717, 15.565, 15.357, 12.926, 13.071, 27.725, 14.15, 12.29, 14.871, 13.562, 17.998, 17.866, 19.635, 15.184, 14.214, 14.128, 13.397, 13.592, 15.853, 13.164, 15.416, 14.305, 12.075, 13.868, 15.31, 25.164, 12.44, 12.342, 12.376, 12.112, 15.638, 12.267, 15.965, 12.221, 13.378, 14.073, 11.697, 73.99, 12.022, 14.135, 12.872, 11.706, 12.051, 12.766, 25.461, 13.212, 12.121, 14.539, 13.47, 12.345, 11.472, 11.791, 12.839, 12.404, 13.71, 12.249, 12.083, 13.901, 13.525, 12.171, 12.13, 11.707, 16.324, 13.599, 20.601, 12.659, 11.545, 11.885, 12.27, 11.907, 13.732, 12.044, 12.192, 12.477, 12.699, 36.741, 12.38, 16.788, 11.893, 80.303, 12.323, 11.794, 13.52, 11.948, 12.787, 12.962, 11.892, 11.904, 24.447, 13.085, 12.606, 14.157, 14.154, 14.55, 11.783, 12.085, 13.03, 11.988, 12.284, 11.382, 13.034, 11.6, 13.275, 11.928, 14.971, 15.339, 12.611, 12.372, 61.214, 11.439, 11.852, 12.809, 12.283, 18.827, 11.851, 12.309, 11.824, 13.276, 11.525, 11.693, 13.059, 16.08, 12.951, 23.203, 11.536, 14.342, 14.909, 12.052, 16.442, 12.772, 11.442, 11.732, 14.297, 12.44, 15.703, 12.75, 20.787, 12.007, 12.063, 12.085, 12.927, 12.253, 18.18, 13.882, 12.164, 11.406, 14.398, 12.016, 12.228, 11.385, 13.646, 14.792, 12.072, 12.673, 14.619, 12.532, 15.227, 14.355, 11.599, 14.453, 12.352, 12.745, 11.636, 13.453, 12.409, 11.861, 12.656, 12.183, 11.814, 15.968, 11.539, 14.063, 12.012, 14.7, 27.533, 11.919, 11.877, 14.349, 13.515, 20.351, 13.165, 11.944, 11.839, 14.627, 14.999, 11.38, 14.936, 11.702, 11.994, 12.963, 12.512, 11.24, 14.583, 15.992, 14.186, 12.321, 12.125, 12.551, 13.971, 20.658, 15.243, 11.925, 14.057, 14.431, 11.817, 12.961, 26.638, 14.391, 11.451, 11.056, 11.877, 11.508, 11.561, 11.595, 12.31, 11.654, 45.558, 12.831, 12.315, 12.314, 14.25, 23.419, 12.386, 12.021, 11.445, 12.867, 13.25, 11.483, 11.268, 21.379, 11.357, 11.734, 12.639, 11.377, 14.854, 14.642, 12.531, 12.474, 11.419, 12.254, 15.577, 13.823, 15.4, 14.725, 15.586, 26.761, 11.079, 11.509, 11.637, 12.41, 11.867, 12.084, 12.713, 16.218, 12.592, 12.225, 12.325, 18.973, 12.492, 11.379, 12.611, 11.939, 16.655, 11.588, 14.187, 16.742, 26.155, 12.661, 11.284, 13.16, 11.713, 12.602, 12.492, 11.682, 11.565, 12.65, 11.617, 13.696, 11.79, 11.477, 11.463, 11.674, 11.1, 11.609, 11.339, 14.434, 11.454, 11.794, 11.263, 16.395, 17.506, 13.302, 12.372, 12.521, 11.959, 11.588, 14.135, 13.339, 13.841, 12.928, 11.407, 16.256, 19.916, 11.466, 26.431, 12.914, 11.552, 11.904, 21.601, 15.113, 14.595, 12.539, 13.205, 13.47, 12.178, 11.946, 12.683, 13.399, 14.698, 184.038, 11.71, 12.071, 12.199, 13.079, 16.392, 25.844, 12.134, 24.139, 20.474, 15.243, 12.156, 14.235, 14.629, 15.779, 12.259, 17.207, 13.251, 11.972, 16.012, 14.571, 12.598, 12.914, 11.217, 46.477, 14.298, 12.048, 12.91, 14.345, 12.121, 15.21, 11.485, 14.156, 12.205, 12.837, 12.083, 11.535, 11.641, 13.12, 20.49, 11.986, 12.165, 11.385, 11.362, 11.529, 13.683, 11.742, 16.697, 11.246, 11.988, 14.978, 11.685, 11.625, 11.412, 11.437, 12.078, 11.77, 11.608, 12.97, 15.163, 18.42, 11.405, 11.379, 12.009, 14.288, 12.518, 16.205, 18.912, 11.731, 12.405, 81.096, 11.423, 14.819, 20.842, 12.615, 13.006, 17.836, 12.816, 11.499, 14.583, 12.459, 12.099, 13.888, 11.457, 11.581, 14.211, 11.736, 11.957, 12.856, 20.413, 11.99, 12.668, 19.463, 12.067, 11.919, 11.491, 11.968, 11.669, 12.903, 12.924, 12.164, 11.549, 12.33, 12.734, 20.88, 14.088, 12.598, 28.575, 11.823, 14.519, 12.488, 17.038, 11.434, 11.452, 12.215, 14.928, 26.434, 12.495, 11.432, 12.084, 11.282, 11.575, 11.252, 12.515, 11.664, 11.916, 15.454, 25.704, 12.281, 11.783, 11.611, 11.451, 11.223, 11.457, 11.529, 29.991, 11.334, 16.127, 12.294, 11.654, 13.887, 13.07, 16.658, 12.041, 14.844, 11.903, 11.84, 16.09, 15.138, 12.113, 63.062, 15.716, 12.115, 12.819, 11.678, 11.538, 11.542, 10.948, 13.254, 13.044, 13.758, 11.892, 11.147, 12.089, 13.507, 22.199, 11.228, 11.466, 11.418, 15.669, 12.209, 12.553, 12.601, 12.98, 15.834, 13.461, 12.173, 15.562, 12.355, 11.893, 17.019, 11.264, 13.1, 15.855, 11.514, 13.164, 11.582, 181.652, 14.148, 12.97, 16.039, 12.311, 13.743, 12.377, 11.58, 16.093, 17.23, 11.31, 12.14, 12.928, 11.637, 12.241, 13.688, 22.048, 12.065, 16.335, 13.85, 12.529, 104.328, 14.9, 12.609, 21.174, 15.038, 12.913, 26.026, 12.26, 12.015, 12.88, 11.98, 12.343, 12.054, 13.21, 16.07, 12.483, 12.155, 13.743, 13.44, 12.888, 15.484, 15.159, 14.322, 15.496, 53.387, 13.829, 12.773, 14.706, 16.644, 13.436, 14.996, 23.642, 24.85, 12.288, 14.475, 13.918, 15.778, 16.192, 12.1, 13.994, 18.498, 15.743, 13.172, 13.173, 12.402, 29.543, 12.163, 11.962, 12.911, 14.225, 12.069, 12.32, 12.429, 13.03, 13.943, 12.215, 15.411, 13.957, 13.887, 13.331, 16.243, 13.232, 15.588, 20.318, 12.607, 27.559, 15.557, 13.395, 14.797, 13.06, 26.094, 13.687, 12.34, 12.677, 12.646, 13.426, 13.286, 15.035, 13.627, 13.039, 14.098, 12.555, 12.948, 11.896, 12.698, 12.323, 12.481, 12.501, 12.391, 12.335, 13.184, 14.267, 16.28, 18.015, 15.361, 12.768, 12.493, 14.46, 12.881, 13.294, 13.912, 14.054, 13.094, 12.0, 16.74, 21.803, 13.567, 19.154, 14.514, 11.869, 12.177, 14.241, 11.948, 12.686, 12.289, 12.213, 11.778, 26.917, 11.927, 14.309, 17.95, 14.276, 13.897, 13.058, 16.683, 12.345, 12.714, 12.189, 12.492, 12.367, 13.407, 14.11, 30.476, 14.469, 12.479, 12.267, 13.135, 13.393, 13.126, 13.742, 12.636, 15.422, 12.902, 13.742, 12.97, 11.712, 12.47, 13.787, 13.143, 13.0, 14.353, 12.308, 13.155, 13.404, 12.668, 13.3, 12.201, 15.322, 35.175, 12.837, 12.984, 13.248, 12.461, 12.565, 12.856, 13.076, 13.501, 13.747, 15.303, 12.049, 13.289, 12.836, 14.863, 12.809, 13.695, 12.971, 18.431, 16.36, 13.278, 11.973, 15.261, 13.263, 12.152, 12.148, 12.829, 12.299, 12.316, 12.608, 12.03, 14.174, 12.724, 11.862, 12.447, 11.996, 12.304, 12.994, 11.952, 13.913, 15.848, 14.771, 12.63, 12.146, 12.465, 13.504, 11.894, 13.526, 12.986, 15.355, 13.695, 12.616, 13.01, 12.105, 12.578, 12.775, 12.243, 13.405, 12.866, 14.356, 75.626, 13.05, 12.402, 13.571, 33.837, 13.11, 16.013, 12.022, 11.939, 14.056, 12.528, 11.854, 12.368, 11.777, 13.079, 14.357, 12.663, 12.612, 13.053, 16.042, 15.156, 12.394, 17.43, 12.53, 15.389, 13.36, 12.05, 11.975, 12.215, 15.436, 12.153, 12.002, 15.078, 12.341, 12.903, 12.463, 13.277, 12.95, 24.435, 15.043, 12.67, 12.294, 12.471, 15.739, 12.368, 12.038, 11.985, 12.384, 13.915, 15.637, 15.804, 14.024, 12.252, 14.137, 13.988, 12.891, 12.268, 16.698, 14.821, 16.535, 12.598, 12.334, 28.837, 12.588, 12.936, 14.248, 16.747, 12.64, 12.837, 11.979, 28.947, 14.189, 13.263, 12.849, 12.875, 12.915, 12.58, 14.669, 15.337, 13.816, 13.759, 13.904, 39.255, 20.453, 13.273, 13.115, 12.25, 13.292, 12.842, 15.628, 12.473, 12.531, 12.069, 12.452, 15.147, 15.136, 13.392, 12.816, 13.408, 13.628, 11.954, 20.699, 11.881, 20.033, 12.599, 11.729, 12.295, 12.821, 12.251, 15.788, 14.981, 13.368, 12.113, 12.12, 15.917, 12.75, 12.124, 12.592, 29.159, 12.028, 12.713, 12.124, 13.825, 13.463, 12.568, 12.029, 13.969, 13.046, 14.882, 12.017, 13.119, 12.351, 13.687, 12.971, 20.056, 12.113, 12.316, 12.181, 13.472, 12.852, 34.701, 13.984, 11.976, 13.131, 12.248, 12.608, 12.502, 12.393, 20.783, 14.697, 12.901, 14.299, 13.232, 12.66, 12.697, 32.535, 12.475, 12.504, 15.828, 15.128, 12.792, 12.732, 12.686, 13.0, 13.474, 12.13, 64.413, 13.296, 29.2, 12.572, 14.865, 12.299, 18.412, 13.355, 12.119, 12.95, 13.481, 23.176, 12.619, 14.011, 13.878, 12.512, 14.724, 12.749, 12.896, 16.821, 12.727, 14.109, 15.061, 14.485, 18.504, 12.168, 13.293, 18.893, 17.349, 14.274, 12.483, 14.742, 12.813, 12.798, 14.375, 14.311, 13.969, 12.944, 12.65, 13.586, 12.657, 14.199, 14.77, 17.33, 15.544, 12.37, 14.35, 34.474, 14.256, 12.317, 12.051, 12.294, 12.085, 13.271, 12.769, 12.503, 12.207, 12.361, 40.413, 14.152, 12.675, 17.296, 13.246, 15.007, 15.866, 13.106, 12.61, 12.859, 12.514, 13.545, 13.881, 15.269, 13.858, 12.71, 15.503, 12.653, 12.647, 12.534, 19.593, 14.743, 23.095, 15.507, 16.64, 12.656, 22.269, 13.197, 14.932, 14.009, 12.555, 11.96, 12.419, 12.198, 12.366, 13.408, 12.468, 13.197, 13.287, 12.092, 13.97, 12.608, 12.774, 12.58, 12.733, 13.855, 23.732, 12.417, 11.908, 14.976, 13.686, 13.242, 12.57, 196.401, 14.3, 12.787, 14.589, 14.002, 14.754, 12.99, 13.837, 18.495, 14.643, 29.341, 13.117, 19.262, 13.303, 18.493, 14.807, 15.947, 17.273, 87.56, 17.739, 111.138, 15.246, 12.815, 16.962, 14.09, 12.935, 13.425, 18.594, 14.593, 15.841, 13.507, 15.73, 12.941, 12.899, 15.319, 15.207, 14.212, 16.574, 14.356, 13.711, 14.47, 16.22, 15.793, 15.549, 14.577, 12.667, 17.061, 15.745, 12.991, 12.824, 18.988, 13.79, 28.888, 15.275, 15.152, 16.435, 18.86, 16.615, 13.575, 12.985, 19.068, 14.221, 20.955, 12.876, 15.998, 14.602, 15.902, 14.024, 14.911, 13.611, 14.019, 17.883, 15.523, 14.021, 16.207, 13.098, 15.544, 15.638, 27.658, 13.212, 51.996, 13.72, 15.511, 16.106, 16.757, 32.422, 16.079, 17.614, 13.55, 12.964, 13.426, 15.256, 13.115, 17.155, 13.108, 18.896, 14.351, 16.154, 13.057, 12.892, 13.556, 12.822, 13.708, 12.562, 13.103, 12.593, 13.143, 13.956, 22.386, 23.308, 15.248, 27.041, 13.982, 13.712, 13.73, 13.764, 12.898, 12.981, 13.507, 16.569, 14.297, 23.189, 13.525, 13.351, 13.283, 16.736, 12.569, 12.271, 12.637, 13.606, 16.427, 14.336, 12.901, 13.283, 14.0, 20.1, 14.435, 12.588, 18.611, 13.441, 16.63, 12.425, 12.752, 15.947, 12.905, 25.402, 12.776, 15.434, 13.559, 12.491, 12.826, 13.743, 13.35, 17.12, 16.562, 13.61, 12.387, 13.7, 14.498, 15.968, 55.155, 13.484, 13.319, 13.606, 15.288, 15.464, 15.855, 15.488, 13.406, 13.574, 13.178, 12.554, 12.66, 13.388, 16.027, 13.385, 36.533, 12.396, 13.29, 12.957, 12.659, 16.421, 19.459, 16.394, 12.629, 13.793, 17.442, 13.338, 12.883, 14.903, 14.051, 14.071, 12.847, 12.451, 14.364, 12.672, 13.81, 15.381, 14.117, 14.925, 12.991, 13.595, 14.076, 13.729, 13.274, 16.455, 15.538, 12.481, 12.78, 12.922, 15.41, 27.532, 16.328, 13.362, 12.453, 15.623, 12.78, 13.374, 12.516, 12.711, 14.638, 13.357, 15.846, 15.398, 12.723, 25.969, 14.042, 12.841, 15.507, 14.26, 12.961, 13.049, 12.265, 12.932, 12.903, 15.076, 14.003, 16.932, 13.966, 14.43, 12.848, 13.379, 13.953, 13.483, 14.753, 15.855, 13.033, 15.99, 14.259, 17.149, 12.476, 14.411, 15.457, 15.768, 14.371, 15.316, 14.081, 15.804, 15.607, 14.92, 21.757, 15.128, 15.449, 15.728, 15.473, 14.949, 14.697, 14.313, 13.703, 14.323, 19.217, 12.686, 16.8, 14.256, 12.194, 17.759, 14.552, 12.684, 12.883, 17.612, 16.246, 16.982, 16.045, 12.806, 15.961, 21.261, 13.126, 12.951, 16.833, 12.763, 13.894, 12.398, 20.999, 14.756, 12.802, 76.831, 13.105, 14.802, 14.163, 13.742, 13.711, 14.546, 13.882, 12.437, 28.532, 15.063, 16.011, 18.873, 14.216, 16.425, 16.038, 12.702, 13.587, 14.502, 14.805, 22.726, 12.99, 13.471, 14.342, 12.394, 13.52, 11.534, 13.299, 20.422, 11.553, 14.497, 30.748, 21.641, 12.188, 17.083, 11.668, 13.132, 11.97, 14.106, 13.1, 14.897, 13.748, 14.653, 20.295, 14.276, 12.759, 13.313, 13.645, 11.567, 12.027, 12.325, 11.598, 11.753, 12.877, 11.91, 12.889, 14.054, 14.06, 14.075, 14.763, 11.725, 14.57, 14.419, 11.666, 11.726, 12.017, 15.548, 11.874, 11.85, 12.917, 12.893, 11.97, 15.152, 15.9, 14.91, 12.402, 13.263, 11.836, 11.9, 12.756, 13.182, 12.062, 12.043, 13.0, 13.501, 11.814, 11.511, 12.561, 12.537, 13.713, 11.936, 11.603, 15.641, 11.754, 14.559, 12.309, 12.25, 12.167, 11.795, 12.45, 11.48, 181.463, 12.247, 12.357, 12.26, 16.394, 16.673, 18.104, 28.269, 12.601, 12.393, 13.136, 12.472, 15.848, 16.424, 14.522, 16.254, 27.971, 12.807, 15.301, 15.001, 14.035, 21.58, 18.73, 17.499, 13.876, 15.886, 15.761, 12.696, 12.433, 12.246, 14.626, 12.427, 14.574, 13.301, 13.099, 13.103, 14.729, 13.149, 15.718, 13.279, 16.095, 13.09, 14.554, 19.934, 13.013, 13.313, 13.569, 14.769, 12.823, 16.134, 15.411, 16.334, 14.72, 12.971, 13.481, 13.056, 12.857, 15.475, 12.22, 13.148, 12.729, 12.099, 48.831, 12.5, 12.871, 12.661, 12.226, 13.621, 12.529, 13.455, 13.17, 12.408, 12.386, 12.324, 13.993, 83.356, 13.888, 16.383, 12.777, 13.019, 12.795, 12.885, 15.482, 13.251, 14.362, 13.649, 16.589, 15.118, 15.501, 17.228, 16.289, 12.392, 13.396, 12.271, 17.405, 16.656, 14.235, 17.842, 13.431, 12.523, 12.503, 12.171, 15.892, 15.489, 15.654, 14.239, 13.093, 18.627, 13.324, 12.504, 19.221, 13.431, 23.84, 12.389, 15.192, 13.432, 14.179, 14.508, 12.665, 12.518, 16.175, 13.267, 15.442, 13.967, 14.209, 13.116, 16.906, 14.142, 23.415, 12.89, 13.253, 13.411, 14.269, 13.9, 14.519, 12.852, 15.402, 15.658, 12.875, 22.786, 23.023, 11.951, 13.064, 12.972, 13.556, 14.424, 13.251, 13.898, 14.735, 18.468, 12.688, 12.748, 13.313, 15.407, 15.718, 13.107, 21.867, 12.401, 13.075, 12.842, 12.496, 12.832, 15.776, 16.084, 14.883, 13.94, 13.601, 14.093, 12.385, 13.361, 13.898, 16.64, 12.996, 19.105, 12.976, 12.534, 23.118, 16.347, 39.124, 15.427, 16.917, 50.276, 12.57, 12.771, 12.584, 16.689, 15.874, 15.442, 14.672, 13.583, 13.317, 16.735, 15.098, 18.822, 14.933, 15.988, 12.886, 14.374, 17.91, 13.883, 12.689, 12.805, 15.233, 16.146, 15.527, 12.815, 14.228, 13.288, 12.502, 14.954, 14.156, 12.404, 15.504, 15.611, 14.401, 14.032, 16.662, 16.472, 15.055, 15.867, 15.939, 13.012, 13.623, 12.534, 19.716, 14.488, 12.656, 14.215, 16.61, 14.614, 12.836, 13.028, 13.684, 16.465, 17.116, 14.896, 13.701, 12.577, 12.814, 12.784, 13.28, 12.538, 13.435, 15.937, 16.309, 12.138, 15.923, 13.053, 15.465, 12.537, 14.507, 14.5, 13.203, 12.128, 12.283, 15.166, 13.932, 11.943, 13.935, 14.151, 12.488, 13.812, 15.608, 12.153, 13.516, 12.817, 13.789, 12.28, 12.278, 13.618, 16.68, 20.764, 12.963, 11.958, 37.743, 12.299, 14.65, 12.776, 12.574, 14.177, 12.469, 15.329, 31.994, 12.564, 14.024, 15.71, 16.367, 15.026, 12.48, 12.49, 13.525, 14.164, 12.578, 12.715, 12.767, 14.1, 14.167, 16.167, 17.185, 14.761, 16.355, 26.299, 12.842, 28.022, 18.56, 18.13, 12.162, 13.3, 28.176, 13.735, 12.374, 14.299, 14.305, 13.831, 13.766, 12.481, 13.848, 13.321, 24.494, 12.844, 13.756, 14.878, 13.193, 13.635, 13.679, 17.329, 13.874, 13.957, 12.883, 13.804, 12.57, 77.681, 12.021, 16.786, 13.08, 22.175, 14.689, 13.594, 24.925, 12.53, 12.93, 14.019, 18.781, 13.075, 13.624, 14.834, 27.485, 106.878, 13.394, 15.282, 12.568, 14.61, 64.635, 12.198, 12.596, 15.692, 13.002, 15.997, 13.069, 12.802, 12.719, 28.961, 12.536, 14.123, 13.304, 15.352, 12.742, 18.3, 14.073, 14.041, 15.494, 13.159, 12.637, 13.317, 14.643, 12.467, 15.516, 12.706, 17.201, 17.151, 12.459, 12.672, 15.334, 13.719, 12.48, 12.306, 14.555, 13.351, 32.733, 12.426, 13.564, 59.041, 13.073, 16.276, 14.196, 14.563, 22.098, 13.279, 15.839, 16.498, 12.669, 12.462, 12.422, 12.445, 12.813, 13.737, 23.147, 19.822, 14.394, 12.703, 13.325, 14.039, 12.858, 13.429, 16.582, 24.796, 13.439, 12.886, 13.647, 13.59, 16.661, 14.782, 15.885, 11.343, 12.327, 16.044, 11.592, 11.876, 11.637, 11.372, 13.023, 12.042, 11.199, 11.216, 11.434, 11.366, 11.339, 10.883, 12.393, 11.796, 11.205, 11.477, 13.811, 13.058, 18.089, 11.739, 11.051, 12.558, 12.996, 11.107, 11.971, 12.29, 22.411, 11.834, 11.298, 11.19, 11.331, 13.052, 22.355, 14.018, 12.426, 11.605, 12.796, 14.144, 13.273, 13.568, 12.41, 12.832, 11.269, 11.682, 12.237, 16.061, 12.189, 11.217, 11.973, 11.81, 14.006, 14.986, 11.815, 11.952, 11.927, 11.441, 11.547, 11.647, 15.32, 23.272, 11.733, 19.01, 12.804, 12.889, 15.229, 20.589, 11.607, 12.295, 11.508, 12.075, 12.272, 11.948, 13.053, 12.12, 11.452, 12.181, 13.02, 12.402, 12.266, 13.279, 11.467, 11.523, 12.069, 12.342, 11.411, 11.665, 14.183, 15.183, 13.603, 11.366, 14.99, 13.484, 14.356, 12.049, 12.503, 12.026, 12.369, 11.571, 184.352, 13.713, 16.48, 15.325, 13.87, 17.824, 16.232, 14.03, 13.678, 65.09, 13.793, 27.759, 13.38, 14.542, 15.549, 14.737, 17.406, 12.634, 13.52, 12.867, 14.982, 16.886, 34.761, 13.125, 15.101, 12.473, 13.644, 12.831, 13.741, 12.62, 13.705, 17.827, 14.236, 19.17, 14.702, 18.949, 17.038, 14.129, 13.007, 13.827, 15.979, 12.202, 27.898, 13.919, 19.274, 15.491, 13.54, 13.176, 13.0, 17.674, 17.186, 14.11, 14.212, 12.498, 12.531, 17.855, 14.48, 14.942, 12.508, 15.072, 13.989, 22.025, 18.644, 13.961, 12.304, 12.808, 15.179, 12.745, 13.618
            ], 
            [
                5.24, 0.535, 0.781, 5.854, 0.889, 1.839, 1.907, 1.172, 0.367, 1.57, 0.531, 0.512, 0.603, 38.07, 0.619, 0.653, 1.941, 1.496, 0.517, 1.034, 0.526, 1.23, 0.819, 0.756, 0.763, 0.308, 2.821, 0.551, 1.668, 0.235, 1.278, 1.196, 0.518, 0.484, 8.688, 3.403, 0.415, 2.32, 0.409, 0.358, 0.271, 1.306, 0.304, 23.935, 0.686, 1.155, 0.859, 0.867, 1.115, 1.247, 0.434, 0.447, 7.727, 0.452, 0.485, 13.135, 1.744, 0.454, 0.639, 0.261, 1.116, 0.647, 1.056, 1.065, 15.871, 0.26, 0.573, 0.418, 0.521, 0.316, 0.602, 0.95, 0.323, 5.052, 0.63, 0.65, 0.37, 3.139, 1.616, 1.789, 3.353, 1.741, 13.8, 0.502, 0.947, 4.478, 1.324, 0.71, 1.117, 0.905, 0.356, 0.69, 0.794, 3.874, 2.139, 0.502, 0.55, 0.554, 1.619, 11.474, 0.988, 1.152, 0.797, 0.598, 0.479, 0.497, 0.711, 4.374, 1.373, 1.303, 0.538, 3.318, 5.271, 0.427, 5.762, 6.661, 1.983, 32.635, 1.649, 4.541, 0.429, 0.458, 3.282, 6.384, 0.716, 3.539, 3.452, 1.072, 0.487, 0.659, 166.19, 0.63, 2.243, 1.682, 0.387, 0.987, 0.638, 0.519, 1.44, 0.567, 0.824, 0.541, 0.708, 0.521, 12.75, 0.585, 0.399, 0.309, 1.017, 0.978, 0.4, 1.014, 8.201, 0.378, 1.185, 2.333, 3.899, 1.072, 2.85, 0.488, 2.05, 0.729, 4.412, 0.637, 1.865, 0.545, 0.348, 0.639, 0.354, 14.303, 0.914, 1.416, 0.626, 2.377, 0.789, 0.582, 1.969, 0.45, 0.722, 89.614, 0.603, 0.587, 0.382, 4.349, 0.498, 2.456, 2.548, 8.734, 0.561, 0.366, 0.555, 0.419, 10.455, 0.873, 0.914, 0.574, 0.681, 0.473, 1.039, 1.013, 0.301, 0.322, 1.057, 0.483, 1.708, 0.956, 1.444, 1.217, 0.957, 0.674, 6.398, 1.775, 0.825, 0.418, 0.422, 0.629, 0.403, 0.822, 0.536, 0.875, 3.525, 1.618, 2.114, 2.857, 4.741, 0.4, 0.827, 0.706, 0.517, 16.005, 8.036, 0.417, 2.845, 0.55, 5.35, 0.813, 0.385, 0.438, 1.126, 0.656, 0.575, 0.665, 1.169, 0.683, 2.162, 1.227, 0.611, 0.841, 0.491, 0.5, 0.524, 0.828, 0.404, 2.411, 0.493, 1.848, 0.553, 2.991, 0.389, 0.509, 0.913, 2.511, 1.117, 15.291, 1.248, 0.495, 0.437, 0.584, 0.426, 22.325, 0.533, 0.912, 0.631, 2.855, 1.23, 1.046, 0.427, 0.461, 8.76, 1.535, 4.585, 0.844, 0.505, 0.617, 0.532, 0.894, 1.89, 6.43, 1.494, 0.818, 1.1, 0.648, 2.061, 0.834, 0.805, 1.341, 0.838, 7.21, 0.328, 0.43, 21.12, 0.855, 1.507, 1.148, 4.288, 0.889, 0.531, 3.106, 2.192, 6.303, 1.426, 4.021, 1.554, 2.349, 0.721, 1.359, 1.492, 16.23, 1.543, 7.532, 0.501, 0.483, 0.467, 0.459, 0.432, 2.341, 1.212, 0.315, 2.374, 1.2, 0.712, 0.727, 0.352, 0.51, 0.436, 0.444, 0.669, 1.051, 0.58, 0.887, 0.379, 0.822, 4.128, 0.429, 0.491, 0.443, 8.228, 2.029, 8.405, 0.982, 0.508, 1.758, 0.51, 0.586, 2.217, 10.306, 1.584, 0.341, 1.496, 60.841, 0.402, 0.994, 1.964, 3.999, 1.111, 1.171, 0.54, 9.175, 0.947, 3.043, 1.184, 0.536, 0.491, 0.302, 15.202, 1.971, 0.47, 0.71, 2.236, 0.854, 2.451, 66.431, 1.15, 0.371, 1.742, 0.917, 1.125, 0.722, 0.426, 0.688, 1.331, 1.991, 1.259, 0.338, 1.181, 1.308, 3.627, 0.828, 1.312, 0.94, 1.302, 0.617, 0.506, 2.305, 0.864, 0.764, 5.467, 1.463, 0.447, 2.261, 1.074, 1.824, 2.662, 0.495, 0.777, 1.011, 0.577, 0.448, 19.694, 0.405, 10.488, 7.381, 4.425, 1.952, 0.478, 8.843, 2.282, 3.214, 0.479, 0.398, 0.743, 1.796, 0.634, 4.203, 0.62, 2.712, 1.829, 0.409, 0.924, 1.481, 0.476, 1.071, 0.923, 2.725, 1.478, 0.42, 1.339, 2.582, 0.767, 0.734, 0.479, 0.307, 0.602, 0.723, 1.307, 0.532, 1.916, 1.008, 2.802, 2.18, 0.745, 0.465, 1.893, 3.845, 0.605, 0.945, 2.877, 0.852, 1.79, 0.723, 0.726, 0.475, 0.437, 1.113, 7.535, 11.119, 0.717, 0.6, 0.81, 0.421, 0.315, 49.332, 0.862, 0.749, 0.428, 2.415, 1.343, 0.823, 2.678, 0.6, 0.398, 1.116, 3.486, 17.495, 0.311, 0.426, 0.333, 0.575, 0.5, 2.157, 1.166, 0.729, 1.263, 0.886, 2.269, 0.81, 1.55, 1.488, 0.747, 0.581, 0.618, 0.625, 2.29, 0.725, 1.999, 1.294, 0.834, 3.221, 3.947, 0.755, 0.57, 4.723, 0.713, 0.805, 1.937, 0.513, 15.733, 1.227, 20.421, 0.734, 38.39, 17.718, 0.727, 0.723, 0.69, 0.675, 0.749, 3.636, 0.56, 0.671, 8.926, 0.647, 2.72, 2.961, 2.741, 1.025, 0.616, 0.999, 1.036, 1.224, 2.053, 1.324, 0.763, 1.902, 1.261, 1.474, 1.013, 0.597, 1.661, 2.09, 1.061, 0.997, 0.826, 2.871, 0.56, 0.698, 3.898, 2.257, 0.514, 5.602, 4.873, 2.282, 1.131, 0.89, 0.753, 0.82, 0.751, 1.284, 1.364, 9.195, 22.861, 0.96, 0.669, 2.019, 1.441, 0.627, 5.273, 1.861, 0.891, 1.579, 0.681, 1.0, 90.489, 0.643, 2.571, 3.543, 7.345, 1.202, 5.971, 1.564, 0.483, 1.444, 1.652, 0.869, 2.211, 0.868, 0.799, 0.662, 0.7, 0.607, 0.893, 1.328, 1.079, 0.85, 1.22, 0.948, 3.973, 0.726, 0.67, 1.946, 0.852, 4.649, 1.186, 1.367, 1.2, 1.078, 0.723, 0.904, 0.647, 0.792, 1.924, 1.196, 1.42, 1.09, 0.77, 0.558, 0.697, 0.578, 0.857, 0.947, 1.0, 1.674, 1.248, 2.088, 1.65, 0.689, 0.705, 0.784, 0.682, 1.551, 0.823, 0.583, 0.714, 1.546, 1.124, 14.387, 0.704, 1.673, 1.024, 1.182, 1.637, 1.777, 1.405, 0.608, 16.086, 0.707, 0.954, 0.95, 2.271, 4.106, 4.232, 7.673, 0.727, 0.566, 2.321, 0.97, 1.709, 4.305, 1.187, 1.145, 0.602, 0.74, 1.419, 4.067, 10.546, 1.538, 1.032, 0.936, 0.842, 1.481, 1.004, 2.682, 0.932, 0.828, 0.689, 0.759, 59.216, 0.531, 0.614, 0.621, 0.57, 0.595, 0.792, 11.519, 0.51, 0.799, 2.927, 1.028, 1.129, 0.753, 0.926, 1.637, 1.338, 2.504, 1.495, 1.215, 2.784, 1.353, 1.225, 1.478, 0.886, 3.545, 2.353, 9.002, 0.987, 0.602, 0.673, 1.202, 0.676, 2.346, 0.942, 0.688, 1.599, 1.658, 24.12, 1.44, 5.687, 0.604, 65.08, 0.924, 0.868, 2.054, 0.823, 0.699, 1.574, 0.821, 0.536, 12.512, 0.772, 0.704, 0.657, 0.683, 0.872, 0.615, 0.754, 1.734, 1.015, 0.642, 0.689, 1.508, 0.624, 2.09, 0.807, 3.598, 4.111, 0.761, 1.039, 47.809, 0.659, 0.944, 1.482, 1.484, 7.379, 0.971, 0.578, 0.581, 1.964, 0.805, 0.709, 1.02, 4.802, 1.156, 10.347, 0.568, 1.212, 0.883, 0.836, 3.946, 1.282, 0.668, 0.684, 0.961, 1.237, 4.07, 1.357, 8.9, 0.93, 0.795, 0.735, 0.796, 1.259, 6.647, 1.094, 0.95, 0.691, 2.784, 0.86, 1.302, 0.61, 2.471, 0.649, 0.943, 0.625, 1.117, 0.736, 2.28, 0.96, 0.877, 0.947, 1.037, 0.914, 0.593, 1.823, 0.702, 0.592, 1.191, 1.009, 0.709, 2.416, 0.601, 2.614, 1.011, 1.55, 14.777, 1.081, 0.837, 2.57, 2.307, 8.638, 1.908, 0.831, 0.806, 3.627, 3.488, 0.543, 3.071, 0.694, 1.206, 1.629, 1.187, 0.601, 0.979, 1.708, 2.961, 1.115, 1.112, 1.062, 2.561, 8.811, 3.918, 1.003, 1.255, 2.965, 0.94, 1.976, 14.585, 3.298, 0.721, 0.572, 1.01, 0.603, 0.55, 0.581, 0.993, 0.777, 32.383, 0.696, 1.48, 1.676, 1.035, 11.462, 1.276, 0.869, 0.761, 1.925, 2.228, 0.631, 0.576, 9.641, 0.653, 0.872, 1.588, 0.844, 2.084, 1.109, 1.195, 1.425, 0.733, 1.267, 4.633, 2.856, 1.182, 0.992, 4.076, 14.806, 0.583, 0.701, 0.616, 1.422, 0.9, 1.142, 0.799, 4.317, 0.672, 1.335, 1.104, 7.369, 1.74, 0.676, 1.626, 0.969, 3.45, 0.795, 2.745, 3.769, 14.306, 1.154, 0.638, 2.007, 0.783, 1.133, 0.817, 0.827, 0.629, 1.428, 0.873, 2.893, 1.13, 0.666, 0.681, 0.787, 0.689, 0.984, 0.563, 3.286, 0.614, 1.062, 0.742, 5.125, 6.892, 2.634, 1.369, 1.527, 1.205, 0.819, 0.991, 1.529, 0.65, 0.61, 0.607, 2.751, 8.022, 0.71, 14.308, 0.771, 0.597, 0.907, 9.879, 2.592, 3.241, 1.564, 1.816, 0.82, 1.063, 0.883, 1.345, 1.976, 3.035, 164.045, 0.673, 0.67, 0.689, 1.375, 4.321, 12.922, 0.773, 11.129, 7.906, 1.358, 0.52, 1.135, 1.912, 3.6, 0.876, 3.005, 0.645, 0.581, 3.8, 2.847, 1.129, 2.354, 0.596, 32.639, 3.818, 1.049, 2.466, 1.587, 1.365, 4.386, 0.641, 3.242, 0.731, 0.697, 1.178, 0.813, 0.66, 0.907, 8.961, 1.148, 1.179, 0.626, 0.724, 0.786, 3.078, 1.199, 5.937, 0.685, 1.517, 4.287, 1.106, 0.969, 0.783, 0.58, 1.46, 0.864, 0.967, 2.062, 4.111, 7.403, 0.887, 0.828, 0.676, 3.457, 1.143, 4.176, 7.716, 1.191, 1.963, 66.522, 0.691, 3.541, 9.063, 0.911, 1.42, 6.715, 1.816, 0.612, 3.305, 0.627, 0.929, 2.796, 0.597, 0.601, 0.887, 0.848, 1.166, 1.414, 8.612, 1.227, 0.574, 8.248, 1.138, 0.955, 0.625, 1.015, 0.737, 2.017, 1.718, 0.927, 0.782, 0.831, 1.747, 9.042, 1.946, 1.179, 15.843, 0.62, 3.61, 1.209, 2.483, 0.602, 0.693, 0.843, 3.956, 15.712, 1.711, 0.727, 1.221, 0.603, 0.923, 0.706, 1.663, 0.704, 0.875, 4.684, 13.209, 0.633, 0.918, 0.933, 0.735, 0.693, 0.617, 0.792, 17.799, 0.646, 5.114, 1.433, 0.699, 0.723, 1.437, 4.338, 1.106, 2.407, 0.96, 0.842, 4.252, 3.999, 0.805, 47.321, 4.4, 0.491, 1.691, 0.576, 0.756, 0.676, 0.725, 2.619, 2.184, 3.115, 1.16, 0.632, 1.301, 2.921, 10.066, 0.624, 0.871, 0.71, 4.244, 1.056, 1.498, 1.944, 2.081, 0.814, 0.686, 1.584, 4.388, 0.953, 1.094, 5.205, 0.582, 1.902, 1.452, 0.678, 0.974, 0.751, 165.006, 2.295, 1.401, 4.357, 0.898, 2.328, 0.617, 0.557, 4.295, 5.953, 0.606, 0.744, 1.657, 0.717, 0.658, 1.993, 9.874, 0.642, 0.98, 2.531, 1.084, 86.723, 0.939, 1.205, 8.835, 3.383, 1.315, 14.048, 0.666, 0.737, 1.158, 0.668, 0.929, 0.745, 1.588, 4.283, 0.91, 0.74, 2.404, 1.405, 0.826, 0.617, 0.57, 2.482, 0.722, 39.421, 1.648, 1.181, 2.647, 1.29, 1.538, 0.789, 11.114, 11.088, 0.714, 2.796, 1.776, 0.579, 1.467, 0.781, 2.323, 3.015, 0.578, 1.375, 1.318, 0.874, 15.973, 0.57, 0.587, 0.777, 0.595, 0.684, 0.668, 0.681, 1.238, 1.203, 0.728, 1.148, 0.644, 1.889, 1.317, 3.704, 1.147, 0.738, 8.135, 1.031, 14.58, 3.77, 1.646, 1.095, 1.176, 12.719, 1.003, 0.653, 0.899, 0.659, 0.893, 1.462, 0.791, 1.734, 1.321, 0.708, 0.616, 0.879, 0.569, 0.963, 0.786, 0.899, 0.71, 0.913, 0.789, 1.282, 2.71, 2.138, 5.83, 0.782, 1.032, 0.824, 1.039, 1.118, 1.637, 1.66, 1.707, 0.916, 0.695, 5.13, 9.922, 1.913, 4.716, 0.802, 0.632, 0.875, 2.398, 0.839, 0.791, 0.95, 0.713, 0.588, 14.825, 0.643, 1.521, 5.842, 2.655, 2.384, 1.05, 1.501, 0.872, 0.941, 0.779, 0.766, 0.695, 1.507, 2.346, 17.804, 1.723, 0.634, 0.713, 1.687, 1.48, 0.681, 2.355, 1.213, 3.946, 1.204, 1.746, 1.098, 0.54, 0.571, 2.009, 0.805, 1.725, 2.836, 0.79, 1.294, 1.68, 1.285, 0.78, 0.798, 3.031, 22.243, 1.209, 1.227, 0.821, 0.637, 0.808, 0.869, 1.529, 1.467, 2.369, 3.684, 0.733, 0.945, 0.925, 2.656, 1.324, 2.193, 1.662, 6.446, 4.657, 1.714, 0.549, 3.376, 1.677, 0.591, 0.78, 1.09, 0.721, 0.753, 1.199, 0.731, 2.616, 1.098, 0.678, 0.993, 0.744, 0.929, 0.798, 0.693, 1.668, 4.459, 2.942, 0.959, 0.639, 0.923, 1.757, 0.511, 0.617, 1.159, 1.68, 1.499, 1.095, 1.184, 0.762, 1.169, 0.62, 0.583, 1.527, 1.12, 2.132, 59.999, 0.744, 0.584, 1.431, 21.3, 1.239, 0.821, 0.686, 0.735, 2.25, 0.564, 0.563, 0.989, 0.737, 1.598, 2.556, 0.805, 0.792, 0.667, 1.6, 3.112, 0.75, 5.594, 0.714, 1.103, 1.241, 0.659, 0.577, 0.921, 3.981, 0.629, 0.588, 2.747, 0.55, 1.115, 0.628, 1.876, 1.282, 11.825, 3.211, 1.007, 0.515, 0.888, 2.325, 0.747, 0.68, 0.599, 0.695, 2.498, 3.938, 3.873, 2.134, 0.623, 2.136, 0.665, 0.861, 0.767, 1.141, 2.123, 1.42, 0.851, 0.704, 15.205, 0.806, 0.702, 1.914, 1.773, 0.924, 1.183, 0.613, 12.084, 2.261, 1.261, 1.152, 0.96, 0.824, 1.019, 2.509, 0.568, 1.595, 1.876, 2.04, 24.199, 7.936, 0.68, 1.072, 0.757, 1.282, 1.108, 3.452, 0.583, 0.757, 0.586, 0.653, 3.495, 3.197, 1.228, 1.727, 1.272, 1.09, 0.76, 8.132, 0.671, 7.549, 1.18, 0.7, 1.071, 1.585, 0.652, 4.489, 3.492, 2.15, 0.723, 0.949, 4.542, 1.41, 0.684, 1.338, 15.98, 0.514, 1.16, 0.681, 2.381, 0.564, 1.245, 0.711, 2.242, 1.548, 3.096, 0.602, 1.469, 1.174, 0.983, 1.301, 8.012, 0.556, 0.614, 0.619, 1.685, 1.053, 21.403, 2.228, 0.565, 0.567, 0.722, 1.144, 0.616, 1.144, 7.914, 2.96, 1.242, 2.278, 1.58, 0.71, 0.977, 17.782, 0.721, 0.884, 3.831, 3.376, 1.45, 1.091, 1.065, 1.362, 1.93, 0.49, 47.488, 1.845, 15.818, 0.594, 2.634, 0.726, 6.334, 1.672, 0.706, 1.235, 1.738, 10.104, 0.979, 1.997, 2.128, 0.646, 2.849, 0.635, 0.878, 4.74, 0.829, 2.359, 1.207, 2.839, 5.944, 0.555, 1.601, 5.815, 4.01, 2.384, 0.607, 2.567, 0.709, 1.013, 1.68, 0.611, 0.828, 0.619, 0.866, 1.779, 0.837, 0.672, 2.741, 3.258, 2.935, 0.574, 2.321, 20.659, 1.067, 0.746, 0.824, 0.755, 0.602, 0.962, 1.152, 0.859, 0.696, 0.749, 24.285, 2.569, 1.174, 4.81, 1.216, 0.734, 3.929, 1.28, 1.016, 1.085, 0.925, 1.708, 1.134, 0.767, 1.578, 0.638, 3.27, 0.89, 0.703, 0.706, 6.818, 0.794, 9.353, 2.949, 4.574, 0.59, 8.245, 1.419, 0.565, 0.82, 0.79, 0.597, 0.682, 0.792, 0.866, 1.015, 0.888, 1.517, 0.571, 0.728, 2.312, 0.839, 1.312, 0.664, 1.261, 0.927, 10.601, 0.765, 0.58, 1.259, 0.664, 1.013, 0.78, 167.638, 1.493, 0.688, 1.513, 0.695, 1.643, 0.782, 1.315, 5.076, 1.046, 15.028, 0.749, 5.811, 0.765, 2.745, 2.11, 0.733, 1.495, 65.501, 1.176, 87.826, 2.658, 0.625, 1.321, 1.545, 0.905, 1.018, 2.756, 1.309, 0.978, 0.963, 3.076, 0.931, 0.728, 0.632, 0.73, 1.297, 0.77, 1.589, 1.105, 1.138, 1.79, 2.354, 0.655, 1.016, 0.676, 3.506, 1.124, 0.81, 0.584, 3.107, 0.998, 14.506, 2.316, 2.221, 1.655, 3.9, 3.552, 1.332, 0.626, 5.692, 1.276, 7.424, 0.759, 1.102, 0.963, 0.56, 0.809, 0.77, 1.178, 1.046, 2.491, 1.785, 1.095, 3.236, 0.614, 1.215, 1.251, 13.29, 0.59, 34.453, 1.484, 1.616, 0.827, 1.237, 15.086, 0.652, 0.868, 0.985, 0.649, 0.678, 1.441, 0.951, 4.044, 0.691, 5.842, 0.921, 0.892, 0.935, 0.76, 1.321, 0.684, 1.439, 0.801, 1.007, 0.605, 0.66, 1.419, 8.938, 9.567, 2.065, 12.267, 1.127, 0.836, 0.877, 0.767, 0.765, 0.811, 0.715, 3.654, 0.95, 9.183, 0.777, 0.826, 1.184, 4.624, 0.724, 0.891, 0.956, 1.511, 3.545, 2.338, 0.741, 1.134, 1.698, 5.613, 0.944, 0.801, 5.766, 0.758, 4.11, 0.617, 1.025, 2.497, 0.723, 12.042, 0.868, 0.595, 1.468, 0.749, 0.94, 1.577, 1.005, 4.465, 1.075, 1.135, 0.701, 1.199, 0.767, 1.847, 38.466, 1.046, 0.983, 0.647, 0.875, 1.087, 0.948, 0.611, 1.603, 1.624, 1.264, 0.839, 0.912, 0.922, 0.741, 1.412, 22.469, 0.95, 1.097, 1.295, 0.865, 2.037, 6.875, 4.562, 0.755, 0.782, 2.581, 1.145, 1.116, 2.499, 0.836, 0.934, 0.924, 0.699, 2.091, 0.838, 1.456, 3.171, 1.605, 0.72, 1.026, 1.476, 1.711, 1.663, 0.701, 1.363, 3.326, 0.705, 1.215, 0.863, 0.634, 13.955, 3.863, 0.94, 0.869, 0.718, 0.869, 1.261, 0.948, 0.782, 0.893, 1.389, 1.113, 3.377, 1.054, 13.036, 1.023, 0.862, 2.315, 1.683, 0.929, 0.918, 0.652, 1.006, 1.098, 1.354, 1.262, 1.886, 0.752, 1.25, 1.057, 1.192, 1.347, 1.045, 2.734, 3.19, 1.014, 1.414, 0.68, 4.579, 0.757, 1.437, 2.188, 0.663, 0.64, 0.827, 0.612, 0.698, 0.58, 0.951, 6.638, 1.285, 1.249, 2.294, 0.808, 0.629, 0.703, 0.598, 1.214, 0.732, 3.65, 0.592, 1.015, 2.291, 0.744, 2.131, 2.683, 0.844, 0.942, 2.243, 0.864, 0.955, 0.963, 0.855, 1.244, 8.432, 1.082, 0.732, 1.046, 0.617, 1.003, 0.65, 7.884, 0.584, 0.834, 61.078, 1.307, 2.485, 1.549, 1.574, 0.999, 0.761, 1.345, 0.746, 15.452, 1.684, 3.803, 4.247, 0.79, 2.826, 2.454, 0.572, 1.509, 1.498, 1.466, 9.858, 0.851, 1.157, 1.788, 1.236, 0.698, 0.695, 2.284, 9.402, 0.855, 2.181, 18.223, 9.895, 1.289, 6.189, 0.671, 1.173, 0.69, 0.669, 2.284, 0.626, 1.011, 1.203, 8.401, 2.947, 1.399, 0.671, 2.904, 0.709, 0.722, 0.569, 0.53, 0.862, 1.962, 1.051, 2.043, 3.28, 3.292, 3.107, 4.004, 0.622, 3.738, 2.799, 0.552, 1.086, 0.565, 1.115, 1.148, 0.613, 1.741, 0.713, 0.696, 3.874, 2.883, 4.146, 1.155, 0.693, 0.733, 0.729, 1.324, 0.954, 0.995, 0.939, 2.304, 2.032, 0.645, 0.601, 1.512, 1.647, 2.918, 1.478, 0.652, 4.629, 0.501, 3.603, 0.894, 1.145, 1.243, 1.226, 1.757, 0.893, 165.228, 0.585, 0.575, 0.596, 3.46, 1.493, 1.749, 15.029, 0.585, 0.586, 1.668, 0.515, 3.758, 0.881, 0.916, 4.04, 14.843, 0.712, 3.085, 0.74, 1.617, 9.283, 6.491, 5.124, 1.698, 2.439, 0.765, 0.906, 0.711, 0.583, 2.485, 0.655, 1.801, 1.401, 1.256, 1.527, 2.779, 0.964, 3.279, 0.661, 1.485, 1.152, 2.467, 7.718, 0.917, 1.25, 1.437, 0.62, 0.609, 0.886, 0.88, 2.051, 1.143, 0.742, 1.975, 1.075, 1.109, 0.964, 0.809, 1.216, 0.715, 0.674, 34.621, 1.165, 1.093, 1.256, 0.608, 1.581, 0.847, 0.933, 1.302, 0.675, 0.596, 0.842, 1.888, 66.713, 0.678, 0.714, 0.652, 1.207, 0.754, 0.607, 0.621, 0.928, 2.931, 1.151, 4.572, 0.821, 4.036, 5.133, 4.146, 0.66, 1.297, 0.625, 4.46, 4.399, 1.645, 5.71, 1.555, 0.761, 0.786, 0.781, 2.389, 0.577, 0.624, 2.244, 1.378, 5.373, 1.123, 0.598, 6.646, 0.584, 10.821, 0.594, 2.404, 1.102, 1.6, 0.527, 0.569, 0.799, 0.817, 1.042, 0.684, 1.033, 1.16, 0.765, 1.833, 1.858, 9.869, 1.1, 1.112, 1.168, 0.538, 1.861, 2.413, 0.533, 0.827, 3.643, 0.895, 9.251, 9.01, 0.521, 0.917, 0.805, 1.511, 2.374, 1.349, 0.739, 1.232, 6.246, 1.014, 1.049, 1.291, 0.776, 1.439, 1.07, 9.074, 0.586, 1.053, 0.891, 1.105, 1.069, 0.88, 1.095, 2.61, 1.941, 1.109, 1.921, 0.667, 0.565, 1.957, 1.666, 0.918, 3.045, 0.892, 0.64, 8.177, 0.703, 21.982, 2.391, 1.799, 35.541, 0.9, 0.795, 1.118, 4.488, 3.182, 2.459, 2.638, 1.45, 1.267, 4.688, 1.129, 5.255, 0.936, 0.775, 0.904, 2.054, 5.272, 1.426, 0.597, 0.758, 1.143, 1.66, 0.71, 0.803, 0.831, 1.611, 0.607, 2.748, 0.575, 0.592, 0.698, 0.689, 1.955, 1.463, 2.508, 1.076, 0.888, 0.677, 0.581, 0.97, 1.098, 0.583, 4.652, 0.815, 0.741, 1.552, 1.124, 1.534, 0.577, 0.798, 1.674, 4.061, 1.53, 0.568, 0.698, 0.986, 1.088, 0.843, 1.4, 0.799, 1.093, 0.707, 1.244, 0.638, 1.019, 0.758, 2.945, 0.674, 2.298, 1.115, 1.353, 0.711, 0.763, 0.77, 2.083, 0.621, 2.162, 2.593, 0.947, 1.991, 1.508, 0.719, 1.651, 1.344, 1.997, 0.625, 0.695, 0.622, 1.483, 5.667, 1.198, 0.577, 24.052, 1.062, 1.24, 0.838, 0.702, 2.462, 0.833, 3.195, 15.917, 0.745, 1.866, 0.961, 0.865, 1.2, 0.957, 0.83, 0.913, 2.099, 0.809, 1.076, 0.68, 0.694, 0.693, 3.134, 1.512, 1.539, 1.951, 12.631, 0.861, 13.554, 5.747, 2.09, 0.591, 1.565, 14.332, 0.788, 0.691, 1.032, 0.691, 0.851, 2.067, 0.602, 1.922, 1.149, 7.855, 0.955, 2.142, 1.024, 1.032, 1.265, 0.731, 5.246, 1.717, 2.133, 0.707, 1.617, 0.798, 61.953, 0.699, 4.968, 1.459, 6.207, 2.657, 1.204, 11.963, 0.622, 0.852, 0.745, 7.179, 0.685, 2.07, 2.548, 12.029, 88.702, 1.316, 1.045, 0.719, 2.648, 51.094, 0.836, 0.695, 3.222, 0.854, 1.285, 1.539, 0.98, 0.804, 16.63, 0.839, 1.425, 0.889, 0.782, 0.824, 5.883, 2.135, 2.186, 3.927, 1.498, 1.094, 0.881, 2.928, 0.975, 0.819, 1.201, 1.311, 0.995, 0.823, 0.724, 1.973, 1.767, 0.653, 0.674, 0.601, 1.278, 19.296, 0.717, 1.14, 40.349, 1.15, 1.201, 2.367, 2.005, 8.841, 1.047, 0.987, 0.672, 0.938, 0.756, 0.724, 0.748, 1.008, 1.963, 10.495, 7.55, 1.19, 0.837, 0.97, 1.086, 0.899, 1.723, 1.593, 11.904, 1.226, 0.627, 1.485, 1.572, 4.206, 0.651, 3.856, 0.589, 1.315, 5.978, 0.663, 1.365, 0.644, 0.83, 2.817, 0.862, 0.626, 0.837, 1.078, 0.912, 0.734, 0.528, 1.067, 1.191, 0.734, 1.101, 2.428, 1.197, 7.536, 0.581, 0.681, 1.352, 0.678, 0.922, 1.629, 0.553, 11.932, 0.78, 0.996, 0.962, 1.039, 2.467, 11.637, 3.59, 0.822, 0.862, 0.652, 2.314, 0.672, 0.844, 1.867, 2.326, 0.746, 0.587, 1.027, 3.434, 0.778, 0.731, 0.991, 0.678, 0.66, 4.156, 0.714, 1.046, 0.807, 0.897, 0.678, 0.815, 1.052, 10.124, 0.992, 7.706, 0.662, 1.088, 4.699, 10.237, 0.628, 1.153, 0.964, 1.494, 1.064, 1.021, 1.674, 1.194, 0.533, 0.909, 1.134, 1.583, 0.632, 2.153, 0.949, 0.75, 0.615, 1.671, 0.635, 1.062, 0.883, 3.429, 2.085, 0.885, 4.542, 2.282, 3.033, 1.322, 2.024, 1.489, 1.004, 0.659, 174.686, 0.746, 1.432, 0.499, 0.85, 5.036, 2.01, 0.697, 0.972, 52.974, 1.684, 15.994, 1.195, 0.729, 3.646, 1.498, 2.8, 0.747, 0.604, 0.706, 2.581, 1.145, 23.634, 0.909, 0.62, 0.62, 1.731, 0.736, 1.085, 0.958, 1.069, 1.378, 1.026, 3.677, 0.595, 5.642, 2.938, 1.757, 0.814, 1.348, 1.867, 0.538, 14.418, 1.311, 2.94, 1.439, 0.801, 0.683, 1.178, 1.423, 1.847, 0.955, 1.165, 0.627, 0.726, 3.331, 0.619, 2.5, 0.578, 2.419, 1.044, 9.786, 6.591, 1.693, 0.626, 0.85, 0.636, 1.022, 1.438, 1.476, 4.088, 4.029, 0.645, 0.738, 0.886, 0.849, 34.782, 0.83, 0.865, 0.964, 0.966, 0.6, 1.18, 0.704, 1.085, 2.078, 0.817, 0.789, 1.094, 1.62, 0.731, 2.647, 0.996, 0.989, 1.545, 0.747, 1.613, 0.899, 2.406, 1.249, 2.743, 0.635, 4.44, 16.035, 1.138, 8.127, 0.674, 1.023, 1.352, 5.606, 2.935, 0.97, 1.203, 0.757, 0.823, 2.133, 9.797, 1.488, 3.315, 1.034, 1.433, 0.982, 0.647, 4.69, 0.885, 0.821, 1.104, 0.733, 3.8, 1.041, 0.981, 69.167, 0.912, 1.706, 5.385, 1.644, 5.228, 1.176, 8.261, 2.667, 0.752, 0.76, 3.867, 0.759, 0.839, 0.766, 6.112, 1.8, 1.593, 20.29, 45.189, 4.033, 1.065, 6.672, 1.916, 0.983, 2.093, 0.609, 90.233, 0.697, 3.048, 0.89, 0.736, 1.101, 1.132, 8.998, 1.139, 1.183, 1.024, 1.585, 1.175, 2.459, 0.584, 1.094, 0.747, 1.372, 9.292, 0.807, 3.354, 4.374, 1.477, 7.965, 1.288, 1.318, 1.736, 1.221, 0.655, 0.723, 0.789, 0.866, 0.681, 8.706, 1.681, 2.39, 0.979, 2.572, 3.84, 0.869, 0.635, 0.599, 0.613, 1.816, 1.404, 3.238, 1.658, 1.01, 1.527, 10.569, 1.622, 0.703, 2.408, 1.085, 9.358, 1.697, 1.288, 5.676, 1.289, 2.77, 0.646, 1.048, 0.632, 1.967, 0.651, 0.72, 0.858, 1.001, 0.915, 0.663, 2.096, 0.756, 0.733, 1.013, 0.756, 13.503, 1.998, 2.493, 1.039, 2.458, 0.628, 0.574, 4.688, 0.637, 1.112, 0.655, 1.324, 0.695, 0.815, 0.682, 1.87, 1.131, 1.005, 0.903, 1.25, 0.7, 1.302, 1.07, 4.213, 0.8, 0.636, 1.025, 0.981, 0.758, 1.045, 0.58, 0.584, 1.839, 0.767, 0.632, 1.012, 1.267, 0.829, 1.204, 17.577, 1.125, 2.493, 0.898, 0.548, 22.82, 0.715, 2.212, 4.862, 0.696, 1.129, 1.884, 3.656, 1.06, 0.535, 13.354, 1.254, 0.703, 1.151, 0.737, 0.737, 0.823, 3.739, 1.205, 1.045, 0.847, 0.842, 1.705, 0.655, 1.275, 1.18, 0.781, 1.759, 1.11, 1.568, 0.825, 0.698, 0.643, 0.756, 0.709, 0.8, 0.933, 2.171, 11.378, 0.992, 0.654, 8.856, 0.928, 1.049, 26.521, 0.639, 0.926, 0.851, 2.082, 8.703, 15.466, 2.344, 2.711, 66.148, 2.463, 0.793, 0.802, 0.538, 1.752, 15.508, 4.713, 2.413, 0.698, 0.801, 0.588, 1.825, 1.489, 1.203, 0.74, 0.876, 1.506, 0.96, 0.615, 0.626, 0.682, 0.907, 1.493, 0.94, 2.043, 1.171, 0.611, 0.727, 0.655, 3.788, 0.738, 2.368, 1.376, 4.055, 1.25, 1.09, 5.628, 1.234, 4.56, 0.654, 1.653, 0.675, 6.065, 0.57, 0.853, 1.564, 0.867, 3.477, 2.447, 3.099, 2.814, 3.118, 0.991, 0.924, 3.569, 3.686, 2.919, 4.457, 1.304, 0.782, 13.643, 6.779, 3.488, 1.315, 0.654, 18.21, 8.004, 1.227, 0.739, 3.675, 0.871, 0.986, 14.292, 0.71, 0.711, 0.864, 0.652, 3.943, 0.99, 6.087, 0.608, 3.253, 1.337, 2.111, 3.136, 0.996, 0.8, 0.668, 0.788, 11.794, 1.078, 1.647, 0.843, 0.736, 0.886, 10.561, 9.321, 0.938, 0.797, 0.898, 4.187, 0.619, 4.357, 60.658, 0.833, 1.279, 8.872, 1.103, 15.861, 0.711, 47.371, 0.689, 2.606, 0.594, 1.486, 0.81, 1.558, 0.551, 0.609, 0.71, 14.291, 2.523, 0.733, 2.082, 0.961, 3.278, 0.915, 0.767, 3.244, 0.931, 2.316, 0.574, 1.752, 1.549, 0.992, 0.857, 0.757, 0.783, 1.138, 0.631, 3.636, 1.188, 0.852, 1.045, 1.831, 1.937, 4.367, 2.838, 0.9, 0.621, 0.856, 0.788, 3.279, 1.576, 1.421, 3.64, 0.963, 1.864, 1.208, 2.325, 1.138, 4.181, 0.882, 1.0, 3.215, 0.845, 1.04, 1.353, 1.214, 1.299, 0.954, 1.34, 0.986, 3.082, 1.26, 0.962, 0.719, 0.535, 0.8, 0.591, 9.435, 1.408, 4.771, 0.71, 0.684, 0.892, 0.885, 2.36, 0.831, 1.313, 2.298, 0.783, 1.143, 0.885, 0.863, 1.979, 1.157, 1.912, 0.706, 2.62, 1.18, 1.007, 12.274, 34.048, 0.674, 0.823, 0.958, 170.401, 0.677, 0.53, 1.002, 1.948, 0.772, 2.097, 1.317, 15.49, 1.185, 0.944, 0.618, 2.241, 2.874, 4.659, 0.637, 3.538, 1.008, 0.905, 0.988, 0.767, 0.851, 3.117, 2.526, 5.002, 1.081, 5.694, 0.7, 1.312, 0.863, 0.606, 0.904, 0.836, 0.844, 1.947, 1.384, 2.047, 0.605, 0.679, 0.648, 11.75, 66.919, 0.944, 0.597, 1.498, 1.67, 1.037, 2.922, 8.227, 3.465, 4.654, 3.927, 9.877, 4.216, 0.822, 0.639, 1.508, 0.631, 2.199, 0.981, 1.247, 6.155, 1.419, 0.898, 3.864, 1.374, 0.768, 1.133, 0.664, 1.015, 0.967, 4.271, 1.473, 17.996, 1.769, 1.337, 26.108, 1.199, 3.312, 0.986, 16.857, 1.237, 1.308, 0.943, 1.288, 1.362, 1.515, 1.669, 0.976, 0.572, 0.822, 0.989, 1.317, 0.852, 2.823, 0.806, 11.301, 0.957, 0.839, 0.951, 1.985, 0.891, 6.638, 1.802, 1.516, 0.924, 0.924, 0.907, 0.741, 0.926, 0.827, 1.008, 2.128, 1.437, 2.889, 1.105, 3.38, 2.148, 1.099, 1.76, 0.707, 0.784, 3.165, 0.744, 0.554, 1.545, 0.687, 1.207, 1.38, 1.904, 0.806, 1.977, 0.776, 0.835, 0.896, 0.63, 7.632, 0.814, 1.094, 8.228, 1.286, 2.995, 1.065, 0.924, 0.679, 2.867, 2.655, 21.075, 0.778, 1.743, 1.12, 0.96, 1.21, 3.742, 1.097, 1.598, 3.391, 1.448, 0.994, 0.95, 2.816, 6.954, 5.971, 2.155, 1.098, 1.324, 5.88, 5.018, 8.773, 1.527, 0.842, 1.248, 5.131, 1.752, 1.403, 0.583, 1.161, 1.307, 0.885, 0.687, 1.063, 1.377, 1.085, 1.84, 2.951, 1.996, 0.702, 1.072, 0.625, 1.975, 0.985, 0.998, 1.446, 3.191, 1.336, 1.338, 1.298, 0.685, 0.879, 2.204, 1.179, 0.84, 1.247, 3.398, 0.941, 0.727, 0.909, 2.359, 0.893, 5.718, 0.64, 17.93, 0.979, 0.829, 0.716, 0.738, 1.22, 1.741, 1.404, 0.886, 0.758, 1.352, 1.39, 1.672, 0.625, 0.955, 7.456, 0.988, 0.663, 1.629, 0.615, 1.042, 1.477, 0.74, 0.972, 0.919, 0.645, 2.196, 1.152, 1.195, 90.907, 0.956, 0.567, 1.134, 0.963, 1.428, 0.852, 2.132, 6.122, 0.745, 3.626, 1.691, 2.589, 6.041, 1.378, 2.891, 0.579, 11.527, 0.955, 0.934, 1.555, 3.477, 0.954, 0.795, 0.854, 14.353, 1.422, 0.788, 3.125, 0.727, 1.824, 3.403, 1.309, 15.165, 1.488, 3.881, 2.4, 0.943, 2.447, 2.118, 1.252, 0.81, 0.95, 0.782, 0.846, 3.324, 1.347, 1.946, 1.063, 1.419, 1.171, 3.412, 1.055, 0.964, 1.783, 0.883, 3.422, 1.596, 0.799, 2.848, 0.766, 3.857, 13.893, 1.494, 7.496, 0.799, 1.092, 2.008, 1.961, 3.863, 1.047, 0.861, 4.686, 1.425, 4.894, 0.901, 1.281, 0.889, 0.958, 0.896, 10.418, 0.652, 1.182, 1.082, 0.909, 1.279, 23.429, 1.208, 1.542, 1.166, 0.774, 1.091, 1.601, 1.043, 0.987, 9.433, 1.779, 1.459, 1.11, 1.155, 52.277, 1.747, 1.106, 1.377, 2.423, 1.911, 2.425, 1.161, 0.967, 1.13, 1.345, 1.473, 0.948, 0.818, 0.958, 1.125, 1.15, 1.387, 1.79, 1.657, 0.906, 0.906, 1.01, 3.047, 1.368, 1.605, 5.44, 1.076, 10.586, 1.16, 1.441, 2.856, 1.724, 1.034, 0.948, 0.937, 1.055, 2.775, 1.007, 3.081, 0.929, 1.584, 1.593, 1.329, 1.017, 2.115, 1.035, 1.238, 11.534, 0.935, 1.829, 1.203, 2.431, 19.113, 0.834, 2.047, 0.838, 1.05, 1.236, 1.249, 1.22, 0.945, 1.082, 0.98, 1.109, 0.732, 2.151, 0.925, 1.246, 3.116, 1.405, 0.946, 1.088, 2.625, 0.796, 5.11, 1.185, 0.81, 0.689, 0.958, 0.833, 0.776, 3.013, 1.987, 5.643, 16.759, 0.848, 0.98, 22.893, 1.264, 1.049, 3.876, 4.697, 2.936, 1.033, 51.735, 3.706, 0.688, 0.795, 1.194, 1.242, 0.853, 1.15, 1.448, 0.692, 0.948, 0.981, 1.652, 1.207, 1.659, 1.112, 0.859, 2.348, 0.867, 1.193, 1.667, 0.793, 2.135, 1.209, 2.293, 0.987, 1.531, 1.031, 4.966, 1.031, 2.259, 1.156, 2.189, 1.276, 3.947, 16.92, 1.407, 1.66, 1.422, 2.037, 1.305, 3.67, 16.244, 1.443, 6.407, 2.597, 1.812, 0.746, 1.224, 1.511, 1.077, 0.82, 26.991, 2.641, 0.994, 1.73, 2.879, 9.455, 1.03, 2.177, 1.016, 5.409, 1.065, 0.911, 6.804, 1.604, 1.348, 0.924, 1.426, 0.859, 0.915, 0.905, 4.739, 0.866, 1.276, 1.047, 3.395, 1.467, 1.32, 9.483, 1.211, 70.254, 0.819, 1.327, 0.983, 1.116, 1.735, 1.201, 0.708, 1.888, 1.032, 0.825, 1.189, 1.584, 1.182, 0.825, 1.306, 1.486, 1.44, 1.816, 0.942, 19.96, 0.89, 62.498, 1.311, 0.967, 0.922, 2.068, 0.787, 4.354, 1.004, 6.473, 1.077, 1.17, 2.054, 3.028, 0.95, 9.647, 0.709, 1.506, 0.953, 1.085, 5.247, 1.221, 1.296, 13.157, 0.828, 0.913, 1.256, 0.698, 1.059, 1.983, 0.836, 1.181, 1.32, 1.356, 0.928, 1.405, 0.77, 1.05, 12.061, 18.29, 2.246, 1.01, 0.769, 6.037, 8.364, 6.857, 1.094, 1.443, 0.949, 1.703, 2.05, 1.066, 0.975, 2.794, 0.935, 1.231, 1.09, 1.362, 0.918, 1.08, 1.51, 2.106, 3.09, 8.805, 2.365, 0.986, 1.21, 2.712, 3.355, 1.031, 1.691, 2.537, 1.208, 0.982, 3.025, 2.811, 3.63, 3.285, 1.765, 1.657, 0.818, 2.077, 2.095, 1.195, 0.783, 1.196, 1.923, 2.658, 0.764, 0.939, 1.359, 4.669, 1.515, 1.889, 0.919, 2.738, 0.823, 0.965, 0.974, 1.399, 1.015, 1.166, 1.162, 11.276, 41.527, 1.927, 1.283, 1.886, 4.277, 2.42, 0.813, 1.415, 2.515, 3.927, 1.768, 3.234, 1.788, 1.282, 1.52, 0.808, 2.303, 1.148, 1.089, 26.198, 0.846, 1.793, 0.81, 0.797, 0.699, 2.077, 1.756, 1.145, 1.798, 1.106, 7.953, 0.775, 33.901, 1.113, 1.027, 1.159, 3.377, 1.012, 0.725, 0.841, 1.065, 4.044, 2.526, 1.346, 1.551, 1.442, 1.171, 1.081, 1.188, 9.115, 1.048, 11.474, 15.365, 0.904, 10.294, 1.505, 1.225, 0.988, 0.775, 1.684, 1.126, 7.53, 0.932, 3.359, 1.058, 2.358, 1.618, 1.101, 0.963, 9.447, 1.248, 0.94, 0.898, 3.383, 0.955, 1.149, 1.086, 2.646, 1.572, 1.431, 1.25, 0.877, 1.922, 2.185, 1.015, 1.048, 4.193, 0.817, 2.579, 5.64, 1.472, 0.904, 0.954, 0.766, 0.747, 1.16, 3.018, 0.836, 2.965, 1.016, 3.223, 1.623, 1.868, 2.001, 1.57, 0.818, 1.811, 1.751, 0.977, 1.216, 1.611, 1.096, 1.09, 6.194, 1.227, 1.393, 2.032, 1.169, 6.103, 1.015, 1.033, 0.82, 5.071, 4.096, 0.998, 3.656, 1.395, 1.149, 1.121, 1.652, 1.698, 3.539, 1.19, 1.837, 0.927, 0.966, 2.144, 1.119, 2.037, 2.371, 9.093, 1.964, 3.02, 8.229, 6.995, 0.781, 0.966, 0.786, 1.066, 4.831, 1.064, 1.587, 0.888, 0.855, 4.367, 1.539, 0.926, 0.959, 2.049, 14.651, 1.563, 3.504, 0.88, 1.48, 0.984, 10.537, 1.546, 13.95, 0.878, 1.123, 0.943, 0.887, 3.897, 3.05, 0.896, 0.965, 1.66, 90.202, 13.889, 3.4, 1.25, 1.2, 1.506, 7.204, 0.884, 1.236, 0.951, 7.121, 0.859, 1.453, 6.3, 1.133, 2.592, 0.96, 166.907, 7.284, 1.75, 3.142, 0.846, 1.135, 1.729, 1.934, 1.564, 0.888, 0.712, 2.452, 1.704, 2.593, 2.249, 1.478, 0.91, 3.633, 2.292, 1.241, 0.839, 1.065, 1.719, 1.619, 1.074, 1.09, 1.291, 2.862, 0.841, 1.17, 2.13, 1.024, 12.936, 5.853, 1.402, 1.267, 1.786, 0.957, 0.983, 3.576, 3.136, 0.806, 0.901, 1.606, 0.849, 1.159, 1.319, 1.426, 1.189, 0.905, 2.351, 1.005, 1.578, 0.792, 1.547, 0.903, 39.433, 3.449, 1.21, 0.792, 4.031, 1.022, 8.729, 1.415, 1.053, 1.116, 2.2, 0.84, 1.026, 0.859, 2.513, 1.003, 1.738, 1.026, 1.726, 0.921, 1.541, 1.127, 2.716, 0.936, 1.221, 1.142, 2.789, 1.026, 2.057, 0.885, 0.879, 0.828, 11.518, 0.942, 0.802, 3.696, 0.952, 2.107, 1.005, 1.539, 1.383, 0.903, 0.934, 1.29, 5.75, 1.558, 1.621, 1.067, 1.383, 0.938, 1.248, 1.87, 1.83, 1.073, 1.643, 3.047, 0.798, 0.828, 6.256, 1.119, 7.048, 1.268, 2.712, 3.174, 11.47, 8.934, 1.701, 8.305, 2.568, 0.854, 10.131, 3.411, 1.071, 0.768, 1.583, 2.176, 1.778, 67.108, 0.983, 5.22, 0.918, 0.864, 1.634, 2.071, 2.144, 1.087, 3.99, 0.828, 16.592, 1.94, 1.129, 13.626, 1.495, 1.893, 6.005, 0.861, 1.603, 1.417, 1.157, 3.077, 12.399, 1.919, 0.821, 61.201, 1.327, 1.781, 0.922, 1.324, 0.951, 2.283, 22.076, 0.992, 0.863, 1.618, 1.718, 1.88, 1.881, 1.398, 1.114, 4.77, 2.366, 1.17, 1.762, 0.885, 0.892, 7.03, 0.956, 3.101, 1.432, 1.224, 1.712, 2.933, 24.22, 2.204, 0.913, 4.774, 1.297, 1.038, 8.322, 2.915, 0.896, 18.148, 0.943, 0.768, 1.416, 1.734, 1.735, 16.259, 13.667, 2.431, 1.022, 0.772, 2.891, 1.585, 2.033, 1.092, 3.133, 2.118, 0.87, 0.855, 1.402, 0.768, 8.146, 0.886, 1.622, 0.807, 6.011, 3.014, 2.045, 4.279, 0.835, 1.447, 1.581, 2.033, 1.062, 15.052, 0.891, 1.183, 1.3, 0.785, 1.087, 5.029, 0.791, 1.358, 0.83, 2.285, 3.831, 1.015, 1.146, 2.877, 0.867, 0.866, 2.851, 1.225, 2.524, 0.989, 1.087, 0.772, 0.9, 0.943, 1.289, 1.146, 1.324, 4.703, 1.386, 0.684, 6.02, 86.689, 1.146, 2.084, 2.052, 1.542, 3.389, 0.944, 1.135, 1.068, 0.961, 1.43, 1.187, 0.771, 0.835, 0.79, 0.864, 2.579, 1.161, 3.875, 1.378, 0.797, 0.944, 1.33, 1.008, 1.749, 1.331, 9.311, 1.773, 0.748, 0.873, 1.127, 0.895, 1.213, 1.148, 1.11, 1.163, 1.803, 26.115, 1.861, 0.976, 0.772, 1.477, 4.692, 4.781, 1.368, 2.948, 0.907, 7.776, 1.021, 3.048, 1.091, 0.787, 0.892, 1.215, 16.909, 0.994, 0.87, 1.516, 0.908, 0.991, 0.952, 0.975, 2.256, 1.193, 2.224, 2.842, 1.528, 0.956, 3.089, 0.831, 0.93, 0.942, 1.159, 0.95, 1.326, 1.028, 0.986, 0.956, 1.064, 1.335, 0.938, 1.544, 1.1, 1.402, 0.822, 1.55, 0.96, 1.052, 0.899, 0.844, 1.202, 1.372, 0.795, 2.128, 3.093, 1.158, 1.037, 1.951, 1.514, 2.332, 0.821, 0.907, 1.094, 48.283, 0.927, 1.883, 1.249, 2.086, 1.12, 1.098, 2.895, 5.275, 1.036, 3.176, 5.188, 0.911, 1.178, 1.791, 0.973, 1.184, 0.766, 2.103, 6.077, 1.843, 2.26, 0.773, 8.071, 0.819, 1.858, 0.892, 1.285, 1.554, 1.336, 1.3, 2.5, 1.088, 0.932, 4.409, 4.493, 0.995, 1.225, 1.076, 0.901, 0.914, 1.282, 4.337, 1.518, 9.547, 0.934, 5.616, 3.106, 1.546, 3.238, 0.846, 2.398, 1.205, 0.864, 2.456, 4.061, 8.711, 1.095, 2.051, 1.333, 0.858, 0.79, 1.51, 4.568, 0.96, 0.921, 1.039, 1.089, 0.875, 2.887, 0.808, 1.643, 1.082, 0.897, 2.815, 1.539, 1.156, 1.163, 0.897, 1.073, 2.25, 0.783, 1.345, 14.987, 1.643, 1.319, 0.682, 0.818, 0.985, 1.086, 0.911, 0.963, 10.294, 0.893, 1.037, 35.111, 3.367, 10.543, 3.106, 1.675, 1.089, 2.157, 1.539, 1.468, 2.194, 4.905, 1.378, 0.873, 0.948, 0.941, 0.87, 3.802, 4.614, 1.598, 3.661, 1.238, 1.289, 2.449, 1.915, 30.267, 1.913, 1.947, 0.913, 0.854, 0.829, 1.209, 3.888, 1.662, 1.409, 4.19, 0.833, 0.864, 1.566, 2.138, 0.877, 1.282, 177.037, 0.776, 1.143, 1.92, 0.898, 1.002, 0.734, 1.044, 7.092, 0.727, 1.041, 2.12, 0.873, 1.402, 0.834, 1.62, 0.842, 15.558, 0.788, 6.164, 1.082, 0.826, 1.819, 0.788
            ]
        ],
        [
            [
                23.862946271896362, 30.7990300655365, 24.301366329193115, 25.542284965515137, 27.984130382537842, 23.431663990020752, 22.893075466156006, 29.85485816001892, 25.518661975860596, 24.996773719787598, 23.457839012145996, 28.728546619415283, 22.994898319244385, 50.08010268211365, 25.267476081848145, 24.632736206054688, 23.032166004180908, 44.3075635433197, 24.202533721923828, 23.405284881591797, 24.311410188674927, 23.514997005462646, 22.64465355873108, 25.312126874923706, 22.834681749343872, 22.68239116668701, 28.483208417892456, 23.71963381767273, 24.814947843551636, 25.346340894699097, 27.86192488670349, 26.463145971298218, 22.69308614730835, 23.978481769561768, 27.70608639717102, 29.533186197280884, 24.835185289382935, 26.33979606628418, 35.14353609085083, 22.28384518623352, 22.91511034965515, 23.329530000686646, 25.08525323867798, 23.047184228897095, 22.673450469970703, 22.56408190727234, 22.738842964172363, 23.791348457336426, 35.18578052520752, 24.82928967475891, 37.294167280197144, 32.51169013977051, 40.55637860298157, 39.52756977081299, 32.05671548843384, 36.375489234924316, 35.93330430984497, 35.04330897331238, 40.754838705062866, 47.81687545776367, 32.31361937522888, 31.59624743461609, 31.609782695770264, 33.31377196311951, 34.57228112220764, 34.0168719291687, 34.1444890499115, 35.1076078414917, 34.713855504989624, 41.472519636154175, 35.88356852531433, 32.1732656955719, 34.3069543838501, 54.009806871414185, 33.33446478843689, 33.50578308105469, 40.768413066864014, 33.292657136917114, 35.1845281124115, 31.157554626464844, 37.85427141189575, 34.48784947395325, 33.4354190826416, 37.04149556159973, 32.98159742355347, 33.16789197921753, 34.14666938781738, 35.053372383117676, 34.30133557319641, 32.024219036102295, 32.247986793518066, 34.351542949676514, 32.14928603172302, 32.33004283905029, 31.692441701889038, 32.750556230545044, 36.06045699119568, 64.16481137275696, 37.0131471157074, 32.86116051673889, 37.576698541641235, 39.8771698474884, 35.40591025352478, 31.86147117614746, 46.63010025024414, 35.60547423362732, 33.56269717216492, 35.17051339149475, 36.23742413520813, 35.90438508987427, 34.45388388633728, 36.21600389480591, 41.838489294052124, 41.03752541542053, 38.1607871055603, 32.79284310340881, 59.62733268737793, 34.5425968170166, 47.54077196121216, 37.08656716346741, 38.35076928138733, 46.302733182907104, 38.30243158340454, 40.69901251792908, 34.63638353347778, 33.38327240943909, 36.28101968765259, 34.78365111351013, 35.65814232826233, 33.83468747138977, 33.929534912109375, 39.31910705566406, 33.97871971130371, 34.802770376205444, 44.14143371582031, 32.42486214637756, 36.06774163246155, 33.119389295578, 34.06433296203613, 34.573089361190796, 41.84554600715637, 33.46652102470398, 35.05968260765076, 37.29571223258972, 35.378403186798096, 34.32404160499573, 45.019076108932495, 41.49309253692627, 43.843703269958496, 34.46031999588013, 37.81638741493225, 41.85065793991089, 39.62910747528076, 38.53528428077698, 49.347901821136475, 45.762661933898926, 40.37091660499573, 50.40963625907898, 40.12741279602051, 42.42104434967041, 39.49160408973694, 40.44241809844971, 39.99658679962158, 36.37964653968811, 38.91546058654785, 37.08204483985901, 36.50967574119568, 40.46634101867676, 80.38724112510681, 55.68762159347534, 52.556875705718994, 42.44523906707764, 39.55934190750122, 39.40042686462402, 38.005422830581665, 40.146265745162964, 41.77787899971008, 37.93854594230652, 36.76822090148926, 39.59665584564209, 42.46231198310852, 38.82187747955322, 37.788347482681274, 41.86937952041626, 45.43691062927246, 52.95456624031067, 35.95640587806702, 39.66444206237793, 39.07843542098999, 37.33102035522461, 37.39865779876709, 38.24940037727356, 37.22823619842529, 35.716129779815674, 42.620864391326904, 42.73165535926819, 40.640623331069946, 40.5337028503418, 41.32518219947815, 38.66775059700012, 40.61131310462952, 38.80021142959595, 48.77559804916382, 41.41272330284119, 37.516419410705566, 44.541401386260986, 43.72827076911926, 74.85999178886414, 44.72622609138489, 38.11971974372864, 39.96331429481506, 35.6227765083313, 45.6926383972168, 48.18630361557007, 41.046239614486694, 50.339635133743286, 35.90110945701599, 36.20644474029541, 38.89244318008423, 37.050092458724976, 38.90113067626953, 39.25314164161682, 37.05678582191467, 40.4855751991272, 38.603503465652466, 47.978819608688354, 37.020450830459595, 40.10516905784607, 37.480080127716064, 36.65995645523071, 39.75048494338989, 39.46464824676514, 41.11017084121704, 36.838701009750366, 39.913837909698486, 44.563133239746094, 41.55189538002014, 39.04584050178528, 44.464032888412476, 38.2830810546875, 40.919710636138916, 47.816866874694824, 59.871877670288086, 42.221020460128784, 41.84485459327698, 40.045613288879395, 49.93052077293396, 38.68062925338745, 44.25516104698181, 43.07658553123474, 39.81653165817261, 38.1936469078064, 45.26575183868408, 44.04028391838074, 40.279664754867554, 43.26986837387085, 42.08379912376404, 41.05108428001404, 41.92124319076538, 40.725194454193115, 79.28293967247009, 56.69285225868225, 50.33417367935181, 39.64163541793823, 39.05928325653076, 40.4090735912323, 40.27926254272461, 50.57999277114868, 42.88844108581543, 40.62595224380493, 41.42918062210083, 38.06179881095886, 37.26045513153076, 50.83488917350769, 38.48643112182617, 71.46325755119324, 39.73041653633118, 38.321229696273804, 37.56338381767273, 38.15364956855774, 37.810303926467896, 39.374382972717285, 41.47488784790039, 41.648112297058105, 39.183690547943115, 39.16878151893616, 39.77094578742981, 45.34759736061096, 39.06883788108826, 38.504727602005005, 40.123522996902466, 39.86039471626282, 42.108460664749146, 45.96034216880798, 38.81138730049133, 37.64426326751709, 39.38715434074402, 38.790926456451416, 39.62992334365845, 42.600520610809326, 42.5757200717926, 45.77119493484497, 41.58747911453247, 38.60188102722168, 44.10331749916077, 39.201401233673096, 36.63715481758118, 40.54272270202637, 39.34202456474304, 42.406524896621704, 36.26472735404968, 44.829673290252686, 40.82392120361328, 69.45270729064941, 46.88128662109375, 42.78732395172119, 39.99082374572754, 42.20521140098572, 51.35108494758606, 41.04720067977905, 40.918052434921265, 47.78567957878113, 39.557669162750244, 40.00004267692566, 38.1369469165802, 40.00075030326843, 39.17612075805664, 40.911051988601685, 42.99233865737915, 36.53089737892151, 39.704243183135986, 36.024479389190674, 36.111321210861206, 36.63054633140564, 35.87693524360657, 37.874481201171875, 36.357330560684204, 54.55869698524475, 36.76216387748718, 40.57133388519287, 37.7189085483551, 37.68843483924866, 35.948134422302246, 42.30012011528015, 38.18482756614685, 36.07951593399048, 40.12131857872009, 44.01799726486206, 35.86827278137207, 34.33327031135559, 37.379931926727295, 35.9565863609314, 37.61504125595093, 37.75921106338501, 36.21709680557251, 36.693859338760376, 41.069090604782104, 47.4222354888916, 36.23521184921265, 35.96325135231018, 37.784141302108765, 41.00453281402588, 42.054232358932495, 37.79204058647156, 35.98149847984314, 48.59209609031677, 35.84430122375488, 39.35262632369995, 36.42713165283203, 37.09897184371948, 35.997884035110474, 39.74595093727112, 37.05031418800354, 37.220622062683105, 36.11685490608215, 36.3332097530365, 35.434372663497925, 36.591941118240356, 42.026543378829956, 38.76964068412781, 34.893784284591675, 40.51499104499817, 36.154435873031616, 36.53537154197693, 36.0319242477417, 35.81165409088135, 35.59110879898071, 35.28966665267944, 35.37918162345886, 36.68376398086548, 36.27958822250366, 35.51093125343323, 36.772990465164185, 36.29247212409973, 37.08362364768982, 59.172873735427856, 35.827096939086914, 66.54130172729492, 36.064666986465454, 35.24344182014465, 39.6875581741333, 37.613404989242554, 37.17860269546509, 44.19266057014465, 36.898476362228394, 35.871405839920044, 36.96990656852722, 35.575483083724976, 36.067750692367554, 37.107842683792114, 54.99503564834595, 38.45213747024536, 40.5733642578125, 40.02077269554138, 41.002214431762695, 35.52927923202515, 39.24444222450256, 41.425307512283325, 35.90488314628601, 35.511884450912476, 36.912601947784424, 36.19702672958374, 35.14773678779602, 52.11279487609863, 36.291619300842285, 35.46130084991455, 35.67399477958679, 40.90824317932129, 37.91406512260437, 36.437867164611816, 35.31458854675293, 35.31917357444763, 34.934049129486084, 35.734519720077515, 50.321969509124756, 36.14918875694275, 36.556830644607544, 35.35565996170044, 37.65563678741455, 35.93724083900452, 35.951337575912476, 35.7068076133728, 36.89529895782471, 39.91712808609009, 35.595908641815186, 39.748265504837036, 35.112523317337036, 64.76955008506775, 37.33895993232727, 36.57025694847107, 52.97779035568237, 39.536399364471436, 40.0098819732666, 41.106064558029175, 43.45064926147461, 70.05551552772522, 38.48444437980652, 41.51700758934021, 41.22993874549866, 42.35874938964844, 38.587899923324585, 48.534122943878174, 50.016427516937256, 40.338322162628174, 38.44627070426941, 37.300880670547485, 40.51941180229187, 43.21596336364746, 42.896676540374756, 48.03751254081726, 45.51711845397949, 39.81838822364807, 45.98504567146301, 47.11103796958923, 41.921133279800415, 48.82821321487427, 51.09404110908508, 44.65169048309326, 43.93498182296753, 41.47694110870361, 42.05411911010742, 40.73821210861206, 47.19403839111328, 45.231693983078, 42.94553780555725, 50.293301820755005, 37.954198360443115, 38.68360710144043, 76.88904047012329, 47.37669801712036, 41.49000334739685, 40.176732778549194, 48.99130415916443, 42.35980463027954, 45.127326250076294, 39.37606954574585, 42.2625949382782, 44.960017681121826, 42.16968584060669, 44.16123390197754
            ], 
            [
                2.7872040271759033, 15.800300598144531, 1.284843921661377, 3.2540321350097656, 5.016008615493774, 4.26910662651062, 5.442137241363525, 2.4065191745758057, 6.300374269485474, 4.273487567901611, 1.5457496643066406, 8.218016862869263, 2.706376314163208, 46.87290811538696, 3.010010004043579, 2.973808765411377, 4.752626895904541, 16.039520502090454, 3.908277750015259, 3.631359100341797, 1.4632091522216797, 1.965771198272705, 4.353687524795532, 3.4911649227142334, 1.4993088245391846, 1.6929740905761719, 7.256209135055542, 3.290015459060669, 2.9769790172576904, 2.5078630447387695, 7.259922742843628, 4.86191201210022, 1.7709407806396484, 1.1612753868103027, 3.807645082473755, 18.73636293411255, 4.367789030075073, 5.205475807189941, 19.73141598701477, 2.2054688930511475, 2.7819697856903076, 7.021178483963013, 5.738959074020386, 2.8054652214050293, 2.1809675693511963, 2.264055013656616, 2.4269142150878906, 3.9259767532348633, 9.268017768859863, 4.813937187194824, 5.356064319610596, 5.487310171127319, 11.038915634155273, 16.227962493896484, 7.072364807128906, 5.913538455963135, 6.522790193557739, 7.434288263320923, 8.872437477111816, 22.84849500656128, 5.261608362197876, 5.623321056365967, 5.457757234573364, 5.019423246383667, 5.097195148468018, 8.969316244125366, 8.075692653656006, 7.168487071990967, 6.818915605545044, 15.617415189743042, 6.619070768356323, 5.77453088760376, 7.536638975143433, 26.308273315429688, 7.1695966720581055, 4.946711778640747, 18.702266454696655, 6.207108497619629, 7.598921060562134, 7.341291427612305, 6.742066144943237, 5.227875709533691, 5.1617631912231445, 10.270657539367676, 6.1311564445495605, 7.453240394592285, 9.650830507278442, 13.588743686676025, 8.961865663528442, 6.2146501541137695, 8.277624130249023, 7.163980007171631, 8.797548294067383, 5.354104042053223, 7.935770750045776, 5.74568247795105, 9.401127576828003, 55.365405797958374, 9.361951351165771, 7.273106813430786, 12.473801851272583, 7.097989797592163, 7.259051322937012, 6.6938111782073975, 20.49481177330017, 7.677272319793701, 7.3625102043151855, 7.314953804016113, 10.805891513824463, 9.378887176513672, 8.75676965713501, 8.361952543258667, 15.214218854904175, 5.726608514785767, 8.090764045715332, 6.9559855461120605, 58.56220602989197, 6.581547975540161, 24.773905038833618, 9.363873720169067, 6.231086730957031, 19.4734525680542, 6.175205230712891, 7.85578727722168, 7.030133962631226, 10.038804531097412, 5.615889310836792, 7.11832594871521, 5.677088022232056, 8.404870986938477, 9.272305727005005, 8.89219331741333, 6.360583305358887, 6.265669822692871, 11.994182825088501, 6.96646523475647, 7.685252904891968, 5.77489447593689, 6.38207483291626, 5.589222431182861, 24.99481177330017, 5.852137088775635, 6.420552730560303, 5.812180519104004, 7.269979476928711, 6.616016864776611, 9.664069890975952, 8.88078260421753, 11.166613340377808, 6.42404580116272, 7.9025046825408936, 6.9555089473724365, 10.059636354446411, 6.905311346054077, 11.66657304763794, 10.214637279510498, 6.612021207809448, 19.611892223358154, 8.067169904708862, 7.967177867889404, 6.0519115924835205, 9.367466926574707, 10.202452182769775, 7.2488157749176025, 7.619283437728882, 8.759608268737793, 6.190096378326416, 8.641040563583374, 61.53855347633362, 27.528093576431274, 24.6679630279541, 6.548511743545532, 6.643623352050781, 9.60161805152893, 7.788132190704346, 10.122241973876953, 14.847466945648193, 6.991470813751221, 8.019025087356567, 9.386174440383911, 8.431142330169678, 8.028527736663818, 9.50048565864563, 6.692370414733887, 17.94740104675293, 12.570030212402344, 8.526314973831177, 7.179994106292725, 7.5351643562316895, 12.052948713302612, 10.682772636413574, 6.278467178344727, 7.828660249710083, 6.809031963348389, 9.110144138336182, 9.275079011917114, 9.329355955123901, 25.91415786743164, 12.382124423980713, 10.55430793762207, 14.163130760192871, 10.460542678833008, 8.88739800453186, 8.559729099273682, 7.505049467086792, 7.416378021240234, 9.39358401298523, 54.97364926338196, 12.445644617080688, 13.617714881896973, 9.340680837631226, 9.17494797706604, 10.297624588012695, 13.80643892288208, 8.4376220703125, 19.96547794342041, 10.329867839813232, 9.932750701904297, 12.420445680618286, 8.415180444717407, 10.678675889968872, 11.170069217681885, 9.314943075180054, 10.300842046737671, 8.92995309829712, 16.627362489700317, 10.018916845321655, 9.607081651687622, 8.964066982269287, 8.692383050918579, 9.40961503982544, 9.157273292541504, 8.753098249435425, 8.844010353088379, 9.618122339248657, 16.169782161712646, 8.358988046646118, 10.506736755371094, 14.892292499542236, 10.518418312072754, 20.69743585586548, 11.398000478744507, 38.11605763435364, 11.189716100692749, 9.77894926071167, 8.513421773910522, 25.002627849578857, 10.667205333709717, 11.524987936019897, 12.795465230941772, 7.908667802810669, 7.693008661270142, 10.481608867645264, 10.531494617462158, 9.740636825561523, 8.407383441925049, 12.456529140472412, 9.088006019592285, 7.821491718292236, 9.09200119972229, 68.93246531486511, 18.907657384872437, 10.564233303070068, 8.452560424804688, 11.989159107208252, 8.97982144355774, 9.95098876953125, 16.968432903289795, 7.667470455169678, 8.17313814163208, 10.313380241394043, 11.534518957138062, 8.362841606140137, 19.936415910720825, 7.987259387969971, 28.27707290649414, 8.945728063583374, 10.092284202575684, 10.69999647140503, 9.700555562973022, 10.613667011260986, 10.49491810798645, 8.901931285858154, 13.177326440811157, 8.33866834640503, 8.0883309841156, 9.268739223480225, 13.677557706832886, 11.10155200958252, 8.24652624130249, 9.145711421966553, 10.321411371231079, 14.290571212768555, 26.39925241470337, 7.5154712200164795, 7.361113548278809, 9.284100532531738, 8.896806001663208, 9.561472177505493, 12.407723426818848, 13.095289707183838, 9.675944328308105, 12.693500757217407, 26.033682346343994, 20.674970388412476, 11.60673189163208, 9.134203910827637, 9.838463544845581, 8.829469919204712, 9.05850863456726, 8.443377494812012, 11.456309080123901, 8.691113948822021, 62.55235576629639, 12.701318979263306, 10.142722845077515, 10.51713252067566, 9.831236600875854, 29.85143256187439, 10.591402053833008, 10.179436445236206, 17.274953365325928, 8.457474708557129, 11.103149175643921, 9.703816413879395, 8.835359811782837, 9.138234376907349, 11.908400774002075, 14.518547296524048, 9.077911138534546, 12.195212364196777, 9.097935914993286, 8.773358345031738, 8.809360027313232, 10.127000570297241, 10.687673568725586, 9.744023561477661, 26.407230377197266, 9.822823286056519, 11.296832084655762, 12.4618661403656, 12.110062599182129, 8.852510213851929, 9.426974058151245, 11.63927149772644, 11.385810136795044, 12.020994663238525, 17.807837963104248, 9.069199323654175, 8.398861646652222, 10.782524347305298, 7.882589340209961, 10.620410919189453, 10.90592908859253, 8.068022012710571, 8.580830335617065, 15.056959867477417, 16.66582226753235, 7.877162933349609, 8.247812986373901, 11.502708673477173, 11.765680074691772, 12.435457706451416, 10.592462301254272, 8.602597951889038, 28.272544622421265, 7.694950342178345, 25.759725332260132, 9.60042428970337, 11.324740409851074, 7.349595546722412, 12.240792512893677, 10.23036503791809, 9.811667203903198, 8.65312933921814, 9.166266679763794, 8.735358953475952, 10.431888341903687, 19.426403045654297, 13.680713653564453, 8.1861572265625, 15.339750289916992, 10.255956172943115, 13.32058048248291, 10.808983087539673, 8.357564926147461, 9.360882997512817, 8.149746417999268, 8.823559999465942, 9.353377103805542, 9.151632308959961, 8.800946712493896, 11.191481351852417, 12.085230588912964, 11.708945035934448, 26.192200660705566, 9.763234853744507, 60.81842350959778, 8.819971323013306, 8.331140995025635, 11.377465009689331, 8.287003755569458, 7.8892982006073, 24.758285999298096, 7.811326742172241, 8.223251819610596, 10.03637170791626, 8.583756685256958, 8.772090673446655, 12.91278886795044, 29.392630577087402, 14.15076231956482, 12.120863199234009, 25.864259481430054, 12.204066038131714, 8.995794534683228, 14.648276805877686, 15.532207012176514, 8.667890071868896, 10.095449447631836, 10.11582064628601, 8.899303436279297, 8.33240795135498, 24.336463689804077, 8.32295298576355, 8.346362829208374, 10.149672508239746, 12.640776872634888, 10.138206005096436, 10.574833869934082, 8.378724575042725, 7.659316301345825, 7.655773401260376, 8.219346523284912, 17.505976915359497, 8.541400671005249, 8.56034779548645, 8.845220565795898, 10.429221630096436, 9.558796882629395, 8.878038167953491, 8.172994375228882, 10.073582887649536, 15.217286586761475, 8.711456060409546, 13.509712219238281, 8.506735801696777, 57.24136829376221, 9.969032526016235, 11.067289352416992
            ]
        ],
        [
            [
                25.207051038742065, 24.574217796325684, 32.4137704372406, 27.183587551116943, 26.296830892562866, 33.18926429748535, 50.049052000045776, 23.22880482673645, 50.67813205718994, 25.240496158599854, 22.06694459915161, 23.603550910949707, 22.276513814926147, 26.88699722290039, 24.944106817245483, 27.12836241722107, 23.048121213912964, 35.08718681335449, 25.328524112701416, 38.14595651626587, 28.798360347747803, 28.459205389022827, 25.66170310974121, 25.163278102874756, 35.35996699333191, 30.302454233169556, 38.38913106918335, 35.86524271965027, 33.92698359489441, 56.502094745635986, 35.9953408241272, 31.586758852005005, 32.044535636901855, 36.30647134780884, 44.55317687988281, 33.00610136985779, 48.81016445159912, 30.439818620681763, 44.26070713996887, 31.575613260269165, 30.657012224197388, 32.068469762802124, 32.666956186294556, 33.60447859764099, 32.84339118003845, 33.41358494758606, 35.24018383026123, 33.95024609565735, 87.9792788028717, 34.73915481567383, 39.62886333465576, 33.36778116226196, 49.75366163253784, 32.416346073150635, 37.631751537323, 34.85916757583618, 39.20647716522217, 34.224955797195435, 81.76329398155212, 53.2660653591156, 39.97438406944275, 33.311779737472534, 38.37971019744873, 32.878493547439575, 30.5129611492157, 32.47025465965271, 31.20580005645752, 30.80095410346985, 29.887266159057617, 29.03621482849121, 39.56156516075134, 30.771332502365112, 32.94774293899536, 31.98406982421875, 36.37174439430237, 33.185497999191284, 35.19802165031433, 41.9675087928772, 48.86206889152527, 38.990456104278564, 38.00146222114563, 37.60164952278137, 38.946746826171875, 35.69969964027405, 90.97019338607788, 52.24198603630066, 32.71003222465515, 32.89333939552307, 37.62391424179077, 33.30660438537598, 33.77849555015564, 32.57943296432495, 39.4018874168396, 32.21380305290222, 34.13894057273865, 36.94279170036316, 32.31002855300903, 32.26892352104187, 50.24871206283569, 34.489418029785156, 37.551716566085815, 37.75195860862732, 32.464449882507324, 80.55302286148071, 36.96609663963318, 32.122819900512695, 37.13082718849182, 42.86584734916687, 36.68855619430542, 32.98190474510193, 37.51912784576416, 36.10377359390259, 38.53918647766113, 37.71945667266846, 37.68446969985962, 35.803539514541626, 32.26139044761658, 38.45881104469299, 33.1401629447937, 36.72176480293274, 51.153709411621094, 71.43371295928955, 42.660295724868774, 38.71170234680176, 43.961735248565674, 34.705260276794434, 34.501914739608765, 39.344664335250854, 38.57242298126221, 35.93117427825928, 96.32978630065918, 43.76835107803345, 39.161542892456055, 43.5345196723938, 34.739038944244385, 35.382511377334595, 49.50643014907837, 67.24802732467651, 37.648881912231445, 36.623857736587524, 38.369872093200684, 36.49886417388916, 36.0240318775177, 39.92702007293701, 36.20799994468689, 42.95094966888428, 60.45094966888428, 36.3453426361084, 39.16606044769287, 47.66511106491089, 40.53795313835144, 55.21732759475708, 51.540777921676636, 40.36256504058838, 40.81959557533264, 37.5981171131134, 100.20028305053711, 46.510331869125366, 38.802361249923706, 61.38677668571472, 47.54647135734558, 35.62098288536072, 37.27913022041321, 38.54328632354736, 40.41576671600342, 45.794084787368774, 38.40926957130432, 43.0876624584198, 57.39204382896423, 36.31207847595215, 40.18557620048523, 36.79188394546509, 39.87518811225891, 52.99739170074463, 35.50762462615967, 40.53597164154053, 38.16510796546936, 38.171353578567505, 54.97357773780823, 38.60466814041138, 45.88773822784424, 42.80483889579773, 55.05280303955078, 51.11714553833008, 43.65885829925537, 43.24805021286011, 37.60257935523987, 35.39673924446106, 36.61992430686951, 44.70255899429321, 36.48890423774719, 39.450382232666016, 39.45343255996704, 37.73447871208191, 44.102678060531616, 41.27226233482361, 44.800737142562866, 68.80612683296204, 100.00265645980835, 38.85524940490723, 40.33230972290039, 46.710790395736694, 37.1269896030426, 38.50861310958862, 41.03024077415466, 54.049142837524414, 55.01696968078613, 40.695645332336426, 45.67106652259827, 40.02653408050537, 38.19880819320679, 57.70615911483765, 36.25119876861572, 39.70625352859497, 40.58733034133911, 37.065300941467285, 34.621318101882935, 44.93997764587402, 37.16103720664978, 37.4517080783844, 34.14437246322632, 38.93305826187134, 38.240190744400024, 68.69159626960754, 36.51283836364746, 48.39744472503662, 39.90062379837036, 63.00156855583191, 39.91847848892212, 43.596007108688354, 40.90021824836731, 41.20374035835266, 40.19091200828552, 41.660669565200806, 37.68167567253113, 36.64081382751465, 53.204545736312866, 42.72097611427307, 39.130455493927, 38.003270387649536, 41.91914200782776, 40.050267934799194, 40.812044858932495, 37.096070528030396, 86.99819231033325, 41.93724775314331, 44.900087118148804, 38.28505206108093, 32.79469847679138, 36.05603504180908    
            ], 
            [
                11.334348678588867, 4.591786623001099, 8.439602136611938, 8.267780065536499, 7.239955186843872, 16.643499851226807, 51.94535684585571, 5.746086359024048, 28.75322675704956, 5.415099143981934, 3.265625, 7.261232376098633, 2.6036367416381836, 8.87998652458191, 4.315459251403809, 11.31937313079834, 2.3053152561187744, 22.285322189331055, 6.528558254241943, 21.08901333808899, 7.11377215385437, 6.485750198364258, 3.161299705505371, 6.589221715927124, 16.90159797668457, 4.904514789581299, 16.97739815711975, 7.028575658798218, 7.875492811203003, 39.59187412261963, 5.049444913864136, 5.499231338500977, 8.325701475143433, 8.448086738586426, 23.236350297927856, 7.872629165649414, 27.373209714889526, 8.16669487953186, 16.862242698669434, 7.773464202880859, 6.01701545715332, 11.772311687469482, 7.285121440887451, 13.221669912338257, 8.907418012619019, 8.51314902305603, 8.737322092056274, 6.2128355503082275, 59.99834394454956, 10.159213066101074, 13.301443338394165, 7.383883714675903, 27.673431396484375, 9.003476858139038, 10.567494869232178, 11.34244990348816, 20.01370644569397, 7.534821271896362, 55.583029985427856, 31.355218410491943, 14.60926103591919, 9.296822309494019, 12.174699306488037, 6.447011470794678, 7.909861087799072, 10.445245742797852, 6.031641483306885, 11.120338916778564, 6.999901533126831, 5.347339630126953, 23.342251539230347, 6.373766899108887, 8.4519784450531, 9.27095890045166, 10.403768301010132, 9.084519863128662, 10.926994800567627, 15.098792314529419, 19.03404450416565, 10.129159450531006, 10.192244529724121, 10.158011674880981, 9.400514364242554, 7.524259567260742, 72.32678151130676, 31.9096999168396, 11.343585968017578, 8.927443265914917, 13.303902626037598, 9.446402549743652, 9.755685091018677, 8.40612006187439, 15.468838691711426, 6.826360464096069, 9.509507894515991, 8.051157236099243, 6.3376147747039795, 7.708012342453003, 23.64605975151062, 12.979315280914307, 15.180866479873657, 7.5789690017700195, 6.786124229431152, 58.86588406562805, 14.504165649414062, 7.358796834945679, 16.947286367416382, 26.14308738708496, 10.624040842056274, 10.082003593444824, 12.239174365997314, 7.997041940689087, 20.006973028182983, 8.222303628921509, 6.131886959075928, 6.515095949172974, 6.446677923202515, 12.776119470596313, 9.722250699996948, 11.811519384384155, 25.73366355895996, 42.502411127090454, 7.676915884017944, 17.897844314575195, 11.287706136703491, 6.644057273864746, 10.895353555679321, 7.019219636917114, 9.862196683883667, 7.582683801651001, 65.08225560188293, 12.988541603088379, 10.291189193725586, 16.297202110290527, 6.210885286331177, 12.720810651779175, 28.198437213897705, 53.521888256073, 9.100870609283447, 10.37922215461731, 10.743295669555664, 9.342824935913086, 6.853562116622925, 13.0729501247406, 9.76939082145691, 8.64943552017212, 29.043098211288452, 5.738906383514404, 9.826453924179077, 13.138309478759766, 10.134976863861084, 28.424336671829224, 22.373056173324585, 7.235867023468018, 7.063569784164429, 7.898686170578003, 61.23226189613342, 10.615869283676147, 9.061485767364502, 22.036795139312744, 15.942819118499756, 8.454258918762207, 7.020089626312256, 9.302395343780518, 10.303946256637573, 10.87062692642212, 6.953409194946289, 14.094254493713379, 43.382174491882324, 10.487557888031006, 12.340535402297974, 6.899552583694458, 11.142493724822998, 22.60677719116211, 6.263460397720337, 8.559257984161377, 10.820104837417603, 6.056280851364136, 19.962157487869263, 5.700475215911865, 14.416521072387695, 12.627400398254395, 26.879698276519775, 22.97770094871521, 10.418060779571533, 12.274236679077148, 9.077362060546875, 7.468851566314697, 8.452296733856201, 19.318939924240112, 13.109134912490845, 14.190926313400269, 8.341471433639526, 7.548062801361084, 8.633474111557007, 7.6862781047821045, 11.423407554626465, 47.11159324645996, 58.15373229980469, 6.404388904571533, 10.36298131942749, 15.560895204544067, 6.547184467315674, 10.15326476097107, 12.283713102340698, 25.68826961517334, 27.31478261947632, 12.872642517089844, 19.774974584579468, 9.205442428588867, 10.19956088066101, 44.69663190841675, 6.938682317733765, 12.4861741065979, 11.064493894577026, 6.623051643371582, 6.645534992218018, 22.829020261764526, 9.451080560684204, 10.224155187606812, 7.2686402797698975, 15.947748184204102, 13.315407991409302, 59.64514899253845, 10.479670286178589, 18.098912239074707, 14.342108011245728, 44.20207452774048, 12.381368160247803, 9.699328184127808, 11.006981372833252, 8.706898212432861, 8.150314569473267, 10.96418571472168, 7.779712438583374, 7.164753437042236, 32.048396587371826, 13.882973432540894, 12.088776111602783, 17.460346460342407, 11.566569805145264, 11.047352313995361, 15.741015434265137, 8.384984731674194, 67.00772595405579, 9.779146909713745, 18.31934380531311, 8.340262174606323, 7.314850091934204, 9.887817621231079
            ]
        ],
        [
            [
                31.4191677570343, 34.49119520187378, 89.20061039924622, 67.44131183624268, 29.560575485229492, 34.722273111343384, 39.59079837799072, 67.0152337551117, 33.676289796829224, 36.19112467765808, 47.43813443183899, 62.13406229019165, 30.608863353729248, 48.236703872680664, 52.32469391822815, 39.472012758255005, 33.52349042892456, 41.157286643981934, 39.179359674453735, 95.67892122268677, 62.332157135009766, 45.758604526519775, 48.97995114326477, 114.69269704818726, 41.210031032562256, 40.945621490478516, 40.7727210521698, 35.1378972530365, 47.77943420410156, 42.9141891002655, 42.56072521209717, 51.68684959411621, 40.48690938949585, 101.76394891738892, 62.2087025642395, 43.4481987953186, 42.11308264732361, 38.38906669616699, 39.92873930931091, 54.03192472457886, 43.93646788597107, 96.78759264945984, 43.04912495613098, 52.55944299697876, 39.76412630081177, 42.6681444644928, 34.02907633781433, 44.28823637962341, 81.43250155448914, 48.02492070198059, 37.89735174179077, 38.785266637802124, 91.24327158927917, 41.130269289016724, 57.74492573738098, 77.65861177444458, 42.36680221557617, 46.47032570838928, 64.59305000305176, 44.54435205459595, 72.73686671257019, 40.623329401016235, 101.52831506729126, 62.61963152885437, 47.23558449745178, 43.138017892837524, 46.707162857055664, 62.3380126953125, 51.85061740875244, 52.48104381561279, 43.07793998718262, 50.273510217666626, 49.14750838279724, 76.36153984069824, 44.98457908630371, 58.62951397895813, 56.513559103012085, 37.7323362827301, 57.08613610267639, 120.95540285110474, 54.08425307273865, 47.44432806968689, 74.59058117866516, 48.82610368728638, 64.38020634651184, 46.70224475860596, 40.54114842414856, 43.94932436943054, 50.314358949661255, 103.00658965110779, 56.12256383895874, 79.12535905838013, 46.52785539627075, 41.29576373100281, 54.37147831916809, 55.91456174850464, 44.59359121322632, 106.26053810119629, 50.40744209289551, 38.48783254623413
            ], 
            [
                22.46599507331848, 19.30089044570923, 67.17018556594849, 36.45310187339783, 11.861125946044922, 16.858728885650635, 18.010891675949097, 42.14241170883179, 17.11984157562256, 22.101218938827515, 31.070271492004395, 44.6781804561615, 10.964457988739014, 34.04074287414551, 45.28269052505493, 27.76472759246826, 15.25009822845459, 26.303799152374268, 21.441004991531372, 72.58698058128357, 44.701926469802856, 22.47047472000122, 32.03324556350708, 80.18012738227844, 25.704179525375366, 16.64448118209839, 19.07066249847412, 12.207347631454468, 27.90603280067444, 23.01442265510559, 26.707675457000732, 33.170003175735474, 20.608627796173096, 78.48861050605774, 33.62437987327576, 29.097170114517212, 27.508022785186768, 18.68793821334839, 13.833526611328125, 29.763103723526, 19.912888288497925, 74.94247770309448, 21.058967351913452, 36.97854709625244, 16.902229070663452, 22.30584716796875, 10.933146476745605, 23.056434631347656, 65.94916939735413, 28.948521614074707, 15.098624229431152, 15.69193148612976, 63.40551018714905, 20.85634708404541, 39.3236939907074, 51.028351068496704, 17.370928525924683, 19.1835355758667, 35.2007691860199, 21.6902334690094, 45.61749625205994, 13.879681825637817, 64.58537101745605, 38.087239265441895, 22.350175380706787, 18.991403579711914, 15.091122150421143, 33.844204902648926, 19.97867774963379, 26.535516500473022, 17.94166660308838, 31.40678119659424, 25.80987310409546, 45.97395348548889, 18.137024402618408, 29.388452768325806, 29.29957151412964, 12.867475748062134, 21.321383953094482, 79.89085793495178, 27.144339084625244, 18.44440221786499, 54.815518617630005, 27.107099533081055, 32.723698139190674, 20.08006978034973, 28.012041091918945, 18.13746404647827, 22.625337839126587, 71.33094954490662, 33.45592164993286, 57.24632716178894, 16.194644451141357, 15.274087190628052, 23.548569440841675, 31.721155405044556, 18.729593515396118, 83.04227471351624, 27.706246614456177, 14.134928941726685
            ]
        ],
        [
            [
                864.4710772037506, 840.880464553833, 825.8787231445312, 862.133603811264, 849.3996293544769, 863.0376286506653, 832.984689950943, 875.6872737407684, 873.3016402721405, 877.0151133537292
            ], 
            [
                838.684921503067, 803.5814905166626, 844.4484376907349, 832.2193918228149, 808.5235304832458, 764.1749932765961, 765.2360281944275, 764.4209582805634
            ]
        ]
    ]

    preprocessing_times = [
        [[5.218836/1000, 5.218836/1000], [7e-06, 7e-06]],  # No preprocessing time for the first six categories
        [[5.218836/1000, 5.218836/1000], [7e-06, 7e-06]]
    ]

    labels = ["(Filter=25)", "(No Filter)"]
    xs_label = ["3", "6", "60\n(Decomposed Structured Model)", "120", "300", "3000\n(DeltaSherlock)", "3\n(Praxi)", "3000\n(Praxi)"]

    # Setup figure and subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    bar_width = 0.3

    # Function to plot bars
    def plot_bars(ax, indices, xs_label_subset):
        bars = []  # List to store bar objects for legend
        for i in indices:
            for j, label in enumerate(labels):
                bar_position = i - bar_width/2 + j*bar_width
                ys = np.mean(ys_d4permodeltrainlatencybylabelspermodel_l[i][j])
                yerr = 1.96 * np.std(ys_d4permodeltrainlatencybylabelspermodel_l[i][j]) / np.sqrt(len(ys_d4permodeltrainlatencybylabelspermodel_l[i][j]))
                if i < 6:
                    additional_time = np.mean(encoder_times[i][j])
                    additional_yerr = 1.96 * np.std(encoder_times[i][j]) / np.sqrt(len(encoder_times[i][j]))
                else:
                    additional_time = np.mean(preprocessing_times[i-6][j])
                    additional_yerr = 1.96 * np.std(preprocessing_times[i-6][j]) / np.sqrt(len(preprocessing_times[i-6][j]))

                training_bar = ax.bar(bar_position, ys, bar_width, color='blue' if j == 0 else 'green', label="Training "+ label if i == indices[0] else "")
                additional_bar = ax.bar(bar_position, additional_time, bar_width, bottom=ys, color='lightblue' if j == 0 else 'lightgreen', label=('Preprocessing ') + label if i == indices[0] else "")
                # Add bar labels for total time
                # if 100000 >= (ys + additional_time)+label_y_offset and (ys + additional_time)+label_y_offset >= 10000:
                if i == 4:
                    label_y_offset = 10 if j == 0 else 5
                    ax.text(bar_position, (ys + additional_time)+label_y_offset, f"{ys + additional_time:.1f}", ha='center', va='bottom', fontsize=16)
                elif i >= 5 and 80000 >= (ys + additional_time):
                    label_y_offset = -1000 if j == 0 else 7000
                    ax.text(bar_position, (ys + additional_time)+label_y_offset, f"{ys + additional_time:.1f}", ha='center', va='bottom', fontsize=16)
                elif i >= 5 and (ys + additional_time) > 80000:
                    label_y_offset = 10000
                    ax.text(bar_position, (ys + additional_time)+label_y_offset, f"{ys + additional_time:.1f}", ha='center', va='bottom', fontsize=16)
                else:
                    ax.bar_label(additional_bar, labels=[f"{ys + additional_time:.1f}"], padding=3, fontsize=16)

                total_error = np.sqrt(yerr**2 + additional_yerr**2)
                ax.errorbar(bar_position, ys + additional_time, yerr=total_error, fmt='o', color='red', capsize=5)

                # Collect bar objects for the legend
                if i == indices[0]:  # Only add once
                    bars.append(training_bar)
                    bars.append(additional_bar)

        ax.grid()

        # Set labels
        ax.set_xticks(indices)
        ax.set_xticklabels(xs_label_subset, fontsize=24)
        ax.tick_params(axis='y', labelsize=22)
        return bars  # Return bars for legend

    # Call the plot function on both subplots
    bars1 = plot_bars(ax1, np.arange(5), xs_label[:5])
    plot_bars(ax2, np.arange(5, 8), xs_label[5:])

    # # Set separate y-axis limits
    # ax1.set_ylim(0, 10)  # Adjust as necessary for your data
    # ax2.set_ylim(0, 4000)  # Adjust as necessary for your data

    ax1.set_ylabel("Time Spent (s)", fontsize=28)

    # # Adjust the overall font size which includes the exponent in scientific notation
    # plt.rcParams['font.size'] = 30  # Adjusts global font size
    # plt.rcParams['text.latex.preamble'] = r'\usepackage{amsmath}'  # Ensure amsmath package is used
    formatter_upper = ScalarFormatter(useMathText=True)
    formatter_upper.set_scientific(True)
    formatter_upper.set_powerlimits((-1,1))  # Use scientific notation
    ax2.yaxis.set_major_formatter(formatter_upper)
    ax2.yaxis.get_offset_text().set_fontsize(20)

    # Create shared legend
    labels = [bar.get_label() for bar in bars1]  # Get labels from the bars (assumes bars1 and bars2 have same labels)
    # fig.legend(bars1, labels, loc='upper left', ncol=1, fontsize=20, bbox_to_anchor=(0.088, 1.03))
    fig.legend(bars1, labels, loc='upper left', ncol=1, fontsize=19, bbox_to_anchor=(0.56, 0.8))
    # # Add structured model X label
    # fig.text(0.5, 0.0, 'Number of Package Labels per Incremental Training Step', ha='center', va='center', fontsize=24)
    # Add common X label
    fig.text(0.5, -0.07, 'Number of Package Labels per Incremental Training Step', ha='center', va='center', fontsize=28)

    fig.tight_layout(rect=[0, -0.06, 1, 1])  # Adjust rect parameter as needed

    # plt.tight_layout()
    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()


    # filename = "testing_per_model_trainlatency_by_labels_per_model_with_rawinput_data_4"
    # from matplotlib.ticker import ScalarFormatter

    # # Data definition
    # # Data from your earlier script setup
    # ys_d4permodeltrainlatencybylabelspermodel_l = [
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             0.123, 0.1, 0.1, 0.1, 0.095, 0.078, 0.15, 0.085, 0.085, 0.077, 0.117, 0.123, 0.072, 0.105, 0.095, 0.075, 0.08, 0.077, 0.128, 0.068, 0.079, 0.094, 0.085, 0.089, 0.095, 0.07, 0.079, 0.682, 0.088, 0.091, 0.084, 0.091, 0.099, 0.122, 0.131, 0.078, 0.071, 0.09, 0.076, 0.114, 0.08, 0.09, 0.084, 0.133, 0.088, 0.094, 0.103, 0.086, 0.091, 0.104, 0.08, 0.087, 0.094, 0.145, 0.092, 0.096, 0.14, 0.086, 0.093, 0.082, 0.095, 0.108, 0.093, 0.115, 0.084, 0.086, 0.08, 0.093, 0.189, 0.072, 0.081, 0.148, 0.093, 0.079, 0.135, 0.07, 0.083, 0.076, 0.08, 0.074, 0.073, 0.074, 0.116, 0.082, 0.078, 0.083, 0.509, 0.078, 0.085, 0.1, 0.085, 0.126, 0.088, 0.072, 0.071, 0.096, 0.117, 0.076, 0.092, 0.096, 0.088, 0.075, 0.088, 0.065, 0.183, 0.091, 0.103, 0.072, 0.066, 0.07, 0.244, 0.096, 0.086, 0.116, 0.088, 0.082, 0.061, 0.069, 0.077, 0.079, 0.087, 0.096, 0.07, 0.069, 0.086, 0.093, 0.082, 0.071, 0.289, 0.067, 0.066, 0.078, 0.071, 0.082, 0.068, 0.085, 0.073, 0.08, 0.076, 0.069, 0.088, 0.088, 0.075, 0.08, 0.069, 0.07, 0.117, 0.082, 0.08, 0.074, 0.084, 0.077, 0.075, 0.086, 0.14, 0.08, 0.141, 0.099, 0.116, 0.094, 0.127, 0.128, 0.085, 0.133, 0.08, 0.259, 0.076, 0.073, 0.098, 0.057, 0.072, 0.159, 0.112, 0.106, 0.075, 0.068, 0.103, 0.075, 0.081, 0.089, 0.075, 0.083, 0.07, 0.084, 0.079, 0.075, 0.115, 0.089, 0.11, 0.07, 0.068, 0.062, 0.074, 0.086, 0.087, 0.078, 0.132, 0.055, 0.074, 0.227, 0.093, 0.092, 0.133, 0.106, 0.09, 0.098, 0.072, 0.091, 0.089, 0.067, 0.072, 0.106, 0.082, 0.093, 0.136, 0.061, 0.094, 0.101, 0.11, 0.079, 0.076, 0.093, 0.131, 0.088, 0.083, 0.154, 0.081, 0.076, 0.164, 0.087, 0.157, 0.084, 0.125, 0.081, 0.067, 0.699, 0.138, 0.093, 0.104, 0.129, 0.084, 0.077, 0.082, 0.088, 0.134, 0.156, 0.085, 0.156, 0.088, 0.079, 0.085, 0.12, 0.134, 0.164, 0.094, 0.081, 0.072, 0.081, 0.096, 0.11, 2.949, 0.095, 0.071, 0.087, 0.118, 0.091, 0.131, 0.074, 0.083, 0.065, 0.093, 0.077, 0.083, 0.077, 0.069, 0.09, 0.076, 0.121, 0.087, 0.105, 0.08, 0.07, 0.075, 0.07, 0.09, 0.083, 0.088, 0.085, 0.079, 0.244, 0.09, 0.084, 0.08, 0.078, 0.074, 0.075, 0.08, 0.134, 0.071, 0.107, 0.065, 0.067, 0.113, 0.072, 0.154, 0.16, 0.088, 0.089, 0.102, 0.078, 0.126, 0.078, 0.14, 0.07, 0.075, 0.096, 0.072, 0.145, 0.074, 0.089, 0.099, 0.126, 0.089, 0.081, 0.075, 0.145, 0.098, 0.095, 0.133, 0.097, 0.081, 0.088, 0.082, 0.084, 0.107, 0.08, 0.086, 0.083, 0.274, 0.092, 0.109, 0.091, 0.119, 0.082, 0.108, 0.084, 0.089, 0.129, 0.072, 0.091, 0.071, 0.068, 0.076, 0.105, 0.075, 0.067, 0.09, 0.074, 0.135, 1.473, 0.091, 0.087, 0.07, 0.096, 0.079, 0.084, 0.149, 0.107, 0.076, 0.08, 0.071, 0.1, 0.126, 0.098, 0.073, 0.182, 0.077, 0.072, 0.065, 0.082, 0.086, 0.092, 0.084, 0.074, 0.121, 0.21, 0.073, 0.11, 0.078, 0.111, 0.067, 0.074, 0.086, 0.083, 0.084, 0.075, 0.08, 0.093, 0.066, 0.082, 0.066, 0.076, 0.08, 0.074, 0.087, 0.109, 0.092, 0.089, 0.104, 0.113, 0.093, 0.089, 0.124, 0.077, 0.083, 0.11, 0.083, 0.096, 0.08, 0.071, 0.148, 0.086, 0.138, 0.078, 0.084, 0.076, 0.072, 0.079, 0.064, 0.069, 0.067, 0.082, 0.086, 0.079, 0.081, 0.097, 0.076, 0.071, 0.085, 0.071, 0.136, 0.068, 0.075, 0.128, 0.104, 0.091, 0.132, 0.083, 0.131, 0.088, 0.072, 0.07, 0.08, 0.064, 0.068, 0.078, 0.072, 0.07, 0.281, 0.141, 0.069, 0.186, 0.069, 0.08, 0.089, 0.108, 0.07, 0.083, 0.149, 0.142, 0.083, 0.093, 0.075, 0.068, 0.087, 0.076, 0.076, 0.112, 0.083, 0.089, 0.094, 0.075, 0.083, 0.084, 0.076, 0.135, 0.07, 0.086, 0.144, 0.09, 0.091, 0.093, 0.089, 0.073, 0.091, 0.089, 0.079, 0.08, 0.087, 0.091, 0.077, 0.08, 0.09, 0.095, 0.086, 0.073, 0.069, 0.108, 0.072, 0.082, 0.081, 0.12, 0.077, 0.081, 0.097, 0.115, 0.069, 0.072, 0.071, 0.096, 0.079, 0.058, 0.09, 0.058, 0.1, 0.072, 0.079, 0.285, 0.089, 0.067, 0.07, 0.084, 0.068, 0.078, 0.083, 0.081, 0.084, 0.084, 0.098, 0.37, 0.068, 0.094, 0.101, 0.068, 0.082, 0.093, 0.085, 0.127, 0.093, 0.084, 0.119, 0.092, 0.075, 0.084, 0.084, 0.082, 0.091, 0.193, 0.117, 0.083, 0.159, 0.104, 0.07, 0.096, 0.066, 0.082, 0.084, 0.081, 0.08, 0.076, 0.089, 0.076, 0.071, 0.116, 0.162, 0.078, 0.103, 0.095, 0.093, 0.121, 0.117, 0.081, 0.08, 0.097, 0.14, 0.095, 0.078, 0.091, 0.099, 0.072, 0.085, 0.111, 0.091, 0.083, 0.164, 0.112, 0.08, 0.088, 0.078, 0.071, 0.379, 0.086, 0.09, 0.085, 0.065, 0.092, 0.093, 0.068, 0.085, 0.129, 0.071, 0.071, 0.078, 0.101, 0.099, 0.142, 0.119, 0.094, 0.09, 0.155, 0.086, 0.058, 0.11, 0.067, 0.063, 0.092, 0.122, 0.077, 0.086, 0.079, 0.109, 0.084, 0.08, 0.111, 0.066, 0.266, 0.077, 0.09, 0.15, 0.087, 0.084, 0.082, 0.097, 0.082, 0.071, 0.074, 0.071, 0.08, 0.059, 0.069, 0.099, 0.112, 0.123, 0.064, 0.059, 0.075, 0.072, 0.134, 0.103, 0.091, 0.093, 0.08, 0.086, 0.078, 0.081, 0.08, 0.079, 0.098, 0.103, 0.091, 0.083, 0.086, 0.114, 0.081, 0.122, 0.08, 0.077, 0.084, 0.088, 0.073, 0.074, 0.078, 0.081, 0.092, 0.15, 0.11, 0.075, 0.084, 0.077, 0.064, 0.07, 0.079, 0.19, 0.087, 0.134, 0.08, 0.19, 0.074, 0.072, 0.103, 0.098, 0.102, 0.167, 0.072, 0.079, 0.088, 0.087, 0.085, 0.15, 0.089, 0.2, 0.096, 0.101, 0.08, 0.083, 0.088, 0.14, 0.089, 1.257, 0.073, 0.067, 0.067, 0.073, 0.076, 0.084, 0.071, 0.122, 0.082, 0.083, 0.081, 0.068, 0.094, 0.091, 0.077, 0.079, 0.189, 0.097, 0.093, 0.135, 0.13, 0.102, 0.074, 0.086, 0.089, 0.09, 0.075, 0.074, 0.085, 0.097, 0.279, 0.151, 0.08, 0.078, 0.069, 0.071, 0.088, 0.093, 0.111, 0.116, 0.083, 0.101, 0.118, 1.188, 0.089, 0.085, 0.083, 0.077, 0.076, 0.132, 0.072, 0.087, 0.084, 0.08, 0.064, 0.084, 0.077, 0.079, 0.088, 0.099, 0.072, 0.072, 0.115, 0.107, 0.103, 0.125, 0.084, 0.063, 0.086, 0.12, 0.101, 0.066, 0.137, 0.078, 0.143, 0.063, 0.098, 0.081, 0.092, 0.103, 0.078, 0.136, 0.082, 0.091, 0.076, 0.091, 0.084, 0.128, 0.08, 0.077, 0.094, 0.07, 0.073, 0.066, 0.144, 0.084, 0.13, 0.085, 0.069, 0.083, 0.116, 0.083, 0.088, 0.137, 0.082, 0.133, 0.091, 0.08, 0.084, 0.084, 0.078, 0.067, 0.101, 0.068, 0.063, 0.066, 0.084, 0.259, 0.105, 0.074, 0.068, 0.206, 0.07, 0.072, 0.175, 0.117, 0.088, 0.085, 0.061, 0.071, 0.062, 0.187, 0.065, 0.117, 0.087, 0.129, 0.076, 0.074, 0.073, 0.089, 0.085, 0.07, 0.081, 0.099, 0.122, 0.072, 0.097, 0.128, 0.091, 0.075, 0.079, 0.074, 0.12, 0.076, 0.09, 0.078, 0.077, 0.085, 0.076, 0.071, 0.117, 0.072, 0.098, 0.099, 0.098, 0.068, 0.079, 0.07, 0.12, 0.103, 0.061, 0.079, 0.074, 0.072, 0.119, 0.099, 0.141, 0.086, 0.082, 0.073, 0.086, 0.076, 0.075, 0.077, 0.071, 0.069, 0.081, 0.076, 0.072, 0.106, 0.077, 0.077, 0.078, 0.128, 0.072, 0.101, 0.102, 0.119, 0.09, 0.133, 0.096, 0.087, 0.08, 0.077, 0.081, 0.118, 0.102, 0.144, 0.099, 0.105, 0.081, 0.081, 0.112, 0.097, 0.132, 0.083, 0.097, 0.089, 0.132, 0.092, 0.079, 0.079, 0.092, 0.07, 0.072, 0.082, 0.069, 0.091, 0.093, 0.078, 0.168, 0.226, 0.075, 0.083, 0.094, 0.089, 0.088, 0.078, 0.094, 0.09, 0.083, 0.087, 0.081, 0.838, 0.082, 0.082, 0.084, 0.08, 0.083, 0.076, 0.072, 0.071, 0.147, 0.085, 0.107, 0.084, 0.089, 0.085, 0.126, 0.102, 0.073, 0.077, 0.078, 0.092, 0.117, 0.104, 0.127, 0.076, 0.328, 0.073, 0.08, 0.081, 0.081, 0.075, 0.07, 0.08, 0.072, 0.075, 0.08, 0.119, 0.083, 0.077, 0.109, 0.08, 0.069, 0.082, 0.102, 0.063, 0.091, 0.09, 0.127, 0.097, 0.093, 0.086, 0.148, 0.136, 0.089, 0.078, 0.102, 0.09, 0.072, 0.073, 0.083, 0.07, 0.094, 0.128, 0.107, 0.08, 0.081, 0.114, 0.097, 0.095, 0.103, 0.076, 0.07, 0.097, 0.112, 0.089, 0.146, 0.095, 0.089, 0.083, 0.075, 0.092, 0.164, 0.075, 0.076, 0.074, 0.066, 0.077, 0.135, 0.074, 0.08, 0.077, 0.299, 0.108, 0.081, 0.368, 0.065, 0.069, 0.08, 0.836, 0.06, 0.302, 0.066, 0.066, 0.073, 0.077, 0.083, 0.084, 0.07, 0.096, 0.074, 0.094, 0.078, 0.148, 0.103, 0.087, 0.085, 0.074, 0.08, 0.181, 0.122, 0.072, 0.074, 0.117, 0.107, 0.137, 0.072, 0.095, 0.102, 0.087, 0.091, 0.088, 0.082, 0.102, 0.069, 0.072, 0.067, 0.09, 0.074, 0.082, 0.138, 0.079, 0.091, 0.088, 0.084, 0.145, 0.095, 0.09, 0.102, 0.091, 0.11, 0.09, 0.09, 0.073, 0.088, 0.102, 0.109, 0.102, 0.142, 0.076, 0.094, 0.087, 0.086, 0.101, 0.068, 0.12, 0.091, 0.069, 0.075, 0.091, 0.087, 0.131, 0.139, 0.126, 0.089, 0.067, 0.077, 0.079, 0.168, 0.139, 0.118, 0.073, 0.124, 0.071, 0.094, 0.081, 0.088, 0.079, 0.107, 0.079, 0.078, 0.065, 0.064, 0.083, 0.075, 0.074, 0.095, 0.081, 0.178, 0.411, 0.067, 0.094, 0.097, 0.087, 0.076, 0.113, 0.083, 0.12, 0.08, 0.087, 0.078, 0.074, 0.148, 0.136, 0.088, 0.095, 0.089, 0.066, 0.134, 0.079, 0.071, 0.096, 0.073, 0.124, 1.486, 0.076, 0.078, 0.131, 0.094, 0.086, 0.156, 0.086, 0.195, 0.08, 0.109, 0.099, 0.136, 0.135, 0.098, 0.081, 0.081, 0.094, 0.114, 0.079, 0.084, 0.081, 0.071, 0.078, 0.124, 0.075, 0.102, 0.078, 0.101, 0.106, 0.074, 0.088, 0.074, 0.084, 0.078, 0.103, 0.099, 0.082, 0.143, 0.083, 0.102, 0.083, 0.078, 0.077, 0.077, 0.088, 0.078, 0.077, 0.139, 0.079, 0.075, 0.077, 0.074, 0.078, 0.115, 0.079, 0.083, 0.149, 0.083, 0.085, 0.105, 0.103, 0.105, 0.141, 0.083, 0.082, 0.112, 0.087, 0.093, 0.077, 0.098, 0.086, 0.089, 0.084, 0.086, 0.09, 0.132, 0.08, 0.099, 0.11, 0.087, 0.061, 0.102, 0.071, 0.077, 0.068, 0.076, 0.068, 0.09, 0.07, 0.09, 0.1, 0.084, 0.085, 0.089, 0.095, 0.092, 0.121, 0.094, 0.088, 0.108, 0.098, 0.126, 0.153, 0.064, 0.078, 0.081, 0.083, 0.089, 0.072, 0.084, 0.089, 0.078, 0.07, 0.111, 0.084, 0.088, 0.074, 0.072, 0.076, 0.077, 0.095, 0.08, 0.08, 0.081, 0.087, 0.286, 0.078, 0.086, 0.112, 0.091, 0.088, 0.084, 0.077, 0.098, 0.084, 0.121, 0.066, 0.137, 0.076, 0.082, 0.076, 0.079, 0.08, 0.297, 0.076, 0.066, 0.087, 0.082, 0.094, 0.077, 0.126, 0.078, 0.07, 0.134, 0.156, 0.072, 0.127, 0.17, 0.1, 0.087, 0.085, 0.077, 0.076, 0.11, 0.072, 0.09, 0.078, 0.112, 0.068, 0.155, 0.092, 0.079, 0.077, 0.084, 0.078, 0.078, 0.093, 0.092, 0.07, 0.096, 0.124, 0.126, 0.171, 0.168, 0.099, 0.075, 0.095, 0.061, 0.078, 0.098, 0.098, 0.088, 0.091, 0.085, 0.077, 0.08, 0.123, 0.082, 0.076, 0.081, 0.092, 0.087, 0.081, 0.066, 0.083, 0.067, 0.066, 1.014, 0.068, 0.073, 0.079, 0.07, 0.073, 0.072, 0.08, 0.076, 0.088, 0.081, 0.084, 0.079, 0.241, 0.102, 0.073, 0.085, 0.072, 0.072, 0.124, 0.126, 0.08, 0.086, 0.072, 0.102, 0.078, 0.086, 0.101, 0.093, 0.095, 0.118, 0.101, 0.093, 0.08, 0.132, 0.069, 0.125, 0.107, 0.087, 0.137, 0.085, 0.08, 0.109, 0.066, 0.097, 0.111, 0.08, 0.087, 0.086, 0.093, 0.132, 0.112, 0.127, 0.185, 0.087, 0.079, 0.087, 0.083, 0.06, 0.073, 0.08, 0.095, 0.082, 0.082, 0.09, 0.09, 0.131, 0.095, 0.103, 0.076, 0.081, 0.075, 0.107, 0.078, 0.114, 0.471, 0.079, 0.087, 0.1, 0.107, 0.154, 0.098, 0.075, 1.219, 0.077, 0.091, 0.095, 0.078, 0.079, 0.096, 0.117, 0.085, 0.078, 0.076, 0.081, 0.078, 0.115, 0.071, 0.086, 0.072, 0.08, 0.274, 0.076, 0.084, 0.098, 0.092, 0.073, 0.082, 0.084, 0.081, 0.087, 0.091, 0.087, 0.085, 0.092, 0.082, 0.082, 0.066, 0.117, 0.078, 0.101, 0.08, 0.088, 0.089, 0.068, 0.08, 0.115, 0.088, 0.086, 0.082, 0.137, 0.082, 0.09, 0.081, 0.129, 0.067, 0.139, 0.069, 0.086, 0.09, 0.087, 0.874, 0.1, 0.082, 0.085, 0.076, 0.071, 0.07, 0.108, 0.12, 0.092, 0.183, 0.074, 0.085, 0.085, 0.081, 0.092, 0.091, 0.091, 0.114, 0.062, 0.089, 0.076, 0.07, 0.08, 0.09, 0.089, 0.08, 0.177, 0.099, 0.097, 0.072, 0.208, 0.089, 0.089, 0.108, 0.083, 0.102, 0.093, 0.082, 0.078, 0.079, 0.125, 0.082, 0.069, 0.084, 0.067, 0.075, 0.072, 0.094, 0.08, 0.084, 0.089, 0.122, 0.071, 0.072, 0.106, 0.198, 0.081, 0.089, 0.078, 0.082, 0.083, 0.081, 0.081, 0.082, 0.09, 0.085, 0.11, 0.167, 0.082, 0.077, 0.099, 0.084, 0.085, 0.081, 0.073, 0.136, 0.082, 0.074, 0.085, 0.095, 0.095, 0.065, 0.071, 0.138, 0.099, 0.086, 0.062, 0.084, 0.084, 0.084, 0.073, 0.096, 0.107, 0.079, 0.092, 0.13, 0.079, 0.067, 0.088, 0.083, 0.064, 0.079, 0.081, 0.061, 0.077, 0.102, 0.095, 0.085, 0.067, 0.113, 0.098, 0.094, 0.084, 0.084, 0.082, 0.085, 0.101, 0.097, 0.081, 0.103, 0.077, 0.113, 0.076, 0.091, 0.091, 0.07, 0.125, 0.092, 0.071, 0.083, 0.125, 0.284, 0.105, 0.086, 0.094, 0.071, 0.086, 0.122, 0.077, 0.138, 0.081, 0.109, 0.21, 0.082, 0.135, 0.089, 0.082, 0.089, 0.08, 0.067, 0.144, 0.085, 0.121, 0.073, 0.069, 0.079, 0.116, 0.067, 0.067, 0.064, 0.073, 0.07, 0.125, 0.073, 0.106, 0.08, 0.075, 0.088, 0.077, 0.094, 0.092, 0.125, 0.123, 0.081, 0.078, 0.099, 0.065, 0.101, 0.087, 0.09, 0.088, 0.21, 0.084, 0.145, 0.074, 0.102, 0.101, 0.069, 0.085, 0.088, 0.114, 0.087, 0.073, 0.084, 0.13, 0.285, 0.084, 0.111, 0.133, 0.092, 0.094, 0.082, 0.08, 0.084, 0.081, 0.083, 0.083, 0.089, 0.076, 0.059, 0.07, 0.089, 0.063, 0.074, 0.083, 0.51, 0.075, 0.066, 0.081, 0.077, 0.113, 0.073, 0.114, 0.09, 0.085, 0.07, 0.246, 0.064, 0.095, 0.074, 0.081, 0.088, 0.09, 0.08, 0.116, 0.075, 0.128, 0.071, 0.103, 0.063, 0.078, 0.126, 0.178, 0.079, 0.075, 0.072, 0.086, 0.093, 0.115, 0.075, 0.061, 0.068, 0.106, 0.089, 0.079, 0.106, 0.088, 0.098, 0.129, 0.094, 0.096, 0.08, 0.084, 0.07, 0.13, 0.075, 0.126, 0.076, 0.102, 0.08, 0.059, 0.102, 0.149, 0.289, 0.078, 0.058, 0.073, 0.081, 0.068, 0.077, 0.075, 0.107, 0.071, 0.072, 0.072, 0.086, 0.079, 0.081, 0.059, 0.119, 0.092, 0.074, 0.072, 0.061, 0.091, 0.091, 0.062, 0.079, 0.173, 0.067, 0.115, 0.081, 0.088, 0.095, 0.128, 0.088, 0.11, 0.098, 0.13, 0.086, 0.08, 0.089, 0.088, 0.088, 0.115, 0.248, 0.075, 0.078, 0.07, 0.07, 0.061, 0.094, 0.093, 0.078, 0.072, 0.07, 0.096, 0.082, 0.086, 0.082, 0.062, 0.091, 0.074, 0.088, 0.098, 0.086, 0.08, 0.092, 0.141, 0.069, 0.119, 0.061, 0.091, 0.063, 0.083, 0.08, 0.073, 0.083, 0.086, 0.079, 0.102, 0.07, 0.058, 0.089, 0.115, 0.075, 0.085, 0.081, 0.089, 0.089, 0.088, 0.073, 0.13, 0.172, 0.077, 0.111, 0.119, 0.129, 0.082, 0.086, 0.103, 0.106, 0.072, 0.097, 0.086, 0.095, 0.097, 0.07, 0.134, 0.071, 0.096, 0.081, 0.062, 0.075, 0.083, 0.12, 0.092, 0.098, 0.188, 0.082, 0.078, 0.126, 0.269, 0.065, 0.086, 0.075, 0.065, 0.074, 0.089, 0.217, 0.094, 0.071, 0.131, 0.087, 0.124, 0.139, 0.092, 0.088, 0.139, 0.083, 0.084, 0.109, 0.081, 0.097, 0.079, 0.083, 0.095, 0.109, 0.092, 0.143, 0.076, 0.075, 3.058, 0.082, 0.073, 0.089, 0.085, 0.076, 0.08, 0.094, 0.129, 0.174, 0.1, 0.214, 0.155, 0.085, 0.078, 0.087, 0.235, 0.165, 0.112, 0.08, 0.111, 0.08, 0.075, 0.07, 0.097, 0.074, 0.146, 0.149, 0.093, 0.073, 0.075, 0.119, 0.086, 0.078, 0.067, 0.067, 0.097, 0.07, 0.141, 0.121, 0.079, 0.076, 0.07, 0.119, 0.08, 0.063, 0.063, 0.575, 0.075, 0.117, 0.11, 0.098, 0.076, 0.075, 0.158, 0.069, 0.129, 0.09, 0.085, 0.158, 0.083, 0.085, 0.074, 0.084, 0.16, 0.08, 0.078, 0.067, 0.083, 0.086, 0.076, 0.074, 0.076, 0.069, 0.074, 0.065, 0.087, 0.169, 0.114, 0.092, 0.075, 0.076, 0.069, 0.062, 0.061, 0.068, 0.072, 0.062, 0.081, 0.126, 0.091, 0.084, 0.072, 0.149, 0.076, 0.07, 0.073, 0.109, 0.076, 0.08, 0.127, 0.07, 0.074, 0.079, 0.066, 0.068, 0.06, 0.076, 0.078, 0.094, 0.079, 0.069, 0.079, 0.063, 0.078, 0.07, 0.098, 0.071, 0.135, 0.181, 0.07, 0.085, 0.086, 0.084, 0.083, 0.069, 0.064, 0.148, 0.077, 0.079, 0.082, 0.149, 0.07, 0.075, 0.176, 0.082, 0.088, 0.092, 0.091, 1.155, 0.084, 0.083, 0.08, 0.122, 0.078, 0.086, 0.197, 0.109, 0.066, 0.107, 0.095, 0.061, 0.154, 0.066, 0.102, 0.075, 0.066, 0.107, 0.072, 0.067, 0.074, 0.091, 0.071, 0.085, 0.107, 0.07, 0.066, 0.071, 0.067, 0.073, 0.073, 0.071, 0.094, 0.068, 0.101, 0.097, 0.076, 0.075, 0.207, 0.077, 0.086, 0.061, 0.063, 0.062, 0.213, 0.067, 0.104, 0.085, 0.085, 0.084, 0.075, 0.069, 0.076, 0.071, 0.074, 0.096, 0.107, 0.166, 0.077, 0.065, 0.09, 0.081, 0.072, 0.095, 0.077, 0.138, 0.114, 0.189, 0.094, 0.101, 0.108, 0.089, 0.068, 0.076, 0.337, 0.064, 0.077, 0.085, 0.14, 0.091, 0.096, 0.091, 0.135, 0.07, 0.081, 0.094, 0.069, 0.092, 0.071, 0.137, 0.09, 0.307, 0.076, 0.065, 0.097, 0.055, 0.07, 0.091, 0.067, 0.066, 0.065, 0.056, 0.088, 0.073, 0.063, 0.059, 0.088, 0.067, 0.073, 0.082, 0.091, 0.091, 0.118, 0.073, 0.242, 0.069, 0.077, 0.075, 0.066, 0.072, 0.084, 0.065, 0.08, 0.094, 0.086, 0.083, 0.074, 0.077, 0.077, 0.332, 0.068, 0.06, 0.079, 0.11, 0.123, 0.068, 0.102, 0.084, 0.073, 0.081, 0.07, 0.073, 0.109, 0.098, 0.119, 0.079, 0.094, 0.124, 0.076, 0.072, 0.071, 0.071, 0.062, 0.131, 0.073, 0.112, 0.113, 0.084, 0.069, 0.063, 0.814, 0.058, 0.141, 0.072, 0.066, 0.124, 0.078, 0.082, 0.067, 0.072, 0.099, 0.074, 0.076, 0.076, 0.068, 0.064, 0.111, 0.118, 0.088, 0.091, 0.108, 0.117, 0.084, 0.08, 0.086, 0.076, 0.098, 0.078, 0.094, 0.08, 0.209, 0.079, 0.077, 0.07, 0.087, 0.068, 0.072, 0.14, 0.084, 0.074, 0.083, 0.103, 0.072, 0.14, 0.091, 0.079, 0.115, 0.083, 0.075, 0.084, 0.073, 0.105, 0.074, 0.123, 0.127, 0.093, 0.092, 0.088, 0.096, 0.162, 0.086, 0.084, 0.074, 0.108, 0.113, 0.08, 0.144, 0.109, 0.097, 0.068, 0.093, 0.098, 0.082, 0.069, 3.079, 0.127, 0.09, 0.087, 0.093, 0.134, 0.086, 0.08, 0.071, 0.135, 0.084, 0.079, 0.077, 0.078, 0.098, 0.142, 0.078, 0.079, 0.129, 0.081, 0.07, 0.062, 0.075, 0.069, 0.096, 0.073, 0.085, 0.087, 0.084, 0.111, 0.102, 0.195, 0.071, 0.069, 0.071, 0.085, 0.07, 0.065, 0.097, 0.097, 0.065, 1.575, 0.09, 0.065, 0.082, 0.064, 0.081, 0.085, 0.177, 0.088, 0.116, 0.09, 0.084, 0.071, 0.28, 0.091, 0.079, 0.08, 0.074, 0.079, 0.091, 0.07, 0.063, 0.068, 0.067, 0.065, 0.077, 0.077, 0.081, 0.126, 0.082, 0.093, 0.064, 0.076, 0.083, 0.094, 0.099, 0.079, 0.071, 0.086, 0.08, 0.083, 0.094, 0.092, 0.077, 0.113, 0.069, 0.079, 0.082, 0.673, 0.134, 0.097, 0.098, 0.094, 0.067, 0.139, 0.091, 0.072, 0.087, 0.079, 0.078, 0.063, 0.074, 0.073, 0.206, 0.21, 0.074, 0.065, 0.071, 0.085, 0.098, 0.07, 0.098, 0.072, 0.066, 0.113, 0.083, 0.072, 0.069, 0.143, 0.076, 0.091, 0.09, 0.06, 0.085, 0.089, 0.075, 0.077, 0.076, 0.06, 0.07, 0.073, 0.297, 0.075, 0.071, 0.085, 0.075, 0.062, 0.08, 0.082, 0.088, 0.088, 0.075, 0.072, 0.081, 0.092, 0.081, 0.076, 0.098, 0.079, 0.088, 0.086, 0.086, 0.099, 0.086, 0.089, 0.092, 0.11, 0.076, 0.098, 0.068, 0.139, 0.076, 0.1, 0.093, 0.098, 0.081, 0.133, 0.172, 0.093, 0.084, 0.071, 0.298, 0.153, 0.078, 0.073, 0.107, 0.079, 0.08, 0.104, 0.111, 0.273, 0.073, 0.074, 0.069, 0.077, 0.076, 0.087, 0.092, 0.095, 0.09, 0.071, 0.096, 0.103, 0.074, 0.068, 0.072, 0.094, 0.067, 0.073, 0.086, 0.085, 0.075, 0.087, 0.073, 0.086, 0.083, 0.07, 0.09, 0.092, 0.079, 0.089, 0.102, 0.081, 0.077, 0.084, 0.081, 0.069, 0.089, 0.079, 0.069, 0.089, 0.102, 0.114, 0.147, 0.13, 0.068, 0.089, 0.157, 0.078, 0.085, 0.082, 0.072, 0.086, 0.081, 0.096, 0.102, 0.077, 0.107, 0.091, 0.09, 0.119, 0.071, 0.1, 0.072, 0.064, 0.074, 0.081, 0.08, 0.142, 0.079, 0.209, 0.08, 0.087, 0.094, 0.125, 0.069, 0.067, 0.066, 0.085, 0.074, 0.085, 0.083, 0.154, 0.093, 0.096, 0.079, 0.095, 0.087, 0.08, 0.077, 0.071, 0.074, 0.077, 0.073, 0.074, 0.262, 0.081, 0.08, 0.071, 0.12, 0.15, 0.092, 0.102, 0.073, 0.08, 0.106, 0.105, 0.084, 0.081, 0.07, 0.074, 0.095, 0.099, 0.078, 0.077, 0.087, 0.09, 0.074, 0.085, 0.085, 0.102, 0.092, 0.115, 0.087, 0.219, 0.193, 0.122, 0.084, 0.079, 0.079, 0.077, 0.075, 0.075, 0.124, 0.102, 0.085, 0.079, 0.079, 0.108, 0.078, 0.095, 0.087, 0.146, 0.093, 0.112, 0.074, 0.094, 0.097, 0.089, 0.085, 0.089, 0.082, 0.077, 0.061, 0.142, 0.099, 0.072, 0.075, 0.133, 0.096, 0.073, 0.107, 0.07, 0.065, 0.077, 0.084, 0.075, 0.073, 0.081, 0.076, 0.077, 0.074, 0.072, 0.075, 0.095, 0.081, 0.073, 0.411, 0.068, 0.085, 0.079, 0.063, 0.076, 0.076, 0.081, 0.072, 0.07, 0.082, 0.084, 0.074, 0.083, 0.07, 0.087, 0.094, 0.095, 0.078, 0.112, 0.107, 0.061, 0.087, 0.092, 0.07, 0.064, 0.078, 0.102, 0.079, 0.069, 0.076, 0.09, 0.108, 0.071, 0.1, 0.067, 0.153, 0.135, 0.067, 0.106, 0.088, 0.089, 0.078, 0.133, 0.123, 0.069, 0.105, 0.067, 0.064, 0.065, 0.067, 0.094, 0.068, 0.098, 0.091, 0.086, 0.084, 0.105, 0.093, 0.072, 0.09, 0.155, 0.084, 0.072, 0.072, 0.081, 0.081, 0.098, 0.076, 0.083, 0.074, 0.11, 0.08, 0.091, 0.082, 0.077, 0.076, 0.092, 0.098, 0.076, 0.147, 0.122, 0.122, 0.074, 0.073, 0.077, 0.072, 0.092, 0.087, 0.133, 0.074, 0.082, 0.08, 0.085, 0.082, 0.118, 0.117, 0.087, 0.094, 0.102, 0.079, 0.096, 0.078, 0.116, 0.09, 0.089, 0.08, 0.092, 0.073, 0.074, 0.088, 0.076, 0.069, 0.132, 0.109, 0.095, 0.095, 0.152, 0.096, 1.285, 0.084, 0.078, 0.082, 0.081, 0.068, 0.095, 0.096, 0.102, 0.392, 0.102, 0.094, 0.079, 0.09, 0.08, 0.08, 0.089, 0.093, 0.106, 0.122, 0.078, 0.072, 0.08, 0.08, 0.1, 0.077, 0.076, 0.086, 0.071, 0.117, 0.089, 0.135, 0.069, 0.098, 0.093, 0.106, 0.079, 0.09, 0.13, 0.086, 0.067, 0.101, 0.063, 0.079, 0.13, 0.091, 0.069, 0.082, 0.091, 0.088, 0.077, 0.098, 0.085, 0.08, 0.078, 0.081, 0.08, 0.072, 0.126, 0.086, 0.078, 0.1, 0.072, 0.087, 0.142, 0.089, 0.08, 0.076, 0.098, 0.092, 0.073, 0.087, 0.124, 0.086, 0.093, 0.122, 0.167, 0.158, 0.125, 0.082, 0.104, 0.084, 0.091, 0.078, 0.074, 0.081, 0.162, 0.078, 0.071, 0.073, 0.077, 0.092, 0.084, 0.075, 0.072, 0.07, 0.08, 0.136, 0.081, 0.134, 0.155, 0.125, 0.077, 0.141, 0.084, 0.065, 0.134, 0.116, 0.091, 0.068, 0.09, 0.091, 0.089, 0.068, 0.088, 0.089, 0.092, 0.147, 0.108, 0.066, 0.076, 0.099, 0.082, 0.07, 0.098, 0.293, 0.095, 0.075, 0.097, 0.094, 0.088, 0.143, 0.134, 0.094, 0.091, 0.09, 0.104, 0.096, 0.095, 0.087, 0.235, 0.102, 0.135, 0.085, 0.081, 0.082, 0.096, 0.079, 0.078, 0.063, 0.083, 0.098, 0.091, 0.082, 0.09, 0.117, 0.077, 0.071, 0.108, 0.097, 0.101, 0.099, 0.105, 0.114, 0.479, 0.08, 0.189, 0.087, 0.074, 0.086, 0.093, 0.089, 0.064, 0.073, 0.107, 0.087, 0.097, 0.08, 0.12, 0.112, 0.079, 0.083, 0.083, 0.092, 0.084, 0.082, 0.088, 0.081, 0.08, 0.137, 0.078, 0.119    
    #         ],
    #         [
    #             0.151, 0.101, 0.085, 0.061, 0.087, 0.068, 0.163, 0.079, 0.105, 0.077, 0.173, 0.122, 0.107, 0.135, 0.138, 0.081, 0.081, 0.083, 0.136, 0.087, 0.081, 0.104, 0.103, 0.095, 0.11, 0.09, 0.09, 0.817, 0.093, 0.074, 0.086, 0.104, 0.087, 0.143, 0.127, 0.081, 0.082, 0.082, 0.08, 0.108, 0.076, 0.102, 0.079, 0.124, 0.102, 0.095, 0.098, 0.095, 0.091, 0.095, 0.091, 0.089, 0.094, 0.129, 0.093, 0.079, 0.135, 0.116, 0.084, 0.082, 0.098, 0.116, 0.089, 0.134, 0.091, 0.101, 0.089, 0.093, 0.193, 0.081, 0.087, 0.147, 0.083, 0.078, 0.147, 0.097, 0.081, 0.088, 0.082, 0.092, 0.085, 0.084, 0.126, 0.091, 0.079, 0.092, 0.565, 0.075, 0.085, 0.097, 0.083, 0.108, 0.112, 0.083, 0.074, 0.119, 0.103, 0.073, 0.122, 0.087, 0.074, 0.064, 0.064, 0.07, 0.189, 0.099, 0.088, 0.102, 0.087, 0.093, 0.292, 0.085, 0.101, 0.113, 0.064, 0.07, 0.091, 0.095, 0.083, 0.058, 0.11, 0.126, 0.073, 0.102, 0.097, 0.101, 0.104, 0.084, 0.31, 0.075, 0.081, 0.074, 0.078, 0.106, 0.071, 0.075, 0.073, 0.085, 0.071, 0.09, 0.083, 0.079, 0.086, 0.125, 0.069, 0.082, 0.143, 0.094, 0.091, 0.081, 0.078, 0.078, 0.066, 0.065, 0.125, 0.068, 0.105, 0.066, 0.111, 0.072, 0.134, 0.114, 0.079, 0.113, 0.095, 0.26, 0.088, 0.078, 0.11, 0.117, 0.101, 0.165, 0.099, 0.103, 0.107, 0.078, 0.138, 0.066, 0.08, 0.109, 0.076, 0.072, 0.088, 0.114, 0.08, 0.103, 0.157, 0.082, 0.13, 0.085, 0.084, 0.088, 0.092, 0.085, 0.09, 0.084, 0.094, 0.075, 0.073, 0.285, 0.106, 0.109, 0.144, 0.111, 0.102, 0.085, 0.073, 0.088, 0.115, 0.077, 0.079, 0.077, 0.081, 0.1, 0.152, 0.08, 0.104, 0.126, 0.135, 0.084, 0.075, 0.087, 0.14, 0.096, 0.102, 0.165, 0.081, 0.077, 0.176, 0.106, 0.2, 0.106, 0.146, 0.076, 0.088, 0.783, 0.105, 0.074, 0.106, 0.135, 0.081, 0.1, 0.076, 0.077, 0.129, 0.127, 0.101, 0.184, 0.11, 0.105, 0.092, 0.128, 0.113, 0.12, 0.09, 0.099, 0.092, 0.072, 0.096, 0.082, 2.938, 0.092, 0.083, 0.086, 0.144, 0.101, 0.143, 0.084, 0.069, 0.074, 0.116, 0.102, 0.079, 0.093, 0.098, 0.08, 0.081, 0.11, 0.083, 0.088, 0.116, 0.087, 0.065, 0.079, 0.09, 0.085, 0.097, 0.087, 0.08, 0.26, 0.077, 0.098, 0.1, 0.087, 0.081, 0.1, 0.081, 0.114, 0.076, 0.122, 0.086, 0.085, 0.134, 0.077, 0.14, 0.149, 0.07, 0.065, 0.082, 0.119, 0.128, 0.076, 0.12, 0.075, 0.088, 0.085, 0.07, 0.138, 0.072, 0.11, 0.109, 0.097, 0.105, 0.082, 0.082, 0.154, 0.088, 0.078, 0.117, 0.108, 0.084, 0.1, 0.081, 0.076, 0.105, 0.088, 0.083, 0.078, 0.264, 0.088, 0.113, 0.092, 0.125, 0.068, 0.102, 0.083, 0.101, 0.143, 0.079, 0.108, 0.095, 0.097, 0.087, 0.135, 0.088, 0.08, 0.094, 0.086, 0.146, 1.463, 0.088, 0.082, 0.081, 0.085, 0.076, 0.07, 0.136, 0.139, 0.072, 0.076, 0.07, 0.131, 0.112, 0.098, 0.089, 0.216, 0.094, 0.074, 0.078, 0.082, 0.068, 0.093, 0.084, 0.073, 0.122, 0.232, 0.08, 0.084, 0.078, 0.092, 0.107, 0.09, 0.072, 0.089, 0.093, 0.057, 0.074, 0.108, 0.085, 0.119, 0.08, 0.069, 0.065, 0.079, 0.067, 0.101, 0.083, 0.081, 0.098, 0.092, 0.083, 0.084, 0.091, 0.081, 0.104, 0.109, 0.097, 0.099, 0.087, 0.066, 0.167, 0.074, 0.099, 0.074, 0.09, 0.08, 0.077, 0.068, 0.072, 0.071, 0.064, 0.071, 0.073, 0.064, 0.069, 0.114, 0.071, 0.084, 0.101, 0.076, 0.113, 0.094, 0.074, 0.132, 0.12, 0.115, 0.129, 0.084, 0.119, 0.092, 0.081, 0.09, 0.111, 0.084, 0.082, 0.063, 0.08, 0.073, 0.288, 0.11, 0.07, 0.197, 0.084, 0.073, 0.093, 0.143, 0.085, 0.08, 0.13, 0.143, 0.084, 0.108, 0.068, 0.075, 0.087, 0.083, 0.088, 0.13, 0.084, 0.08, 0.092, 0.088, 0.095, 0.078, 0.088, 0.114, 0.089, 0.111, 0.138, 0.074, 0.09, 0.096, 0.103, 0.071, 0.069, 0.097, 0.099, 0.082, 0.08, 0.093, 0.091, 0.084, 0.075, 0.082, 0.073, 0.093, 0.081, 0.109, 0.089, 0.094, 0.083, 0.113, 0.095, 0.08, 0.105, 0.145, 0.08, 0.081, 0.092, 0.079, 0.132, 0.086, 0.138, 0.095, 0.109, 0.089, 0.096, 0.307, 0.149, 0.079, 0.085, 0.103, 0.075, 0.076, 0.092, 0.096, 0.098, 0.085, 0.148, 0.397, 0.081, 0.081, 0.117, 0.08, 0.067, 0.095, 0.067, 0.122, 0.095, 0.075, 0.094, 0.074, 0.087, 0.076, 0.077, 0.078, 0.073, 0.191, 0.075, 0.082, 0.138, 0.131, 0.089, 0.091, 0.084, 0.084, 0.1, 0.069, 0.097, 0.097, 0.093, 0.08, 0.075, 0.108, 0.196, 0.061, 0.11, 0.108, 0.089, 0.119, 0.112, 0.084, 0.076, 0.101, 0.126, 0.115, 0.083, 0.105, 0.121, 0.078, 0.08, 0.145, 0.101, 0.102, 0.155, 0.122, 0.078, 0.075, 0.069, 0.092, 0.397, 0.09, 0.126, 0.086, 0.087, 0.081, 0.078, 0.088, 0.086, 0.143, 0.104, 0.093, 0.07, 0.093, 0.111, 0.137, 0.141, 0.173, 0.078, 0.154, 0.116, 0.063, 0.126, 0.077, 0.088, 0.104, 0.129, 0.077, 0.078, 0.088, 0.112, 0.081, 0.074, 0.134, 0.08, 0.307, 0.107, 0.111, 0.177, 0.091, 0.11, 0.076, 0.083, 0.075, 0.066, 0.099, 0.079, 0.073, 0.075, 0.086, 0.127, 0.132, 0.153, 0.071, 0.068, 0.079, 0.085, 0.11, 0.092, 0.11, 0.086, 0.089, 0.087, 0.108, 0.081, 0.077, 0.066, 0.072, 0.072, 0.087, 0.084, 0.093, 0.09, 0.077, 0.097, 0.074, 0.075, 0.088, 0.118, 0.09, 0.075, 0.078, 0.069, 0.108, 0.133, 0.133, 0.089, 0.093, 0.08, 0.077, 0.079, 0.084, 0.206, 0.084, 0.115, 0.084, 0.192, 0.068, 0.071, 0.09, 0.096, 0.083, 0.1, 0.077, 0.07, 0.075, 0.081, 0.072, 0.105, 0.09, 0.229, 0.091, 0.113, 0.061, 0.085, 0.078, 0.125, 0.085, 1.158, 0.089, 0.085, 0.069, 0.064, 0.104, 0.112, 0.079, 0.128, 0.086, 0.098, 0.078, 0.084, 0.104, 0.096, 0.086, 0.084, 0.209, 0.119, 0.089, 0.13, 0.14, 0.136, 0.066, 0.079, 0.087, 0.099, 0.077, 0.077, 0.083, 0.102, 0.292, 0.139, 0.077, 0.076, 0.081, 0.084, 0.107, 0.09, 0.132, 0.114, 0.095, 0.096, 0.139, 1.122, 0.07, 0.07, 0.077, 0.085, 0.079, 0.094, 0.077, 0.075, 0.122, 0.127, 0.079, 0.098, 0.106, 0.091, 0.088, 0.104, 0.084, 0.069, 0.122, 0.133, 0.107, 0.133, 0.082, 0.066, 0.071, 0.129, 0.093, 0.082, 0.127, 0.09, 0.123, 0.071, 0.112, 0.12, 0.109, 0.116, 0.09, 0.139, 0.082, 0.098, 0.087, 0.089, 0.084, 0.125, 0.102, 0.069, 0.107, 0.108, 0.073, 0.067, 0.148, 0.077, 0.112, 0.076, 0.086, 0.155, 0.115, 0.138, 0.095, 0.136, 0.087, 0.15, 0.088, 0.091, 0.096, 0.106, 0.086, 0.089, 0.105, 0.084, 0.105, 0.095, 0.109, 0.296, 0.153, 0.084, 0.091, 0.237, 0.09, 0.082, 0.197, 0.133, 0.122, 0.123, 0.113, 0.076, 0.078, 0.211, 0.067, 0.12, 0.121, 0.135, 0.086, 0.088, 0.087, 0.078, 0.097, 0.094, 0.119, 0.082, 0.085, 0.06, 0.068, 0.199, 0.102, 0.076, 0.09, 0.084, 0.124, 0.084, 0.138, 0.086, 0.103, 0.115, 0.101, 0.082, 0.105, 0.085, 0.091, 0.089, 0.11, 0.1, 0.123, 0.084, 0.168, 0.136, 0.102, 0.08, 0.108, 0.095, 0.123, 0.123, 0.148, 0.088, 0.089, 0.093, 0.097, 0.071, 0.098, 0.081, 0.064, 0.072, 0.085, 0.111, 0.087, 0.133, 0.079, 0.071, 0.089, 0.126, 0.075, 0.096, 0.105, 0.156, 0.091, 0.138, 0.066, 0.098, 0.101, 0.093, 0.09, 0.1, 0.112, 0.142, 0.076, 0.077, 0.072, 0.085, 0.124, 0.095, 0.125, 0.091, 0.113, 0.095, 0.109, 0.097, 0.084, 0.1, 0.085, 0.096, 0.088, 0.081, 0.082, 0.069, 0.077, 0.065, 0.189, 0.219, 0.085, 0.087, 0.087, 0.06, 0.085, 0.079, 0.102, 0.092, 0.086, 0.085, 0.077, 0.904, 0.072, 0.105, 0.112, 0.086, 0.125, 0.088, 0.097, 0.065, 0.122, 0.1, 0.122, 0.078, 0.105, 0.092, 0.133, 0.091, 0.061, 0.083, 0.063, 0.098, 0.114, 0.128, 0.133, 0.071, 0.36, 0.084, 0.088, 0.092, 0.094, 0.095, 0.092, 0.098, 0.093, 0.092, 0.091, 0.127, 0.086, 0.084, 0.113, 0.084, 0.077, 0.086, 0.102, 0.084, 0.111, 0.078, 0.128, 0.097, 0.089, 0.091, 0.144, 0.082, 0.073, 0.052, 0.083, 0.082, 0.082, 0.076, 0.098, 0.084, 0.094, 0.121, 0.15, 0.1, 0.083, 0.122, 0.111, 0.09, 0.139, 0.119, 0.088, 0.114, 0.135, 0.078, 0.143, 0.091, 0.077, 0.082, 0.071, 0.09, 0.176, 0.088, 0.102, 0.09, 0.098, 0.082, 0.139, 0.08, 0.085, 0.08, 0.318, 0.122, 0.114, 0.424, 0.081, 0.104, 0.083, 0.727, 0.072, 0.339, 0.081, 0.076, 0.099, 0.105, 0.083, 0.088, 0.092, 0.096, 0.085, 0.104, 0.082, 0.154, 0.104, 0.084, 0.079, 0.088, 0.09, 0.21, 0.102, 0.078, 0.079, 0.138, 0.101, 0.116, 0.07, 0.095, 0.12, 0.082, 0.093, 0.069, 0.099, 0.111, 0.086, 0.098, 0.104, 0.112, 0.074, 0.079, 0.1, 0.087, 0.111, 0.108, 0.068, 0.128, 0.099, 0.092, 0.105, 0.089, 0.116, 0.106, 0.085, 0.071, 0.07, 0.092, 0.133, 0.119, 0.122, 0.075, 0.126, 0.091, 0.111, 0.1, 0.076, 0.118, 0.117, 0.093, 0.065, 0.074, 0.079, 0.123, 0.124, 0.143, 0.08, 0.061, 0.076, 0.087, 0.175, 0.127, 0.127, 0.071, 0.104, 0.089, 0.101, 0.09, 0.103, 0.068, 0.09, 0.062, 0.101, 0.09, 0.089, 0.099, 0.069, 0.092, 0.13, 0.075, 0.217, 0.388, 0.068, 0.096, 0.109, 0.091, 0.082, 0.141, 0.092, 0.146, 0.087, 0.088, 0.079, 0.084, 0.163, 0.107, 0.098, 0.083, 0.073, 0.072, 0.105, 0.076, 0.076, 0.08, 0.065, 0.12, 1.531, 0.091, 0.071, 0.127, 0.118, 0.1, 0.125, 0.08, 0.188, 0.096, 0.107, 0.094, 0.174, 0.163, 0.093, 0.079, 0.064, 0.121, 0.124, 0.126, 0.138, 0.104, 0.074, 0.088, 0.102, 0.076, 0.086, 0.07, 0.096, 0.103, 0.089, 0.105, 0.092, 0.09, 0.083, 0.095, 0.108, 0.089, 0.148, 0.095, 0.104, 0.09, 0.075, 0.099, 0.1, 0.094, 0.092, 0.1, 0.139, 0.084, 0.095, 0.08, 0.079, 0.109, 0.114, 0.083, 0.085, 0.167, 0.085, 0.078, 0.118, 0.093, 0.121, 0.1, 0.092, 0.079, 0.089, 0.079, 0.102, 0.084, 0.082, 0.086, 0.088, 0.087, 0.072, 0.09, 0.096, 0.075, 0.119, 0.118, 0.09, 0.076, 0.103, 0.083, 0.086, 0.092, 0.086, 0.085, 0.088, 0.079, 0.072, 0.118, 0.1, 0.075, 0.104, 0.092, 0.088, 0.131, 0.103, 0.089, 0.116, 0.115, 0.097, 0.098, 0.077, 0.091, 0.097, 0.086, 0.098, 0.099, 0.125, 0.076, 0.093, 0.087, 0.134, 0.08, 0.083, 0.087, 0.074, 0.081, 0.062, 0.095, 0.069, 0.11, 0.068, 0.08, 0.309, 0.087, 0.073, 0.091, 0.093, 0.094, 0.084, 0.092, 0.117, 0.094, 0.11, 0.074, 0.127, 0.071, 0.129, 0.08, 0.09, 0.091, 0.31, 0.093, 0.086, 0.101, 0.091, 0.103, 0.061, 0.135, 0.077, 0.086, 0.131, 0.134, 0.077, 0.126, 0.171, 0.063, 0.096, 0.083, 0.083, 0.104, 0.107, 0.097, 0.083, 0.084, 0.113, 0.083, 0.132, 0.129, 0.088, 0.119, 0.099, 0.085, 0.09, 0.095, 0.072, 0.078, 0.125, 0.128, 0.138, 0.15, 0.178, 0.095, 0.077, 0.09, 0.08, 0.091, 0.102, 0.104, 0.086, 0.111, 0.103, 0.085, 0.101, 0.101, 0.075, 0.088, 0.09, 0.093, 0.071, 0.062, 0.075, 0.078, 0.085, 0.091, 1.139, 0.066, 0.088, 0.091, 0.087, 0.088, 0.073, 0.08, 0.089, 0.087, 0.09, 0.08, 0.078, 0.241, 0.119, 0.085, 0.079, 0.1, 0.088, 0.128, 0.126, 0.1, 0.107, 0.082, 0.112, 0.093, 0.1, 0.111, 0.085, 0.111, 0.148, 0.099, 0.12, 0.09, 0.145, 0.092, 0.083, 0.084, 0.083, 0.129, 0.075, 0.089, 0.115, 0.076, 0.118, 0.122, 0.082, 0.095, 0.07, 0.094, 0.118, 0.114, 0.115, 0.2, 0.09, 0.084, 0.087, 0.079, 0.07, 0.059, 0.08, 0.098, 0.115, 0.1, 0.081, 0.06, 0.125, 0.099, 0.07, 0.081, 0.08, 0.072, 0.099, 0.087, 0.124, 0.506, 0.105, 0.095, 0.12, 0.09, 0.156, 0.081, 0.067, 1.278, 0.093, 0.083, 0.078, 0.082, 0.074, 0.089, 0.106, 0.083, 0.076, 0.077, 0.096, 0.07, 0.134, 0.078, 0.094, 0.086, 0.089, 0.25, 0.095, 0.08, 0.106, 0.086, 0.079, 0.076, 0.09, 0.082, 0.086, 0.103, 0.086, 0.065, 0.076, 0.075, 0.067, 0.095, 0.106, 0.079, 0.086, 0.079, 0.084, 0.092, 0.072, 0.084, 0.116, 0.081, 0.07, 0.072, 0.134, 0.065, 0.093, 0.099, 0.123, 0.084, 0.146, 0.066, 0.099, 0.079, 0.089, 0.847, 0.102, 0.084, 0.066, 0.069, 0.1, 0.075, 0.1, 0.108, 0.075, 0.196, 0.094, 0.088, 0.068, 0.079, 0.072, 0.08, 0.074, 0.103, 0.066, 0.082, 0.064, 0.069, 0.075, 0.069, 0.074, 0.082, 0.147, 0.096, 0.092, 0.083, 0.237, 0.076, 0.07, 0.118, 0.074, 0.083, 0.072, 0.075, 0.077, 0.067, 0.126, 0.091, 0.112, 0.087, 0.085, 0.085, 0.083, 0.09, 0.069, 0.091, 0.088, 0.118, 0.075, 0.101, 0.119, 0.209, 0.082, 0.11, 0.089, 0.09, 0.075, 0.081, 0.094, 0.08, 0.077, 0.072, 0.107, 0.18, 0.063, 0.093, 0.102, 0.092, 0.087, 0.073, 0.097, 0.15, 0.078, 0.072, 0.09, 0.085, 0.083, 0.089, 0.072, 0.107, 0.071, 0.068, 0.077, 0.089, 0.076, 0.079, 0.072, 0.08, 0.09, 0.064, 0.08, 0.117, 0.077, 0.082, 0.098, 0.086, 0.084, 0.085, 0.077, 0.082, 0.081, 0.087, 0.074, 0.073, 0.067, 0.119, 0.08, 0.069, 0.091, 0.078, 0.071, 0.088, 0.094, 0.09, 0.087, 0.081, 0.078, 0.117, 0.075, 0.067, 0.071, 0.095, 0.14, 0.1, 0.078, 0.07, 0.108, 0.279, 0.107, 0.097, 0.101, 0.083, 0.076, 0.106, 0.083, 0.111, 0.088, 0.092, 0.181, 0.066, 0.078, 0.071, 0.075, 0.081, 0.07, 0.063, 0.121, 0.082, 0.113, 0.08, 0.082, 0.08, 0.139, 0.069, 0.074, 0.067, 0.093, 0.07, 0.085, 0.074, 0.1, 0.079, 0.076, 0.103, 0.086, 0.123, 0.087, 0.12, 0.127, 0.124, 0.069, 0.105, 0.073, 0.108, 0.082, 0.102, 0.123, 0.219, 0.072, 0.131, 0.1, 0.087, 0.085, 0.063, 0.099, 0.085, 0.116, 0.07, 0.067, 0.082, 0.1, 0.278, 0.095, 0.132, 0.108, 0.083, 0.067, 0.07, 0.077, 0.077, 0.076, 0.09, 0.079, 0.098, 0.078, 0.08, 0.073, 0.104, 0.072, 0.079, 0.084, 0.678, 0.087, 0.083, 0.083, 0.088, 0.126, 0.082, 0.109, 0.106, 0.078, 0.074, 0.272, 0.086, 0.091, 0.081, 0.093, 0.094, 0.085, 0.086, 0.122, 0.062, 0.114, 0.064, 0.085, 0.085, 0.093, 0.134, 0.194, 0.084, 0.07, 0.068, 0.109, 0.092, 0.111, 0.07, 0.081, 0.071, 0.108, 0.11, 0.087, 0.105, 0.075, 0.072, 0.118, 0.085, 0.074, 0.065, 0.093, 0.067, 0.125, 0.083, 0.104, 0.069, 0.095, 0.098, 0.066, 0.1, 0.121, 0.274, 0.093, 0.075, 0.073, 0.069, 0.098, 0.085, 0.07, 0.092, 0.076, 0.088, 0.084, 0.079, 0.078, 0.093, 0.068, 0.134, 0.102, 0.071, 0.084, 0.072, 0.138, 0.095, 0.06, 0.073, 0.191, 0.077, 0.119, 0.09, 0.092, 0.1, 0.123, 0.082, 0.099, 0.098, 0.132, 0.077, 0.091, 0.115, 0.099, 0.082, 0.125, 0.267, 0.116, 0.129, 0.083, 0.088, 0.094, 0.128, 0.095, 0.084, 0.079, 0.069, 0.085, 0.067, 0.093, 0.086, 0.08, 0.076, 0.082, 0.094, 0.118, 0.111, 0.083, 0.099, 0.135, 0.087, 0.095, 0.086, 0.071, 0.072, 0.071, 0.071, 0.061, 0.069, 0.091, 0.069, 0.104, 0.078, 0.082, 0.098, 0.111, 0.077, 0.061, 0.075, 0.077, 0.083, 0.07, 0.095, 0.191, 0.186, 0.095, 0.117, 0.109, 0.105, 0.076, 0.091, 0.096, 0.1, 0.076, 0.087, 0.09, 0.077, 0.092, 0.078, 0.104, 0.066, 0.067, 0.087, 0.071, 0.065, 0.091, 0.102, 0.072, 0.072, 0.201, 0.074, 0.072, 0.113, 0.259, 0.073, 0.078, 0.078, 0.07, 0.073, 0.086, 0.23, 0.089, 0.065, 0.127, 0.098, 0.128, 0.145, 0.103, 0.097, 0.137, 0.086, 0.107, 0.113, 0.069, 0.091, 0.101, 0.078, 0.115, 0.14, 0.101, 0.125, 0.086, 0.067, 3.096, 0.085, 0.089, 0.086, 0.076, 0.09, 0.075, 0.104, 0.125, 0.157, 0.092, 0.22, 0.143, 0.107, 0.094, 0.102, 0.264, 0.152, 0.123, 0.081, 0.126, 0.091, 0.103, 0.096, 0.129, 0.099, 0.153, 0.139, 0.125, 0.088, 0.094, 0.148, 0.107, 0.087, 0.117, 0.097, 0.096, 0.082, 0.131, 0.13, 0.097, 0.122, 0.097, 0.12, 0.081, 0.101, 0.082, 0.632, 0.075, 0.121, 0.105, 0.105, 0.079, 0.081, 0.126, 0.091, 0.15, 0.134, 0.114, 0.175, 0.102, 0.092, 0.092, 0.087, 0.157, 0.092, 0.09, 0.086, 0.078, 0.108, 0.067, 0.094, 0.087, 0.087, 0.092, 0.099, 0.103, 0.192, 0.12, 0.118, 0.08, 0.091, 0.104, 0.083, 0.082, 0.09, 0.083, 0.082, 0.1, 0.137, 0.099, 0.125, 0.085, 0.18, 0.091, 0.1, 0.09, 0.123, 0.089, 0.104, 0.13, 0.082, 0.089, 0.098, 0.071, 0.071, 0.1, 0.086, 0.086, 0.162, 0.083, 0.084, 0.113, 0.101, 0.122, 0.094, 0.156, 0.098, 0.135, 0.177, 0.088, 0.093, 0.088, 0.074, 0.081, 0.075, 0.083, 0.167, 0.064, 0.107, 0.097, 0.138, 0.087, 0.121, 0.2, 0.092, 0.135, 0.121, 0.132, 1.336, 0.129, 0.088, 0.09, 0.16, 0.108, 0.09, 0.249, 0.115, 0.089, 0.134, 0.08, 0.087, 0.195, 0.097, 0.129, 0.091, 0.096, 0.147, 0.098, 0.086, 0.091, 0.088, 0.101, 0.134, 0.138, 0.09, 0.103, 0.096, 0.084, 0.1, 0.089, 0.084, 0.102, 0.105, 0.123, 0.149, 0.112, 0.091, 0.206, 0.101, 0.109, 0.086, 0.079, 0.084, 0.206, 0.081, 0.137, 0.104, 0.105, 0.092, 0.09, 0.088, 0.114, 0.106, 0.082, 0.127, 0.138, 0.141, 0.078, 0.078, 0.123, 0.11, 0.098, 0.116, 0.091, 0.147, 0.106, 0.21, 0.086, 0.128, 0.104, 0.106, 0.1, 0.08, 0.335, 0.09, 0.084, 0.134, 0.152, 0.112, 0.115, 0.105, 0.142, 0.1, 0.089, 0.09, 0.094, 0.107, 0.093, 0.133, 0.102, 0.308, 0.092, 0.097, 0.139, 0.1, 0.089, 0.112, 0.1, 0.089, 0.085, 0.096, 0.108, 0.091, 0.097, 0.09, 0.145, 0.089, 0.091, 0.098, 0.083, 0.15, 0.154, 0.091, 0.287, 0.088, 0.086, 0.104, 0.096, 0.087, 0.101, 0.091, 0.088, 0.09, 0.091, 0.091, 0.085, 0.088, 0.087, 0.351, 0.088, 0.075, 0.094, 0.147, 0.146, 0.084, 0.156, 0.081, 0.091, 0.089, 0.094, 0.098, 0.146, 0.129, 0.163, 0.087, 0.136, 0.161, 0.109, 0.098, 0.108, 0.107, 0.093, 0.166, 0.086, 0.117, 0.135, 0.093, 0.087, 0.089, 0.899, 0.079, 0.146, 0.092, 0.083, 0.155, 0.092, 0.095, 0.084, 0.078, 0.088, 0.08, 0.088, 0.082, 0.093, 0.095, 0.126, 0.124, 0.102, 0.098, 0.135, 0.124, 0.083, 0.079, 0.084, 0.076, 0.122, 0.088, 0.137, 0.102, 0.221, 0.087, 0.098, 0.091, 0.093, 0.084, 0.087, 0.146, 0.095, 0.084, 0.107, 0.117, 0.093, 0.116, 0.099, 0.094, 0.097, 0.075, 0.091, 0.072, 0.065, 0.112, 0.072, 0.105, 0.112, 0.077, 0.104, 0.073, 0.124, 0.166, 0.093, 0.08, 0.079, 0.123, 0.108, 0.085, 0.125, 0.087, 0.094, 0.097, 0.088, 0.092, 0.077, 0.096, 3.321, 0.136, 0.086, 0.116, 0.112, 0.153, 0.102, 0.097, 0.089, 0.129, 0.106, 0.083, 0.082, 0.069, 0.07, 0.161, 0.09, 0.096, 0.164, 0.083, 0.092, 0.08, 0.087, 0.081, 0.123, 0.092, 0.078, 0.081, 0.084, 0.105, 0.104, 0.203, 0.079, 0.085, 0.08, 0.091, 0.09, 0.08, 0.138, 0.117, 0.089, 1.429, 0.146, 0.093, 0.117, 0.098, 0.128, 0.098, 0.214, 0.121, 0.148, 0.122, 0.084, 0.072, 0.275, 0.093, 0.07, 0.065, 0.075, 0.095, 0.085, 0.071, 0.087, 0.085, 0.083, 0.09, 0.09, 0.074, 0.113, 0.118, 0.079, 0.1, 0.088, 0.095, 0.087, 0.136, 0.118, 0.108, 0.096, 0.097, 0.09, 0.076, 0.088, 0.075, 0.078, 0.099, 0.076, 0.08, 0.063, 0.759, 0.099, 0.09, 0.117, 0.112, 0.081, 0.108, 0.077, 0.079, 0.104, 0.118, 0.09, 0.075, 0.08, 0.073, 0.256, 0.238, 0.085, 0.096, 0.084, 0.095, 0.12, 0.076, 0.115, 0.081, 0.097, 0.125, 0.099, 0.095, 0.086, 0.132, 0.091, 0.106, 0.093, 0.076, 0.087, 0.094, 0.092, 0.116, 0.09, 0.084, 0.096, 0.084, 0.328, 0.078, 0.076, 0.086, 0.088, 0.087, 0.091, 0.075, 0.091, 0.089, 0.081, 0.082, 0.089, 0.093, 0.091, 0.081, 0.112, 0.103, 0.088, 0.086, 0.069, 0.097, 0.111, 0.079, 0.082, 0.127, 0.08, 0.111, 0.069, 0.142, 0.073, 0.087, 0.1, 0.082, 0.09, 0.128, 0.171, 0.083, 0.111, 0.1, 0.292, 0.122, 0.078, 0.086, 0.095, 0.097, 0.084, 0.11, 0.079, 0.285, 0.092, 0.1, 0.091, 0.089, 0.094, 0.089, 0.102, 0.07, 0.071, 0.072, 0.095, 0.116, 0.069, 0.084, 0.075, 0.119, 0.08, 0.096, 0.116, 0.092, 0.082, 0.073, 0.089, 0.084, 0.09, 0.081, 0.101, 0.106, 0.103, 0.097, 0.097, 0.082, 0.093, 0.077, 0.089, 0.08, 0.068, 0.088, 0.081, 0.119, 0.086, 0.115, 0.106, 0.123, 0.071, 0.093, 0.171, 0.083, 0.094, 0.081, 0.084, 0.111, 0.097, 0.106, 0.086, 0.089, 0.082, 0.104, 0.116, 0.12, 0.083, 0.114, 0.079, 0.083, 0.096, 0.096, 0.085, 0.171, 0.085, 0.217, 0.085, 0.085, 0.126, 0.145, 0.096, 0.094, 0.098, 0.08, 0.089, 0.097, 0.082, 0.111, 0.096, 0.074, 0.068, 0.085, 0.091, 0.095, 0.085, 0.093, 0.092, 0.084, 0.082, 0.084, 0.304, 0.08, 0.081, 0.09, 0.13, 0.166, 0.098, 0.129, 0.079, 0.063, 0.103, 0.094, 0.07, 0.127, 0.076, 0.081, 0.087, 0.082, 0.109, 0.067, 0.078, 0.086, 0.079, 0.081, 0.083, 0.09, 0.079, 0.11, 0.092, 0.221, 0.207, 0.125, 0.07, 0.063, 0.076, 0.082, 0.071, 0.082, 0.126, 0.117, 0.095, 0.089, 0.082, 0.12, 0.093, 0.11, 0.082, 0.128, 0.079, 0.122, 0.096, 0.116, 0.129, 0.116, 0.078, 0.085, 0.083, 0.098, 0.089, 0.119, 0.109, 0.089, 0.095, 0.137, 0.105, 0.095, 0.132, 0.096, 0.085, 0.112, 0.113, 0.106, 0.1, 0.114, 0.075, 0.082, 0.073, 0.07, 0.082, 0.134, 0.107, 0.104, 0.41, 0.071, 0.09, 0.097, 0.067, 0.097, 0.076, 0.068, 0.061, 0.069, 0.105, 0.107, 0.093, 0.122, 0.101, 0.069, 0.113, 0.104, 0.075, 0.104, 0.142, 0.097, 0.096, 0.082, 0.086, 0.069, 0.079, 0.106, 0.088, 0.113, 0.113, 0.106, 0.129, 0.097, 0.103, 0.068, 0.163, 0.143, 0.079, 0.1, 0.091, 0.071, 0.068, 0.139, 0.151, 0.089, 0.113, 0.081, 0.085, 0.096, 0.082, 0.091, 0.095, 0.1, 0.083, 0.088, 0.077, 0.118, 0.097, 0.08, 0.09, 0.101, 0.087, 0.098, 0.126, 0.092, 0.078, 0.096, 0.091, 0.097, 0.088, 0.109, 0.082, 0.095, 0.089, 0.097, 0.08, 0.09, 0.116, 0.09, 0.168, 0.123, 0.148, 0.099, 0.102, 0.088, 0.094, 0.108, 0.083, 0.134, 0.087, 0.091, 0.083, 0.092, 0.078, 0.104, 0.094, 0.084, 0.122, 0.122, 0.11, 0.099, 0.097, 0.101, 0.101, 0.083, 0.071, 0.097, 0.066, 0.069, 0.094, 0.081, 0.063, 0.123, 0.091, 0.102, 0.107, 0.128, 0.097, 1.129, 0.079, 0.088, 0.069, 0.092, 0.092, 0.105, 0.124, 0.09, 0.433, 0.119, 0.099, 0.1, 0.095, 0.096, 0.083, 0.106, 0.093, 0.117, 0.107, 0.096, 0.077, 0.083, 0.08, 0.092, 0.102, 0.099, 0.078, 0.072, 0.107, 0.088, 0.139, 0.08, 0.11, 0.091, 0.082, 0.097, 0.084, 0.135, 0.093, 0.086, 0.14, 0.09, 0.096, 0.148, 0.12, 0.085, 0.098, 0.114, 0.101, 0.087, 0.147, 0.087, 0.079, 0.069, 0.073, 0.07, 0.088, 0.127, 0.092, 0.078, 0.082, 0.083, 0.088, 0.106, 0.078, 0.061, 0.073, 0.076, 0.085, 0.07, 0.076, 0.091, 0.091, 0.075, 0.103, 0.177, 0.18, 0.141, 0.085, 0.107, 0.098, 0.081, 0.095, 0.086, 0.084, 0.125, 0.101, 0.091, 0.084, 0.083, 0.078, 0.079, 0.079, 0.081, 0.098, 0.09, 0.124, 0.09, 0.128, 0.106, 0.128, 0.089, 0.096, 0.071, 0.077, 0.136, 0.114, 0.084, 0.085, 0.089, 0.09, 0.103, 0.073, 0.075, 0.104, 0.078, 0.091, 0.13, 0.07, 0.099, 0.098, 0.083, 0.086, 0.105, 0.309, 0.094, 0.086, 0.088, 0.087, 0.086, 0.117, 0.116, 0.095, 0.098, 0.106, 0.109, 0.098, 0.095, 0.093, 0.238, 0.113, 0.129, 0.083, 0.095, 0.127, 0.134, 0.08, 0.096, 0.088, 0.085, 0.096, 0.089, 0.064, 0.09, 0.126, 0.091, 0.075, 0.103, 0.09, 0.141, 0.124, 0.116, 0.09, 0.527, 0.068, 0.207, 0.089, 0.086, 0.081, 0.105, 0.105, 0.079, 0.095, 0.092, 0.108, 0.102, 0.102, 0.137, 0.128, 0.09, 0.077, 0.093, 0.086, 0.079, 0.095, 0.091, 0.075, 0.077, 0.119, 0.089, 0.145, 0.099, 0.064, 0.098, 0.08, 0.088, 0.092, 0.08, 0.078, 0.066, 0.067, 0.063, 0.183, 0.089, 0.084, 0.185, 0.081, 0.069, 0.102, 0.074, 0.065, 0.086, 0.095, 0.073, 0.125, 0.086, 0.091, 0.158, 0.135, 0.094, 0.117, 0.095, 0.108, 0.093, 0.104, 0.084, 0.103, 0.129, 0.116, 0.099, 0.084, 0.083, 0.098, 0.101, 0.109, 0.304, 0.084, 0.07, 0.085, 0.105, 0.1, 0.074, 0.077, 0.079, 0.12, 0.077, 0.09, 0.09, 0.093, 0.108, 0.088, 0.116, 0.09, 0.084, 0.154, 0.13, 0.082, 0.067, 0.068, 0.114, 0.072, 0.099, 0.079, 0.105, 0.079, 0.075, 0.097, 0.145, 0.135, 0.067, 0.068, 0.081, 0.079, 0.073, 0.084, 0.102, 0.072, 0.089, 0.095, 0.378, 0.105, 0.112, 0.096, 0.081, 0.083, 0.081, 0.073, 0.074, 0.075, 0.108, 0.105, 0.091, 0.074, 0.076, 0.112, 0.215, 0.093, 0.122, 0.077, 0.11, 0.077, 0.096, 0.129, 0.102, 0.084, 0.088, 0.083, 0.07, 0.099, 0.067, 0.323, 0.085, 0.071, 0.083, 0.075, 0.141, 0.084, 0.145, 0.104, 0.116, 0.098, 0.07, 0.073, 0.093, 0.076, 0.072, 0.094, 0.061, 0.116, 0.068, 0.061, 0.08, 0.839, 0.129, 0.085, 0.316, 0.097, 0.088, 0.071, 0.125, 0.07, 0.084, 0.099, 0.111, 0.164, 0.071, 0.127, 0.096, 0.1, 0.093, 0.094, 0.073, 0.112, 0.112, 0.22, 0.089, 0.093, 0.09, 0.129, 0.112, 0.113, 0.089, 0.072, 0.088, 0.151, 0.075, 0.079, 0.11, 0.083, 0.137, 0.091, 0.08, 0.086, 0.126, 0.122, 0.099, 0.102, 0.084, 0.114, 0.098, 0.156, 0.079, 0.073, 0.083, 0.09, 0.114, 0.134, 0.137, 0.067, 0.111, 0.099, 0.07, 0.079, 0.128, 0.068, 0.08, 0.071, 0.077, 0.093, 0.084, 0.114, 0.07, 0.09, 0.083, 0.077, 0.067, 0.069, 0.076, 0.082, 0.117, 0.09, 0.1, 0.096, 0.074, 0.076, 0.079, 0.118, 0.083, 0.112, 0.109, 0.083, 0.077, 0.075, 0.104, 0.098, 0.272, 0.214, 0.069, 0.119, 0.09, 0.079, 0.071, 0.075, 0.105, 0.089, 0.086, 0.092, 0.082, 0.097, 0.07, 0.103, 0.102, 0.07, 0.08, 0.072, 0.069, 0.089, 0.064, 0.502, 0.091, 0.127, 0.075, 0.089, 0.099, 0.139, 0.11, 0.093, 0.087, 0.073, 0.065, 0.136, 0.063, 0.082, 0.072, 0.064, 0.079, 0.074, 0.069, 0.108, 0.107, 0.109, 0.123, 0.061, 0.079, 0.07, 0.071, 0.11, 0.076, 0.07, 0.126, 0.098, 0.091, 0.07, 0.089, 0.092, 0.086, 0.093, 0.187, 0.073, 0.098, 0.085, 0.2, 0.097, 0.15, 0.074, 0.097, 0.142, 0.081, 0.101, 0.204, 0.092, 0.085, 0.159, 0.087, 0.085, 0.089, 0.083, 0.097, 0.091, 0.068, 0.088, 0.096, 0.071, 0.071, 0.089, 0.074, 0.091, 0.094, 0.09, 0.074, 0.1, 0.129, 0.074, 0.083, 0.092, 0.087, 0.07, 0.101, 0.068, 0.079, 0.085, 0.105, 0.087, 0.08, 0.067, 0.08, 0.072, 0.087, 0.09, 0.218, 0.076, 0.076, 0.079, 0.065, 0.068, 0.163, 0.068, 0.068, 0.088, 0.098, 0.083, 0.089, 0.072, 0.099, 3.036, 0.061, 0.104, 0.065, 0.076, 0.07, 0.118, 0.083, 0.082, 0.095, 0.125, 0.092, 0.086, 0.091, 0.108, 0.08, 0.156, 0.068, 0.103, 0.326, 0.079, 0.096, 0.069, 0.094, 0.16, 0.074, 0.063, 0.112, 0.073, 0.085, 0.076, 0.084, 0.077, 0.078, 0.099, 0.065, 1.296, 0.109, 0.071, 0.112, 1.457, 0.077, 0.135, 0.084, 0.067, 0.094, 0.155, 0.071, 0.141, 0.07, 0.082, 0.076, 0.124, 0.127, 0.08, 0.092, 0.07, 0.078, 0.079, 0.08, 0.062, 0.078, 0.122, 0.083, 0.083, 0.069, 0.074, 0.074, 0.072, 0.079, 0.075, 0.083, 0.089, 0.099, 0.083, 0.095, 0.116, 0.081, 0.085, 0.081, 0.095, 0.121, 0.113, 0.089, 0.105, 0.084, 0.091, 0.115, 0.077, 0.072, 0.069, 0.106, 0.129, 0.107, 0.112, 0.11, 0.08, 0.083, 0.069, 0.1, 0.111, 0.079, 0.103, 0.272, 0.079, 0.114, 0.083, 0.103, 0.119, 0.088, 0.113, 0.068, 0.135, 0.144, 0.146, 0.074, 0.102, 0.067, 0.065, 0.164, 0.08, 0.08, 0.11, 0.066, 0.19, 0.076, 0.076, 0.093, 0.065, 0.077, 0.09, 0.074, 0.067, 0.093, 0.096, 0.098, 0.074, 0.106, 0.085, 0.106, 0.085, 0.076, 0.108, 0.117, 0.14, 0.085, 0.084, 0.127, 0.07, 0.071, 0.078, 0.096, 0.101, 0.108, 0.07, 0.261, 0.074, 0.076, 0.066, 0.587, 0.148, 0.086, 0.14, 0.128, 0.07, 0.075, 0.086, 0.094, 0.087, 0.284, 0.088, 0.101, 0.088, 0.098, 0.093, 0.098, 0.092, 0.08, 0.079, 0.093, 0.088, 0.102, 0.08, 0.07, 0.082, 0.079, 0.126, 0.066, 0.076, 0.07, 0.168, 0.076, 0.097, 0.091, 0.077, 0.069, 0.1, 0.083, 0.078, 0.081, 0.091, 0.06, 0.077, 0.104, 0.096, 0.088, 0.091, 0.085, 0.103, 0.073, 0.064, 0.074, 0.076, 0.111, 0.078, 0.216, 0.076, 0.109, 0.228, 0.075, 0.131, 0.129, 0.226, 0.09, 0.072, 0.09, 0.065, 0.085, 0.065, 0.07, 0.081, 0.087, 0.076, 0.107, 0.068, 0.077, 0.075, 0.138, 0.082, 0.08, 0.101, 0.203, 0.087, 0.086, 0.066, 0.069, 0.073, 0.126, 0.08, 0.153, 0.09, 0.083, 0.086, 0.077, 0.075, 0.09, 0.133, 0.067, 0.119, 0.134, 0.089, 0.075, 0.128, 0.086, 0.081, 0.084, 0.069, 0.106, 0.067, 0.061, 0.16, 0.066, 0.093, 0.082, 0.076, 0.168, 0.087, 0.084, 0.1, 0.074, 0.131, 0.074, 0.077, 0.096, 0.09, 0.098, 0.166, 0.082, 0.081, 0.124, 0.25, 0.095, 0.07, 0.064, 0.065, 0.128, 0.084, 0.083, 0.079, 0.105, 0.07, 0.065, 0.121, 0.104, 0.079, 0.149, 0.096, 0.093, 0.091, 0.094, 0.099, 0.068, 0.066, 0.09, 0.083, 0.07, 0.083, 0.103, 0.091, 0.681, 0.079, 0.073, 0.1, 0.069, 0.101, 0.074, 0.089, 0.091, 0.075, 0.11, 0.07, 0.1, 0.082, 0.086, 0.092, 0.086, 0.111, 0.072, 0.132, 0.109, 0.075, 0.093, 0.093, 0.076, 0.093, 0.076, 0.074, 0.1, 0.084, 0.076, 0.156, 0.087, 0.414, 0.078, 0.105, 0.094, 0.066, 0.071, 0.099, 0.105, 0.083, 0.071, 0.128, 0.065, 0.18, 0.16, 0.082, 0.078, 0.066, 0.066, 0.076, 0.067, 0.103, 0.087, 0.079, 0.075, 0.091, 0.105, 0.074, 0.095, 0.098, 0.082, 0.079, 0.069, 0.08, 0.062, 0.074, 0.1, 0.083, 0.078, 0.068, 0.095, 0.075, 0.105, 0.131, 0.099, 0.074, 0.073, 0.062, 0.063, 0.104, 0.08, 0.1, 0.089, 0.075, 0.102, 0.107, 0.093, 0.067, 0.085, 0.063, 0.118, 0.112, 0.068, 0.085, 0.088, 0.065, 0.073, 0.067, 0.064, 0.067, 0.081, 0.271, 0.118, 0.099, 0.077, 0.117, 0.091, 0.07, 0.061, 0.068, 0.073, 0.07, 0.09, 0.096, 0.105, 0.106, 0.09, 0.078, 0.074, 0.083, 0.124, 0.075, 0.093, 0.068, 0.105, 0.076, 0.071, 0.076, 0.066, 0.276, 0.088, 0.065, 0.074, 0.082, 0.063, 0.104, 0.095, 0.091, 0.086, 0.078, 0.059, 0.084, 0.074, 0.069, 0.069, 0.087, 0.096, 0.074, 0.094, 0.066, 0.07, 0.09, 0.097, 0.087, 0.065, 0.09, 0.067, 0.098, 0.078, 0.087, 0.064, 0.096, 0.105, 0.071, 0.078, 0.096, 0.126, 0.089, 0.116, 0.099, 0.084, 0.069, 0.071, 0.096, 0.06, 0.071, 0.082, 0.126, 0.081, 0.074, 0.096, 0.085, 0.073, 0.148, 0.081, 0.074, 0.079, 0.073, 0.091, 0.089, 0.095, 0.089, 0.069, 0.075, 0.093, 0.082, 0.084, 0.071, 0.072, 0.171, 0.069, 0.103, 0.101, 0.088, 0.126, 0.1, 0.087, 0.083, 0.063, 0.093, 0.094, 0.069, 0.093, 0.074, 0.062, 0.096, 0.094, 0.102, 0.132, 0.073, 0.071, 0.06, 0.065, 0.121, 0.105, 0.084, 0.062, 0.094, 0.109, 0.066, 0.117, 0.085, 0.083, 0.07, 0.072, 0.069, 0.083, 0.104, 0.068, 0.077, 0.08, 0.084, 0.073, 0.076, 0.065, 0.102, 0.069, 0.105, 0.119, 0.152, 0.082, 0.081, 0.078, 0.088, 0.069, 0.086, 0.075, 0.067, 0.094, 0.082, 0.073, 0.086, 0.188, 0.08, 0.072, 0.079, 0.09, 0.088, 0.066, 1.078, 0.082, 0.104, 0.142, 0.12, 0.13, 0.104, 0.082, 0.125, 0.094, 0.114, 0.073, 0.088, 0.071, 0.097, 0.079, 0.07, 0.066, 0.293, 0.086, 0.116, 0.122, 0.085, 0.08, 0.156, 0.109, 0.075, 0.104, 0.102, 0.141, 0.075, 0.087, 0.068, 0.119, 0.083, 0.076, 0.098, 0.113, 0.09, 0.207, 0.112, 0.07, 0.089, 0.077, 0.084, 0.092, 0.077, 0.074, 0.081, 0.082, 0.094, 0.074, 0.078, 0.133, 0.084, 0.097, 0.207, 0.085, 0.09, 0.078, 0.135, 0.081, 0.357, 0.089, 0.238, 0.102, 0.068, 0.124, 0.091, 0.083, 0.063, 0.084, 0.087, 0.073, 0.075, 0.07, 0.084, 0.125, 0.068, 0.066, 0.077, 0.087, 0.066, 0.068, 0.096, 0.094, 0.208, 0.115, 0.126, 0.096, 0.125, 0.095, 0.074, 0.109, 0.058, 0.061, 0.072, 0.06, 0.063, 0.058, 0.077, 0.068, 0.08, 0.078, 0.116, 0.126, 0.089, 0.082, 0.108, 0.128, 0.127, 0.105, 0.109, 0.07, 0.139, 0.09, 0.131, 0.143, 0.144, 0.076, 0.084, 0.097, 0.144, 0.094, 0.136, 0.081, 0.083, 0.084, 0.111, 0.092, 0.083, 0.099, 0.11, 0.074, 0.092, 0.073, 0.074, 0.095, 0.083, 0.078, 0.084, 0.074, 0.092, 0.121, 0.077, 0.115, 0.078, 0.103, 0.135, 0.101, 0.099, 0.084, 0.08, 0.107, 0.093, 0.11, 0.082, 0.137, 0.08, 0.094, 0.069, 0.114, 0.09, 0.083, 0.083, 0.12, 0.163, 0.097, 0.132, 0.096, 0.076, 0.059, 0.069, 0.095, 0.092, 0.108, 0.086, 0.083, 0.146, 0.085, 0.11, 0.082, 0.081, 0.15, 0.145, 0.08, 0.09, 0.105, 0.086, 0.072, 0.058, 0.091, 0.074, 0.105, 0.134, 0.11, 0.086, 0.105, 0.134, 0.111, 0.077, 2.943, 0.084, 0.093, 0.085, 0.086, 0.085, 0.082, 0.074, 0.091, 0.103, 0.067, 0.089, 0.084, 0.078, 0.072, 0.298, 0.08, 0.064, 0.07, 0.068, 0.081, 0.089, 0.06, 0.063, 0.075, 0.143, 0.086, 0.077, 0.081, 0.09, 0.133, 0.138, 0.089, 0.287, 0.098, 0.085, 0.137, 0.095, 0.078, 0.084, 0.102, 0.096, 0.07, 0.213, 0.174, 0.068, 0.121, 0.129, 0.1, 0.088, 0.134, 0.108, 0.086, 0.097, 0.082, 0.084, 0.075, 0.085, 0.08, 0.073, 0.117, 0.085, 0.063, 0.071, 0.069, 0.101, 0.071, 0.106, 0.091, 0.093, 0.077, 0.121, 0.082, 0.107, 0.08, 0.079, 0.074, 0.144, 0.088, 0.072, 0.134, 0.104, 0.113, 0.086, 0.13, 0.13, 0.207, 0.095, 0.074, 0.081, 0.1, 0.099, 0.108, 0.092, 0.074, 0.071, 0.086, 0.088, 0.088, 0.082, 0.092, 0.093, 0.136, 0.109, 0.075, 0.103, 0.077, 0.087, 0.08, 0.102, 0.065, 0.086, 0.096, 0.087, 0.086, 0.088, 0.1, 0.071, 0.101, 0.102, 0.102, 0.084, 0.075, 0.088, 0.661, 0.116, 0.091, 0.121, 0.081, 0.136, 0.112, 0.084, 0.077, 0.1, 0.092, 0.13, 0.087, 0.09, 0.094, 0.075, 0.123, 0.091, 0.089, 0.082, 0.077, 0.083, 0.079, 0.065, 0.118, 0.079, 1.189, 0.094, 0.07, 0.067, 0.071, 0.075, 0.085, 0.088, 0.078, 0.094, 0.074, 0.08, 0.064, 0.068, 0.067, 0.078, 0.077, 0.068, 0.121, 0.069, 0.088, 0.082, 0.088, 0.13, 0.098, 0.08, 0.142, 0.12, 0.07, 0.153, 0.078, 0.15, 0.075, 0.076, 0.081, 0.103, 0.079, 0.072, 0.154, 0.111, 0.089, 0.157, 0.115, 0.104, 0.11, 0.171, 0.104, 0.118, 0.088, 0.095, 0.095, 0.084, 0.103, 0.069, 0.073, 0.116, 0.075, 0.066, 0.085, 0.082, 0.112, 0.108, 0.121, 0.089, 0.165, 0.091, 0.103, 0.064, 0.073, 0.074, 0.06, 0.173, 0.082, 0.096, 0.221, 0.086, 0.073, 0.088, 0.09, 0.136, 0.097, 0.085, 0.122, 0.086, 0.08, 0.081, 0.09, 0.08, 0.095, 0.076, 0.113, 0.093, 0.073, 0.073, 0.064, 0.063, 0.072, 0.079, 0.069, 0.093, 0.074, 0.081, 0.105, 0.087, 0.097, 0.093, 0.072, 0.213, 0.079, 0.081, 0.104, 0.082, 0.104, 0.073, 0.071, 0.075, 0.09, 0.096, 0.069, 0.105, 0.074, 0.062, 0.096, 0.084, 0.081, 0.127, 0.105, 0.084, 0.075, 0.2, 0.106, 0.201, 0.101, 0.061, 0.08, 0.084, 0.081, 0.081, 0.076, 0.095, 0.085, 0.099, 0.086, 0.09, 0.093, 0.08, 0.104, 0.089, 0.134, 0.089, 0.087, 0.102, 0.089, 0.089, 0.092, 0.11, 0.094, 0.091, 0.114, 0.093, 0.09, 0.111, 0.213, 0.095, 0.067, 0.078, 0.098, 0.077, 0.087, 0.104, 0.092, 0.084, 0.086, 0.072, 0.085, 0.084, 0.106, 0.077, 0.104, 0.123, 0.093, 0.081, 0.085, 0.085, 0.097, 0.102, 0.071, 0.071, 0.08, 0.068, 0.086, 0.12, 0.144, 0.08, 0.067, 0.075, 0.107, 0.085, 0.079, 0.082, 0.067, 0.073, 0.201, 0.077, 0.071, 0.086, 0.074, 0.387, 0.082, 0.124, 0.109, 0.084, 0.294, 0.403, 0.073, 0.084, 0.075, 0.067, 0.074, 0.084, 0.13, 0.112, 0.076, 0.115, 0.083, 0.072, 0.072, 0.098, 0.067, 0.106, 0.104, 0.082, 0.105, 0.165, 0.087, 0.078, 0.114, 0.132, 0.067, 0.067, 0.069, 0.057, 0.084, 0.074, 0.102, 0.09, 0.087, 0.151, 0.096, 0.089, 0.071, 0.078, 0.077, 0.093, 0.086, 0.081, 0.079, 0.128, 0.088, 0.069, 0.077, 0.073, 0.081, 0.084, 0.083, 0.147, 0.081, 0.078, 0.093, 0.078, 0.077, 0.081, 0.089, 0.087, 0.086, 0.083, 0.064, 0.069, 0.062, 0.09, 0.078, 0.099, 0.114, 0.108, 0.076, 0.084, 0.082, 0.076, 0.062, 0.063, 0.069, 0.08, 0.093, 0.091, 0.1, 0.091, 0.074, 0.081, 0.084, 0.138, 0.09, 0.093, 0.073, 0.079, 0.086, 0.092, 0.094, 0.096, 0.101, 0.074, 0.086, 0.073, 0.081, 0.069, 0.079, 0.113, 0.128, 0.072, 0.098, 0.093, 0.078, 0.065, 0.079, 0.082, 0.1, 0.084, 0.077, 0.073, 0.106, 0.09, 0.09, 0.112, 0.08, 0.083, 0.09, 0.097, 0.075, 0.077, 0.085, 0.083, 0.077, 0.073, 0.083, 0.094, 0.079, 0.077, 0.094, 0.134, 0.068, 0.069, 0.066, 0.091, 0.084, 0.095, 0.086, 0.068, 0.072, 0.071, 0.07, 0.071, 0.061, 0.089, 0.124, 0.117, 0.093, 0.063, 0.103, 0.111, 0.095, 0.128, 0.101, 0.081, 0.079, 0.107, 0.086, 0.099, 0.079, 0.084, 0.071, 0.102, 0.073, 0.098, 0.095, 0.078, 0.068, 0.068, 0.084, 0.064, 0.072, 0.075, 0.082, 0.081, 0.063, 0.16, 0.079, 0.109, 0.08, 0.071, 0.085, 0.448, 0.086, 0.08, 0.098, 0.107, 0.095, 0.08, 0.09, 0.089, 0.098, 0.129, 0.09, 0.086, 0.12, 0.073, 0.275, 0.132, 0.083, 0.088, 0.139, 0.097, 0.095, 0.08, 0.07, 0.107, 0.1, 0.096, 0.101, 0.088, 0.072, 0.079, 0.066, 0.085, 0.082, 0.103, 0.078, 0.07, 0.09, 0.088, 0.085, 0.081, 0.088, 0.085, 0.075, 0.062, 0.125, 0.081, 0.093, 0.108, 0.08, 0.08, 0.069, 0.087, 0.066, 0.28, 0.079, 0.078, 0.264, 0.084, 0.071, 0.185, 0.084, 0.101, 0.06, 0.071, 0.111, 0.073, 0.274, 0.075, 0.076, 0.08, 0.062, 0.079, 0.082, 0.097, 0.081, 0.086, 0.1, 0.095, 0.079, 0.104, 0.076, 0.076, 0.13, 0.084, 0.093, 0.092, 0.101, 0.204, 0.086, 0.079, 0.061, 0.123, 0.092, 0.101, 0.096, 0.098, 0.094, 0.095, 0.084, 0.093, 0.147, 0.094, 0.098, 0.066, 0.111, 0.131, 0.086, 0.098, 0.103, 0.133, 0.093, 0.098, 0.116, 1.033, 0.078, 0.079, 0.135, 0.15, 0.081, 0.086, 0.089, 0.169, 0.102, 0.086, 0.097, 0.102, 0.172, 0.161, 0.061, 0.065, 0.083, 0.079, 0.081, 0.062, 0.102, 0.162, 0.088, 0.064, 0.107, 0.115, 0.084, 0.127, 0.096, 0.238, 1.517, 0.072, 0.083, 0.093, 0.065, 0.085, 0.083, 0.077, 0.106, 0.093, 0.82, 0.139, 0.087, 0.107, 0.093, 0.111, 0.121, 0.124, 0.104, 0.092, 0.083, 0.088, 0.128, 0.085, 0.077, 0.087, 0.094, 0.076, 0.301, 0.073, 0.07, 0.072, 0.113, 0.088, 0.075, 0.083, 0.075, 0.078, 0.085, 0.084, 0.082, 0.154, 0.112, 0.085, 0.095, 0.081, 0.088, 0.154, 0.098, 0.083, 0.095, 0.09, 0.072, 0.083, 0.101, 0.068, 0.071, 0.077, 0.081, 0.072, 0.096, 0.086, 0.107, 0.073, 0.095, 0.092, 0.086, 0.086, 0.075, 0.069, 0.088, 0.13, 0.122, 0.085, 0.077, 0.067, 0.084, 0.08, 0.067, 0.082, 0.076, 0.112, 0.337, 0.137, 0.075, 0.085, 0.079, 0.093, 0.75, 0.114, 0.084, 0.083, 0.084, 0.121, 0.11, 0.09, 0.074, 0.089, 0.102, 0.197, 0.112, 0.091, 0.09, 0.068, 0.073, 0.076, 0.086, 0.124, 0.093, 0.095, 0.076, 0.087, 0.086, 0.098, 0.089, 0.081, 0.104, 0.073, 0.078, 0.228, 0.087, 0.185, 0.087, 0.081, 0.095, 0.088, 0.104, 0.093, 0.111, 0.098, 0.078, 0.101, 0.094, 0.125, 0.085, 0.122, 0.095, 0.242, 0.075, 0.09, 0.08, 0.087, 0.097, 0.096, 0.103, 0.098, 0.124, 0.085, 0.068, 0.085, 0.095, 0.136, 0.06, 0.068, 0.123, 0.084, 0.167, 0.097, 0.089, 0.073, 0.1, 0.109, 0.09, 0.089, 0.075, 0.104, 0.121, 0.089, 0.104, 0.085, 0.096, 0.085, 0.082, 0.09, 0.089, 0.102, 0.098, 0.091, 0.093, 0.096, 0.083, 0.066, 0.108, 0.079, 0.111, 0.094, 0.079, 0.083, 0.084, 0.088, 0.102, 0.12, 0.078, 0.109, 0.088, 0.182, 0.083, 0.088, 0.077, 0.072, 0.11, 0.071, 0.081, 0.074, 0.093, 0.104, 0.109, 0.068, 0.065, 0.063, 0.078, 0.245, 0.071, 0.075, 0.088, 0.082, 0.092, 0.082, 0.087, 0.088, 0.124, 0.118, 0.239, 0.084, 0.13, 0.125, 0.061, 0.103, 0.089, 0.115, 0.083, 0.082, 0.098, 0.114, 0.073, 0.077, 0.08, 0.079, 0.097, 0.08, 0.117, 0.113, 0.094, 0.071, 0.089, 0.071, 0.072, 0.069, 0.117, 0.133, 0.085, 0.076, 0.085, 0.076, 0.101, 0.082, 0.09, 0.089, 0.066, 0.086, 0.123, 0.073, 0.077, 0.072, 0.083, 0.093, 0.085, 0.076, 0.072, 0.088, 0.075, 0.066, 0.079, 0.077, 0.095, 0.074, 0.228, 0.082, 0.116, 0.078, 0.19, 0.069, 0.081, 0.083, 0.106, 0.082, 0.1, 0.152, 0.105, 0.216, 0.082, 0.072, 0.09, 0.092, 0.085, 0.062, 0.073, 0.124, 0.096, 0.093, 0.097, 0.076, 0.102, 0.134, 0.073, 0.109, 0.084, 0.079, 0.082, 0.098, 0.113, 0.097, 0.139, 0.086, 0.088, 0.082, 0.115, 0.089, 0.108, 0.083, 0.098, 0.077, 0.085, 0.075, 0.101, 0.134, 0.09, 0.079, 0.086, 0.111, 0.102, 0.087, 0.116, 0.129, 0.115, 0.091, 0.074, 0.091, 0.135, 0.097, 0.117, 0.128, 0.16, 0.119, 0.093, 0.141, 0.144, 0.123, 0.12, 0.122, 0.099, 0.077, 0.081, 0.084
    #         ]
    #     ], 
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             0.173, 0.151, 0.172, 0.212, 0.17, 0.164, 0.223, 0.231, 0.152, 0.256, 0.157, 0.152, 0.166, 0.61, 0.159, 0.151, 0.157, 0.192, 0.139, 0.15, 0.128, 0.192, 0.17, 0.162, 0.143, 0.125, 0.21, 0.148, 0.254, 0.136, 0.195, 0.19, 0.142, 0.137, 0.231, 0.212, 0.126, 0.16, 0.122, 0.126, 0.119, 0.211, 0.121, 0.421, 0.161, 0.192, 0.178, 0.182, 0.189, 0.203, 0.14, 0.136, 0.231, 0.124, 0.111, 0.274, 0.206, 0.122, 0.153, 0.14, 0.191, 0.128, 0.151, 0.161, 0.327, 0.159, 0.142, 0.145, 0.126, 0.134, 0.143, 0.194, 0.126, 0.169, 0.141, 0.134, 0.096, 0.148, 0.2, 0.21, 0.177, 0.178, 0.283, 0.141, 0.177, 0.201, 0.186, 0.163, 0.15, 0.125, 0.111, 0.155, 0.138, 0.175, 0.188, 0.134, 0.155, 0.17, 0.234, 0.271, 0.178, 0.203, 0.166, 0.132, 0.144, 0.155, 0.156, 0.186, 0.195, 0.211, 0.118, 0.187, 0.217, 0.128, 0.182, 0.226, 0.198, 0.525, 0.185, 0.155, 0.132, 0.137, 0.204, 0.177, 0.14, 0.195, 0.177, 0.158, 0.152, 0.144, 2.159, 0.143, 0.224, 0.215, 0.138, 0.175, 0.145, 0.143, 0.21, 0.16, 0.156, 0.14, 0.166, 0.142, 0.28, 0.158, 0.149, 0.121, 0.238, 0.195, 0.141, 0.192, 0.241, 0.136, 0.18, 0.226, 0.208, 0.208, 0.195, 0.155, 0.199, 0.167, 0.21, 0.185, 0.26, 0.14, 0.134, 0.165, 0.14, 0.274, 0.201, 0.21, 0.162, 0.227, 0.159, 0.148, 0.152, 0.14, 0.155, 1.205, 0.159, 0.122, 0.138, 0.2, 0.129, 0.221, 0.215, 0.224, 0.164, 0.13, 0.149, 0.148, 0.243, 0.235, 0.193, 0.143, 0.167, 0.133, 0.179, 0.192, 0.134, 0.145, 0.202, 0.15, 0.167, 0.169, 0.218, 0.21, 0.17, 0.152, 0.183, 0.24, 0.145, 0.13, 0.144, 0.123, 0.144, 0.147, 0.143, 0.176, 0.202, 0.231, 0.238, 0.253, 0.217, 0.143, 0.189, 0.158, 0.139, 0.457, 0.224, 0.133, 0.209, 0.151, 0.22, 0.176, 0.141, 0.149, 0.242, 0.133, 0.12, 0.114, 0.155, 0.12, 0.168, 0.165, 0.122, 0.122, 0.12, 0.123, 0.094, 0.123, 0.105, 0.194, 0.119, 0.201, 0.123, 0.17, 0.125, 0.102, 0.155, 0.157, 0.141, 0.298, 0.18, 0.131, 0.123, 0.124, 0.163, 0.374, 0.126, 0.185, 0.157, 0.191, 0.182, 0.169, 0.111, 0.135, 0.21, 0.217, 0.181, 0.124, 0.126, 0.108, 0.13, 0.143, 0.174, 0.205, 0.205, 0.218, 0.189, 0.164, 0.152, 0.15, 0.183, 0.189, 0.152, 0.18, 0.136, 0.112, 0.357, 0.158, 0.182, 0.165, 0.173, 0.177, 0.156, 0.167, 0.173, 0.204, 0.125, 0.151, 0.148, 0.127, 0.108, 0.113, 0.13, 0.262, 0.141, 0.187, 0.13, 0.122, 0.108, 0.097, 0.11, 0.129, 0.185, 0.103, 0.147, 0.184, 0.129, 0.148, 0.115, 0.138, 0.122, 0.134, 0.152, 0.153, 0.103, 0.147, 0.117, 0.124, 0.177, 0.114, 0.13, 0.124, 0.196, 0.19, 0.217, 0.176, 0.118, 0.202, 0.138, 0.138, 0.166, 0.227, 0.179, 0.103, 0.243, 0.939, 0.115, 0.18, 0.171, 0.182, 0.143, 0.186, 0.125, 0.218, 0.144, 0.2, 0.197, 0.155, 0.127, 0.113, 0.293, 0.248, 0.114, 0.136, 0.151, 0.167, 0.15, 0.949, 0.186, 0.132, 0.207, 0.168, 0.17, 0.151, 0.134, 0.142, 0.164, 0.209, 0.169, 0.1, 0.175, 0.209, 0.203, 0.152, 0.191, 0.137, 0.17, 0.144, 0.146, 0.193, 0.141, 0.15, 0.182, 0.201, 0.122, 0.179, 0.161, 0.235, 0.199, 0.133, 0.187, 0.156, 0.136, 0.134, 0.362, 0.128, 0.241, 0.236, 0.187, 0.139, 0.154, 0.213, 0.192, 0.202, 0.13, 0.121, 0.127, 0.194, 0.133, 0.16, 0.115, 0.155, 0.167, 0.14, 0.126, 0.218, 0.114, 0.181, 0.16, 0.178, 0.21, 0.128, 0.159, 0.186, 0.156, 0.139, 0.125, 0.119, 0.121, 0.123, 0.17, 0.102, 0.161, 0.182, 0.187, 0.183, 0.108, 0.117, 0.142, 0.146, 0.12, 0.171, 0.139, 0.144, 0.143, 0.12, 0.124, 0.094, 0.104, 0.177, 0.196, 0.239, 0.128, 0.122, 0.108, 0.096, 0.1, 0.726, 0.155, 0.153, 0.124, 0.163, 0.202, 0.147, 0.15, 0.122, 0.119, 0.204, 0.169, 0.319, 0.128, 0.085, 0.098, 0.11, 0.117, 0.179, 0.152, 0.121, 0.164, 0.143, 0.156, 0.137, 0.217, 0.191, 0.128, 0.135, 0.12, 0.134, 0.199, 0.128, 0.167, 0.12, 0.11, 0.156, 0.176, 0.124, 0.129, 0.187, 0.136, 0.118, 0.176, 0.097, 0.278, 0.147, 0.355, 0.141, 0.599, 0.314, 0.122, 0.118, 0.116, 0.106, 0.125, 0.167, 0.104, 0.106, 0.209, 0.133, 0.178, 0.143, 0.198, 0.167, 0.141, 0.167, 0.102, 0.103, 0.109, 0.14, 0.106, 0.148, 0.113, 0.141, 0.13, 0.104, 0.156, 0.159, 0.144, 0.152, 0.146, 0.188, 0.102, 0.114, 0.163, 0.175, 0.115, 0.216, 0.162, 0.146, 0.133, 0.123, 0.131, 0.13, 0.11, 0.141, 0.124, 0.195, 0.363, 0.134, 0.12, 0.181, 0.185, 0.148, 0.163, 0.136, 0.109, 0.129, 0.1, 0.118, 1.186, 0.119, 0.164, 0.166, 0.194, 0.145, 0.166, 0.146, 0.114, 0.182, 0.205, 0.134, 0.145, 0.134, 0.138, 0.151, 0.161, 0.137, 0.154, 0.225, 0.103, 0.086, 0.107, 0.11, 0.136, 0.116, 0.144, 0.176, 0.155, 0.141, 0.128, 0.148, 0.144, 0.145, 0.116, 0.144, 0.129, 0.125, 0.171, 0.17, 0.215, 0.199, 0.141, 0.112, 0.124, 0.108, 0.142, 0.126, 0.135, 0.197, 0.186, 0.187, 0.18, 0.142, 0.134, 0.158, 0.115, 0.239, 0.15, 0.123, 0.143, 0.129, 0.139, 0.314, 0.129, 0.153, 0.151, 0.186, 0.185, 0.167, 0.136, 0.117, 0.294, 0.12, 0.139, 0.133, 0.128, 0.16, 0.175, 0.22, 0.166, 0.113, 0.129, 0.138, 0.169, 0.187, 0.143, 0.158, 0.115, 0.106, 0.223, 0.171, 0.264, 0.176, 0.163, 0.125, 0.115, 0.164, 0.159, 0.162, 0.121, 0.11, 0.123, 0.128, 0.97, 0.138, 0.11, 0.109, 0.115, 0.113, 0.104, 0.257, 0.107, 0.145, 0.161, 0.121, 0.178, 0.137, 0.154, 0.166, 0.205, 0.189, 0.236, 0.2, 0.228, 0.177, 0.151, 0.193, 0.147, 0.16, 0.141, 0.217, 0.104, 0.099, 0.116, 0.152, 0.122, 0.168, 0.135, 0.099, 0.163, 0.16, 0.427, 0.158, 0.183, 0.126, 0.952, 0.16, 0.141, 0.21, 0.155, 0.139, 0.242, 0.148, 0.083, 0.275, 0.124, 0.105, 0.115, 0.114, 0.13, 0.128, 0.178, 0.203, 0.11, 0.102, 0.117, 0.131, 0.115, 0.111, 0.134, 0.178, 0.208, 0.111, 0.163, 0.863, 0.159, 0.185, 0.227, 0.123, 0.172, 0.101, 0.106, 0.128, 0.177, 0.132, 0.145, 0.112, 0.197, 0.145, 0.235, 0.134, 0.135, 0.134, 0.134, 0.152, 0.126, 0.106, 0.098, 0.128, 0.15, 0.198, 0.148, 0.226, 0.124, 0.115, 0.108, 0.106, 0.145, 0.19, 0.135, 0.114, 0.116, 0.152, 0.125, 0.142, 0.117, 0.158, 0.101, 0.157, 0.084, 0.141, 0.118, 0.168, 0.149, 0.12, 0.144, 0.149, 0.161, 0.082, 0.136, 0.125, 0.111, 0.184, 0.168, 0.141, 0.129, 0.111, 0.153, 0.117, 0.131, 0.392, 0.132, 0.103, 0.117, 0.118, 0.2, 0.157, 0.139, 0.133, 0.169, 0.199, 0.119, 0.149, 0.116, 0.181, 0.162, 0.148, 0.113, 0.125, 0.207, 0.165, 0.147, 0.187, 0.165, 0.174, 0.223, 0.164, 0.151, 0.178, 0.165, 0.132, 0.165, 0.271, 0.209, 0.143, 0.131, 0.155, 0.134, 0.131, 0.123, 0.146, 0.139, 0.548, 0.121, 0.174, 0.143, 0.127, 0.26, 0.132, 0.115, 0.113, 0.179, 0.16, 0.107, 0.116, 0.221, 0.101, 0.12, 0.165, 0.098, 0.174, 0.161, 0.164, 0.181, 0.118, 0.151, 0.183, 0.186, 0.164, 0.167, 0.195, 0.306, 0.084, 0.117, 0.108, 0.114, 0.152, 0.149, 0.126, 0.205, 0.101, 0.145, 0.161, 0.199, 0.239, 0.128, 0.186, 0.142, 0.169, 0.128, 0.158, 0.204, 0.285, 0.151, 0.112, 0.194, 0.127, 0.186, 0.144, 0.149, 0.134, 0.204, 0.144, 0.186, 0.169, 0.131, 0.119, 0.126, 0.107, 0.152, 0.107, 0.208, 0.128, 0.172, 0.138, 0.217, 0.195, 0.17, 0.188, 0.165, 0.157, 0.124, 0.145, 0.217, 0.11, 0.102, 0.109, 0.159, 0.203, 0.103, 0.268, 0.127, 0.136, 0.137, 0.224, 0.15, 0.16, 0.179, 0.145, 0.116, 0.141, 0.147, 0.168, 0.169, 0.153, 2.091, 0.093, 0.092, 0.123, 0.19, 0.167, 0.256, 0.12, 0.244, 0.202, 0.16, 0.117, 0.137, 0.177, 0.17, 0.133, 0.18, 0.115, 0.1, 0.155, 0.188, 0.114, 0.162, 0.102, 0.484, 0.186, 0.125, 0.166, 0.173, 0.143, 0.155, 0.124, 0.173, 0.111, 0.109, 0.149, 0.138, 0.099, 0.108, 0.208, 0.187, 0.151, 0.135, 0.149, 0.122, 0.157, 0.134, 0.169, 0.152, 0.21, 0.159, 0.171, 0.126, 0.117, 0.1, 0.114, 0.088, 0.096, 0.105, 0.18, 0.203, 0.124, 0.108, 0.097, 0.161, 0.141, 0.188, 0.198, 0.143, 0.125, 1.031, 0.112, 0.155, 0.202, 0.133, 0.191, 0.226, 0.203, 0.105, 0.201, 0.141, 0.16, 0.209, 0.124, 0.13, 0.154, 0.15, 0.203, 0.205, 0.22, 0.174, 0.133, 0.228, 0.166, 0.157, 0.104, 0.143, 0.11, 0.186, 0.219, 0.161, 0.141, 0.127, 0.171, 0.201, 0.133, 0.124, 0.274, 0.133, 0.182, 0.124, 0.148, 0.111, 0.134, 0.161, 0.168, 0.287, 0.152, 0.126, 0.182, 0.107, 0.112, 0.104, 0.193, 0.132, 0.145, 0.172, 0.29, 0.104, 0.132, 0.12, 0.103, 0.121, 0.123, 0.108, 0.319, 0.137, 0.211, 0.18, 0.109, 0.141, 0.184, 0.163, 0.177, 0.251, 0.146, 0.141, 0.213, 0.213, 0.153, 0.716, 0.178, 0.106, 0.16, 0.121, 0.109, 0.107, 0.114, 0.158, 0.179, 0.192, 0.193, 0.134, 0.178, 0.149, 0.221, 0.117, 0.147, 0.133, 0.192, 0.122, 0.156, 0.148, 0.175, 0.12, 0.115, 0.168, 0.159, 0.151, 0.157, 0.213, 0.121, 0.187, 0.206, 0.112, 0.127, 0.111, 2.406, 0.164, 0.175, 0.18, 0.145, 0.227, 0.096, 0.095, 0.137, 0.165, 0.107, 0.106, 0.177, 0.105, 0.092, 0.218, 0.212, 0.124, 0.172, 0.194, 0.155, 1.178, 0.12, 0.11, 0.193, 0.148, 0.128, 0.256, 0.12, 0.099, 0.126, 0.099, 0.108, 0.133, 0.197, 0.188, 0.15, 0.126, 0.18, 0.159, 0.106, 0.13, 0.143, 0.219, 0.135, 0.677, 0.255, 0.174, 0.188, 0.178, 0.188, 0.12, 0.244, 0.248, 0.114, 0.167, 0.214, 0.127, 0.205, 0.137, 0.165, 0.139, 0.096, 0.143, 0.133, 0.116, 0.292, 0.105, 0.11, 0.124, 0.118, 0.132, 0.136, 0.146, 0.18, 0.12, 0.104, 0.148, 0.11, 0.171, 0.179, 0.175, 0.156, 0.121, 0.213, 0.105, 0.444, 0.201, 0.211, 0.119, 0.144, 0.273, 0.121, 0.114, 0.117, 0.128, 0.149, 0.197, 0.149, 0.208, 0.168, 0.138, 0.128, 0.141, 0.124, 0.149, 0.145, 0.152, 0.154, 0.154, 0.136, 0.151, 0.154, 0.164, 0.18, 0.122, 0.143, 0.164, 0.187, 0.174, 0.196, 0.232, 0.211, 0.154, 0.137, 0.185, 0.213, 0.14, 0.147, 0.097, 0.089, 0.124, 0.196, 0.126, 0.131, 0.135, 0.123, 0.117, 0.311, 0.131, 0.188, 0.178, 0.157, 0.172, 0.17, 0.164, 0.149, 0.16, 0.154, 0.144, 0.1, 0.195, 0.207, 0.308, 0.158, 0.131, 0.134, 0.239, 0.181, 0.122, 0.229, 0.211, 0.166, 0.171, 0.143, 0.139, 0.117, 0.127, 0.156, 0.12, 0.175, 0.179, 0.13, 0.174, 0.188, 0.172, 0.135, 0.109, 0.164, 0.347, 0.153, 0.154, 0.133, 0.108, 0.119, 0.141, 0.172, 0.172, 0.134, 0.161, 0.14, 0.128, 0.132, 0.195, 0.171, 0.206, 0.201, 0.226, 0.174, 0.154, 0.104, 0.179, 0.142, 0.133, 0.118, 0.137, 0.148, 0.128, 0.145, 0.142, 0.151, 0.125, 0.117, 0.132, 0.121, 0.132, 0.124, 0.14, 0.137, 0.178, 0.173, 0.155, 0.133, 0.129, 0.19, 0.114, 0.125, 0.181, 0.178, 0.188, 0.164, 0.144, 0.133, 0.188, 0.106, 0.129, 0.15, 0.167, 0.18, 0.963, 0.12, 0.128, 0.165, 0.336, 0.145, 0.134, 0.103, 0.123, 0.167, 0.1, 0.13, 0.162, 0.152, 0.128, 0.128, 0.119, 0.096, 0.098, 0.198, 0.136, 0.111, 0.222, 0.106, 0.147, 0.135, 0.107, 0.095, 0.126, 0.146, 0.117, 0.123, 0.145, 0.1, 0.155, 0.122, 0.205, 0.2, 0.248, 0.147, 0.131, 0.122, 0.13, 0.173, 0.123, 0.118, 0.128, 0.135, 0.161, 0.19, 0.174, 0.17, 0.13, 0.201, 0.127, 0.171, 0.145, 0.144, 0.149, 0.221, 0.147, 0.141, 0.295, 0.129, 0.138, 0.148, 0.191, 0.121, 0.17, 0.116, 0.272, 0.128, 0.127, 0.166, 0.117, 0.114, 0.122, 0.174, 0.11, 0.225, 0.214, 0.189, 0.425, 0.191, 0.108, 0.137, 0.115, 0.145, 0.159, 0.208, 0.101, 0.107, 0.102, 0.116, 0.146, 0.128, 0.162, 0.149, 0.133, 0.139, 0.111, 0.183, 0.09, 0.191, 0.133, 0.105, 0.11, 0.152, 0.091, 0.158, 0.135, 0.115, 0.096, 0.092, 0.162, 0.147, 0.121, 0.137, 0.31, 0.101, 0.13, 0.146, 0.158, 0.111, 0.151, 0.127, 0.148, 0.154, 0.181, 0.114, 0.189, 0.149, 0.106, 0.132, 0.205, 0.103, 0.106, 0.151, 0.202, 0.132, 0.347, 0.146, 0.113, 0.116, 0.125, 0.156, 0.092, 0.158, 0.192, 0.127, 0.112, 0.119, 0.133, 0.109, 0.103, 0.315, 0.123, 0.131, 0.164, 0.199, 0.157, 0.116, 0.1, 0.115, 0.134, 0.083, 0.679, 0.126, 0.278, 0.087, 0.12, 0.11, 0.189, 0.128, 0.096, 0.154, 0.157, 0.204, 0.095, 0.135, 0.119, 0.097, 0.139, 0.125, 0.14, 0.157, 0.098, 0.159, 0.129, 0.138, 0.155, 0.11, 0.138, 0.195, 0.164, 0.149, 0.115, 0.171, 0.099, 0.119, 0.154, 0.103, 0.131, 0.102, 0.128, 0.191, 0.114, 0.122, 0.199, 0.159, 0.2, 0.102, 0.124, 0.355, 0.105, 0.116, 0.102, 0.128, 0.101, 0.118, 0.139, 0.102, 0.136, 0.107, 0.434, 0.16, 0.138, 0.174, 0.141, 0.118, 0.18, 0.15, 0.139, 0.127, 0.118, 0.202, 0.113, 0.096, 0.119, 0.135, 0.151, 0.108, 0.106, 0.105, 0.179, 0.115, 0.208, 0.113, 0.16, 0.11, 0.205, 0.172, 0.105, 0.113, 0.121, 0.104, 0.103, 0.126, 0.12, 0.124, 0.101, 0.139, 0.127, 0.112, 0.197, 0.131, 0.134, 0.14, 0.144, 0.119, 0.233, 0.118, 0.106, 0.145, 0.117, 0.132, 0.115, 2.214, 0.156, 0.105, 0.149, 0.098, 0.158, 0.106, 0.151, 0.177, 0.151, 0.287, 0.111, 0.18, 0.121, 0.144, 0.135, 0.112, 0.173, 0.973, 0.15, 1.176, 0.144, 0.105, 0.147, 0.134, 0.103, 0.086, 0.165, 0.149, 0.123, 0.139, 0.146, 0.131, 0.127, 0.111, 0.101, 0.181, 0.112, 0.131, 0.101, 0.123, 0.201, 0.211, 0.129, 0.105, 0.09, 0.176, 0.129, 0.112, 0.089, 0.144, 0.121, 0.392, 0.133, 0.193, 0.168, 0.156, 0.142, 0.121, 0.097, 0.166, 0.131, 0.163, 0.109, 0.123, 0.094, 0.104, 0.088, 0.101, 0.096, 0.098, 0.127, 0.135, 0.117, 0.129, 0.087, 0.106, 0.101, 0.254, 0.116, 0.543, 0.14, 0.127, 0.105, 0.149, 0.291, 0.102, 0.111, 0.109, 0.094, 0.103, 0.119, 0.096, 0.135, 0.081, 0.168, 0.092, 0.103, 0.082, 0.101, 0.149, 0.108, 0.172, 0.113, 0.153, 0.099, 0.125, 0.131, 0.202, 0.208, 0.13, 0.259, 0.123, 0.121, 0.101, 0.102, 0.107, 0.106, 0.102, 0.14, 0.096, 0.197, 0.118, 0.099, 0.106, 0.151, 0.091, 0.091, 0.12, 0.126, 0.216, 0.202, 0.1, 0.129, 0.147, 0.162, 0.101, 0.089, 0.15, 0.095, 0.176, 0.094, 0.103, 0.154, 0.093, 0.255, 0.141, 0.094, 0.13, 0.118, 0.138, 0.212, 0.158, 0.196, 0.129, 0.109, 0.141, 0.192, 0.152, 0.193, 0.576, 0.134, 0.17, 0.127, 0.17, 0.13, 0.123, 0.101, 0.223, 0.204, 0.168, 0.128, 0.131, 0.149, 0.132, 0.204, 0.39, 0.121, 0.121, 0.141, 0.102, 0.173, 0.226, 0.19, 0.128, 0.125, 0.126, 0.136, 0.128, 0.137, 0.1, 0.118, 0.096, 0.087, 0.11, 0.089, 0.149, 0.183, 0.152, 0.115, 0.151, 0.209, 0.221, 0.227, 0.138, 0.16, 0.152, 0.127, 0.117, 0.106, 0.094, 0.265, 0.139, 0.126, 0.151, 0.105, 0.108, 0.107, 0.115, 0.103, 0.114, 0.139, 0.137, 0.176, 0.107, 0.289, 0.172, 0.15, 0.127, 0.126, 0.12, 0.124, 0.112, 0.126, 0.115, 0.16, 0.155, 0.127, 0.106, 0.127, 0.132, 0.134, 0.133, 0.11, 0.124, 0.139, 0.145, 0.158, 0.137, 0.147, 0.116, 0.186, 0.171, 0.124, 0.097, 0.128, 0.108, 0.095, 0.092, 0.107, 0.188, 0.126, 0.127, 0.137, 0.097, 0.099, 0.111, 0.109, 0.134, 0.114, 0.146, 0.109, 0.128, 0.204, 0.125, 0.172, 0.158, 0.139, 0.139, 0.154, 0.117, 0.138, 0.176, 0.136, 0.146, 0.216, 0.161, 0.146, 0.123, 0.095, 0.116, 0.105, 0.186, 0.098, 0.136, 0.926, 0.189, 0.162, 0.195, 0.173, 0.159, 0.112, 0.206, 0.108, 0.294, 0.194, 0.17, 0.192, 0.121, 0.227, 0.171, 0.136, 0.16, 0.172, 0.194, 0.233, 0.153, 0.132, 0.199, 0.122, 0.087, 0.091, 0.129, 0.219, 0.1, 0.151, 0.303, 0.212, 0.117, 0.182, 0.092, 0.121, 0.098, 0.121, 0.156, 0.144, 0.13, 0.156, 0.225, 0.165, 0.187, 0.126, 0.215, 0.139, 0.118, 0.134, 0.109, 0.161, 0.289, 0.169, 0.161, 0.167, 0.188, 0.195, 0.234, 0.15, 0.214, 0.211, 0.114, 0.144, 0.107, 0.157, 0.16, 0.108, 0.171, 0.135, 0.128, 0.162, 0.159, 0.147, 0.152, 0.122, 0.113, 0.139, 0.188, 0.178, 0.172, 0.155, 0.221, 0.172, 0.135, 0.137, 0.144, 0.151, 0.147, 0.137, 0.12, 0.174, 0.116, 0.155, 0.112, 0.131, 0.167, 0.166, 0.162, 0.11, 2.138, 0.105, 0.112, 0.114, 0.141, 0.147, 0.151, 0.305, 0.116, 0.138, 0.222, 0.109, 0.165, 0.121, 0.152, 0.194, 0.306, 0.123, 0.192, 0.144, 0.22, 0.216, 0.192, 0.222, 0.24, 0.147, 0.103, 0.175, 0.147, 0.115, 0.192, 0.116, 0.134, 0.126, 0.141, 0.152, 0.15, 0.124, 0.148, 0.11, 0.107, 0.097, 0.124, 0.218, 0.115, 0.126, 0.19, 0.113, 0.089, 0.124, 0.113, 0.174, 0.168, 0.129, 0.177, 0.15, 0.142, 0.14, 0.143, 0.121, 0.124, 0.094, 0.523, 0.151, 0.164, 0.121, 0.115, 0.189, 0.109, 0.162, 0.144, 0.147, 0.119, 0.159, 0.159, 0.936, 0.133, 0.127, 0.117, 0.144, 0.091, 0.116, 0.127, 0.102, 0.121, 0.143, 0.158, 0.138, 0.164, 0.175, 0.161, 0.101, 0.191, 0.121, 0.216, 0.214, 0.225, 0.234, 0.23, 0.138, 0.128, 0.14, 0.203, 0.117, 0.114, 0.188, 0.163, 0.181, 0.166, 0.11, 0.197, 0.123, 0.254, 0.109, 0.168, 0.144, 0.153, 0.119, 0.122, 0.153, 0.139, 0.133, 0.148, 0.144, 0.186, 0.153, 0.204, 0.2, 0.217, 0.15, 0.132, 0.13, 0.126, 0.141, 0.143, 0.139, 0.119, 0.153, 0.127, 0.225, 0.199, 0.111, 0.142, 0.135, 0.165, 0.142, 0.135, 0.102, 0.177, 0.18, 0.128, 0.123, 0.173, 0.107, 0.136, 0.14, 0.221, 0.108, 0.151, 0.12, 0.203, 0.113, 0.12, 0.123, 0.16, 0.136, 0.126, 0.143, 0.107, 0.103, 0.153, 0.171, 0.107, 0.168, 0.104, 0.113, 0.204, 0.124, 0.38, 0.169, 0.181, 0.514, 0.142, 0.128, 0.12, 0.194, 0.163, 0.168, 0.202, 0.154, 0.167, 0.158, 0.15, 0.179, 0.103, 0.139, 0.122, 0.163, 0.185, 0.147, 0.095, 0.147, 0.149, 0.156, 0.108, 0.106, 0.118, 0.187, 0.129, 0.142, 0.112, 0.094, 0.095, 0.127, 0.252, 0.152, 0.155, 0.125, 0.11, 0.118, 0.111, 0.125, 0.134, 0.124, 0.195, 0.154, 0.146, 0.219, 0.144, 0.2, 0.111, 0.147, 0.239, 0.195, 0.232, 0.095, 0.125, 0.16, 0.133, 0.15, 0.145, 0.143, 0.14, 0.126, 0.132, 0.112, 0.133, 0.098, 0.178, 0.109, 0.158, 0.152, 0.143, 0.125, 0.118, 0.137, 0.156, 0.117, 0.158, 0.157, 0.138, 0.165, 0.163, 0.122, 0.204, 0.165, 0.222, 0.12, 0.118, 0.123, 0.18, 0.198, 0.158, 0.116, 0.435, 0.142, 0.15, 0.154, 0.151, 0.22, 0.146, 0.188, 0.32, 0.125, 0.201, 0.117, 0.116, 0.126, 0.116, 0.105, 0.113, 0.125, 0.104, 0.124, 0.103, 0.108, 0.12, 0.152, 0.168, 0.141, 0.172, 0.254, 0.117, 0.276, 0.148, 0.115, 0.086, 0.123, 0.394, 0.119, 0.12, 0.177, 0.107, 0.14, 0.187, 0.111, 0.188, 0.14, 0.198, 0.129, 0.151, 0.116, 0.13, 0.148, 0.131, 0.169, 0.158, 0.156, 0.108, 0.207, 0.139, 0.942, 0.132, 0.181, 0.197, 0.192, 0.179, 0.181, 0.266, 0.114, 0.141, 0.12, 0.269, 0.12, 0.181, 0.228, 0.241, 1.176, 0.162, 0.14, 0.152, 0.177, 0.727, 0.131, 0.137, 0.196, 0.119, 0.12, 0.18, 0.126, 0.144, 0.323, 0.154, 0.153, 0.132, 0.125, 0.113, 0.203, 0.145, 0.252, 0.219, 0.181, 0.166, 0.143, 0.238, 0.148, 0.128, 0.165, 0.151, 0.121, 0.09, 0.117, 0.165, 0.262, 0.142, 0.137, 0.124, 0.149, 0.343, 0.127, 0.162, 0.587, 0.179, 0.151, 0.157, 0.128, 0.203, 0.142, 0.156, 0.119, 0.156, 0.119, 0.136, 0.145, 0.172, 0.163, 0.24, 0.23, 0.156, 0.107, 0.128, 0.179, 0.14, 0.22, 0.134, 0.247, 0.142, 0.13, 0.184, 0.179, 0.173, 0.107, 0.161, 0.118, 0.176, 0.185, 0.1, 0.149, 0.105, 0.122, 0.207, 0.141, 0.104, 0.131, 0.119, 0.117, 0.144, 0.131, 0.133, 0.115, 0.125, 0.12, 0.18, 0.161, 0.2, 0.117, 0.099, 0.173, 0.118, 0.151, 0.212, 0.115, 0.267, 0.147, 0.146, 0.13, 0.179, 0.201, 0.263, 0.215, 0.167, 0.115, 0.132, 0.143, 0.113, 0.128, 0.21, 0.172, 0.141, 0.101, 0.121, 0.169, 0.139, 0.139, 0.145, 0.122, 0.133, 0.166, 0.132, 0.184, 0.171, 0.138, 0.116, 0.15, 0.13, 0.217, 0.132, 0.205, 0.103, 0.177, 0.178, 0.242, 0.083, 0.128, 0.114, 0.137, 0.147, 0.139, 0.168, 0.107, 0.128, 0.151, 0.126, 0.151, 0.102, 0.133, 0.143, 0.15, 0.104, 0.182, 0.144, 0.163, 0.132, 0.131, 0.129, 0.11, 0.146, 0.149, 0.158, 0.18, 0.184, 0.157, 0.114, 0.115, 2.078, 0.154, 0.209, 0.105, 0.115, 0.188, 0.135, 0.11, 0.134, 0.708, 0.153, 0.299, 0.164, 0.124, 0.167, 0.164, 0.164, 0.116, 0.123, 0.108, 0.159, 0.191, 0.345, 0.137, 0.116, 0.085, 0.131, 0.105, 0.117, 0.122, 0.134, 0.104, 0.101, 0.127, 0.13, 0.154, 0.14, 0.143, 0.115, 0.137, 0.137, 0.103, 0.287, 0.181, 0.17, 0.212, 0.112, 0.1, 0.124, 0.158, 0.193, 0.139, 0.111, 0.092, 0.094, 0.147, 0.167, 0.188, 0.118, 0.116, 0.112, 0.23, 0.184, 0.159, 0.107, 0.147, 0.142, 0.115, 0.163
    #         ],
    #         [
    #             0.206, 0.139, 0.151, 0.253, 0.213, 0.239, 0.23, 0.242, 0.135, 0.212, 0.154, 0.161, 0.174, 0.582, 0.142, 0.158, 0.175, 0.173, 0.161, 0.188, 0.156, 0.19, 0.176, 0.181, 0.178, 0.142, 0.207, 0.165, 0.189, 0.12, 0.247, 0.238, 0.176, 0.122, 0.281, 0.201, 0.164, 0.225, 0.148, 0.143, 0.131, 0.179, 0.137, 0.412, 0.149, 0.216, 0.185, 0.175, 0.222, 0.225, 0.152, 0.115, 0.235, 0.146, 0.165, 0.287, 0.195, 0.131, 0.137, 0.114, 0.198, 0.185, 0.236, 0.171, 0.367, 0.133, 0.157, 0.14, 0.184, 0.12, 0.156, 0.142, 0.125, 0.191, 0.17, 0.142, 0.145, 0.172, 0.149, 0.124, 0.126, 0.111, 0.251, 0.133, 0.164, 0.229, 0.186, 0.16, 0.222, 0.135, 0.129, 0.172, 0.173, 0.198, 0.149, 0.15, 0.162, 0.157, 0.23, 0.264, 0.225, 0.188, 0.226, 0.196, 0.16, 0.152, 0.148, 0.184, 0.162, 0.214, 0.164, 0.202, 0.236, 0.147, 0.199, 0.223, 0.17, 0.713, 0.148, 0.19, 0.137, 0.152, 0.189, 0.217, 0.155, 0.215, 0.193, 0.195, 0.144, 0.136, 2.191, 0.122, 0.206, 0.219, 0.136, 0.214, 0.134, 0.149, 0.186, 0.157, 0.189, 0.163, 0.18, 0.136, 0.276, 0.153, 0.112, 0.127, 0.179, 0.227, 0.147, 0.217, 0.249, 0.151, 0.252, 0.227, 0.177, 0.226, 0.184, 0.18, 0.211, 0.174, 0.261, 0.171, 0.208, 0.128, 0.151, 0.158, 0.157, 0.31, 0.193, 0.191, 0.16, 0.216, 0.229, 0.165, 0.241, 0.149, 0.146, 1.297, 0.176, 0.18, 0.139, 0.206, 0.132, 0.165, 0.148, 0.211, 0.141, 0.14, 0.171, 0.13, 0.305, 0.144, 0.163, 0.179, 0.15, 0.135, 0.139, 0.124, 0.105, 0.117, 0.155, 0.142, 0.158, 0.193, 0.202, 0.179, 0.139, 0.138, 0.216, 0.134, 0.157, 0.119, 0.127, 0.181, 0.115, 0.14, 0.154, 0.188, 0.137, 0.136, 0.128, 0.132, 0.206, 0.1, 0.188, 0.144, 0.141, 0.423, 0.23, 0.136, 0.207, 0.143, 0.202, 0.197, 0.135, 0.138, 0.271, 0.179, 0.182, 0.163, 0.245, 0.164, 0.162, 0.241, 0.165, 0.211, 0.146, 0.122, 0.164, 0.182, 0.174, 0.186, 0.15, 0.224, 0.141, 0.192, 0.115, 0.16, 0.206, 0.2, 0.177, 0.312, 0.249, 0.159, 0.133, 0.164, 0.166, 0.546, 0.145, 0.185, 0.152, 0.201, 0.234, 0.173, 0.112, 0.126, 0.238, 0.186, 0.185, 0.224, 0.154, 0.166, 0.161, 0.162, 0.227, 0.244, 0.159, 0.24, 0.214, 0.119, 0.119, 0.183, 0.162, 0.193, 0.151, 0.24, 0.088, 0.16, 0.494, 0.216, 0.144, 0.171, 0.156, 0.16, 0.129, 0.149, 0.167, 0.201, 0.204, 0.195, 0.199, 0.184, 0.172, 0.165, 0.223, 0.343, 0.168, 0.224, 0.172, 0.141, 0.169, 0.168, 0.155, 0.241, 0.207, 0.138, 0.194, 0.185, 0.125, 0.131, 0.113, 0.158, 0.119, 0.137, 0.166, 0.175, 0.166, 0.192, 0.14, 0.194, 0.223, 0.153, 0.152, 0.145, 0.222, 0.176, 0.233, 0.211, 0.149, 0.239, 0.144, 0.133, 0.173, 0.312, 0.22, 0.144, 0.186, 0.995, 0.145, 0.193, 0.146, 0.16, 0.16, 0.173, 0.167, 0.218, 0.185, 0.189, 0.239, 0.145, 0.147, 0.106, 0.295, 0.163, 0.155, 0.13, 0.148, 0.117, 0.137, 1.485, 0.145, 0.1, 0.167, 0.157, 0.213, 0.146, 0.12, 0.159, 0.197, 0.2, 0.225, 0.114, 0.25, 0.268, 0.169, 0.18, 0.215, 0.182, 0.217, 0.176, 0.142, 0.193, 0.193, 0.185, 0.219, 0.181, 0.129, 0.153, 0.155, 0.173, 0.155, 0.131, 0.168, 0.205, 0.166, 0.157, 0.366, 0.118, 0.345, 0.271, 0.228, 0.209, 0.148, 0.253, 0.167, 0.171, 0.12, 0.121, 0.157, 0.157, 0.192, 0.217, 0.132, 0.189, 0.167, 0.15, 0.194, 0.212, 0.169, 0.224, 0.194, 0.207, 0.178, 0.144, 0.194, 0.181, 0.195, 0.177, 0.15, 0.135, 0.106, 0.109, 0.137, 0.107, 0.159, 0.129, 0.146, 0.124, 0.119, 0.159, 0.201, 0.196, 0.165, 0.194, 0.199, 0.184, 0.173, 0.167, 0.155, 0.145, 0.157, 0.238, 0.266, 0.252, 0.144, 0.138, 0.18, 0.13, 0.117, 1.034, 0.201, 0.178, 0.151, 0.17, 0.19, 0.178, 0.188, 0.163, 0.135, 0.216, 0.219, 0.361, 0.137, 0.138, 0.14, 0.173, 0.154, 0.226, 0.189, 0.158, 0.178, 0.179, 0.175, 0.194, 0.208, 0.206, 0.156, 0.135, 0.156, 0.159, 0.167, 0.161, 0.213, 0.279, 0.162, 0.188, 0.214, 0.161, 0.138, 0.223, 0.138, 0.161, 0.162, 0.113, 0.353, 0.214, 0.401, 0.16, 0.591, 0.366, 0.159, 0.171, 0.19, 0.155, 0.174, 0.222, 0.148, 0.167, 0.259, 0.143, 0.193, 0.183, 0.193, 0.167, 0.14, 0.17, 0.162, 0.182, 0.18, 0.199, 0.154, 0.179, 0.19, 0.154, 0.16, 0.129, 0.17, 0.182, 0.166, 0.167, 0.175, 0.188, 0.136, 0.141, 0.224, 0.205, 0.09, 0.202, 0.237, 0.173, 0.145, 0.181, 0.161, 0.158, 0.18, 0.228, 0.236, 0.242, 0.594, 0.194, 0.147, 0.187, 0.234, 0.144, 0.224, 0.234, 0.163, 0.186, 0.154, 0.159, 1.267, 0.126, 0.161, 0.175, 0.22, 0.188, 0.222, 0.165, 0.113, 0.147, 0.155, 0.174, 0.194, 0.174, 0.169, 0.156, 0.149, 0.143, 0.181, 0.199, 0.196, 0.149, 0.228, 0.206, 0.219, 0.175, 0.182, 0.203, 0.181, 0.198, 0.233, 0.241, 0.227, 0.166, 0.145, 0.119, 0.109, 0.107, 0.182, 0.217, 0.254, 0.216, 0.177, 0.135, 0.162, 0.127, 0.162, 0.158, 0.183, 0.205, 0.235, 0.183, 0.201, 0.16, 0.139, 0.155, 0.148, 0.185, 0.158, 0.14, 0.151, 0.231, 0.175, 0.301, 0.145, 0.225, 0.203, 0.171, 0.141, 0.17, 0.217, 0.153, 0.318, 0.131, 0.183, 0.189, 0.202, 0.229, 0.183, 0.268, 0.12, 0.091, 0.137, 0.139, 0.177, 0.208, 0.199, 0.112, 0.094, 0.096, 0.114, 0.191, 0.243, 0.148, 0.145, 0.143, 0.149, 0.189, 0.166, 0.191, 0.168, 0.162, 0.147, 0.162, 0.989, 0.098, 0.109, 0.142, 0.144, 0.157, 0.166, 0.292, 0.129, 0.168, 0.19, 0.19, 0.204, 0.159, 0.161, 0.16, 0.187, 0.169, 0.16, 0.188, 0.196, 0.189, 0.19, 0.16, 0.151, 0.202, 0.176, 0.244, 0.165, 0.128, 0.13, 0.195, 0.146, 0.202, 0.15, 0.147, 0.17, 0.157, 0.421, 0.191, 0.188, 0.135, 1.005, 0.186, 0.183, 0.221, 0.173, 0.149, 0.179, 0.156, 0.136, 0.274, 0.151, 0.158, 0.134, 0.138, 0.143, 0.119, 0.14, 0.176, 0.169, 0.139, 0.153, 0.216, 0.146, 0.18, 0.166, 0.226, 0.171, 0.161, 0.195, 1.174, 0.148, 0.182, 0.189, 0.203, 0.223, 0.187, 0.154, 0.119, 0.174, 0.144, 0.131, 0.18, 0.192, 0.137, 0.307, 0.113, 0.171, 0.168, 0.157, 0.174, 0.194, 0.145, 0.145, 0.13, 0.168, 0.174, 0.205, 0.281, 0.172, 0.147, 0.151, 0.153, 0.177, 0.196, 0.141, 0.134, 0.115, 0.13, 0.106, 0.164, 0.109, 0.177, 0.129, 0.172, 0.135, 0.196, 0.157, 0.183, 0.175, 0.165, 0.18, 0.173, 0.159, 0.132, 0.194, 0.14, 0.119, 0.184, 0.161, 0.105, 0.159, 0.117, 0.148, 0.18, 0.176, 0.458, 0.213, 0.168, 0.214, 0.204, 0.308, 0.209, 0.162, 0.169, 0.197, 0.19, 0.127, 0.203, 0.145, 0.201, 0.156, 0.169, 0.13, 0.166, 0.183, 0.172, 0.151, 0.186, 0.173, 0.182, 0.24, 0.198, 0.177, 0.209, 0.219, 0.176, 0.215, 0.282, 0.155, 0.116, 0.124, 0.148, 0.125, 0.126, 0.127, 0.16, 0.144, 0.784, 0.141, 0.234, 0.184, 0.192, 0.282, 0.213, 0.167, 0.163, 0.197, 0.191, 0.157, 0.142, 0.245, 0.116, 0.136, 0.146, 0.135, 0.188, 0.183, 0.198, 0.165, 0.15, 0.199, 0.23, 0.179, 0.182, 0.191, 0.203, 0.321, 0.119, 0.145, 0.138, 0.192, 0.182, 0.174, 0.158, 0.21, 0.141, 0.192, 0.204, 0.254, 0.198, 0.142, 0.197, 0.188, 0.219, 0.198, 0.208, 0.206, 0.319, 0.193, 0.158, 0.135, 0.114, 0.155, 0.14, 0.138, 0.132, 0.179, 0.165, 0.194, 0.157, 0.115, 0.119, 0.142, 0.13, 0.179, 0.126, 0.154, 0.121, 0.171, 0.145, 0.245, 0.215, 0.16, 0.17, 0.137, 0.155, 0.131, 0.148, 0.16, 0.143, 0.15, 0.134, 0.198, 0.225, 0.136, 0.299, 0.187, 0.147, 0.179, 0.325, 0.212, 0.219, 0.185, 0.199, 0.155, 0.184, 0.17, 0.203, 0.213, 0.187, 2.187, 0.142, 0.111, 0.116, 0.207, 0.174, 0.361, 0.16, 0.297, 0.276, 0.183, 0.133, 0.166, 0.195, 0.21, 0.114, 0.144, 0.127, 0.109, 0.194, 0.154, 0.152, 0.158, 0.121, 0.663, 0.229, 0.188, 0.155, 0.178, 0.211, 0.234, 0.152, 0.207, 0.157, 0.157, 0.224, 0.154, 0.151, 0.206, 0.298, 0.211, 0.212, 0.147, 0.166, 0.168, 0.224, 0.209, 0.249, 0.126, 0.159, 0.183, 0.221, 0.185, 0.161, 0.131, 0.18, 0.167, 0.126, 0.142, 0.158, 0.186, 0.098, 0.155, 0.166, 0.193, 0.21, 0.224, 0.233, 0.22, 0.217, 1.579, 0.153, 0.221, 0.281, 0.158, 0.172, 0.217, 0.174, 0.138, 0.23, 0.139, 0.151, 0.217, 0.151, 0.156, 0.176, 0.162, 0.181, 0.199, 0.27, 0.183, 0.119, 0.236, 0.22, 0.193, 0.141, 0.148, 0.144, 0.186, 0.188, 0.165, 0.157, 0.18, 0.209, 0.254, 0.236, 0.196, 0.34, 0.142, 0.228, 0.215, 0.18, 0.11, 0.121, 0.135, 0.221, 0.334, 0.208, 0.167, 0.18, 0.141, 0.159, 0.145, 0.193, 0.143, 0.165, 0.19, 0.301, 0.142, 0.173, 0.159, 0.127, 0.114, 0.113, 0.127, 0.34, 0.123, 0.213, 0.216, 0.148, 0.152, 0.171, 0.192, 0.175, 0.175, 0.179, 0.155, 0.182, 0.206, 0.152, 1.042, 0.213, 0.112, 0.202, 0.132, 0.127, 0.107, 0.138, 0.193, 0.177, 0.194, 0.174, 0.124, 0.216, 0.223, 0.317, 0.134, 0.176, 0.14, 0.166, 0.189, 0.195, 0.18, 0.232, 0.184, 0.159, 0.203, 0.233, 0.187, 0.159, 0.237, 0.157, 0.194, 0.245, 0.146, 0.162, 0.156, 2.25, 0.212, 0.27, 0.228, 0.152, 0.21, 0.148, 0.141, 0.254, 0.246, 0.14, 0.18, 0.197, 0.135, 0.135, 0.181, 0.253, 0.126, 0.181, 0.208, 0.191, 1.29, 0.183, 0.214, 0.297, 0.231, 0.225, 0.32, 0.144, 0.152, 0.192, 0.137, 0.17, 0.159, 0.211, 0.227, 0.169, 0.161, 0.171, 0.235, 0.164, 0.146, 0.135, 0.195, 0.176, 0.594, 0.2, 0.207, 0.2, 0.212, 0.171, 0.15, 0.256, 0.262, 0.152, 0.19, 0.184, 0.123, 0.216, 0.144, 0.194, 0.208, 0.134, 0.237, 0.223, 0.166, 0.329, 0.146, 0.144, 0.163, 0.15, 0.138, 0.156, 0.158, 0.214, 0.196, 0.151, 0.177, 0.145, 0.206, 0.191, 0.201, 0.211, 0.153, 0.25, 0.194, 0.479, 0.177, 0.15, 0.16, 0.178, 0.305, 0.204, 0.143, 0.182, 0.131, 0.143, 0.232, 0.177, 0.205, 0.234, 0.124, 0.122, 0.137, 0.125, 0.126, 0.144, 0.124, 0.122, 0.162, 0.149, 0.211, 0.207, 0.182, 0.184, 0.165, 0.182, 0.18, 0.183, 0.189, 0.171, 0.172, 0.157, 0.148, 0.159, 0.244, 0.307, 0.213, 0.177, 0.148, 0.14, 0.15, 0.196, 0.156, 0.139, 0.158, 0.141, 0.139, 0.323, 0.143, 0.208, 0.183, 0.191, 0.237, 0.215, 0.23, 0.146, 0.165, 0.147, 0.16, 0.12, 0.175, 0.206, 0.499, 0.149, 0.15, 0.165, 0.203, 0.259, 0.144, 0.17, 0.21, 0.197, 0.223, 0.2, 0.192, 0.121, 0.114, 0.174, 0.134, 0.194, 0.21, 0.171, 0.19, 0.185, 0.206, 0.15, 0.168, 0.147, 0.568, 0.206, 0.235, 0.168, 0.141, 0.159, 0.179, 0.186, 0.224, 0.199, 0.209, 0.128, 0.172, 0.171, 0.188, 0.2, 0.183, 0.176, 0.245, 0.2, 0.189, 0.132, 0.207, 0.203, 0.139, 0.172, 0.164, 0.138, 0.128, 0.18, 0.158, 0.177, 0.16, 0.155, 0.17, 0.132, 0.133, 0.133, 0.157, 0.183, 0.182, 0.205, 0.192, 0.149, 0.188, 0.203, 0.137, 0.147, 0.191, 0.188, 0.171, 0.178, 0.189, 0.156, 0.185, 0.148, 0.134, 0.153, 0.191, 0.205, 1.022, 0.108, 0.15, 0.212, 0.517, 0.222, 0.173, 0.148, 0.159, 0.174, 0.144, 0.139, 0.188, 0.155, 0.185, 0.194, 0.177, 0.165, 0.155, 0.197, 0.216, 0.167, 0.251, 0.125, 0.191, 0.234, 0.129, 0.143, 0.188, 0.203, 0.113, 0.117, 0.162, 0.113, 0.153, 0.127, 0.209, 0.185, 0.262, 0.151, 0.135, 0.126, 0.178, 0.181, 0.161, 0.144, 0.135, 0.138, 0.221, 0.192, 0.202, 0.167, 0.131, 0.244, 0.159, 0.171, 0.173, 0.218, 0.236, 0.24, 0.183, 0.141, 0.336, 0.168, 0.165, 0.217, 0.205, 0.173, 0.185, 0.135, 0.296, 0.165, 0.169, 0.141, 0.139, 0.132, 0.18, 0.224, 0.132, 0.152, 0.163, 0.174, 0.428, 0.226, 0.157, 0.224, 0.157, 0.225, 0.188, 0.196, 0.133, 0.142, 0.146, 0.154, 0.188, 0.214, 0.125, 0.123, 0.137, 0.101, 0.096, 0.264, 0.147, 0.218, 0.182, 0.137, 0.178, 0.177, 0.139, 0.231, 0.214, 0.215, 0.163, 0.204, 0.224, 0.233, 0.142, 0.208, 0.324, 0.113, 0.182, 0.125, 0.193, 0.109, 0.197, 0.129, 0.18, 0.166, 0.199, 0.132, 0.155, 0.209, 0.191, 0.247, 0.233, 0.096, 0.101, 0.1, 0.117, 0.171, 0.507, 0.146, 0.127, 0.148, 0.162, 0.175, 0.118, 0.184, 0.221, 0.209, 0.186, 0.172, 0.195, 0.15, 0.179, 0.333, 0.139, 0.152, 0.202, 0.201, 0.188, 0.186, 0.17, 0.208, 0.192, 0.127, 1.054, 0.217, 0.337, 0.152, 0.14, 0.119, 0.195, 0.186, 0.146, 0.207, 0.221, 0.332, 0.208, 0.191, 0.177, 0.129, 0.202, 0.147, 0.194, 0.247, 0.178, 0.211, 0.24, 0.227, 0.252, 0.123, 0.29, 0.26, 0.225, 0.224, 0.167, 0.251, 0.169, 0.223, 0.24, 0.16, 0.181, 0.15, 0.192, 0.236, 0.191, 0.19, 0.169, 0.171, 0.132, 0.109, 0.166, 0.367, 0.173, 0.13, 0.158, 0.163, 0.137, 0.184, 0.206, 0.174, 0.159, 0.172, 0.422, 0.169, 0.21, 0.192, 0.199, 0.12, 0.172, 0.164, 0.148, 0.19, 0.176, 0.197, 0.205, 0.168, 0.188, 0.168, 0.187, 0.128, 0.14, 0.149, 0.216, 0.181, 0.257, 0.182, 0.223, 0.132, 0.232, 0.143, 0.117, 0.16, 0.155, 0.146, 0.152, 0.165, 0.156, 0.146, 0.13, 0.158, 0.114, 0.121, 0.213, 0.183, 0.219, 0.159, 0.221, 0.142, 0.333, 0.138, 0.126, 0.184, 0.144, 0.209, 0.192, 2.172, 0.204, 0.159, 0.186, 0.151, 0.202, 0.163, 0.191, 0.213, 0.211, 0.3, 0.16, 0.22, 0.114, 0.176, 0.213, 0.135, 0.15, 0.994, 0.251, 1.184, 0.198, 0.13, 0.23, 0.222, 0.195, 0.202, 0.214, 0.207, 0.165, 0.163, 0.214, 0.179, 0.14, 0.129, 0.166, 0.18, 0.141, 0.18, 0.171, 0.205, 0.192, 0.16, 0.126, 0.137, 0.154, 0.204, 0.179, 0.18, 0.137, 0.208, 0.206, 0.426, 0.21, 0.201, 0.193, 0.238, 0.193, 0.2, 0.143, 0.238, 0.251, 0.254, 0.161, 0.15, 0.157, 0.108, 0.143, 0.147, 0.218, 0.22, 0.206, 0.181, 0.199, 0.231, 0.159, 0.193, 0.224, 0.317, 0.151, 0.833, 0.297, 0.239, 0.157, 0.223, 0.308, 0.147, 0.186, 0.215, 0.163, 0.177, 0.224, 0.146, 0.189, 0.116, 0.186, 0.12, 0.142, 0.12, 0.138, 0.157, 0.109, 0.181, 0.133, 0.179, 0.124, 0.154, 0.274, 0.252, 0.231, 0.193, 0.304, 0.209, 0.14, 0.182, 0.162, 0.169, 0.185, 0.155, 0.236, 0.203, 0.26, 0.141, 0.146, 0.182, 0.204, 0.157, 0.17, 0.164, 0.205, 0.163, 0.199, 0.121, 0.175, 0.147, 0.201, 0.169, 0.16, 0.194, 0.163, 0.204, 0.136, 0.182, 0.192, 0.147, 0.255, 0.16, 0.144, 0.2, 0.146, 0.189, 0.202, 0.218, 0.212, 0.2, 0.197, 0.161, 0.181, 0.169, 0.215, 0.631, 0.21, 0.21, 0.159, 0.174, 0.22, 0.175, 0.144, 0.186, 0.174, 0.202, 0.174, 0.176, 0.178, 0.164, 0.215, 0.43, 0.169, 0.19, 0.211, 0.152, 0.236, 0.251, 0.242, 0.151, 0.146, 0.222, 0.191, 0.156, 0.167, 0.186, 0.187, 0.173, 0.169, 0.255, 0.192, 0.264, 0.231, 0.164, 0.154, 0.207, 0.284, 0.217, 0.213, 0.167, 0.248, 0.216, 0.171, 0.213, 0.159, 0.134, 0.308, 0.235, 0.193, 0.201, 0.147, 0.161, 0.22, 0.176, 0.168, 0.161, 0.179, 0.176, 0.201, 0.2, 0.316, 0.169, 0.169, 0.201, 0.201, 0.173, 0.181, 0.154, 0.173, 0.185, 0.226, 0.199, 0.189, 0.18, 0.267, 0.239, 0.213, 0.215, 0.194, 0.216, 0.212, 0.199, 0.217, 0.168, 0.194, 0.157, 0.145, 0.217, 0.141, 0.165, 0.175, 0.151, 0.165, 0.157, 0.211, 0.219, 0.21, 0.164, 0.211, 0.155, 0.158, 0.133, 0.133, 0.184, 0.143, 0.19, 0.133, 0.218, 0.194, 0.163, 0.197, 0.203, 0.195, 0.191, 0.206, 0.187, 0.203, 0.213, 0.182, 0.233, 0.304, 0.16, 0.183, 0.168, 0.113, 0.22, 0.14, 0.215, 0.148, 0.138, 1.021, 0.207, 0.204, 0.169, 0.202, 0.192, 0.144, 0.21, 0.128, 0.329, 0.199, 0.176, 0.189, 0.179, 0.147, 0.206, 0.153, 0.171, 0.179, 0.198, 0.291, 0.175, 0.199, 0.224, 0.165, 0.121, 0.153, 0.162, 0.24, 0.149, 0.215, 0.344, 0.298, 0.224, 0.246, 0.158, 0.226, 0.14, 0.15, 0.206, 0.15, 0.192, 0.241, 0.275, 0.221, 0.217, 0.166, 0.168, 0.15, 0.154, 0.116, 0.118, 0.184, 0.213, 0.21, 0.235, 0.21, 0.199, 0.235, 0.238, 0.147, 0.207, 0.174, 0.123, 0.209, 0.131, 0.203, 0.204, 0.149, 0.193, 0.125, 0.156, 0.201, 0.192, 0.201, 0.19, 0.124, 0.164, 0.153, 0.203, 0.178, 0.179, 0.158, 0.18, 0.183, 0.126, 0.149, 0.207, 0.168, 0.206, 0.201, 0.146, 0.204, 0.115, 0.178, 0.173, 0.203, 0.218, 0.22, 0.217, 0.168, 2.235, 0.141, 0.116, 0.137, 0.156, 0.245, 0.196, 0.343, 0.14, 0.135, 0.171, 0.137, 0.209, 0.145, 0.144, 0.229, 0.307, 0.136, 0.167, 0.152, 0.213, 0.246, 0.258, 0.242, 0.194, 0.189, 0.158, 0.186, 0.158, 0.126, 0.21, 0.142, 0.181, 0.197, 0.121, 0.164, 0.146, 0.144, 0.174, 0.118, 0.193, 0.181, 0.187, 0.277, 0.141, 0.177, 0.19, 0.144, 0.14, 0.17, 0.158, 0.149, 0.147, 0.135, 0.188, 0.15, 0.197, 0.175, 0.171, 0.184, 0.144, 0.145, 0.809, 0.186, 0.165, 0.174, 0.14, 0.222, 0.172, 0.195, 0.228, 0.151, 0.134, 0.164, 0.2, 1.513, 0.148, 0.145, 0.144, 0.176, 0.161, 0.138, 0.157, 0.171, 0.193, 0.171, 0.227, 0.166, 0.166, 0.246, 0.2, 0.141, 0.203, 0.134, 0.193, 0.22, 0.223, 0.251, 0.158, 0.157, 0.141, 0.157, 0.194, 0.133, 0.133, 0.203, 0.19, 0.263, 0.194, 0.14, 0.201, 0.139, 0.267, 0.13, 0.143, 0.135, 0.138, 0.109, 0.133, 0.17, 0.146, 0.169, 0.14, 0.156, 0.173, 0.142, 0.183, 0.186, 0.302, 0.132, 0.152, 0.146, 0.098, 0.201, 0.189, 0.1, 0.17, 0.167, 0.155, 0.278, 0.217, 0.128, 0.128, 0.158, 0.222, 0.193, 0.217, 0.152, 0.184, 0.2, 0.172, 0.173, 0.198, 0.142, 0.23, 0.177, 0.255, 0.131, 0.192, 0.167, 0.206, 0.179, 0.164, 0.175, 0.193, 0.186, 0.192, 0.197, 0.138, 0.14, 0.221, 0.192, 0.164, 0.211, 0.182, 0.135, 0.215, 0.131, 0.534, 0.157, 0.182, 0.878, 0.165, 0.173, 0.149, 0.194, 0.219, 0.21, 0.184, 0.214, 0.192, 0.181, 0.179, 0.194, 0.161, 0.164, 0.165, 0.22, 0.223, 0.237, 0.137, 0.151, 0.197, 0.185, 0.153, 0.148, 0.168, 0.203, 0.138, 0.202, 0.132, 0.141, 0.156, 0.148, 0.194, 0.208, 0.156, 0.147, 0.171, 0.135, 0.133, 0.167, 0.205, 0.14, 0.164, 0.132, 0.123, 0.193, 0.158, 0.151, 0.117, 0.138, 0.178, 0.201, 0.224, 0.15, 0.164, 0.181, 0.201, 0.174, 0.211, 0.151, 0.17, 0.148, 0.18, 0.139, 0.161, 0.134, 0.187, 0.143, 0.19, 0.184, 0.196, 0.154, 0.137, 0.164, 0.173, 0.136, 0.16, 0.174, 0.158, 0.147, 0.193, 0.144, 0.17, 0.201, 0.208, 0.14, 0.142, 0.137, 0.22, 0.245, 0.176, 0.124, 0.452, 0.159, 0.197, 0.165, 0.154, 0.214, 0.184, 0.217, 0.347, 0.15, 0.172, 0.14, 0.167, 0.176, 0.162, 0.147, 0.151, 0.173, 0.134, 0.177, 0.145, 0.146, 0.138, 0.205, 0.155, 0.174, 0.175, 0.296, 0.181, 0.303, 0.227, 0.22, 0.149, 0.199, 0.46, 0.169, 0.165, 0.148, 0.138, 0.156, 0.187, 0.145, 0.163, 0.19, 0.284, 0.158, 0.217, 0.169, 0.187, 0.194, 0.165, 0.215, 0.2, 0.22, 0.153, 0.207, 0.182, 1.04, 0.159, 0.24, 0.242, 0.217, 0.222, 0.203, 0.307, 0.142, 0.149, 0.154, 0.218, 0.12, 0.195, 0.231, 0.282, 1.187, 0.186, 0.159, 0.141, 0.219, 0.827, 0.147, 0.154, 0.233, 0.154, 0.203, 0.208, 0.16, 0.161, 0.346, 0.161, 0.213, 0.179, 0.156, 0.165, 0.233, 0.2, 0.197, 0.229, 0.2, 0.158, 0.156, 0.182, 0.155, 0.151, 0.162, 0.194, 0.166, 0.13, 0.11, 0.187, 0.168, 0.121, 0.147, 0.137, 0.234, 0.373, 0.143, 0.186, 0.673, 0.21, 0.195, 0.195, 0.196, 0.296, 0.174, 0.163, 0.147, 0.165, 0.151, 0.143, 0.156, 0.175, 0.203, 0.339, 0.223, 0.196, 0.169, 0.17, 0.194, 0.171, 0.186, 0.193, 0.275, 0.197, 0.129, 0.234, 0.244, 0.221, 0.135, 0.227, 0.094, 0.123, 0.197, 0.097, 0.136, 0.092, 0.163, 0.173, 0.13, 0.101, 0.12, 0.134, 0.162, 0.129, 0.102, 0.157, 0.164, 0.099, 0.152, 0.143, 0.143, 0.207, 0.103, 0.134, 0.151, 0.13, 0.156, 0.142, 0.118, 0.27, 0.112, 0.11, 0.113, 0.117, 0.123, 0.256, 0.184, 0.158, 0.125, 0.114, 0.16, 0.128, 0.127, 0.135, 0.142, 0.132, 0.096, 0.125, 0.186, 0.123, 0.12, 0.187, 0.149, 0.127, 0.191, 0.142, 0.155, 0.13, 0.129, 0.155, 0.128, 0.166, 0.309, 0.173, 0.229, 0.115, 0.176, 0.207, 0.299, 0.141, 0.138, 0.124, 0.168, 0.169, 0.184, 0.197, 0.208, 0.116, 0.18, 0.183, 0.173, 0.127, 0.15, 0.139, 0.137, 0.122, 0.158, 0.121, 0.152, 0.136, 0.149, 0.193, 0.116, 0.18, 0.156, 0.19, 0.143, 0.14, 0.131, 0.157, 0.137, 2.169, 0.131, 0.181, 0.104, 0.125, 0.199, 0.213, 0.155, 0.171, 1.113, 0.181, 0.31, 0.167, 0.169, 0.222, 0.215, 0.16, 0.121, 0.109, 0.117, 0.194, 0.202, 0.521, 0.157, 0.11, 0.131, 0.152, 0.176, 0.146, 0.169, 0.164, 0.192, 0.161, 0.188, 0.132, 0.182, 0.152, 0.167, 0.145, 0.232, 0.169, 0.118, 0.281, 0.148, 0.156, 0.222, 0.144, 0.125, 0.166, 0.192, 0.15, 0.184, 0.147, 0.11, 0.139, 0.156, 0.128, 0.152, 0.106, 0.185, 0.176, 0.228, 0.19, 0.221, 0.111, 0.199, 0.128, 0.177, 0.193, 0.189, 0.167, 0.191, 0.119, 0.12, 0.201, 0.147, 0.729, 0.125, 0.122, 0.136, 0.14, 0.098, 0.145, 0.109, 0.166, 0.195, 0.168, 0.147, 0.189, 0.152, 0.143, 0.216, 0.208, 0.139, 0.244, 0.164, 0.166, 0.133, 0.194, 0.162, 0.204, 0.104, 0.22, 0.294, 0.172, 0.227, 0.135, 0.146, 0.224, 0.204, 0.162, 0.17, 0.172, 0.13, 0.1, 0.127, 0.286, 0.168, 0.184, 0.159, 0.186, 0.14, 0.118, 0.197, 0.113, 0.116, 0.166, 0.163, 0.227, 0.187, 0.19, 0.973, 0.129, 0.15, 0.188, 0.179, 0.186, 0.199, 0.212, 0.209, 0.161, 0.136, 0.214, 0.169, 0.157, 0.14, 0.23, 0.197, 0.14, 0.348, 0.615, 0.189, 0.172, 0.23, 0.192, 0.179, 0.196, 0.138, 1.168, 0.179, 0.17, 0.148, 0.149, 0.185, 0.182, 0.22, 0.183, 0.158, 0.134, 0.134, 0.148, 0.204, 0.11, 0.171, 0.169, 0.199, 0.288, 0.18, 0.175, 0.232, 0.184, 0.283, 0.213, 0.191, 0.157, 0.151, 0.125, 0.118, 0.109, 0.125, 0.115, 0.212, 0.139, 0.146, 0.147, 0.165, 0.164, 0.139, 0.125, 0.109, 0.108, 0.204, 0.178, 0.206, 0.149, 0.15, 0.199, 0.276, 0.178, 0.128, 0.147, 0.157, 0.232, 0.15, 0.146, 0.205, 0.202, 0.176, 0.109, 0.154, 0.105, 0.186, 0.115, 0.115, 0.144, 0.159, 0.157, 0.123, 0.169, 0.128, 0.143, 0.178, 0.159, 0.299, 0.174, 0.171, 0.145, 0.157, 0.114, 0.122, 0.19, 0.123, 0.148, 0.12, 0.185, 0.125, 0.134, 0.112, 0.178, 0.16, 0.136, 0.123, 0.141, 0.111, 0.172, 0.138, 0.165, 0.126, 0.148, 0.191, 0.188, 0.129, 0.208, 0.113, 0.14, 0.196, 0.126, 0.111, 0.181, 0.227, 0.164, 0.15, 0.372, 0.162, 0.17, 0.14, 0.119, 0.465, 0.152, 0.164, 0.172, 0.122, 0.175, 0.171, 0.161, 0.143, 0.106, 0.284, 0.175, 0.123, 0.195, 0.147, 0.109, 0.152, 0.195, 0.182, 0.16, 0.151, 0.126, 0.159, 0.128, 0.162, 0.152, 0.118, 0.143, 0.203, 0.217, 0.126, 0.123, 0.108, 0.109, 0.137, 0.149, 0.141, 0.162, 0.302, 0.165, 0.111, 0.201, 0.145, 0.181, 0.426, 0.12, 0.129, 0.146, 0.164, 0.287, 0.399, 0.164, 0.184, 0.995, 0.187, 0.12, 0.126, 0.112, 0.153, 0.318, 0.238, 0.197, 0.144, 0.161, 0.123, 0.166, 0.192, 0.224, 0.149, 0.149, 0.192, 0.145, 0.108, 0.108, 0.113, 0.126, 0.14, 0.134, 0.162, 0.138, 0.101, 0.115, 0.132, 0.179, 0.126, 0.139, 0.152, 0.153, 0.152, 0.174, 0.22, 0.121, 0.155, 0.094, 0.121, 0.103, 0.212, 0.087, 0.093, 0.13, 0.122, 0.179, 0.157, 0.162, 0.15, 0.157, 0.146, 0.141, 0.219, 0.187, 0.191, 0.183, 0.207, 0.119, 0.274, 0.214, 0.198, 0.181, 0.128, 0.335, 0.251, 0.208, 0.108, 0.144, 0.149, 0.155, 0.274, 0.124, 0.103, 0.146, 0.119, 0.201, 0.189, 0.224, 0.11, 0.162, 0.163, 0.2, 0.181, 0.204, 0.096, 0.096, 0.117, 0.236, 0.18, 0.152, 0.178, 0.166, 0.187, 0.248, 0.25, 0.165, 0.143, 0.148, 0.169, 0.113, 0.187, 1.001, 0.154, 0.214, 0.221, 0.216, 0.343, 0.111, 0.724, 0.148, 0.191, 0.133, 0.266, 0.147, 0.143, 0.105, 0.116, 0.126, 0.476, 0.2, 0.126, 0.165, 0.164, 0.19, 0.132, 0.163, 0.201, 0.123, 0.147, 0.107, 0.194, 0.182, 0.151, 0.154, 0.121, 0.156, 0.194, 0.137, 0.21, 0.193, 0.137, 0.156, 0.204, 0.197, 0.209, 0.155, 0.148, 0.141, 0.168, 0.131, 0.175, 0.204, 0.218, 0.241, 0.15, 0.21, 0.168, 0.214, 0.148, 0.209, 0.167, 0.172, 0.175, 0.134, 0.175, 0.161, 0.21, 0.192, 0.162, 0.183, 0.115, 0.19, 0.165, 0.128, 0.111, 0.089, 0.103, 0.09, 0.221, 0.19, 0.17, 0.111, 0.111, 0.135, 0.117, 0.144, 0.123, 0.139, 0.161, 0.121, 0.136, 0.121, 0.11, 0.139, 0.161, 0.153, 0.128, 0.15, 0.152, 0.117, 0.256, 0.787, 0.145, 0.172, 0.175, 2.362, 0.145, 0.115, 0.145, 0.156, 0.122, 0.145, 0.187, 0.318, 0.142, 0.125, 0.108, 0.141, 0.177, 0.201, 0.16, 0.171, 0.128, 0.115, 0.137, 0.115, 0.155, 0.153, 0.141, 0.204, 0.142, 0.206, 0.114, 0.156, 0.124, 0.102, 0.14, 0.173, 0.165, 0.19, 0.173, 0.18, 0.112, 0.137, 0.114, 0.337, 1.006, 0.179, 0.136, 0.211, 0.187, 0.175, 0.192, 0.284, 0.171, 0.211, 0.23, 0.268, 0.186, 0.201, 0.167, 0.199, 0.15, 0.252, 0.204, 0.244, 0.206, 0.274, 0.187, 0.207, 0.247, 0.17, 0.179, 0.13, 0.153, 0.155, 0.187, 0.252, 0.345, 0.236, 0.213, 0.446, 0.179, 0.204, 0.159, 0.364, 0.209, 0.231, 0.168, 0.215, 0.227, 0.263, 0.214, 0.21, 0.124, 0.127, 0.157, 0.201, 0.131, 0.163, 0.171, 0.356, 0.151, 0.16, 0.169, 0.213, 0.166, 0.241, 0.199, 0.223, 0.141, 0.182, 0.191, 0.164, 0.169, 0.14, 0.19, 0.226, 0.221, 0.224, 0.177, 0.201, 0.192, 0.158, 0.192, 0.127, 0.124, 0.177, 0.141, 0.123, 0.188, 0.147, 0.202, 0.217, 0.198, 0.17, 0.204, 0.157, 0.167, 0.181, 0.145, 0.267, 0.169, 0.208, 0.233, 0.219, 0.207, 0.216, 0.184, 0.152, 0.209, 0.226, 0.454, 0.121, 0.196, 0.169, 0.143, 0.183, 0.226, 0.153, 0.218, 0.196, 0.19, 0.146, 0.148, 0.154, 0.225, 0.21, 0.196, 0.152, 0.19, 0.2, 0.168, 0.246, 0.245, 0.17, 0.226, 0.218, 0.189, 0.23, 0.129, 0.168, 0.167, 0.119, 0.113, 0.146, 0.18, 0.158, 0.197, 0.209, 0.216, 0.142, 0.17, 0.147, 0.194, 0.182, 0.184, 0.238, 0.238, 0.23, 0.237, 0.227, 0.138, 0.195, 0.209, 0.174, 0.161, 0.19, 0.211, 0.145, 0.134, 0.159, 0.194, 0.173, 0.257, 0.146, 0.334, 0.136, 0.149, 0.097, 0.117, 0.146, 0.144, 0.174, 0.154, 0.141, 0.163, 0.182, 0.187, 0.135, 0.155, 0.222, 0.18, 0.156, 0.228, 0.15, 0.222, 0.237, 0.146, 0.19, 0.162, 0.152, 0.241, 0.174, 0.168, 1.202, 0.195, 0.134, 0.227, 0.169, 0.227, 0.113, 0.17, 0.222, 0.138, 0.19, 0.185, 0.218, 0.243, 0.142, 0.157, 0.113, 0.263, 0.175, 0.171, 0.252, 0.226, 0.196, 0.143, 0.179, 0.327, 0.176, 0.138, 0.173, 0.138, 0.193, 0.164, 0.175, 0.299, 0.221, 0.205, 0.233, 0.124, 0.191, 0.211, 0.213, 0.136, 0.153, 0.141, 0.15, 0.188, 0.186, 0.176, 0.175, 0.22, 0.197, 0.212, 0.195, 0.2, 0.179, 0.154, 0.221, 0.189, 0.156, 0.243, 0.151, 0.206, 0.342, 0.208, 0.225, 0.152, 0.205, 0.246, 0.221, 0.23, 0.161, 0.154, 0.225, 0.234, 0.199, 0.153, 0.194, 0.134, 0.155, 0.16, 0.305, 0.12, 0.193, 0.208, 0.154, 0.217, 0.551, 0.151, 0.205, 0.2, 0.157, 0.214, 0.193, 0.219, 0.218, 0.229, 0.201, 0.195, 0.202, 0.204, 1.104, 0.288, 0.184, 0.152, 0.158, 0.187, 0.199, 0.215, 0.208, 0.204, 0.206, 0.225, 0.173, 0.155, 0.182, 0.153, 0.14, 0.216, 0.197, 0.246, 0.144, 0.114, 0.1, 0.149, 0.123, 0.119, 0.18, 0.12, 0.289, 0.159, 0.167, 0.184, 0.157, 0.129, 0.123, 0.122, 0.119, 0.148, 0.139, 0.151, 0.133, 0.176, 0.198, 0.176, 0.155, 0.158, 0.158, 0.19, 0.246, 0.122, 0.167, 0.145, 0.157, 0.36, 0.107, 0.143, 0.12, 0.134, 0.142, 0.179, 0.188, 0.155, 0.175, 0.161, 0.122, 0.147, 0.204, 0.114, 0.182, 0.166, 0.15, 0.122, 0.121, 0.141, 0.098, 0.218, 0.13, 0.114, 0.114, 0.122, 0.104, 0.096, 0.135, 0.12, 0.205, 0.322, 0.116, 0.13, 0.575, 0.139, 0.148, 0.196, 0.16, 0.14, 0.106, 1.077, 0.173, 0.108, 0.101, 0.142, 0.133, 0.125, 0.132, 0.165, 0.093, 0.123, 0.133, 0.169, 0.131, 0.169, 0.13, 0.131, 0.186, 0.134, 0.156, 0.224, 0.115, 0.151, 0.132, 0.171, 0.112, 0.156, 0.13, 0.173, 0.094, 0.146, 0.119, 0.149, 0.128, 0.171, 0.321, 0.142, 0.174, 0.162, 0.132, 0.155, 0.153, 0.289, 0.197, 0.178, 0.165, 0.168, 0.112, 0.154, 0.165, 0.107, 0.099, 0.445, 0.158, 0.116, 0.137, 0.178, 0.224, 0.152, 0.173, 0.124, 0.205, 0.139, 0.109, 0.191, 0.159, 0.148, 0.108, 0.156, 0.119, 0.123, 0.117, 0.181, 0.11, 0.165, 0.141, 0.157, 0.149, 0.159, 0.288, 0.154, 1.048, 0.122, 0.169, 0.2, 0.117, 0.19, 0.15, 0.097, 0.142, 0.145, 0.106, 0.166, 0.189, 0.168, 0.145, 0.139, 0.117, 0.156, 0.157, 0.132, 0.546, 0.161, 1.017, 0.203, 0.147, 0.147, 0.176, 0.132, 0.192, 0.144, 0.296, 0.176, 0.169, 0.196, 0.154, 0.125, 0.271, 0.096, 0.198, 0.137, 0.152, 0.172, 0.115, 0.128, 0.279, 0.11, 0.154, 0.137, 0.113, 0.137, 0.158, 0.133, 0.125, 0.129, 0.141, 0.116, 0.15, 0.123, 0.123, 0.263, 0.344, 0.166, 0.119, 0.115, 0.213, 0.212, 0.178, 0.108, 0.126, 0.115, 0.184, 0.148, 0.14, 0.15, 0.173, 0.133, 0.153, 0.17, 0.195, 0.154, 0.182, 0.189, 0.174, 0.206, 0.279, 0.218, 0.15, 0.155, 0.174, 0.214, 0.157, 0.246, 0.203, 0.171, 0.141, 0.207, 0.231, 0.204, 0.222, 0.194, 0.242, 0.142, 0.208, 0.218, 0.131, 0.115, 0.163, 0.145, 0.165, 0.126, 0.115, 0.149, 0.169, 0.199, 0.177, 0.144, 0.201, 0.148, 0.137, 0.138, 0.22, 0.154, 0.158, 0.161, 0.319, 0.582, 0.18, 0.143, 0.157, 0.178, 0.203, 0.121, 0.179, 0.154, 0.177, 0.155, 0.154, 0.273, 0.157, 0.184, 0.118, 0.191, 0.159, 0.159, 0.582, 0.131, 0.158, 0.127, 0.128, 0.111, 0.219, 0.192, 0.152, 0.208, 0.157, 0.256, 0.143, 0.518, 0.147, 0.162, 0.193, 0.208, 0.179, 0.117, 0.13, 0.152, 0.176, 0.248, 0.198, 0.221, 0.218, 0.183, 0.176, 0.182, 0.281, 0.141, 0.283, 0.291, 0.144, 0.243, 0.173, 0.123, 0.109, 0.104, 0.174, 0.179, 0.24, 0.163, 0.211, 0.171, 0.235, 0.226, 0.163, 0.136, 0.251, 0.157, 0.128, 0.118, 0.15, 0.147, 0.135, 0.132, 0.153, 0.219, 0.176, 0.173, 0.168, 0.206, 0.227, 0.173, 0.165, 0.211, 0.122, 0.187, 0.236, 0.176, 0.134, 0.149, 0.123, 0.13, 0.173, 0.175, 0.154, 0.225, 0.16, 0.215, 0.24, 0.153, 0.186, 0.22, 0.123, 0.2, 0.259, 0.169, 0.181, 0.246, 0.136, 0.181, 0.226, 0.214, 0.201, 0.145, 0.186, 0.193, 0.152, 0.127, 0.123, 0.206, 0.207, 0.136, 0.194, 0.217, 0.175, 0.18, 0.272, 0.211, 0.208, 0.165, 0.227, 0.15, 0.11, 0.184, 0.156, 0.166, 0.171, 0.288, 0.202, 0.211, 0.217, 0.269, 0.116, 0.162, 0.137, 0.167, 0.21, 0.177, 0.209, 0.119, 0.129, 0.186, 0.163, 0.151, 0.15, 0.159, 0.293, 0.166, 0.169, 0.141, 0.196, 0.14, 0.289, 0.225, 0.319, 0.149, 0.191, 0.153, 0.144, 0.226, 0.237, 0.137, 0.14, 0.166, 1.2, 0.301, 0.183, 0.18, 0.158, 0.18, 0.267, 0.131, 0.167, 0.149, 0.211, 0.13, 0.216, 0.266, 0.181, 0.216, 0.14, 2.137, 0.203, 0.275, 0.231, 0.139, 0.184, 0.205, 0.202, 0.265, 0.145, 0.13, 0.187, 0.214, 0.183, 0.205, 0.206, 0.125, 0.179, 0.192, 0.19, 0.131, 0.172, 0.234, 0.28, 0.182, 0.19, 0.177, 0.195, 0.131, 0.165, 0.171, 0.155, 0.287, 0.227, 0.183, 0.172, 0.253, 0.158, 0.155, 0.204, 0.185, 0.148, 0.152, 0.248, 0.149, 0.184, 0.211, 0.22, 0.19, 0.16, 0.197, 0.169, 0.195, 0.125, 0.223, 0.153, 0.598, 0.233, 0.206, 0.153, 0.238, 0.186, 0.322, 0.259, 0.189, 0.212, 0.212, 0.147, 0.157, 0.086, 0.164, 0.15, 0.174, 0.164, 0.214, 0.117, 0.206, 0.176, 0.221, 0.129, 0.15, 0.191, 0.217, 0.15, 0.185, 0.152, 0.158, 0.149, 0.27, 0.096, 0.095, 0.126, 0.093, 0.151, 0.137, 0.188, 0.184, 0.15, 0.163, 0.165, 0.252, 0.201, 0.208, 0.149, 0.2, 0.157, 0.205, 0.202, 0.27, 0.194, 0.258, 0.214, 0.146, 0.142, 0.238, 0.175, 0.239, 0.188, 0.213, 0.217, 0.272, 0.253, 0.304, 0.253, 0.194, 0.149, 0.298, 0.179, 0.178, 0.139, 0.212, 0.212, 0.246, 0.97, 0.178, 0.263, 0.163, 0.145, 0.215, 0.203, 0.194, 0.137, 0.175, 0.12, 0.302, 0.187, 0.129, 0.325, 0.15, 0.115, 0.174, 0.117, 0.173, 0.171, 0.154, 0.144, 0.284, 0.178, 0.136, 1.001, 0.197, 0.252, 0.148, 0.202, 0.169, 0.224, 0.53, 0.118, 0.111, 0.182, 0.193, 0.169, 0.126, 0.157, 0.142, 0.218, 0.184, 0.163, 0.175, 0.192, 0.139, 0.277, 0.12, 0.202, 0.193, 0.147, 0.197, 0.189, 0.568, 0.228, 0.145, 0.236, 0.181, 0.195, 0.23, 0.208, 0.147, 0.351, 0.15, 0.135, 0.204, 0.193, 0.239, 0.362, 0.385, 0.155, 0.142, 0.121, 0.204, 0.214, 0.195, 0.181, 0.197, 0.211, 0.15, 0.151, 0.192, 0.137, 0.224, 0.137, 0.198, 0.145, 0.231, 0.227, 0.181, 0.216, 0.16, 0.194, 0.197, 0.187, 0.145, 0.324, 0.109, 0.118, 0.141, 0.109, 0.14, 0.207, 0.114, 0.19, 0.132, 0.209, 0.213, 0.163, 0.177, 0.193, 0.164, 0.141, 0.21, 0.17, 0.144, 0.138, 0.164, 0.135, 0.14, 0.14, 0.193, 0.18, 0.188, 0.196, 0.191, 0.115, 0.2, 1.264, 0.2, 0.235, 0.238, 0.24, 0.23, 0.156, 0.154, 0.15, 0.143, 0.165, 0.125, 0.141, 0.136, 0.132, 0.153, 0.211, 0.192, 0.251, 0.195, 0.147, 0.155, 0.198, 0.149, 0.253, 0.174, 0.275, 0.156, 0.117, 0.152, 0.188, 0.166, 0.218, 0.185, 0.145, 0.168, 0.212, 0.483, 0.209, 0.146, 0.146, 0.161, 0.228, 0.24, 0.207, 0.175, 0.127, 0.291, 0.179, 0.148, 0.159, 0.15, 0.161, 0.173, 0.354, 0.154, 0.179, 0.21, 0.133, 0.125, 0.17, 0.154, 0.208, 0.147, 0.175, 0.212, 0.214, 0.127, 0.224, 0.15, 0.155, 0.154, 0.143, 0.141, 0.212, 0.171, 0.157, 0.158, 0.164, 0.191, 0.152, 0.243, 0.149, 0.22, 0.127, 0.224, 0.128, 0.188, 0.156, 0.135, 0.163, 0.159, 0.132, 0.176, 0.197, 0.178, 0.19, 0.188, 0.228, 0.148, 0.152, 0.141, 0.184, 1.08, 0.146, 0.223, 0.226, 0.196, 0.173, 0.17, 0.169, 0.171, 0.149, 0.214, 0.208, 0.138, 0.158, 0.159, 0.124, 0.189, 0.138, 0.144, 0.223, 0.245, 0.229, 0.129, 0.267, 0.174, 0.152, 0.147, 0.206, 0.228, 0.213, 0.208, 0.21, 0.164, 0.15, 0.192, 0.183, 0.129, 0.172, 0.149, 0.156, 0.165, 0.192, 0.192, 0.21, 0.224, 0.138, 0.223, 0.186, 0.217, 0.181, 0.133, 0.183, 0.147, 0.113, 0.202, 0.218, 0.28, 0.159, 0.169, 0.149, 0.123, 0.095, 0.166, 0.171, 0.136, 0.157, 0.146, 0.147, 0.137, 0.201, 0.12, 0.208, 0.169, 0.155, 0.202, 0.227, 0.178, 0.194, 0.165, 0.176, 0.21, 0.124, 0.196, 0.43, 0.172, 0.164, 0.106, 0.115, 0.149, 0.152, 0.138, 0.136, 0.295, 0.133, 0.148, 0.728, 0.22, 0.244, 0.193, 0.218, 0.129, 0.143, 0.133, 0.146, 0.136, 0.151, 0.194, 0.147, 0.151, 0.144, 0.15, 0.204, 0.196, 0.162, 0.166, 0.184, 0.184, 0.162, 0.182, 0.785, 0.144, 0.167, 0.169, 0.138, 0.138, 0.202, 0.234, 0.218, 0.233, 0.248, 0.158, 0.164, 0.267, 0.239, 0.155, 0.218, 4.321, 0.125, 0.158, 0.189, 0.16, 0.163, 0.124, 0.17, 0.224, 0.142, 0.185, 0.204, 0.14, 0.213, 0.153, 0.189, 0.142, 0.43, 0.138, 0.2, 0.16, 0.14, 0.183, 0.14
    #         ]
    #     ], 
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             2.198, 5.82, 1.644, 2.446, 4.125, 3.16, 2.999, 2.422, 3.851, 3.294, 1.767, 8.1, 2.624, 20.112, 3.236, 2.9, 3.077, 20.598, 2.528, 2.163, 2.293, 1.638, 4.996, 3.241, 1.374, 1.561, 5.111, 2.202, 2.191, 1.834, 4.63, 4.664, 1.682, 1.372, 3.022, 9.643, 3.037, 2.765, 15.002, 1.884, 1.977, 4.527, 4.454, 1.989, 1.96, 1.65, 1.792, 2.738, 6.733, 3.232, 1.479, 1.82, 5.173
    #         ],
    #         [
    #             3.732, 6.956, 2.661, 4.144, 8.312, 6.578, 6.191, 3.614, 8.927, 5.16, 3.447, 10.002, 4.014, 25.411, 4.581, 8.635, 5.95, 19.499, 4.922, 3.172, 2.375, 2.715, 10.492, 13.346, 4.257, 4.972, 9.5, 4.183, 3.647, 2.971, 8.03, 8.89, 2.213, 2.73, 5.569, 11.039, 7.405, 7.856, 10.59, 3.143, 2.851, 9.699, 8.615, 3.277, 3.942, 2.893, 3.379, 4.342, 10.463, 5.298, 2.712, 3.321, 12.619, 15.376, 5.145, 3.315, 4.404, 8.218, 20.964, 32.07, 2.807, 3.367, 2.623, 2.62, 3.79, 4.108, 6.413, 5.741, 4.275, 21.896, 8.563, 3.323, 4.82, 18.497, 4.214, 1.722, 14.493, 3.63, 4.89, 3.612, 3.006, 2.365, 2.062, 7.498, 3.37, 4.83, 4.269, 5.863, 4.796, 2.99, 5.631, 3.503, 4.99, 1.869, 3.844, 2.378, 6.51, 29.027, 6.616, 3.295, 11.748, 3.867, 4.396, 3.927, 19.239, 4.996, 3.876, 4.049, 7.851, 6.613, 4.113, 5.0, 14.934, 2.97, 4.736, 3.423, 34.848, 3.249, 30.293, 4.711, 9.741, 13.079, 3.302, 4.614, 4.161, 8.778, 1.737, 3.618, 2.07, 14.139, 6.045, 4.991, 2.887, 2.174, 5.255, 3.29, 4.348, 1.93, 3.366, 1.997, 15.43, 2.031, 2.451, 1.809, 3.593, 2.742, 3.658, 3.373, 6.012, 2.546, 5.497, 3.883, 5.276, 4.61, 7.009, 7.476, 2.815, 21.149, 7.299, 8.359, 3.542, 13.03, 10.285, 4.044, 3.684, 7.3, 6.843, 6.407, 50.788, 18.271, 19.806, 2.866, 2.843, 8.278, 4.227, 5.432, 10.718, 3.389, 3.555, 5.833, 4.567, 4.848, 4.717, 2.815, 8.644, 5.758, 3.996, 3.303, 2.825, 4.779, 5.169, 2.735, 3.577, 2.625, 3.421, 3.414, 3.856, 15.102, 5.794, 5.041, 9.971, 3.92, 2.125, 5.377, 3.336, 3.128, 3.664, 34.078, 5.026, 7.18, 3.666, 3.455, 3.416, 7.005, 1.957, 14.892, 5.007, 4.667, 5.985, 1.81, 3.272, 5.588, 3.312, 3.693, 2.967, 15.425, 4.247, 3.759, 2.48, 2.186, 2.705, 2.859, 2.213, 2.439, 3.232, 11.764, 2.43, 5.219, 10.089, 3.777, 14.31, 8.314, 54.291, 5.74, 4.919, 2.695, 13.661, 3.765, 5.871, 5.669, 3.236, 2.671, 5.814, 4.976, 3.457, 2.603, 6.468, 1.89, 1.846, 3.116, 37.668, 13.995, 5.501, 3.566, 4.076, 2.984, 3.793, 7.644, 1.897, 2.728, 10.438, 7.138, 3.374, 30.661, 3.228, 41.132, 2.567, 4.39, 4.178, 4.756, 5.136, 8.164, 1.736, 3.198, 2.975, 2.654, 1.494, 7.331, 4.488, 2.354, 1.94, 3.983, 10.947, 17.268, 2.572, 2.017, 3.808, 3.851, 4.15, 6.961, 7.537, 4.983, 7.16, 17.68, 9.787, 7.225, 4.545, 6.58, 3.237, 2.971, 1.654, 4.238, 2.256, 50.829, 4.308, 3.868, 4.408, 4.114, 29.766, 5.424, 3.148, 14.322, 3.373, 4.311, 2.098, 2.973, 1.982, 4.345, 8.322, 2.071, 6.698, 2.359, 2.119, 2.521, 2.453, 4.665, 3.399, 17.712, 3.512, 4.725, 5.85, 7.162, 4.688, 3.229, 5.02, 3.172, 5.507, 10.644, 2.715, 1.952, 3.49, 2.529, 3.641, 3.858, 1.466, 2.19, 6.459, 8.42, 1.487, 1.66, 4.821, 4.622, 5.609, 5.571, 2.879, 13.992, 2.303, 15.998, 4.643, 6.912, 2.316, 7.127, 4.993, 3.414, 3.07, 3.632, 2.377, 2.449, 11.217, 5.651, 2.16, 6.776, 3.799, 7.354, 4.803, 1.788, 4.166, 2.194, 3.128, 3.218, 3.029, 2.989, 5.056, 3.872, 4.959, 22.097, 4.166, 33.978, 2.565, 2.474, 4.336, 2.451, 1.85, 7.969, 1.962, 2.147, 3.131, 2.254, 2.741, 6.553, 14.917, 3.884, 4.148, 13.072, 4.716, 2.889, 6.683, 7.537, 2.387, 3.994, 3.353, 2.999, 1.806, 14.828, 2.04, 2.589, 2.7, 4.874, 3.071, 3.554, 1.887, 1.56, 1.504, 1.997, 8.004, 3.075, 3.127, 3.051, 4.555, 3.734, 2.353, 1.942, 3.676, 9.337, 2.511, 7.58, 2.793, 21.907, 1.97, 4.825
    #         ]
    #     ], 
    #     [
    #         [
    #             14.849, 7.229, 13.458, 9.353, 12.132, 17.089, 42.65, 9.868, 27.474, 8.853, 6.041, 14.518, 4.493, 13.703, 6.887, 16.5, 3.835, 25.077, 10.438, 20.706, 9.148, 11.729, 5.05, 8.112, 18.751, 5.126, 24.539, 7.303, 8.02, 37.465, 4.7, 3.902, 6.786, 11.231, 21.064, 7.205, 35.583, 5.925, 17.05, 9.274, 5.668, 12.107
    #         ],
    #         [
    #             22.174, 11.216, 19.947, 17.87, 16.275, 23.255, 89.372, 11.384, 48.279, 13.587, 8.171, 21.217, 8.879, 27.455, 13.331, 35.09, 5.384, 40.399, 21.216, 43.755, 13.998, 23.449, 7.979, 12.028, 24.483, 9.841, 50.011, 18.667, 29.306, 63.957, 8.925, 8.148, 10.66, 36.816, 40.153, 12.376, 42.923, 8.803, 25.933, 14.411, 9.548, 17.995, 12.988, 21.031, 14.198, 16.339, 12.52, 10.014, 72.303, 21.754, 24.707, 13.314, 36.728, 11.408, 23.66, 20.209, 38.798, 13.554, 72.144, 50.169, 33.363, 13.411, 27.698, 19.078, 14.828, 28.281, 10.377, 18.118, 13.444, 7.83, 47.984, 8.147, 13.416, 14.169, 19.175, 14.801, 16.762, 25.255, 36.961, 21.271, 18.361, 20.811, 18.805, 10.548, 100.591, 43.61, 26.447, 19.854, 28.924, 17.922, 17.964, 14.313, 54.139, 13.654, 19.879, 15.395, 10.564, 11.967, 47.312, 33.505, 25.654, 13.237, 9.745, 145.075, 65.357, 62.178, 66.173, 67.421, 79.35, 23.917, 29.43, 13.6, 38.394, 15.902, 9.14, 10.926, 10.898, 27.438, 13.218, 28.75, 62.509, 70.508, 11.024, 34.541, 19.194, 10.817, 19.442, 11.032, 15.166, 9.682, 140.208, 25.428, 14.96, 30.77, 11.393, 34.491, 44.498, 67.044, 12.175, 14.531, 15.851, 14.736, 8.519, 18.857, 12.895, 13.053, 57.008, 6.689, 13.754, 30.256, 17.03, 52.323, 33.511, 10.526, 10.24, 9.643, 94.064, 23.349, 13.942, 65.536, 27.439, 12.929, 12.68, 19.586, 15.239, 20.577, 7.495, 11.895, 27.882, 18.007, 17.831, 14.709, 19.352, 32.425, 6.547, 14.85, 18.678, 9.584, 39.883, 7.94, 26.978, 18.485, 39.028, 43.304, 18.948, 12.676, 23.691, 12.484, 11.514, 32.996, 15.22, 29.752, 18.635, 8.742, 8.937, 11.952, 33.072, 50.096, 85.796, 8.85, 13.845, 25.947, 8.676, 9.507, 28.179, 41.059, 52.486, 22.9, 44.401, 15.235, 16.084, 43.017, 8.793, 23.497, 20.347, 8.742, 7.656, 29.065, 16.353, 21.15, 9.433, 32.137, 33.291, 61.35, 16.359
    #         ]
    #     ],   
    #     [
    #         [
    #             66.519, 59.066, 159.58, 97.916, 48.263, 54.411, 71.096, 121.258, 56.131, 68.466,
    #             80.879, 102.242, 22.25, 95.597, 107.314, 67.143, 49.235, 72.488, 53.172, 195.691
    #         ],
    #         [
    #             137.52, 108.837, 246.572, 154.826, 72.207, 91.959, 100.265, 194.845, 110.499, 105.434, 
    #             200.806, 230.496, 54.144, 169.071, 182.641, 132.875, 100.119, 105.447, 100.602, 255.987,
    #             205.14, 147.829, 134.508, 239.642, 115.852, 74.865, 86.575, 51.963, 145.612, 135.914, 
    #             141.868, 246.479, 107.631, 290.425, 170.007, 138.145, 135.179, 192.867, 185.605, 258.184, 123.862, 212.337, 81.014, 131.813, 70.9, 103.839, 45.547, 138.468, 337.39, 151.631, 74.157, 75.901, 258.526, 85.102, 163.956, 215.382, 69.61, 112.424, 194.122, 119.476, 165.655, 63.929, 208.652, 148.711, 103.568, 87.623, 88.546, 158.681, 133.89, 127.948, 71.644, 128.312, 102.619, 177.731, 96.87, 137.776, 132.611, 71.119, 125.586, 311.709, 100.045, 77.098, 180.829, 110.486, 116.486, 96.684, 66.725, 86.089, 90.376, 214.9
    #         ]
    #     ],  
    #     [
    #         [
    #             9806.265
    #         ],
    #         [
    #             12346.28, 12422.935
    #         ]
    #     ],
    #     [
    #         [
    #             66.713757, 27.303638, 28.933013, 15.040427, 31.832221, 15.822427, 39.659982, 16.17639, 49.957405, 16.892539, 71.813707, 59.22021, 40.204244, 89.076626, 66.949182, 22.410824, 21.787291, 22.674498, 91.928393, 46.050556, 45.436041, 46.135238, 46.214144, 24.212086, 47.954019, 49.161428, 24.774572, 543.030172, 50.92655, 25.253184, 26.008995, 52.089157, 27.438542, 59.124583, 54.253089, 53.13916, 52.876159, 53.474895, 27.498166, 81.529547, 27.517216, 54.645572, 55.073375, 55.718001, 56.197316, 55.545122, 56.367325, 55.324673, 55.631132, 58.011412, 29.192948, 29.434539, 58.581264, 42.27576, 58.834052, 59.455832, 63.181528, 59.88227, 30.029715, 30.670623, 60.469143, 90.384191, 62.116117, 91.009873, 61.972065, 62.10329, 62.037815, 63.112592, 127.465099, 62.127594, 63.912351, 49.210021, 62.929781, 64.763315, 111.806609, 64.146391, 63.642399, 65.067513, 32.834886, 32.783628, 32.907109, 33.435734, 67.354955, 65.163417, 33.81026, 66.891651, 336.836146, 66.299415, 66.625926, 67.025504, 34.377081, 100.488107, 69.035865, 34.529896, 34.158856, 102.658906, 68.734358, 67.207508, 102.430754, 34.479178, 68.926058, 68.762973, 68.847611, 69.293594, 125.490163, 69.670868, 69.482525, 70.222211, 35.737868, 69.314755, 171.349481, 105.317721, 70.12058, 104.820062, 36.196355, 70.268987, 70.714814, 70.275466, 35.310807, 37.169552, 71.092015, 70.173878, 36.220102, 71.067662, 71.065286, 71.027194, 70.902011, 70.463353, 237.613465, 36.718967, 36.402745, 71.905121, 36.968681, 71.312711, 72.028328, 71.502168, 71.982348, 71.231912, 36.615173, 36.704, 72.393682, 36.839928, 36.750586, 108.988475, 71.871456, 72.832602, 196.87902, 72.712106, 72.462307, 72.962539, 36.959872, 73.665186, 37.652796, 37.014514, 172.832798, 73.079304, 155.028575, 74.114117, 75.998182, 73.654732, 87.880411, 75.03358, 74.302367, 117.183801, 74.75444, 189.703566, 73.118068, 37.512824, 74.925125, 74.089314, 74.425734, 63.355518, 112.322403, 37.786912, 73.362124, 74.542727, 110.312629, 74.122876, 75.525088, 74.205304, 38.071936, 37.776551, 37.062789, 75.160551, 73.691666, 74.687334, 97.13263, 38.248381, 125.632069, 74.680612, 38.427063, 75.147329, 76.199641, 75.377472, 38.717832, 74.708955, 123.486298, 38.199919, 38.638698, 103.227113, 76.06351, 77.280838, 76.25736, 75.785727, 75.703777, 76.113636, 38.727361, 76.471439, 76.197064, 39.407531, 39.194357, 76.080404, 76.100145, 77.151177, 108.04195, 76.206087, 76.996669, 114.270728, 80.6434, 38.978655, 39.181544, 76.494713, 50.735464, 41.684434, 77.170943, 69.348997, 77.598529, 38.582697, 127.366524, 39.516122, 75.876952, 77.92682, 128.475328, 39.525023, 39.878575, 324.180485, 79.949708, 79.719327, 80.881544, 57.76456, 77.470235, 39.596038, 41.227166, 78.107912, 127.80863, 119.494056, 78.380629, 67.091887, 77.94742, 78.013164, 77.77475, 55.168014, 49.24549, 123.843258, 78.029063, 77.661388, 79.008292, 39.569581, 77.19768, 77.726212, 1133.255177, 78.166559, 78.477081, 79.244246, 89.686172, 78.717798, 129.193391, 79.120047, 39.821531, 79.609262, 79.566871, 78.368102, 40.720032, 78.094254, 78.476153, 79.348635, 39.463069, 121.35294, 79.072339, 79.25479, 79.06358, 40.251953, 40.241444, 40.003901, 80.349713, 41.036068, 78.504932, 40.78523, 40.369834, 274.330949, 80.436071, 40.721706, 79.447138, 40.655898, 40.845606, 40.647547, 40.870384, 43.225411, 40.913119, 120.718427, 81.822727, 41.404454, 81.501698, 41.116529, 103.038085, 163.474075, 41.398907, 41.596297, 81.047188, 80.956592, 213.852896, 40.406971, 108.48261, 40.852201, 83.128386, 82.127013, 81.374926, 183.223125, 41.000612, 42.032379, 82.160727, 124.131868, 83.122767, 41.079359, 41.892745, 65.408521, 82.017948, 42.144266, 125.02262, 81.534171, 81.633011, 82.242208, 41.564043, 41.823882, 81.498716, 41.906614, 41.877378, 82.451207, 278.919459, 81.838683, 125.122128, 84.574828, 125.268392, 82.437383, 83.318291, 81.945805, 42.469404, 49.189312, 42.257321, 83.18552, 41.805967, 42.039089, 42.546135, 136.028361, 82.546001, 82.660854, 83.307875, 41.708755, 208.686743, 751.419697, 42.451352, 42.360238, 83.200869, 42.268444, 82.502676, 42.251266, 62.209919, 125.910007, 42.25959, 82.802381, 83.418793, 53.971815, 92.107618, 126.601657, 42.098094, 283.77618, 82.657851, 81.913344, 42.462012, 41.540281, 82.627653, 83.64133, 84.295825, 42.679684, 85.529099, 98.336605, 42.422308, 85.439021, 82.407727, 84.865541, 82.416464, 84.160984, 42.956339, 84.351053, 83.999117, 42.505868, 42.752769, 124.842071, 83.800278, 84.762552, 82.768162, 42.453274, 84.278681, 84.286084, 42.484763, 85.398688, 42.582923, 84.128597, 84.757037, 85.607728, 84.263131, 84.670191, 171.682096, 43.021438, 83.232996, 127.29775, 85.073353, 84.709025, 83.425694, 42.977644, 236.118506, 84.364649, 131.21293, 43.091418, 84.847899, 43.055565, 83.821867, 85.31438, 84.539636, 84.496853, 43.012511, 84.995355, 43.619355, 85.636472, 84.998302, 85.18621, 43.108799, 84.054441, 85.075593, 85.686936, 109.748295, 84.657322, 85.257538, 131.429853, 89.480384, 83.982965, 190.644954, 84.859968, 257.738793, 85.624993, 84.403099, 43.261113, 44.119645, 43.731463, 85.91148, 85.815451, 43.694477, 85.193725, 133.972425, 132.089985, 43.866147, 156.863719, 85.4262, 43.936632, 84.952353, 54.977668, 84.36631, 85.792475, 192.297877, 107.391962, 43.099183, 45.640424, 43.033624, 85.213094, 85.456077, 44.004802, 43.530174, 128.801028, 87.061416, 85.781104, 44.411654, 85.351723, 85.485404, 87.951457, 43.889436, 86.896698, 86.138195, 86.584472, 135.553232, 86.371567, 85.725497, 85.120807, 84.786604, 85.256454, 85.4034, 85.619678, 43.385827, 44.244304, 43.530937, 84.987281, 44.867717, 43.745726, 85.421575, 44.196163, 85.162945, 86.535738, 44.035272, 143.221359, 44.042619, 86.551179, 86.288466, 133.865566, 86.029882, 44.140498, 87.471962, 99.890382, 44.226022, 44.352523, 87.482866, 44.616035, 87.737413, 87.620566, 147.058259, 86.414521, 129.841128, 43.974903, 86.366122, 194.785927, 131.066746, 44.415524, 44.69832, 86.128853, 43.935658, 43.922133, 86.483004, 87.783421, 44.184387, 87.725785, 87.351792, 174.520182, 86.414953, 85.951607, 87.853843, 44.453355, 44.427136, 87.864874, 43.753312, 55.928378, 88.542917, 44.002256, 87.489991, 43.914896, 45.294568, 44.051134, 87.170183, 44.429414, 44.570531, 93.562119, 134.356898, 86.514711, 67.681642, 88.113893, 43.947618, 89.468989, 43.66146, 88.247773, 89.912108, 44.727448, 87.94474, 44.545046, 89.949322, 86.685467, 44.835805, 184.230038, 82.0003, 45.022281, 88.926271, 132.281761, 46.231257, 45.548515, 87.248042, 89.129903, 44.460474, 87.93096, 182.851536, 88.601861, 45.132324, 87.612324, 88.409741, 88.519623, 87.264771, 131.730431, 44.092482, 87.210122, 71.444787, 144.98817, 43.97733, 44.759032, 87.291294, 44.915594, 236.837057, 88.441342, 87.689911, 44.579153, 88.908918, 136.461134, 131.905189, 45.850509, 89.014673, 162.141542, 88.518189, 88.029493, 44.87327, 88.793981, 131.387328, 150.13017, 133.351865, 90.769532, 90.425248, 127.476954, 91.67609, 44.579687, 65.360815, 45.500159, 45.03859, 92.461691, 145.437636, 45.066094, 88.31065, 88.2984, 91.838556, 44.348023, 45.094143, 91.013345, 88.180833, 135.704687, 88.719671, 89.669771, 144.95943, 89.13188, 45.713421, 44.651707, 89.028747, 45.078857, 89.522621, 89.024619, 45.059007, 45.102056, 44.951649, 89.35762, 143.555043, 133.379848, 134.248595, 45.522591, 89.349819, 89.5242, 45.350031, 101.556952, 89.039098, 92.047133, 88.804842, 88.97735, 45.505438, 89.524835, 45.593193, 45.216027, 45.677691, 88.064723, 88.855418, 89.617802, 45.962319, 45.34211, 91.029252, 89.891928, 133.13554, 45.495275, 88.952363, 89.650522, 89.621723, 45.901407, 45.224776, 44.739195, 45.900826, 45.736698, 56.919374, 184.703459, 89.348325, 89.59971, 90.973746, 45.240572, 89.230502, 90.381023, 94.094599, 45.319457, 145.373824, 89.956725, 153.488662, 89.399511, 45.506687, 90.343112, 45.987479, 45.766716, 139.683526, 45.158676, 45.253869, 90.669727, 45.480976, 89.383511, 185.883089, 90.069485, 209.223333, 90.092001, 100.868751, 45.560075, 45.402616, 45.152845, 139.009184, 89.048108, 755.065929, 89.653401, 46.211217, 45.99126, 45.554375, 137.093416, 93.301991, 92.792485, 115.24227, 90.541191, 89.834898, 90.175815, 90.475667, 134.676555, 90.248697, 46.067756, 89.6518, 190.227383, 91.194691, 90.057443, 151.818727, 137.743483, 136.351115, 46.180616, 92.006987, 90.205523, 90.8689, 45.740673, 45.97964, 45.935519, 46.681639, 131.433554, 142.044572, 46.322141, 89.584428, 46.683903, 89.337708, 46.676133, 46.041123, 247.599752, 89.872382, 90.052084, 46.176728, 197.796776, 482.558087, 90.967778, 91.504552, 90.832535, 93.147354, 45.902807, 141.888179, 47.626295, 91.680468, 46.999436, 138.81739, 90.492805, 92.621346, 46.749901, 46.795951, 91.077987, 91.442992, 46.104046, 92.193083, 94.416689, 139.870863, 92.722111, 137.944494, 46.746843, 47.77905, 91.859031, 92.590896, 46.105342, 46.999895, 137.556408, 91.898069, 164.628375, 45.541328, 91.760664, 91.65391, 93.713244, 93.527157, 92.504534, 140.091486, 46.665132, 93.479052, 92.899861, 46.920306, 46.664031, 54.742769, 47.29509, 90.918197, 91.579336, 91.452632, 46.304044, 91.410086, 129.820072, 92.22536, 94.397071, 46.805697, 91.627497, 94.31765, 95.134614, 93.628171, 91.326928, 97.101085, 46.453335, 153.140756, 46.723949, 91.400212, 92.010416, 91.498381, 113.83929, 52.45629, 100.758786, 112.279287, 94.307017, 47.114942, 91.926522, 141.069123, 121.776767, 92.390385, 95.361372, 109.744698, 91.693717, 47.78111, 231.259774, 67.802159, 95.794351, 101.221251, 93.795449, 47.43927, 94.406226, 201.314465, 48.596535, 145.891384, 92.313905, 114.10112, 95.226556, 48.75766, 48.36167, 48.60395, 50.225746, 48.451972, 96.324459, 49.201782, 144.295512, 48.782471, 95.196768, 121.588209, 95.872603, 49.038592, 95.367644, 48.982979, 58.855872, 96.004627, 103.885395, 48.325732, 95.992926, 94.837659, 96.527022, 48.580488, 97.975987, 47.330459, 96.344848, 95.735838, 139.346712, 49.279831, 97.494802, 95.409549, 212.019933, 142.774046, 49.565535, 49.447254, 97.160424, 49.224574, 100.249271, 95.163381, 109.804456, 94.869917, 48.908309, 97.171386, 96.814189, 48.384334, 94.226537, 93.997504, 48.040954, 94.408005, 94.73421, 91.548637, 47.726458, 138.14682, 91.96105, 93.246831, 92.280501, 101.998814, 47.318336, 92.71193, 93.513156, 148.295716, 94.449524, 102.949458, 47.303112, 47.357177, 92.979858, 92.828688, 48.043317, 95.595589, 94.14516, 166.849136, 93.488669, 93.643794, 94.579789, 92.291782, 94.587506, 47.304602, 154.71618, 92.94248, 92.477909, 94.3259, 143.781634, 96.592627, 51.942326, 103.370185, 100.713888, 101.837237, 51.726309, 51.518912, 103.62765, 101.793373, 102.409624, 101.017369, 91.638514, 116.64703, 100.840015, 101.018337, 51.294129, 51.935383, 101.510679, 51.467388, 101.17447, 51.644209, 51.070291, 51.227925, 51.61632, 356.621141, 51.739739, 101.769576, 100.470574, 51.12466, 100.771773, 51.529595, 101.223234, 51.248169, 167.899297, 51.543892, 152.565922, 51.386336, 101.292925, 51.048394, 167.755422, 100.472413, 101.846515, 51.983355, 51.514055, 101.461408, 103.347919, 101.837715, 115.650021, 100.61766, 160.094142, 100.174788, 51.369717, 101.022528, 51.189568, 51.641091, 51.34715, 100.833418, 101.154303, 101.103924, 51.818392, 109.371802, 101.886867,
    #             2.064632, 13.897698, 8.175998, 4.452423, 8.970353, 19.352669, 13.659489, 18.213639, 16.863995, 82.593065, 28.415293, 27.160618, 27.442423, 42.374424, 33.837799, 30.403061, 29.245424, 31.153731, 16.674541, 16.509296, 32.237468, 18.057135, 17.148432, 34.884817, 45.413078, 40.673843, 35.28101, 35.347249, 48.244873, 39.978783, 20.657704, 46.550522, 39.107512, 38.701856, 50.90647, 86.305564, 38.120477, 210.929576, 39.247538, 39.732839, 40.345053, 20.53701, 40.094937, 261.608498, 21.23978, 41.97542, 42.0561, 43.043164, 44.073908, 83.758083, 43.84687, 22.999035, 45.382462, 715.795131, 50.869615, 45.3082, 1613.43959, 44.949273, 24.075769, 46.229213, 1745.439102, 46.968234, 857.460771, 24.652799, 24.332831, 50.343865, 50.194381, 25.881387, 50.818538, 50.861149, 51.209645, 26.053925, 53.150365, 51.467007, 209.844044, 52.810534, 26.851263, 27.021168, 27.266647, 54.199375, 644.742676, 70.231576, 27.645285, 54.535459, 130.464942, 57.559808, 179.676081, 54.721097, 28.399859, 136.751992, 60.646892, 57.710749, 28.739275, 55.986686, 58.178115, 28.933249, 57.695267, 57.923947, 60.927511, 56.69873, 58.170751, 88.229174, 58.406197, 60.562184, 58.378488, 29.276068, 77.447808, 58.36571, 58.975856, 61.943305, 58.922369, 63.482996, 59.427372, 59.240384, 57.88804, 58.522309, 33.378958, 66.227487, 62.552844, 84.60547, 30.151375, 62.216124, 30.377027, 62.162726, 61.173059, 30.550941, 122.467335, 65.676857, 30.578318, 59.671175, 31.125318, 31.281929, 116.914087, 110.36886, 109.39567, 30.938746, 61.043915, 31.566788, 61.963205, 334.71325, 278.927918, 69.108251, 32.554389, 112.3094, 63.187418, 68.274018, 63.964841, 65.350432, 32.790411, 64.999737, 33.035032, 66.017012, 33.70161, 34.144202, 70.667754, 33.424859, 65.917777, 70.43545, 34.695694, 421.255813, 1045.870461, 33.326299, 65.959765, 34.977667, 67.917144, 66.14938, 105.1235, 33.992265, 83.284971, 66.510385, 67.627505, 34.568509, 34.501059, 444.514549, 78.622274, 67.606561, 68.481323, 68.832065, 67.612047, 90.552208, 68.358446, 68.479427, 71.505055, 35.321882, 89.72953, 5797.757577, 68.434982, 69.862904, 134.936089, 71.152359, 35.574357, 208.610842, 35.671099, 669.780704, 36.553608, 75.806698, 72.161432, 344.066899, 89.144169, 71.00266, 35.840958, 35.875245, 73.748276, 76.770145, 74.799543, 76.882246, 73.628485, 36.401509, 71.484921, 78.951068, 36.160012, 73.479281, 36.081847, 38.907757, 37.503495, 71.211135, 71.887087, 36.55565, 39.888201, 77.823424, 37.089025, 73.076715, 36.915938, 84.895377, 38.008847, 74.382316, 37.008677, 37.333939, 74.663132, 74.404083, 74.8939, 73.840648, 73.294326, 214.441832, 75.430904, 73.476657, 37.604886, 72.96329, 38.440028, 120.653424, 74.631877, 38.511215, 290.780962, 37.644506, 73.713423, 77.158621, 76.240605, 76.850592, 78.956447, 73.860593, 73.64461, 76.466696, 37.597917, 74.456984, 73.342101, 76.298117, 38.409054, 74.296646, 74.155746, 74.694658, 77.369937, 105.930811, 37.796101, 79.842599, 83.651568, 38.708006, 38.729266, 79.685267, 76.257566, 75.053381, 74.78697, 38.901122, 74.702419, 38.935258, 38.157168, 38.7071, 40.744373, 75.383106, 74.831009, 77.416289, 77.353716, 77.206912, 93.47784, 40.007197, 76.714944, 81.148021, 42.393202, 96.820792, 111.440406, 76.024642, 39.128535, 77.39078, 39.077953, 77.847697, 78.238495, 77.248389, 39.332949, 77.822124, 40.22121, 94.613455, 80.508403, 39.500431, 39.329169, 39.472895, 40.200899, 77.804682, 85.798269, 39.856333, 81.817371, 77.307109, 78.526438, 745.055547, 78.512303, 78.648767, 87.293395, 79.938758, 84.305332, 40.206954, 78.580528, 83.556352, 78.585588, 102.642493, 40.659116, 109.410624, 79.188393, 87.779562, 40.407735, 40.632556, 80.960064, 810.489332, 79.935843, 40.18016, 80.638283, 78.972297, 42.863525, 40.421602, 126.183323, 78.794268, 40.294266, 241.211816, 324.503817, 78.898027, 112.064839, 540.422284, 40.308134, 80.453103, 40.685225, 40.471297, 80.164052, 112.000002, 80.983475, 41.376355, 41.506608, 127.476848, 78.458895, 265.133454, 46.148539, 40.55101, 43.431624, 80.703406, 80.078916, 79.320847, 80.041656, 40.676866, 80.10318, 93.619997, 114.743352, 146.799702, 310.526034, 321.035742, 92.548912, 79.080014, 84.044563, 80.266303, 41.183809, 82.703195, 82.530692, 41.15346, 84.651849, 82.721172, 41.968588, 82.582045, 108.121141, 81.375023, 81.532312, 82.066058, 80.966906, 80.812769, 41.611181, 41.554635, 83.162766, 41.755149, 81.173098, 2980.277605, 42.192816, 81.317396, 41.962078, 41.455844, 41.969445, 41.84896, 41.966722, 82.054265, 42.28359, 82.106324, 82.613188, 42.081127, 573.962319, 89.732736, 82.62494, 82.571789, 84.907887, 42.150245, 109.146629, 109.539476, 83.547005, 84.363341, 82.503479, 90.314768, 82.545295, 44.262729, 86.232167, 42.263003, 83.838719, 91.584318, 84.667907, 90.208076, 43.243946, 154.779602, 83.42722, 106.399129, 46.288789, 84.099093, 186.259409, 42.762261, 82.601438, 92.76667, 42.737617, 88.37318, 95.161407, 83.473293, 84.73406, 42.919716, 83.886353, 217.46784, 92.720917, 131.240367, 824.785658, 85.483934, 85.469085, 85.108305, 84.667514, 43.335652, 42.541154, 85.166423, 89.414788, 43.093705, 84.576002, 84.062208, 42.470825, 142.155602, 86.734421, 84.127932, 42.913665, 42.947909, 43.352485, 100.178145, 84.932998, 95.729863, 1271.746639, 84.770633, 85.091392, 93.124173, 84.619665, 331.145629, 42.583308, 43.487181, 5518.666288, 83.703192, 85.333123, 84.554718, 85.359256, 84.269949, 87.164132, 110.024928, 44.242233, 85.732301, 43.356246, 85.185313, 43.190723, 108.550292, 43.207819, 86.61046, 43.123186, 43.675255, 674.321123, 83.701443, 43.43784, 86.250137, 85.97901, 85.163926, 43.320863, 85.672317, 85.781931, 85.005584, 86.789762, 44.126879, 43.39245, 84.011177, 86.696917, 85.676431, 44.11326, 113.762343, 85.020795, 88.163869, 84.489756, 84.75742, 86.37105, 86.0388, 87.068721, 92.197453, 85.690054, 44.616951, 84.732778, 96.743404, 43.941967, 87.698316, 86.805621, 300.891064, 44.431457, 229.940961, 44.127139, 45.554126, 88.03284, 88.916336, 2828.531173, 89.852274, 44.773153, 43.537793, 44.270462, 88.939357, 87.447076, 102.795027, 94.618484, 87.015946, 651.600216, 87.542564, 91.098904, 87.897756, 85.371731, 91.476218, 44.340617, 86.878346, 123.810205, 86.645257, 87.694929, 43.995387, 45.045434, 86.5654, 45.191437, 45.006457, 87.338817, 270.771703, 89.894468, 89.549949, 89.520763, 859.531724, 44.352807, 87.169661, 90.861555, 45.101661, 89.197526, 87.216427, 86.416281, 45.296454, 86.91046, 226.697365, 88.756218, 89.287565, 87.666581, 87.151067, 44.277519, 87.968611, 88.798467, 44.83917, 87.879786, 90.362204, 256.550279, 86.454091, 89.491182, 90.949333, 733.771059, 86.949335, 89.161989, 44.191228, 88.36207, 87.572974, 87.961974, 44.75385, 87.247446, 88.824037, 45.643262, 57.555361, 356.944251, 87.649242, 87.96198, 90.217924, 88.487844, 44.763044, 44.254681, 86.912216, 186.484666, 45.787405, 88.2031, 45.506735, 89.650792, 89.665439, 88.277721, 44.945838, 162.821579, 89.289873, 44.932547, 88.173827, 89.199371, 88.742573, 87.878249, 45.044117, 46.16641, 92.299209, 44.743596, 90.164185, 142.512339, 88.180557, 44.856384, 94.148087, 88.521809, 91.097407, 45.988165, 47.07744, 89.439516, 88.239157, 97.809639, 88.066097, 87.732934, 44.788143, 112.881715, 89.287624, 88.131944, 88.578193, 45.09487, 88.700105, 89.449509, 93.577233, 90.899397, 89.635338, 88.908978, 45.178971, 154.277773, 89.648278, 45.030797, 45.382141, 45.414136, 186.62864, 91.649928, 88.72147, 45.266743, 100.401233, 903.502366, 95.246688, 89.322155, 91.931467, 45.368675, 89.885459, 136.541355, 87.655066, 149.073806, 88.272658, 94.898428, 667.042308, 90.172599, 117.152358, 88.810845, 91.085752, 91.355147, 45.168036, 45.480282, 303.045082, 94.697747, 292.263176, 88.871695, 45.241804, 89.461754, 160.696861, 45.654397, 45.705047, 89.916534, 95.017635, 45.564501, 107.592362, 89.677085, 95.298025, 89.498746, 45.41191, 91.997732, 89.493036, 100.23763, 92.030949, 118.555999, 122.564159, 93.670614, 45.426678, 93.303165, 46.021398, 93.527193, 94.537693, 91.344835, 129.713678, 862.429757, 46.07122, 232.903923, 90.141225, 89.297755, 92.338143, 89.992374, 96.637707, 89.469295, 232.602861, 90.744961, 89.02822, 88.727796, 133.272239, 726.692755, 46.078343, 95.666262, 172.32373, 90.151852, 45.785121, 46.087406, 45.508339, 90.839543, 90.3024, 89.543839, 90.060743, 90.534534, 45.82872, 46.021921, 89.339961, 48.043095, 45.721271, 89.483085, 92.157455, 1914.220237, 94.233175, 46.515897, 90.733012, 45.796082, 110.320009, 45.697814, 107.810856, 92.700577, 90.082533, 89.810539, 588.098991, 48.054799, 93.315165, 90.805503, 92.250634, 91.774196, 46.106527, 90.319914, 120.977462, 46.673775, 153.141828, 46.354175, 46.455069, 46.091865, 46.447028, 123.736851, 590.482286, 89.719362, 46.156406, 46.050539, 92.662285, 92.379369, 101.908442, 46.221248, 92.429815, 45.720495, 121.891149, 94.818122, 91.035336, 93.056189, 46.428459, 46.052549, 100.412673, 91.552748, 90.269396, 91.828053, 94.745275, 89.977321, 339.02415, 91.352101, 181.161864, 46.259625, 101.807607, 96.027833, 46.869473, 96.3764, 221.26285, 582.845426, 92.554847, 46.886153, 46.269587, 90.691499, 91.525216, 47.248618, 46.650461, 61.76688, 46.450033, 91.726466, 47.246392, 95.923944, 47.634408, 93.200346, 50.505338, 319.61822, 94.567637, 46.542154, 46.401375, 46.996424, 101.58165, 97.048565, 46.988948, 47.033005, 563.341597, 93.091944, 121.366488, 47.261467, 91.851932, 92.860225, 109.492229, 46.869118, 96.306218, 49.427531, 207.979108, 46.732714, 93.167119, 145.657814, 95.933865, 95.110296, 283.276529, 676.510867, 97.683609, 95.904569, 46.780857, 91.547201, 46.830218, 105.836423, 101.073102, 92.734127, 92.131777, 47.046048, 98.891685, 47.446062, 48.888184, 47.588869, 91.261336, 91.825565, 46.985377, 94.55655, 98.324217, 94.990701, 91.041447, 94.305858, 160.836286, 46.589553, 100.759029, 47.204925, 92.373656, 46.544367, 92.545741, 94.796853, 47.211429, 47.293466, 91.91095, 46.983797, 97.551021, 47.373605, 47.029468, 98.848891, 162.704818, 47.617632, 47.417868, 92.935987, 49.395816, 47.867924, 91.505779, 46.93956, 374.139156, 566.178656, 93.925708, 121.598418, 107.634737, 101.400135, 47.13911, 95.106836, 96.511205, 98.27241, 91.538619, 93.69825, 47.836629, 47.007948, 94.9818, 48.193446, 105.039807, 47.302324, 47.514319, 92.228012, 92.963711, 47.119025, 47.364752, 162.766147, 92.443944, 91.9382, 444.005093, 94.095655, 47.425347, 115.444313, 848.893755, 92.675779, 94.612133, 47.637565, 47.346658, 47.09145, 94.671731, 776.873399, 94.153023, 94.052842, 180.217479, 93.804709, 180.986455, 103.771313, 47.615792, 48.295993, 124.970207, 47.345699, 94.11115, 98.315169, 94.316947, 95.217304, 92.984565, 93.064323, 99.905599, 134.410401, 94.899552, 193.547561, 47.363085, 92.727701, 6770.431421, 48.042637, 48.096192, 93.114544, 47.984706, 94.006872, 47.959252, 94.293421, 100.608875, 348.50169, 49.089751, 898.075068, 341.846087, 95.246525, 47.900507, 95.052267, 1044.007409, 365.816741, 153.661645, 47.919267, 101.392522, 47.703236, 47.57426, 93.328653, 97.674042, 48.255573, 127.390638, 179.940532, 99.269994, 95.343759, 49.271174, 168.728621, 94.339346, 48.259884, 47.952879, 47.735963, 47.93292, 47.784124, 345.494122, 183.296558, 47.895655, 96.241742, 93.633729
    #         ],
    #         [
    #             75.678666, 40.315424, 28.045789, 14.367179, 47.975924, 16.086629, 51.188264, 31.962981, 49.494796, 32.750834, 53.148805, 37.882628, 38.263466, 105.690049, 60.693504, 38.417247, 19.473744, 39.318537, 69.253935, 39.168172, 40.09744, 40.586181, 40.881421, 41.525616, 42.902821, 43.134277, 21.729024, 334.342987, 67.46461, 45.190763, 23.668568, 68.700342, 45.967513, 80.163963, 100.534459, 47.067297, 47.155886, 47.597054, 48.115567, 97.353999, 47.831647, 48.475999, 48.268105, 76.602074, 49.070508, 72.403153, 49.256515, 49.541184, 48.627753, 49.429113, 25.260736, 49.758585, 50.593801, 39.910717, 74.304407, 49.736393, 80.831098, 51.1056, 26.025361, 51.136212, 52.145443, 76.962412, 50.44878, 78.294174, 51.867302, 26.089259, 52.009257, 53.289167, 83.835104, 52.178042, 26.961946, 47.516123, 53.451227, 52.91267, 95.321397, 53.736757, 27.319438, 53.776115, 27.293112, 28.009075, 54.331136, 28.031742, 88.158263, 27.721178, 27.708173, 55.169479, 249.039767, 55.316096, 55.196592, 56.318305, 56.442026, 84.480945, 83.925266, 56.540859, 29.303904, 86.987554, 88.077469, 56.88398, 88.764028, 57.298018, 30.022709, 58.243402, 56.718488, 57.708193, 80.428657, 59.173819, 58.28058, 59.557641, 58.043032, 59.345218, 245.833242, 60.335531, 92.924063, 91.946135, 59.144373, 58.70197, 59.854915, 59.612433, 29.804809, 30.757892, 60.462268, 61.467186, 59.485632, 60.161573, 60.630911, 61.087315, 60.246232, 61.013253, 189.42042, 59.81736, 30.493429, 60.686388, 59.967873, 30.907108, 60.048267, 60.35508, 62.641249, 60.600717, 60.854097, 61.44783, 60.464478, 60.360122, 61.223594, 91.466264, 60.391782, 31.227167, 58.66247, 91.319651, 61.085793, 60.999795, 30.489986, 61.989625, 60.186568, 30.947914, 80.04003, 61.003152, 163.658136, 31.935679, 67.408252, 91.940105, 216.63707, 64.395531, 61.355104, 101.089678, 61.917125, 215.869675, 61.418758, 31.426507, 62.921478, 61.498046, 62.067361, 60.843659, 95.357751, 31.198258, 62.0872, 61.581908, 126.422347, 61.414231, 62.646466, 61.329319, 31.955953, 31.161865, 32.146832, 93.270299, 62.920583, 62.688049, 93.118227, 31.528344, 107.584936, 31.583887, 62.499888, 62.391973, 63.2593, 62.601776, 62.77851, 62.145712, 39.455783, 32.491959, 32.182267, 153.84649, 63.59001, 63.421372, 94.130343, 94.326256, 64.436702, 62.888442, 63.036525, 64.1113, 32.869347, 32.148935, 62.624524, 63.324815, 62.68725, 63.000218, 104.806094, 32.708584, 95.030825, 95.261124, 99.051091, 63.2254, 32.198349, 64.103606, 81.635833, 63.761237, 64.406701, 65.758958, 32.026476, 63.805415, 107.124952, 63.52954, 114.753063, 64.37498, 145.101767, 63.689749, 63.714868, 318.989057, 71.983298, 63.612406, 102.832407, 94.866651, 63.861699, 64.500787, 63.238271, 64.51244, 42.415343, 111.73988, 64.753712, 71.242709, 63.790673, 64.970013, 64.986533, 53.251951, 44.775501, 137.4232, 64.093425, 96.144335, 64.343707, 64.014605, 64.899159, 64.419985, 1163.461394, 65.032887, 33.264755, 65.63366, 77.297646, 32.563183, 144.351601, 64.88002, 33.423779, 64.972178, 65.124683, 97.68205, 64.808178, 65.013018, 65.067442, 66.642557, 64.874947, 108.288298, 65.064001, 65.804299, 65.230164, 67.091298, 64.748445, 65.680022, 98.398252, 64.613536, 64.472912, 65.055664, 33.787893, 242.414613, 33.672539, 66.045234, 65.369414, 65.194765, 66.527999, 33.188914, 33.706793, 102.689266, 65.699903, 67.547646, 67.159928, 65.873212, 101.679018, 65.636602, 89.51293, 149.607675, 66.348288, 33.714616, 99.961929, 66.569185, 156.782845, 66.034095, 95.692869, 34.277778, 99.780401, 66.974158, 34.097854, 164.890085, 66.551497, 68.644449, 100.730051, 109.075293, 67.601133, 33.479392, 67.205523, 99.28577, 67.62042, 66.314327, 105.764379, 67.743393, 34.637657, 67.63229, 67.452281, 34.355174, 68.048829, 68.309844, 34.371247, 68.492862, 119.894834, 67.641928, 102.863951, 68.112471, 145.277735, 67.514597, 69.221068, 34.510084, 68.610817, 84.36531, 35.820086, 102.446913, 68.096574, 68.917894, 35.296761, 112.206722, 69.405357, 35.173003, 69.534511, 68.91571, 97.182006, 1063.794632, 71.134772, 68.125803, 34.742099, 69.26315, 68.946115, 68.795325, 55.57428, 71.896961, 67.835069, 68.706423, 34.431709, 83.718945, 43.787782, 102.811316, 69.045294, 157.688792, 69.566234, 68.478926, 35.085847, 68.082068, 34.747772, 69.252252, 35.323026, 34.966619, 105.737275, 146.836843, 68.39599, 103.015833, 75.363766, 105.292119, 35.384901, 68.194772, 34.576727, 103.184519, 68.196592, 35.162417, 68.593309, 69.790251, 68.699677, 104.733454, 34.909493, 69.151388, 36.041033, 35.518407, 69.157531, 104.80681, 69.928399, 69.379249, 71.765087, 108.783255, 70.576319, 71.198244, 76.788208, 69.033836, 69.756553, 107.466822, 69.336915, 70.004081, 70.297022, 35.215059, 204.59589, 69.503882, 114.463601, 68.977976, 105.81632, 35.252885, 69.665178, 35.886863, 35.44739, 70.221011, 69.852798, 70.616337, 70.058325, 68.918585, 35.036295, 106.319617, 69.384419, 69.769325, 70.301517, 69.886035, 133.796141, 69.713959, 69.723006, 112.333315, 113.94003, 106.009352, 162.361507, 70.332903, 113.379663, 71.36712, 69.80255, 70.484768, 70.683272, 69.668872, 106.058932, 69.870955, 70.001588, 70.434904, 335.788504, 111.277294, 35.375066, 147.449247, 70.207028, 35.955964, 70.751674, 50.755005, 70.839118, 70.113297, 49.68123, 53.918231, 37.36708, 71.337124, 35.790361, 70.50472, 70.300862, 36.203923, 70.227173, 107.026889, 70.382824, 70.678308, 35.705544, 69.766447, 70.839189, 71.452601, 35.397219, 75.078572, 70.90169, 70.354354, 42.98032, 70.750309, 105.465754, 70.685139, 70.53399, 35.333621, 70.478458, 70.590447, 69.533868, 69.910705, 70.349447, 70.535354, 35.858258, 35.498053, 70.429015, 71.126003, 35.701485, 70.419485, 70.71222, 164.974141, 70.192895, 70.227429, 69.994315, 78.058793, 70.802875, 70.511408, 71.281358, 86.097535, 70.04936, 69.315009, 70.178074, 70.226351, 106.644445, 71.089606, 169.280131, 70.151239, 72.96877, 70.097756, 71.024557, 128.776951, 109.783259, 36.119885, 71.106775, 70.358635, 36.415954, 70.814515, 70.608985, 71.387024, 70.887421, 36.252098, 73.269616, 168.491917, 70.97773, 71.960317, 37.259733, 35.87976, 71.22716, 71.761979, 36.283922, 91.904963, 145.468709, 71.102721, 106.798272, 72.266397, 35.901244, 71.209586, 71.423431, 71.207617, 71.526167, 155.803553, 40.853245, 36.753164, 59.791236, 110.087449, 35.638028, 106.87612, 36.512647, 71.249743, 71.536675, 71.169422, 72.603615, 36.352967, 71.800449, 72.500792, 71.035383, 155.194818, 77.129532, 70.645447, 107.772703, 109.264512, 71.515363, 37.451978, 109.52763, 72.158276, 71.967558, 72.378774, 119.094568, 107.373431, 36.357257, 106.942235, 107.725057, 37.064512, 71.532088, 77.142112, 37.041527, 71.771635, 70.438949, 87.137571, 71.098894, 73.834112, 71.773494, 71.420617, 269.708191, 36.23424, 72.826252, 71.713017, 37.345114, 152.623833, 110.965971, 36.552516, 72.364732, 187.026248, 72.113656, 72.589044, 36.857813, 73.016523, 108.897804, 168.074342, 112.09991, 115.510267, 111.201615, 121.177824, 116.019876, 36.494446, 60.984501, 72.244933, 37.095252, 117.06617, 166.168609, 72.568542, 72.157718, 108.32132, 120.02125, 72.162236, 72.156986, 40.081383, 36.478831, 139.905715, 108.153986, 73.781737, 126.289125, 73.0956, 72.553382, 72.076594, 72.008626, 36.544153, 37.540421, 72.54665, 72.406005, 72.463934, 37.110244, 72.195255, 120.777639, 75.73348, 114.161029, 37.099003, 36.602972, 72.506015, 72.347086, 85.949716, 73.759102, 73.678937, 72.88554, 73.221233, 72.458225, 72.357373, 71.792292, 36.241245, 72.628331, 73.002739, 72.800231, 37.466467, 73.390459, 72.058167, 72.348113, 72.827981, 110.066027, 72.477604, 72.683184, 73.051212, 107.917377, 72.581102, 37.672657, 72.341967, 36.862811, 109.392638, 55.007155, 154.528143, 72.823686, 72.481247, 74.527732, 36.921832, 73.641798, 73.218305, 139.487429, 72.181026, 123.619627, 72.976243, 139.4052, 73.741378, 73.57821, 74.527697, 37.535521, 73.087532, 123.065823, 37.673584, 73.999592, 72.99227, 72.944914, 73.453685, 83.869331, 74.76582, 97.508113, 73.63179, 123.216218, 74.177497, 74.014, 37.00139, 155.840381, 73.994008, 901.393873, 73.420884, 37.783755, 72.705286, 73.43605, 113.1636, 116.353933, 39.547033, 101.881349, 74.302063, 111.654676, 37.917327, 75.792342, 110.078495, 38.242017, 73.036113, 74.241847, 208.117735, 112.14593, 73.916222, 166.271561, 77.910904, 149.543039, 74.013844, 74.691317, 75.6064, 73.792355, 37.850724, 74.385194, 73.228621, 74.975736, 328.864594, 46.823156, 74.14361, 73.789341, 74.269244, 74.043853, 74.538132, 74.198808, 48.486005, 38.408573, 74.971806, 37.383605, 137.626899, 997.93602, 75.441852, 75.067868, 75.05424, 74.598901, 38.221395, 123.086392, 74.944853, 74.874202, 75.59565, 113.421366, 74.910502, 75.256773, 74.665586, 74.188196, 74.613157, 75.61844, 38.167459, 74.305872, 42.063493, 84.508126, 75.267343, 116.935519, 38.224625, 37.604296, 74.425077, 77.753685, 74.337394, 74.231529, 153.237683, 74.896388, 96.272379, 74.497042, 112.08446, 113.904497, 75.159342, 76.015192, 75.396871, 117.670144, 38.153677, 74.636597, 74.295855, 38.872867, 40.037913, 87.079918, 75.537191, 75.748571, 77.33301, 76.354826, 75.679262, 37.717015, 74.301645, 74.93292, 159.405289, 75.515964, 75.974129, 114.369599, 118.851507, 114.561771, 76.258502, 43.791085, 75.098763, 96.797921, 74.870708, 38.806722, 76.506302, 76.576867, 74.420285, 75.423847, 112.368019, 76.913192, 76.034104, 76.744873, 75.231106, 132.61332, 160.744977, 75.359538, 38.790577, 107.08393, 77.640055, 75.073678, 136.64373, 59.443404, 117.852529, 84.906005, 111.798997, 76.558391, 76.53512, 150.052349, 75.454036, 45.658652, 112.787899, 56.6199, 74.962518, 75.625599, 75.678882, 75.251574, 75.572802, 75.971058, 76.047126, 75.505671, 119.690266, 74.987814, 75.823212, 64.902713, 75.609837, 74.993132, 76.692307, 100.334357, 58.857642, 83.30553, 49.113456, 53.175503, 78.108682, 79.073942, 79.385489, 76.854676, 124.772919, 38.775889, 77.725239, 79.24933, 117.168917, 77.769362, 117.192579, 77.183309, 94.330708, 163.333297, 40.799819, 39.588403, 77.969582, 78.631181, 43.338885, 117.991019, 89.324126, 78.356495, 116.713388, 77.822786, 77.756993, 77.965993, 78.35812, 79.72552, 77.855024, 77.985466, 79.61181, 80.83018, 40.276621, 120.145317, 77.42992, 78.731712, 78.849657, 51.734188, 40.612797, 80.047159, 80.014107, 55.127742, 79.277668, 52.692019, 40.228201, 41.017318, 79.753231, 79.565692, 79.413214, 118.42433, 120.790633, 123.434375, 77.438115, 79.420855, 79.896205, 40.239874, 79.36029, 79.017315, 244.290066, 64.550498, 79.475868, 79.031691, 126.587131, 80.314153, 80.22323, 79.057344, 79.488953, 78.158425, 80.471683, 78.867473, 78.238017, 79.189232, 79.185566, 78.198165, 90.005677, 168.769342, 78.387409, 78.030843, 114.515341, 75.583036, 76.402494, 76.35405, 76.261626, 39.395726, 38.523019, 77.057957, 38.568905, 534.319067, 38.942376, 77.568389, 77.067894, 77.960476, 114.995858, 77.541984, 76.547143, 38.921052, 49.049956, 77.914564, 120.054585, 40.173127, 77.002893, 77.798188, 53.929337, 78.085139, 77.51608, 77.069232, 76.662168, 76.939959, 116.124383, 154.999415, 55.461589, 76.400352, 220.76933, 85.222285, 43.009236, 84.109094, 83.923117, 42.892813, 84.402374, 91.508075, 84.338041, 84.127733, 84.005515, 52.93529, 83.624434,
    #             3.058573, 12.293336, 4.900088, 2.887298, 5.444768, 13.750949, 5.886262, 8.515226, 7.149313, 65.119724, 10.194052, 7.202299, 9.388727, 28.945797, 18.431972, 11.656631, 9.004633, 10.960115, 10.800149, 10.968385, 11.529094, 12.365875, 11.746205, 13.476285, 39.359413, 22.717339, 14.246977, 12.458554, 40.123806, 16.734802, 13.56268, 23.463137, 15.453047, 14.70991, 35.110643, 66.59867, 14.277803, 181.736151, 15.535314, 15.447897, 15.059939, 15.611423, 16.115072, 297.082465, 9.008978, 9.692646, 17.467143, 17.850744, 18.431703, 65.543417, 17.419359, 9.628074, 10.010934, 754.122581, 25.58887, 20.120993, 1618.986906, 18.722211, 20.578599, 19.980509, 1750.959168, 20.137712, 861.000309, 20.735199, 10.693467, 22.457645, 21.751029, 20.996381, 21.059339, 21.229923, 21.937236, 10.819856, 22.935139, 20.924677, 206.952639, 22.653439, 21.2214, 20.593242, 21.027517, 22.025062, 765.346375, 59.792003, 21.946424, 21.457071, 72.784831, 24.591411, 165.270916, 21.465553, 21.760074, 114.704653, 24.156895, 24.428259, 21.132092, 22.129595, 27.356196, 21.831998, 23.84232, 24.215498, 27.920022, 23.536582, 23.988432, 76.156017, 24.58002, 31.815349, 24.294443, 21.747093, 64.75689, 24.317613, 23.538182, 30.510501, 24.99216, 40.094173, 25.020357, 24.970556, 22.091523, 22.717396, 16.006107, 40.911474, 27.333491, 64.323641, 22.658488, 31.450236, 22.866847, 28.406095, 26.380863, 11.883795, 94.214219, 33.109046, 22.883847, 22.60252, 23.514911, 24.639122, 103.271984, 81.049951, 128.923028, 12.496484, 23.798326, 23.874891, 24.848573, 437.526899, 260.630293, 46.821024, 12.953768, 106.164851, 25.821928, 32.003192, 25.526044, 28.581312, 12.995599, 26.439093, 13.342447, 15.772372, 26.251852, 27.054049, 34.327466, 13.562462, 26.942384, 36.070267, 15.142162, 452.046246, 1014.934408, 26.470747, 28.576471, 28.959009, 27.441001, 26.302638, 93.669966, 14.078243, 54.5375, 27.242287, 28.47229, 14.206928, 27.459944, 426.512112, 75.119579, 29.385915, 29.431573, 29.924063, 15.465191, 65.842029, 28.948282, 27.879867, 32.497802, 27.812682, 65.322129, 4189.504462, 28.596017, 29.161825, 75.430866, 31.620722, 28.75745, 174.639434, 28.592528, 720.909063, 29.389479, 47.110511, 31.914365, 456.359377, 58.583736, 30.726022, 15.409964, 28.760075, 36.094469, 35.786545, 35.533134, 48.263742, 33.630102, 15.686863, 30.538938, 71.24057, 29.361365, 33.698366, 29.297742, 18.697672, 17.395862, 15.973891, 32.750841, 30.218908, 31.543364, 30.727585, 31.729489, 19.628669, 16.628837, 48.315353, 32.3056, 35.980422, 31.514702, 32.990074, 36.676747, 35.365746, 35.872021, 31.433121, 32.743981, 211.424586, 33.597348, 17.64434, 33.164709, 31.786288, 34.087793, 85.458973, 33.646816, 33.398328, 366.636491, 32.695893, 32.033368, 40.145823, 36.444916, 36.290242, 39.077269, 32.03296, 33.006138, 36.021693, 32.521999, 33.312177, 17.288041, 36.090577, 17.524533, 33.894092, 33.181732, 35.154139, 35.880997, 77.285504, 33.081061, 41.39458, 56.672373, 33.739395, 33.430511, 40.334634, 35.531855, 17.622298, 33.221262, 33.573652, 33.193256, 18.687583, 33.414725, 33.28251, 20.124245, 33.968019, 34.124343, 37.178254, 37.750399, 34.802163, 60.895368, 36.018296, 34.79125, 43.671522, 40.363501, 71.142387, 73.023394, 33.858831, 33.69381, 34.484438, 33.662814, 35.249859, 36.37561, 33.670125, 17.985003, 35.909864, 34.802027, 63.91473, 37.714064, 18.186513, 35.559984, 34.484725, 18.419854, 19.002328, 57.072627, 36.82928, 42.084323, 35.476163, 35.335409, 730.530131, 37.062309, 36.086512, 51.529766, 39.821897, 21.220598, 35.788667, 36.308793, 44.231131, 35.830928, 69.483731, 35.480105, 86.987431, 36.501318, 58.191536, 35.479478, 35.978816, 37.993126, 805.61476, 37.977261, 18.695537, 40.479481, 36.230206, 23.085651, 35.91369, 109.601606, 36.592823, 37.593334, 219.976384, 366.40528, 36.135191, 87.65648, 481.928464, 36.569539, 38.895163, 19.220884, 37.250494, 40.760404, 98.777853, 40.630766, 38.688897, 19.44022, 89.261439, 36.993519, 289.478471, 32.434647, 36.811568, 42.485515, 39.191476, 37.809336, 37.103419, 38.95715, 37.937973, 37.336572, 70.071146, 91.409113, 193.886446, 314.881212, 314.45601, 78.057886, 37.933813, 45.413895, 38.394514, 20.134959, 43.505254, 42.820983, 20.093203, 47.313449, 43.668148, 40.338711, 43.62631, 130.819927, 39.668124, 40.424092, 41.748412, 40.937589, 40.417409, 39.544043, 40.428968, 41.516975, 38.739571, 39.935333, 3049.143142, 39.256336, 39.553348, 40.278048, 39.583111, 39.69715, 41.34152, 39.75399, 40.648647, 40.581088, 40.393382, 42.212562, 39.636569, 543.90183, 58.264683, 21.077059, 21.097598, 44.571011, 40.525271, 80.657318, 89.10815, 42.392841, 45.99608, 21.556805, 56.183765, 41.036509, 24.089832, 47.451736, 41.052197, 44.337954, 67.228216, 44.066941, 50.44253, 42.482544, 131.434377, 40.801547, 76.693977, 49.310939, 44.615837, 200.734238, 22.265359, 21.797491, 64.387457, 43.338355, 54.049734, 70.114615, 42.41766, 24.415067, 43.399724, 43.481103, 258.51973, 57.553765, 91.599036, 853.977148, 44.431917, 44.529481, 45.313532, 42.830481, 41.632279, 41.698665, 44.09473, 52.541709, 23.117746, 42.709053, 43.169169, 41.691906, 80.070296, 46.006205, 42.642322, 42.924161, 42.922873, 42.686037, 79.007792, 44.043914, 76.837443, 982.497003, 44.251263, 22.842214, 69.033706, 42.50351, 312.568463, 42.520681, 42.455744, 6966.191335, 43.228873, 46.644616, 44.022581, 46.663055, 43.860202, 48.732123, 80.991356, 44.025875, 44.257287, 43.174713, 44.074508, 43.196886, 82.637609, 42.89068, 46.533134, 43.235878, 43.744752, 672.20494, 44.149573, 43.495369, 46.361655, 44.791354, 44.473946, 43.851764, 44.859059, 22.786149, 45.8702, 47.468158, 23.667942, 44.144457, 45.021166, 45.844604, 44.752054, 44.284849, 90.936501, 23.422124, 50.077311, 44.470492, 44.525378, 46.272756, 23.335063, 48.078082, 53.714603, 45.332018, 44.348561, 44.559585, 118.0086, 23.211559, 48.069928, 45.47876, 260.665611, 45.496861, 227.180086, 44.629947, 47.092551, 47.087692, 48.203091, 1908.852399, 50.051614, 46.893698, 23.458064, 44.959405, 50.791708, 46.662643, 69.996376, 71.654586, 46.896631, 710.948467, 46.862672, 53.082821, 45.237949, 45.775228, 24.560019, 24.082798, 46.514809, 93.878676, 47.318748, 49.689429, 23.802766, 24.988012, 46.183959, 47.868997, 49.072652, 48.182953, 266.389545, 50.280816, 49.928664, 49.93375, 1130.803777, 46.681664, 46.538247, 59.612356, 47.46445, 50.583297, 47.787286, 47.558177, 48.521234, 47.519987, 231.043077, 50.679178, 52.811719, 48.038729, 24.271019, 47.754827, 48.992476, 53.149967, 47.686499, 51.278992, 51.70386, 223.774719, 48.372123, 50.589327, 55.705438, 788.523912, 47.44421, 52.64515, 46.83769, 49.525004, 48.077441, 47.920706, 47.863252, 47.776102, 50.114265, 47.999895, 39.462671, 371.293242, 48.36287, 48.502905, 51.973146, 50.381178, 25.352791, 46.784327, 48.576725, 152.264229, 49.064173, 48.350353, 51.028658, 51.537457, 53.996911, 48.515522, 24.512959, 128.141555, 50.235887, 48.446166, 48.227922, 49.661742, 50.869755, 25.0656, 48.104434, 50.001249, 53.412908, 24.85478, 50.512405, 112.838388, 48.558666, 48.015935, 54.25324, 49.643011, 49.751941, 49.904193, 50.786242, 53.008014, 49.964519, 52.941236, 48.337175, 48.533398, 48.107163, 90.978999, 50.487422, 47.931775, 50.953122, 49.124168, 49.877846, 51.721169, 55.484394, 56.920957, 49.808209, 51.011741, 25.347348, 131.629573, 51.05647, 25.492554, 50.023602, 49.283318, 153.688199, 53.000222, 50.907079, 49.263959, 85.133654, 724.339538, 57.081561, 52.739518, 55.150117, 50.083789, 52.466217, 196.653541, 26.15656, 126.215825, 50.348368, 60.835769, 762.144213, 53.479171, 93.839749, 50.952146, 51.991794, 53.622001, 49.93237, 49.499982, 264.931569, 57.794356, 248.071055, 50.167994, 50.552358, 52.306481, 175.765159, 50.705484, 51.252788, 50.721685, 63.017055, 26.708075, 89.904756, 51.999863, 59.867982, 51.685974, 51.044445, 55.695214, 50.922818, 73.090832, 57.15613, 90.826635, 101.801285, 63.695096, 50.423012, 59.510895, 51.907322, 58.145163, 50.981972, 55.611386, 128.725293, 863.618987, 51.846601, 233.093454, 51.806643, 52.015085, 56.193477, 52.05034, 60.244761, 51.977746, 221.484666, 56.257721, 26.782391, 26.78157, 109.21446, 750.104222, 52.843505, 73.838603, 149.479655, 53.808517, 50.909861, 51.862006, 50.940446, 54.452569, 53.766243, 51.805104, 51.192812, 51.555925, 51.546306, 52.241646, 51.432109, 57.425569, 53.234652, 51.677143, 55.359256, 1259.512636, 58.12187, 52.352619, 54.65489, 52.454771, 79.881276, 27.230057, 98.371629, 59.959433, 53.352087, 55.281515, 613.196529, 54.715665, 62.725709, 27.607677, 56.396937, 55.101028, 53.297341, 53.062023, 110.939124, 27.572929, 127.69305, 27.251828, 53.829668, 53.1884, 53.689042, 56.835365, 579.721428, 54.731986, 53.696323, 27.935784, 59.077333, 57.52133, 71.590017, 53.768572, 56.010919, 54.764083, 121.29473, 60.944622, 54.40172, 61.079067, 55.493421, 53.963802, 84.452568, 55.16805, 53.874805, 55.081077, 65.958436, 28.931896, 336.196549, 56.524792, 206.49741, 27.978721, 69.475939, 61.381559, 54.137011, 69.580882, 195.378596, 743.841905, 58.364833, 27.895177, 54.039255, 54.884557, 55.449499, 54.516334, 54.544396, 47.247877, 28.162905, 55.660523, 56.666804, 59.20472, 29.985973, 57.742734, 54.209112, 308.682512, 59.869293, 55.197767, 54.922979, 28.46995, 75.724286, 68.152405, 28.355423, 55.949106, 676.407488, 54.900957, 101.5005, 55.398066, 55.215062, 59.145334, 80.765471, 55.237749, 59.834042, 59.702658, 249.555519, 55.547479, 57.637315, 133.42874, 61.665188, 61.48286, 265.794572, 702.473877, 64.355804, 64.323912, 55.525689, 28.711365, 56.008, 75.112149, 75.189809, 57.506413, 55.414684, 55.570913, 64.694663, 55.632075, 58.029211, 29.88509, 56.567698, 55.801746, 54.84376, 58.070358, 72.879912, 60.186183, 29.159195, 62.217162, 141.611305, 55.039264, 67.735784, 28.587788, 56.844621, 55.332639, 56.74658, 59.552608, 28.777184, 55.947405, 56.954172, 28.990554, 62.840522, 55.913921, 29.058815, 64.62809, 151.017525, 56.295904, 29.38974, 58.528047, 60.634403, 57.948212, 56.072387, 56.020291, 377.488878, 567.559964, 59.989751, 96.885277, 83.889851, 78.172782, 56.316181, 63.298179, 63.249303, 68.900702, 56.170906, 58.195101, 57.851533, 56.418839, 64.549132, 58.665009, 83.111673, 57.357528, 56.96817, 56.5795, 57.127958, 57.313437, 57.248232, 206.191787, 30.250419, 56.839591, 459.224022, 58.785945, 57.720803, 97.716464, 845.933939, 57.795846, 59.809237, 57.945014, 57.217003, 57.91898, 61.029874, 403.233174, 61.08213, 57.575697, 158.970055, 59.997514, 242.013381, 86.663627, 59.339015, 59.455842, 102.623026, 57.635979, 61.096974, 64.343341, 57.528838, 61.359069, 58.349216, 58.617672, 76.247888, 104.205038, 61.076816, 239.378667, 57.531189, 58.303066, 10184.284211, 59.465758, 60.589143, 30.277421, 58.88027, 31.168128, 30.409903, 60.159622, 77.748296, 344.453683, 30.925341, 834.234294, 316.60008, 61.583957, 59.479154, 60.465544, 592.830426, 355.306699, 204.081087, 59.493377, 81.099298, 59.634403, 30.241627, 60.160241, 65.847818, 59.936714, 113.519886, 252.6413, 67.349062, 60.910886, 62.353581, 234.433436, 62.897344, 59.506271, 59.827722, 31.078959, 31.17346, 59.951942, 303.236671, 223.970364, 59.373168, 66.567007, 61.728294
    #         ]
    #     ],
    #     [
    #         [
    #             83720.33528900002, 129494.22880700014, 80329.52590799995, 118830.82944199987, 278694.86032000015
    #         ],
    #         [
    #             79335.71080400002, 108984.9144119999, 79091.35687100007, 106109.76268500005, 291799.2537669998
    #         ]
    #     ]
    # ]

    # encoder_times = [
    #     [
    #         [
    #             9.425, 6.307, 6.03, 7.262, 6.554, 6.146, 10.599, 5.732, 6.425, 5.956, 6.812, 6.881, 6.976, 7.139, 6.396, 6.07, 5.83, 5.95, 6.892, 5.953, 6.79, 6.288, 5.787, 5.85, 6.123, 6.464, 5.789, 42.069, 6.214, 6.377, 5.875, 5.923, 5.812, 7.19, 7.059, 5.954, 5.839, 6.091, 6.065, 6.727, 6.011, 6.546, 6.76, 6.569, 6.012, 5.806, 6.308, 6.16, 6.983, 6.126, 5.808, 5.633, 6.739, 7.791, 6.327, 6.622, 6.543, 5.854, 6.574, 6.104, 7.037, 6.142, 6.174, 7.044, 5.815, 5.686, 5.823, 5.845, 13.168, 6.106, 5.793, 8.737, 6.624, 5.757, 7.511, 6.103, 5.846, 6.702, 6.197, 5.928, 6.061, 5.996, 6.725, 5.744, 5.902, 5.92, 28.203, 6.657, 5.912, 6.731, 5.963, 6.384, 6.219, 5.748, 6.644, 6.346, 6.998, 5.906, 6.558, 6.133, 5.689, 6.301, 6.802, 6.116, 12.428, 7.488, 6.741, 7.057, 6.137, 7.477, 16.979, 6.397, 6.465, 7.35, 6.041, 5.926, 6.449, 6.025, 5.962, 5.863, 6.06, 6.836, 5.888, 6.258, 6.395, 6.67, 6.674, 6.541, 21.559, 7.378, 5.883, 5.789, 5.945, 6.017, 5.875, 6.723, 5.925, 5.813, 5.983, 5.922, 6.466, 5.687, 6.339, 6.438, 6.292, 5.85, 9.327, 6.131, 5.932, 5.895, 5.968, 5.781, 5.774, 6.803, 8.565, 6.013, 7.344, 6.697, 6.533, 6.55, 7.94, 6.791, 6.142, 7.086, 6.019, 18.047, 6.837, 5.829, 6.36, 6.183, 6.782, 9.539, 6.669, 6.858, 6.11, 6.11, 6.415, 6.049, 6.643, 6.556, 6.569, 8.17, 5.822, 6.158, 5.96, 6.768, 8.918, 7.557, 7.726, 5.91, 5.869, 6.035, 6.44, 6.169, 5.902, 6.03, 7.145, 5.822, 5.739, 16.138, 6.079, 6.429, 6.521, 6.004, 6.875, 5.87, 6.081, 6.845, 6.126, 5.841, 5.951, 6.054, 5.931, 6.491, 9.615, 5.965, 7.114, 6.547, 7.227, 6.54, 5.902, 6.156, 8.492, 6.354, 6.245, 10.497, 6.417, 5.958, 11.893, 6.697, 12.671, 6.511, 7.897, 5.977, 6.01, 37.009, 7.713, 6.311, 6.891, 9.377, 6.317, 6.635, 5.937, 5.782, 7.543, 7.134, 6.12, 10.67, 5.956, 5.907, 5.871, 8.606, 7.581, 7.008, 6.187, 6.368, 6.033, 5.862, 6.133, 6.063, 174.154, 7.542, 6.488, 6.858, 7.887, 6.534, 7.719, 6.446, 7.405, 6.753, 6.84, 6.82, 6.62, 6.473, 6.368, 6.646, 6.588, 7.671, 7.96, 7.063, 6.838, 6.706, 6.686, 6.657, 6.988, 6.415, 6.36, 6.428, 6.359, 17.756, 6.582, 6.729, 6.491, 6.373, 6.578, 6.325, 6.466, 8.256, 6.68, 6.784, 7.604, 6.348, 7.387, 6.438, 9.185, 10.162, 6.583, 6.457, 7.103, 7.172, 8.374, 7.256, 9.67, 6.467, 6.942, 6.62, 6.564, 8.5, 6.342, 6.705, 6.906, 7.569, 6.864, 6.75, 7.46, 10.05, 6.833, 6.584, 7.467, 6.902, 6.576, 6.624, 6.252, 6.505, 6.967, 6.294, 6.65, 6.578, 19.337, 6.437, 7.178, 6.372, 7.618, 6.679, 6.633, 6.54, 6.649, 8.113, 6.414, 6.922, 7.106, 6.573, 6.403, 8.171, 6.67, 6.502, 7.405, 6.717, 9.686, 91.62, 7.032, 6.569, 6.915, 7.216, 6.639, 6.432, 9.857, 7.738, 6.472, 6.614, 7.333, 9.126, 8.115, 6.932, 6.403, 14.334, 6.837, 6.475, 6.763, 6.512, 6.727, 6.922, 6.524, 6.474, 7.461, 15.261, 6.613, 7.117, 6.879, 7.075, 7.126, 6.648, 6.518, 6.682, 6.63, 6.351, 6.45, 7.42, 6.61, 7.131, 6.461, 6.46, 6.603, 6.48, 6.46, 7.264, 6.833, 6.466, 7.386, 7.51, 6.892, 6.83, 7.674, 6.663, 6.807, 7.241, 6.957, 6.987, 6.996, 6.519, 11.728, 7.586, 7.72, 6.772, 7.465, 6.465, 6.77, 6.888, 6.552, 7.838, 6.659, 7.014, 6.489, 6.419, 6.589, 8.197, 6.801, 6.66, 7.21, 6.787, 9.332, 6.854, 7.775, 7.37, 7.732, 7.19, 8.623, 6.614, 9.808, 7.171, 6.635, 6.55, 7.073, 6.669, 6.931, 6.362, 6.727, 7.608, 19.964, 9.562, 6.845, 13.933, 7.752, 6.417, 8.364, 8.891, 6.683, 6.836, 8.336, 8.925, 6.6, 7.037, 7.158, 6.654, 6.699, 7.0, 6.692, 7.459, 6.668, 8.277, 6.819, 6.485, 6.858, 6.695, 6.819, 7.691, 6.379, 7.1, 8.15, 6.904, 7.112, 7.019, 6.664, 6.639, 6.853, 6.686, 6.742, 6.547, 7.978, 6.828, 6.691, 6.349, 7.69, 6.936, 7.158, 7.676, 6.722, 8.197, 6.672, 6.879, 7.003, 8.226, 7.223, 6.593, 7.549, 8.334, 6.603, 6.869, 6.88, 8.121, 7.737, 6.612, 8.47, 6.584, 7.311, 6.761, 6.689, 20.075, 7.403, 6.371, 6.512, 7.055, 7.003, 6.847, 6.832, 6.727, 6.74, 6.496, 8.248, 26.96, 6.407, 7.137, 6.956, 6.557, 6.369, 7.104, 6.242, 8.896, 7.283, 6.433, 6.907, 6.635, 7.229, 7.842, 7.265, 6.706, 6.685, 14.087, 7.348, 6.644, 9.927, 7.397, 6.905, 6.819, 6.402, 6.527, 6.683, 6.389, 6.645, 7.059, 6.984, 7.753, 6.662, 8.656, 13.05, 7.773, 7.108, 6.97, 6.768, 6.924, 7.292, 6.631, 6.291, 6.686, 7.938, 6.821, 6.454, 6.833, 6.873, 6.407, 6.571, 7.145, 6.692, 6.764, 10.849, 8.332, 6.703, 6.488, 7.308, 6.7, 25.413, 6.579, 7.505, 6.764, 6.117, 7.667, 7.44, 6.365, 7.528, 9.623, 6.67, 6.68, 6.783, 6.699, 7.114, 8.579, 7.321, 7.608, 7.142, 11.063, 7.672, 6.516, 9.867, 6.627, 6.404, 7.658, 8.206, 6.569, 6.419, 6.84, 7.197, 6.569, 6.597, 7.634, 6.568, 20.776, 6.865, 7.047, 12.227, 6.873, 6.506, 6.439, 6.706, 6.239, 6.454, 6.679, 6.396, 6.682, 6.584, 6.852, 7.897, 7.351, 7.673, 6.519, 6.612, 7.213, 6.833, 8.286, 6.932, 6.715, 6.752, 6.873, 6.477, 7.107, 6.443, 8.209, 6.712, 6.758, 6.66, 6.497, 6.83, 6.488, 6.988, 6.346, 8.343, 6.48, 6.483, 6.529, 6.967, 6.454, 6.47, 6.782, 6.713, 6.921, 8.832, 7.706, 6.226, 6.559, 6.555, 6.807, 6.707, 6.874, 13.701, 6.446, 7.791, 6.522, 13.279, 6.527, 6.595, 6.996, 7.371, 6.523, 8.639, 6.25, 7.066, 6.982, 6.408, 7.595, 8.078, 7.187, 15.015, 6.904, 7.649, 6.615, 7.108, 6.574, 7.844, 6.599, 64.632, 6.464, 8.217, 6.801, 6.602, 7.687, 7.493, 8.037, 9.89, 6.876, 7.204, 6.826, 7.094, 7.246, 7.378, 6.779, 7.39, 14.6, 7.443, 7.672, 8.272, 7.749, 7.604, 7.275, 7.036, 7.134, 6.97, 6.575, 6.668, 8.209, 7.689, 19.97, 9.124, 6.92, 7.793, 6.771, 6.729, 7.004, 7.05, 8.343, 7.364, 6.684, 6.646, 9.039, 70.814, 7.337, 7.764, 6.867, 6.63, 7.909, 7.86, 6.732, 7.979, 7.27, 7.367, 6.854, 8.042, 6.815, 7.261, 7.075, 7.237, 6.582, 6.658, 7.516, 7.963, 7.83, 7.566, 6.717, 7.186, 6.637, 7.645, 6.97, 6.826, 7.523, 7.031, 10.26, 7.204, 7.835, 7.742, 7.462, 7.421, 6.77, 7.837, 6.85, 7.106, 6.779, 6.988, 6.891, 8.399, 6.964, 7.956, 7.17, 7.277, 6.866, 6.448, 11.403, 6.745, 7.823, 7.024, 7.05, 7.54, 7.871, 7.273, 6.923, 7.779, 6.862, 8.918, 6.691, 6.984, 7.001, 7.317, 6.794, 6.983, 7.33, 6.926, 6.996, 6.699, 7.313, 19.768, 10.509, 7.359, 7.042, 15.965, 6.644, 7.033, 13.306, 9.621, 8.043, 7.987, 7.306, 7.078, 6.977, 14.598, 6.85, 8.046, 7.977, 9.834, 6.792, 6.947, 7.132, 6.605, 6.832, 6.897, 8.001, 7.341, 8.358, 7.074, 7.287, 10.894, 7.021, 6.487, 6.901, 6.641, 9.012, 6.668, 8.079, 7.451, 6.643, 7.997, 6.717, 6.532, 7.841, 6.674, 7.142, 6.95, 8.699, 7.743, 7.284, 7.985, 9.133, 7.639, 6.63, 6.71, 6.709, 6.588, 7.803, 7.259, 8.285, 6.492, 7.068, 6.853, 7.315, 7.046, 6.972, 8.244, 6.826, 6.856, 6.92, 7.085, 6.704, 7.511, 6.812, 6.734, 6.996, 9.081, 6.823, 7.021, 7.956, 8.605, 6.672, 8.301, 7.498, 6.825, 7.116, 7.37, 6.669, 9.229, 8.611, 9.845, 6.712, 6.881, 6.74, 6.563, 7.517, 6.921, 8.455, 7.266, 8.292, 7.153, 7.864, 6.912, 6.856, 6.888, 7.166, 6.96, 6.77, 6.89, 7.1, 6.929, 7.357, 7.017, 13.372, 16.659, 6.656, 6.858, 7.078, 6.717, 7.141, 6.659, 8.55, 6.907, 8.859, 7.683, 8.449, 52.743, 6.907, 6.832, 7.219, 6.571, 7.076, 7.075, 6.585, 6.737, 8.878, 6.932, 7.635, 6.653, 7.159, 6.823, 10.156, 8.115, 6.699, 6.899, 7.214, 7.26, 7.498, 7.495, 9.443, 6.691, 22.97, 6.46, 7.212, 6.475, 6.854, 7.228, 6.561, 6.869, 6.869, 6.933, 7.268, 8.28, 6.793, 6.557, 10.072, 6.823, 6.747, 6.806, 6.956, 6.631, 6.693, 6.962, 8.143, 8.689, 8.763, 6.98, 9.042, 7.386, 6.86, 6.76, 6.845, 7.904, 6.781, 6.578, 6.884, 6.553, 7.357, 7.597, 7.841, 6.749, 6.604, 7.529, 6.917, 6.666, 7.22, 6.76, 6.521, 7.228, 7.939, 6.543, 9.911, 6.521, 6.633, 6.728, 6.759, 6.571, 10.306, 6.487, 6.505, 6.851, 6.683, 6.569, 8.127, 6.55, 6.556, 6.619, 22.433, 7.048, 7.114, 27.977, 6.789, 6.655, 6.642, 46.761, 7.028, 24.903, 7.006, 6.698, 6.86, 6.646, 6.386, 7.852, 6.469, 6.758, 6.501, 6.656, 7.534, 9.329, 6.811, 6.68, 6.562, 6.586, 6.38, 14.837, 7.482, 6.614, 6.771, 8.33, 7.061, 9.02, 6.404, 6.461, 8.622, 6.581, 6.698, 6.93, 6.62, 6.92, 6.538, 6.668, 7.548, 7.11, 8.823, 6.883, 8.788, 7.149, 6.78, 6.824, 6.504, 7.766, 9.27, 6.588, 6.944, 7.163, 6.969, 8.048, 8.163, 8.067, 7.424, 7.003, 9.439, 6.87, 8.555, 6.476, 6.855, 8.289, 7.085, 6.744, 6.523, 8.043, 6.942, 6.977, 6.436, 7.189, 6.659, 8.224, 7.972, 8.312, 7.495, 6.621, 6.699, 7.48, 11.757, 11.08, 7.146, 6.338, 8.109, 6.823, 6.995, 6.716, 6.862, 6.674, 8.034, 6.698, 6.587, 6.558, 6.979, 6.888, 6.529, 6.461, 7.179, 7.712, 14.977, 28.764, 8.057, 6.626, 8.94, 7.528, 6.654, 9.252, 6.536, 7.334, 6.395, 7.917, 6.444, 7.075, 11.236, 7.495, 6.641, 7.814, 7.139, 6.604, 7.571, 6.804, 6.423, 7.943, 6.475, 7.451, 94.772, 7.372, 6.778, 8.483, 7.815, 6.59, 9.731, 8.491, 14.079, 6.843, 7.494, 6.981, 12.071, 7.827, 7.829, 6.628, 8.05, 7.171, 7.138, 7.445, 7.702, 7.1, 6.778, 6.832, 8.312, 6.671, 7.307, 6.757, 7.594, 6.652, 6.66, 6.98, 6.761, 6.825, 6.696, 7.177, 7.109, 6.674, 7.39, 6.638, 7.198, 6.555, 8.084, 7.029, 7.019, 7.17, 6.602, 6.814, 10.226, 6.767, 6.908, 6.96, 6.531, 7.08, 7.788, 6.886, 7.294, 10.893, 6.622, 8.295, 7.235, 6.709, 7.232, 7.194, 6.411, 6.645, 6.97, 8.002, 6.721, 6.864, 7.436, 6.757, 6.671, 6.723, 6.856, 7.023, 7.893, 6.875, 7.11, 7.698, 7.768, 6.585, 9.358, 8.324, 6.666, 6.758, 7.208, 6.78, 9.232, 7.869, 6.834, 6.885, 6.728, 6.773, 7.306, 7.288, 7.721, 7.699, 9.079, 7.074, 7.291, 7.281, 7.928, 8.009, 6.581, 6.778, 6.804, 7.138, 7.025, 7.212, 7.027, 6.934, 8.338, 6.72, 7.66, 8.772, 9.013, 6.947, 7.014, 8.95, 7.048, 7.63, 6.637, 6.973, 7.132, 6.668, 21.409, 6.833, 7.206, 7.536, 7.228, 6.692, 9.225, 9.216, 7.401, 6.892, 8.477, 6.882, 8.006, 6.798, 7.647, 8.057, 8.835, 7.009, 22.866, 6.86, 6.833, 6.909, 6.816, 7.438, 6.553, 9.815, 8.562, 6.6, 10.294, 10.453, 6.682, 8.221, 12.969, 6.717, 7.712, 6.701, 6.887, 7.055, 8.192, 9.001, 7.027, 6.995, 9.792, 6.678, 10.611, 7.453, 7.46, 7.356, 7.192, 7.206, 6.912, 7.637, 6.802, 6.941, 8.398, 8.163, 9.053, 13.135, 12.085, 8.013, 8.747, 7.478, 6.858, 6.757, 7.309, 6.937, 6.961, 7.471, 7.007, 8.234, 7.371, 8.872, 8.396, 6.808, 7.221, 6.815, 6.971, 8.104, 6.868, 7.377, 6.821, 6.833, 68.454, 6.886, 6.594, 8.217, 6.748, 6.927, 7.576, 8.592, 6.872, 6.829, 6.684, 7.232, 6.935, 17.692, 7.584, 6.668, 6.867, 9.047, 8.135, 8.25, 9.55, 7.263, 7.366, 6.918, 7.596, 6.583, 8.714, 7.557, 6.884, 7.101, 7.497, 7.203, 7.606, 6.824, 8.797, 6.78, 7.718, 7.271, 7.069, 8.959, 6.88, 7.546, 7.661, 6.962, 7.686, 9.518, 6.903, 8.522, 6.996, 7.343, 9.778, 7.491, 7.914, 15.337, 7.012, 6.989, 8.389, 8.503, 7.054, 6.685, 7.281, 7.443, 6.968, 6.663, 6.728, 7.932, 8.614, 7.297, 7.77, 6.884, 6.952, 7.0, 8.121, 7.078, 10.047, 32.132, 7.182, 7.428, 7.773, 7.017, 12.3, 7.331, 6.975, 75.247, 6.814, 8.359, 7.183, 7.187, 8.564, 7.608, 8.228, 8.8, 7.351, 6.893, 8.259, 6.983, 8.384, 7.219, 7.109, 6.805, 7.993, 19.666, 6.924, 6.672, 7.383, 6.816, 7.899, 6.982, 6.912, 7.633, 7.058, 6.971, 7.249, 6.676, 7.034, 6.925, 6.789, 7.088, 7.951, 7.106, 7.39, 6.702, 7.953, 6.928, 6.938, 7.011, 7.11, 8.907, 6.77, 6.868, 8.674, 6.757, 7.164, 8.236, 9.875, 7.02, 11.646, 6.763, 7.034, 7.354, 8.894, 56.177, 8.235, 6.962, 6.986, 6.744, 8.417, 7.561, 7.785, 7.916, 6.671, 14.194, 6.834, 7.36, 6.862, 7.151, 6.756, 7.419, 7.137, 8.293, 6.846, 7.127, 7.083, 7.493, 6.925, 6.952, 7.36, 7.128, 11.664, 7.26, 7.09, 7.468, 17.225, 6.983, 7.036, 9.831, 7.312, 7.425, 7.143, 7.968, 7.11, 6.939, 10.851, 7.32, 7.461, 8.559, 6.907, 6.895, 6.956, 7.568, 6.799, 7.949, 8.4, 10.134, 7.295, 8.279, 7.66, 15.886, 6.93, 7.243, 6.684, 7.16, 7.004, 7.035, 7.99, 6.827, 6.966, 6.827, 9.404, 13.459, 8.949, 6.892, 7.158, 6.996, 6.697, 8.564, 7.392, 8.97, 7.668, 6.963, 7.223, 7.809, 9.2, 6.985, 6.802, 8.554, 7.819, 6.699, 6.946, 7.037, 9.306, 7.428, 6.739, 7.182, 7.362, 6.891, 8.427, 8.749, 6.955, 7.208, 7.111, 8.942, 7.142, 7.013, 6.915, 7.922, 6.965, 7.222, 6.968, 6.74, 6.836, 8.004, 6.897, 7.457, 6.976, 6.68, 8.637, 7.809, 7.399, 7.939, 6.917, 9.06, 8.611, 8.711, 6.911, 6.739, 6.847, 7.027, 9.272, 7.33, 7.86, 6.843, 7.97, 21.586, 8.124, 6.865, 7.34, 7.325, 7.006, 9.015, 8.629, 8.925, 6.918, 7.861, 14.818, 7.041, 8.433, 6.898, 7.258, 7.166, 8.468, 8.741, 10.269, 7.662, 9.483, 6.873, 8.228, 7.198, 9.545, 9.089, 7.583, 6.788, 8.711, 7.067, 8.084, 6.827, 7.461, 6.987, 6.769, 7.43, 6.851, 7.822, 7.439, 7.925, 9.754, 7.696, 7.362, 9.306, 7.512, 8.232, 7.545, 7.489, 8.611, 16.045, 7.939, 10.472, 6.796, 8.464, 7.173, 7.89, 7.554, 8.525, 9.494, 7.684, 6.865, 7.101, 8.34, 22.229, 6.957, 7.895, 8.909, 6.963, 6.922, 6.701, 6.923, 7.115, 7.186, 6.833, 8.616, 6.935, 6.937, 6.917, 6.841, 7.593, 7.125, 6.823, 9.082, 41.614, 7.508, 6.843, 7.319, 8.472, 7.803, 6.557, 8.152, 7.368, 6.793, 7.547, 18.912, 6.753, 8.382, 6.867, 7.128, 7.219, 9.134, 8.129, 9.898, 6.859, 8.512, 6.899, 6.897, 7.146, 6.924, 7.755, 15.511, 8.408, 7.054, 6.898, 8.38, 7.79, 7.426, 6.841, 7.0, 6.795, 9.788, 8.017, 7.939, 7.613, 7.144, 8.093, 7.852, 7.215, 8.685, 6.953, 7.367, 7.039, 11.028, 6.995, 9.484, 7.612, 7.572, 7.548, 6.883, 8.522, 10.248, 22.187, 7.069, 6.799, 6.765, 8.575, 7.069, 6.729, 8.079, 7.769, 8.145, 7.021, 7.176, 7.064, 7.007, 7.895, 6.762, 10.453, 7.952, 6.978, 6.933, 6.825, 7.897, 7.482, 6.931, 7.328, 14.227, 6.704, 8.268, 6.834, 6.727, 7.223, 7.866, 6.848, 7.146, 7.227, 9.584, 6.672, 6.987, 8.734, 7.349, 7.23, 9.854, 20.654, 7.534, 7.428, 7.729, 6.767, 7.07, 7.921, 7.435, 7.511, 6.892, 9.347, 8.346, 6.942, 7.184, 7.07, 6.958, 6.843, 8.219, 8.462, 7.672, 7.283, 6.877, 7.342, 8.621, 6.898, 7.54, 6.82, 7.025, 6.898, 6.816, 7.175, 6.869, 9.088, 6.705, 7.052, 7.167, 6.968, 6.736, 7.631, 8.862, 6.777, 7.006, 7.454, 7.203, 8.213, 6.742, 6.686, 12.962, 12.957, 7.012, 7.854, 7.633, 7.619, 6.774, 9.331, 7.585, 7.48, 6.805, 9.689, 8.213, 7.053, 7.27, 7.418, 7.566, 7.051, 8.468, 6.725, 6.99, 6.762, 6.872, 9.158, 7.964, 6.817, 15.306, 6.882, 8.466, 9.344, 19.892, 6.691, 6.98, 8.443, 6.79, 6.765, 7.157, 16.31, 7.675, 7.609, 8.701, 7.011, 9.464, 7.848, 6.977, 7.273, 8.262, 7.241, 7.162, 9.175, 6.945, 7.115, 6.998, 6.94, 9.134, 9.825, 7.066, 9.474, 6.916, 7.99, 175.916, 6.963, 8.329, 9.015, 7.049, 7.225, 7.006, 7.359, 8.0, 10.85, 7.306, 16.738, 12.516, 7.293, 6.95, 7.331, 18.492, 12.903, 9.45, 7.015, 8.051, 9.06, 7.344, 7.426, 9.714, 7.44, 8.311, 10.094, 8.01, 8.529, 7.334, 9.303, 7.588, 7.236, 7.304, 7.055, 9.681, 6.95, 10.349, 9.464, 7.059, 7.595, 7.182, 8.424, 6.753, 7.336, 7.173, 41.401, 7.175, 9.17, 7.902, 7.464, 6.984, 6.987, 8.657, 6.858, 8.811, 7.962, 7.44, 11.181, 7.543, 7.234, 7.008, 7.283, 9.438, 7.248, 7.095, 7.239, 7.029, 7.906, 7.139, 7.17, 6.971, 7.763, 7.038, 7.13, 7.521, 14.425, 8.387, 7.783, 7.416, 7.811, 7.404, 7.068, 7.168, 7.158, 7.539, 7.091, 8.547, 9.266, 7.374, 7.678, 6.989, 12.538, 7.335, 7.472, 7.368, 8.223, 7.367, 7.412, 10.859, 7.425, 7.335, 7.398, 8.127, 7.042, 7.419, 7.149, 7.188, 7.671, 7.244, 7.255, 7.251, 7.274, 7.565, 7.193, 8.308, 7.28, 10.788, 14.646, 7.825, 7.161, 6.872, 7.002, 7.057, 7.31, 6.942, 9.74, 6.819, 7.303, 7.333, 10.783, 7.167, 7.356, 14.11, 6.923, 8.039, 7.785, 8.316, 79.049, 7.66, 8.935, 7.719, 9.855, 7.274, 7.167, 16.487, 7.507, 7.11, 8.258, 7.241, 7.368, 13.807, 7.176, 8.577, 8.31, 7.172, 9.709, 8.614, 7.421, 7.265, 8.548, 8.087, 7.932, 9.19, 9.123, 7.203, 7.313, 8.309, 7.394, 7.214, 7.379, 7.771, 7.172, 9.042, 7.935, 7.824, 7.41, 15.972, 7.604, 9.293, 8.597, 7.294, 7.5, 15.569, 7.142, 7.771, 7.578, 7.402, 7.222, 7.264, 7.37, 7.981, 7.454, 6.818, 7.556, 8.217, 8.35, 7.041, 7.16, 7.521, 7.437, 7.232, 7.679, 8.233, 8.179, 7.443, 16.33, 7.206, 8.206, 7.898, 7.751, 9.421, 7.275, 23.963, 7.292, 8.818, 7.706, 9.672, 7.367, 7.307, 7.04, 10.957, 7.202, 6.967, 7.248, 7.171, 7.607, 6.899, 10.565, 9.534, 22.95, 7.315, 7.455, 8.332, 9.077, 7.716, 7.656, 7.267, 7.257, 7.236, 7.779, 10.023, 8.533, 8.624, 8.072, 9.152, 7.678, 8.111, 7.643, 8.405, 8.252, 10.073, 7.241, 21.569, 7.363, 9.303, 9.787, 9.05, 8.778, 7.395, 7.618, 8.763, 7.262, 7.183, 9.578, 7.762, 8.02, 7.41, 26.744, 7.357, 7.375, 7.704, 8.76, 10.564, 7.349, 7.984, 7.864, 8.141, 9.603, 7.646, 7.326, 9.448, 8.209, 11.052, 7.599, 7.871, 9.076, 8.825, 8.55, 7.657, 7.494, 8.473, 13.416, 7.256, 8.274, 10.781, 7.66, 7.5, 7.152, 59.13, 9.186, 11.26, 7.104, 7.498, 8.261, 7.541, 8.57, 7.308, 7.974, 8.891, 8.331, 7.994, 9.048, 9.252, 8.05, 9.17, 10.119, 8.088, 8.847, 10.175, 7.942, 7.536, 8.162, 7.303, 7.242, 8.123, 7.596, 9.843, 8.325, 17.921, 7.391, 7.113, 7.487, 7.6, 7.368, 7.263, 10.966, 7.617, 8.403, 8.212, 9.966, 9.283, 8.681, 7.456, 8.708, 8.995, 8.093, 7.573, 8.262, 7.362, 8.473, 7.443, 9.647, 10.864, 7.709, 7.516, 7.221, 8.096, 12.396, 7.22, 8.801, 7.077, 8.894, 8.119, 7.309, 9.606, 7.183, 8.857, 9.642, 7.537, 7.678, 7.169, 8.406, 186.501, 10.534, 9.009, 8.532, 9.496, 11.242, 8.204, 9.559, 8.209, 9.161, 9.108, 7.712, 9.204, 7.525, 9.435, 11.547, 7.919, 7.935, 13.098, 9.273, 9.066, 9.788, 7.872, 8.859, 9.603, 8.532, 9.001, 7.913, 8.016, 7.965, 8.771, 17.132, 8.976, 8.779, 7.665, 7.856, 8.148, 7.703, 10.239, 7.979, 8.964, 102.636, 9.059, 8.608, 8.165, 8.671, 10.03, 8.284, 17.019, 8.442, 12.015, 9.948, 9.308, 7.819, 22.833, 9.24, 9.968, 8.879, 7.866, 7.998, 8.419, 8.654, 8.814, 9.3, 7.751, 8.727, 8.564, 7.931, 8.052, 11.248, 7.83, 8.083, 7.823, 8.569, 7.757, 8.954, 8.321, 9.017, 8.497, 9.05, 8.163, 8.42, 8.583, 8.874, 9.473, 10.875, 7.75, 9.496, 9.623, 49.364, 8.089, 8.225, 8.174, 8.411, 7.592, 9.444, 8.18, 7.898, 8.37, 8.238, 7.634, 7.957, 7.318, 8.366, 19.029, 18.473, 8.021, 8.586, 9.29, 7.538, 9.623, 7.963, 8.677, 8.232, 7.358, 8.329, 7.702, 7.621, 7.616, 8.614, 7.995, 9.44, 8.711, 7.363, 7.907, 7.875, 7.886, 8.478, 8.572, 7.44, 7.912, 8.056, 24.878, 7.375, 8.881, 7.435, 8.381, 7.287, 7.303, 8.46, 7.881, 7.509, 7.46, 7.188, 7.575, 7.374, 7.424, 7.461, 7.888, 7.591, 7.329, 7.673, 7.024, 7.538, 7.739, 7.241, 7.779, 8.56, 7.155, 8.174, 7.322, 10.42, 7.436, 7.794, 7.805, 9.671, 7.552, 9.552, 13.301, 7.885, 8.13, 7.535, 22.666, 10.542, 7.061, 7.451, 8.108, 9.139, 8.187, 8.099, 7.04, 20.326, 7.55, 9.252, 8.766, 7.517, 7.149, 7.103, 8.863, 7.416, 7.064, 7.402, 7.588, 8.293, 7.519, 7.674, 7.595, 8.747, 7.297, 7.673, 7.942, 8.128, 7.138, 7.264, 7.431, 7.227, 9.313, 7.475, 7.358, 7.45, 7.675, 7.329, 7.711, 7.474, 7.785, 7.394, 7.588, 7.737, 7.497, 7.207, 7.391, 8.395, 8.75, 8.076, 8.503, 8.737, 7.258, 7.565, 13.158, 7.534, 7.721, 8.256, 7.575, 7.603, 7.976, 7.636, 7.385, 7.56, 8.288, 7.672, 9.218, 11.103, 8.736, 9.009, 7.216, 8.334, 7.599, 7.558, 7.402, 11.977, 7.64, 17.404, 7.538, 7.128, 8.493, 13.194, 7.346, 8.347, 7.396, 7.193, 7.77, 7.415, 7.29, 8.627, 7.627, 7.627, 7.446, 7.236, 7.87, 7.657, 8.292, 7.662, 7.316, 7.215, 7.312, 8.26, 22.331, 7.134, 7.533, 7.373, 7.927, 13.424, 7.551, 9.86, 7.478, 7.345, 9.001, 7.808, 7.039, 8.122, 7.434, 8.764, 7.735, 8.999, 7.785, 8.861, 7.843, 7.52, 8.347, 7.709, 8.445, 7.94, 7.723, 8.968, 8.04, 17.671, 15.621, 8.649, 7.816, 7.187, 8.067, 7.236, 7.091, 8.467, 8.796, 7.715, 10.02, 7.245, 7.18, 9.566, 7.331, 8.123, 7.211, 10.939, 7.389, 7.888, 7.127, 8.124, 8.206, 7.809, 7.203, 7.219, 7.435, 7.327, 7.281, 8.399, 7.7, 7.386, 7.318, 8.112, 9.429, 8.841, 11.158, 7.524, 7.631, 7.906, 7.773, 8.192, 7.74, 10.388, 8.054, 7.386, 7.259, 7.387, 7.634, 9.517, 8.438, 7.424, 30.774, 7.34, 8.161, 8.163, 7.769, 8.706, 8.466, 9.069, 9.025, 7.656, 9.254, 9.496, 8.529, 8.3, 8.521, 8.546, 8.227, 10.962, 9.212, 9.774, 12.105, 8.779, 9.016, 8.475, 9.133, 8.691, 7.675, 10.849, 9.445, 8.351, 8.272, 9.653, 8.901, 9.642, 8.87, 7.561, 13.081, 12.855, 7.275, 8.466, 7.2, 7.466, 7.089, 9.18, 8.913, 7.463, 8.411, 7.827, 8.79, 7.466, 9.143, 7.816, 7.762, 7.637, 7.612, 7.593, 9.076, 8.312, 7.828, 8.976, 7.522, 9.296, 8.625, 8.815, 8.042, 7.953, 7.662, 7.704, 7.383, 7.442, 7.325, 7.853, 9.195, 8.657, 10.293, 7.963, 7.292, 6.955, 8.4, 9.543, 11.394, 8.282, 8.45, 7.941, 7.694, 7.263, 8.585, 7.729, 7.333, 10.832, 7.805, 7.421, 7.623, 7.608, 7.336, 8.342, 9.688, 8.07, 9.283, 8.144, 8.071, 7.965, 7.812, 8.259, 7.82, 7.528, 7.975, 8.05, 7.865, 9.287, 7.576, 8.095, 8.32, 8.494, 10.286, 7.716, 9.194, 10.811, 9.989, 70.668, 9.082, 8.855, 8.291, 8.388, 7.986, 9.917, 9.647, 8.193, 29.605, 9.977, 10.109, 10.333, 8.678, 8.843, 9.119, 9.629, 8.773, 9.812, 10.042, 8.099, 9.107, 9.04, 9.018, 9.858, 9.936, 9.733, 9.965, 9.732, 10.373, 9.843, 10.481, 9.36, 9.401, 10.291, 9.296, 9.488, 10.801, 10.105, 9.599, 9.152, 10.696, 8.529, 9.487, 13.177, 9.952, 9.352, 8.177, 9.164, 9.403, 8.912, 10.697, 9.471, 9.537, 9.641, 9.535, 9.996, 9.473, 12.702, 9.583, 9.849, 9.945, 8.863, 9.285, 10.96, 9.225, 9.395, 9.109, 9.494, 8.553, 9.033, 9.549, 11.031, 9.924, 9.329, 10.469, 15.718, 15.14, 12.042, 10.573, 10.052, 9.427, 8.761, 8.713, 9.824, 9.116, 9.591, 9.208, 9.739, 9.385, 9.224, 9.629, 8.344, 8.472, 9.692, 9.08, 9.25, 10.701, 10.014, 12.02, 12.013, 10.219, 10.057, 10.351, 9.322, 9.04, 9.181, 9.824, 9.271, 9.678, 8.112, 10.077, 9.06, 8.846, 9.304, 9.688, 9.009, 11.06, 10.162, 8.816, 10.067, 10.051, 9.491, 8.913, 8.694, 26.532, 9.952, 9.841, 8.981, 9.369, 7.673, 8.523, 8.328, 9.816, 9.915, 7.736, 7.823, 8.605, 8.217, 7.811, 20.78, 10.294, 9.58, 7.983, 9.229, 10.456, 8.104, 7.524, 9.226, 9.025, 8.212, 9.963, 9.077, 8.387, 7.599, 9.673, 9.259, 7.794, 8.113, 8.505, 10.662, 10.296, 9.276, 9.223, 35.289, 8.605, 17.095, 9.676, 9.798, 9.676, 10.648, 10.529, 9.903, 10.318, 10.076, 10.29, 9.625, 9.163, 11.384, 9.914, 9.726, 10.478, 10.319, 10.429, 10.12, 9.703, 9.339, 10.15, 9.525, 11.845, 10.182, 12.013
    #         ], 
    #         [
    #             4.413, 0.767, 0.361, 0.149, 0.653, 0.115, 5.775, 0.149, 0.806, 0.12, 1.03, 0.789, 0.473, 1.401, 0.928, 0.216, 0.149, 0.236, 1.419, 0.199, 0.188, 0.242, 0.279, 0.211, 0.345, 0.256, 0.153, 38.945, 0.395, 0.18, 0.182, 0.47, 0.16, 1.645, 1.236, 0.21, 0.211, 0.24, 0.139, 0.827, 0.125, 0.485, 0.214, 0.954, 0.481, 0.473, 0.463, 0.358, 0.291, 0.487, 0.19, 0.162, 0.447, 2.616, 0.414, 0.157, 1.119, 0.512, 0.123, 0.13, 0.56, 0.703, 0.337, 0.843, 0.213, 0.294, 0.227, 0.234, 8.853, 0.249, 0.168, 3.41, 0.246, 0.164, 2.072, 0.208, 0.162, 0.224, 0.132, 0.247, 0.153, 0.12, 1.273, 0.133, 0.18, 0.186, 25.416, 0.27, 0.298, 0.489, 0.293, 0.863, 0.663, 0.227, 0.118, 0.768, 1.038, 0.152, 1.077, 0.235, 0.198, 0.249, 0.206, 0.172, 7.172, 0.78, 0.163, 0.284, 0.137, 0.265, 11.726, 0.838, 0.852, 0.97, 0.277, 0.176, 0.204, 0.471, 0.167, 0.133, 0.522, 0.668, 0.136, 0.463, 0.504, 0.541, 0.516, 0.482, 16.269, 0.144, 0.142, 0.188, 0.292, 0.283, 0.195, 0.211, 0.271, 0.22, 0.162, 0.183, 0.434, 0.189, 0.244, 0.663, 0.185, 0.194, 3.962, 0.648, 0.372, 0.288, 0.183, 0.46, 0.217, 0.159, 2.817, 0.314, 1.542, 0.135, 1.177, 0.575, 2.391, 0.895, 0.448, 1.334, 0.487, 12.795, 0.302, 0.131, 0.474, 0.474, 0.332, 4.182, 0.96, 0.449, 0.382, 0.43, 0.953, 0.209, 0.521, 0.467, 0.196, 0.17, 0.149, 0.565, 0.492, 0.41, 3.51, 0.239, 1.878, 0.157, 0.204, 0.272, 0.134, 0.396, 0.309, 0.202, 1.512, 0.137, 0.134, 10.814, 0.444, 0.638, 0.683, 0.507, 0.591, 0.317, 0.178, 0.476, 0.32, 0.148, 0.225, 0.253, 0.175, 0.517, 4.385, 0.162, 0.667, 0.862, 1.218, 0.196, 0.156, 0.45, 2.613, 0.441, 0.438, 4.788, 0.202, 0.213, 5.343, 0.453, 6.395, 0.422, 1.955, 0.139, 0.192, 32.117, 1.309, 0.431, 1.118, 3.525, 0.216, 0.211, 0.188, 0.268, 2.096, 1.474, 0.514, 5.291, 0.399, 0.376, 0.296, 3.364, 2.159, 1.405, 0.504, 0.565, 0.268, 0.229, 0.477, 0.221, 164.131, 0.603, 0.157, 0.508, 2.087, 0.338, 1.504, 0.28, 0.181, 0.209, 0.616, 0.544, 0.406, 0.204, 0.169, 0.371, 0.199, 1.393, 0.248, 0.294, 0.47, 0.288, 0.218, 0.259, 0.585, 0.158, 0.278, 0.227, 0.233, 12.814, 0.182, 0.422, 0.239, 0.161, 0.175, 0.154, 0.154, 0.9, 0.219, 0.796, 0.214, 0.215, 0.959, 0.16, 3.357, 4.392, 0.185, 0.215, 0.623, 0.563, 2.01, 0.215, 3.7, 0.166, 0.575, 0.405, 0.145, 2.654, 0.156, 0.294, 0.641, 1.562, 0.637, 0.151, 0.169, 4.244, 0.433, 0.225, 1.151, 0.559, 0.157, 0.413, 0.15, 0.199, 0.522, 0.193, 0.146, 0.217, 13.399, 0.393, 0.771, 0.174, 1.215, 0.225, 0.455, 0.187, 0.356, 1.994, 0.179, 0.65, 0.314, 0.314, 0.225, 1.754, 0.245, 0.193, 0.491, 0.249, 3.91, 86.712, 0.508, 0.191, 0.278, 0.292, 0.204, 0.154, 3.516, 0.954, 0.176, 0.375, 0.179, 2.51, 1.93, 0.786, 0.207, 8.443, 0.37, 0.256, 0.154, 0.176, 0.145, 0.467, 0.242, 0.182, 0.987, 9.59, 0.155, 0.814, 0.244, 0.673, 0.228, 0.365, 0.177, 0.538, 0.344, 0.149, 0.14, 0.794, 0.331, 0.71, 0.167, 0.17, 0.168, 0.158, 0.21, 0.907, 0.215, 0.274, 0.83, 1.068, 0.526, 0.494, 1.351, 0.32, 0.433, 0.983, 0.465, 0.529, 0.513, 0.191, 5.78, 0.318, 1.381, 0.201, 0.601, 0.22, 0.167, 0.221, 0.157, 0.248, 0.15, 0.464, 0.186, 0.171, 0.159, 0.654, 0.226, 0.261, 0.47, 0.47, 3.45, 0.353, 0.428, 1.284, 1.568, 0.638, 2.37, 0.479, 3.88, 0.689, 0.205, 0.163, 0.59, 0.241, 0.519, 0.199, 0.238, 0.283, 14.254, 1.374, 0.168, 8.261, 0.245, 0.165, 0.303, 2.64, 0.273, 0.444, 2.418, 2.896, 0.166, 0.625, 0.169, 0.245, 0.211, 0.277, 0.229, 0.955, 0.351, 0.372, 0.493, 0.236, 0.488, 0.265, 0.159, 1.062, 0.181, 0.593, 1.679, 0.343, 0.673, 0.587, 0.413, 0.25, 0.267, 0.479, 0.243, 0.2, 0.16, 0.348, 0.338, 0.192, 0.398, 0.424, 0.164, 0.205, 0.235, 2.023, 0.15, 0.267, 0.514, 1.336, 0.377, 0.191, 0.763, 1.997, 0.229, 0.162, 0.244, 0.234, 0.767, 0.21, 2.36, 0.256, 0.836, 0.21, 0.366, 14.279, 1.071, 0.154, 0.215, 0.328, 0.212, 0.221, 0.22, 0.413, 0.246, 0.183, 0.918, 22.059, 0.299, 0.321, 0.755, 0.152, 0.15, 0.625, 0.174, 2.933, 0.976, 0.355, 0.698, 0.491, 0.249, 0.187, 0.323, 0.183, 0.245, 8.46, 1.332, 0.289, 3.515, 1.025, 0.208, 0.707, 0.19, 0.416, 0.43, 0.184, 0.458, 0.17, 0.482, 0.361, 0.189, 1.639, 6.241, 0.215, 0.71, 0.816, 0.155, 0.637, 0.911, 0.369, 0.158, 0.551, 1.609, 0.549, 0.192, 0.607, 0.677, 0.194, 0.234, 0.978, 0.454, 0.509, 4.916, 2.076, 0.172, 0.186, 0.242, 0.187, 21.21, 0.199, 0.686, 0.185, 0.211, 1.404, 0.944, 0.227, 0.52, 3.664, 0.442, 0.535, 0.165, 0.445, 0.845, 2.376, 1.105, 1.185, 0.927, 5.204, 1.364, 0.159, 3.593, 0.381, 0.324, 1.261, 2.015, 0.318, 0.208, 0.567, 1.206, 0.31, 0.202, 1.191, 0.198, 16.111, 0.688, 0.749, 6.848, 0.598, 0.467, 0.175, 0.404, 0.195, 0.192, 0.348, 0.177, 0.372, 0.2, 0.355, 1.481, 0.938, 1.161, 0.173, 0.193, 0.219, 0.334, 2.265, 0.704, 0.57, 0.438, 0.406, 0.232, 0.539, 0.228, 0.166, 0.203, 0.388, 0.388, 0.177, 0.175, 0.408, 0.561, 0.197, 0.971, 0.239, 0.236, 0.426, 0.581, 0.277, 0.172, 0.273, 0.2, 0.703, 2.859, 1.404, 0.318, 0.21, 0.435, 0.183, 0.257, 0.28, 7.899, 0.232, 1.659, 0.387, 7.591, 0.389, 0.29, 0.72, 0.337, 0.291, 1.445, 0.202, 0.2, 0.426, 0.342, 0.382, 1.556, 0.669, 9.153, 0.497, 1.403, 0.189, 0.241, 0.177, 1.317, 0.238, 59.446, 0.316, 0.282, 0.223, 0.15, 0.909, 1.122, 0.918, 3.508, 0.685, 0.679, 0.488, 0.508, 0.717, 0.44, 0.214, 0.486, 9.285, 0.694, 0.325, 1.93, 1.139, 1.011, 0.226, 0.357, 0.372, 0.406, 0.183, 0.184, 0.172, 0.682, 14.351, 1.829, 0.188, 0.317, 0.245, 0.235, 0.554, 0.414, 1.969, 0.655, 0.299, 0.234, 2.369, 66.334, 0.696, 0.68, 0.562, 0.288, 0.181, 1.483, 0.354, 0.372, 0.621, 0.898, 0.347, 0.432, 0.466, 0.235, 0.306, 0.562, 0.192, 0.185, 1.172, 1.476, 0.661, 1.129, 0.177, 0.153, 0.267, 0.992, 0.297, 0.293, 1.079, 0.369, 3.119, 0.216, 0.722, 0.825, 0.556, 0.771, 0.305, 1.203, 0.21, 0.452, 0.321, 0.367, 0.185, 1.961, 0.391, 0.216, 0.706, 0.585, 0.366, 0.187, 5.777, 0.203, 1.375, 0.182, 0.373, 0.895, 1.282, 0.845, 0.332, 1.465, 0.327, 2.575, 0.171, 0.268, 0.289, 0.626, 0.222, 0.365, 0.763, 0.421, 0.274, 0.205, 0.331, 14.479, 4.497, 0.322, 0.172, 10.193, 0.344, 0.349, 7.515, 3.359, 1.078, 1.435, 0.585, 0.201, 0.434, 8.987, 0.206, 1.56, 0.7, 2.952, 0.296, 0.299, 0.38, 0.312, 0.197, 0.319, 0.622, 0.676, 1.217, 0.191, 0.524, 3.921, 0.471, 0.242, 0.468, 0.184, 2.882, 0.308, 1.7, 0.213, 0.303, 0.637, 0.395, 0.215, 1.42, 0.165, 0.431, 0.427, 0.814, 0.318, 0.722, 0.285, 2.396, 1.271, 0.218, 0.188, 0.319, 0.186, 1.285, 0.73, 1.938, 0.342, 0.505, 0.377, 0.471, 0.277, 0.367, 0.231, 0.187, 0.35, 0.379, 0.598, 0.186, 0.988, 0.476, 0.302, 0.415, 1.812, 0.163, 0.573, 0.497, 2.307, 0.544, 1.985, 0.178, 0.219, 0.552, 0.349, 0.189, 0.811, 1.125, 3.534, 0.231, 0.395, 0.372, 0.21, 0.85, 0.435, 2.191, 0.225, 0.736, 0.434, 1.411, 0.442, 0.381, 0.286, 0.523, 0.388, 0.202, 0.233, 0.294, 0.44, 0.752, 0.21, 7.324, 10.557, 0.277, 0.315, 0.499, 0.195, 0.469, 0.298, 0.534, 0.301, 0.196, 0.217, 0.174, 47.718, 0.26, 0.433, 0.518, 0.218, 0.611, 0.277, 0.281, 0.214, 1.994, 0.395, 1.026, 0.184, 0.584, 0.277, 2.516, 0.446, 0.287, 0.27, 0.266, 0.409, 0.872, 1.01, 2.731, 0.198, 17.619, 0.189, 0.181, 0.277, 0.371, 0.353, 0.209, 0.433, 0.391, 0.421, 0.287, 1.975, 0.237, 0.354, 1.169, 0.448, 0.369, 0.365, 1.027, 0.364, 0.629, 0.439, 2.146, 0.665, 0.411, 0.479, 1.373, 1.089, 0.671, 0.389, 0.559, 0.416, 0.374, 0.386, 0.447, 0.379, 0.491, 1.421, 1.131, 0.564, 0.4, 1.498, 0.802, 0.42, 1.099, 0.578, 0.412, 1.355, 2.086, 0.396, 3.626, 0.473, 0.472, 0.383, 0.358, 0.37, 4.296, 0.376, 0.455, 0.422, 0.473, 0.446, 1.783, 0.369, 0.348, 0.485, 15.531, 0.955, 0.517, 20.413, 0.373, 0.51, 0.479, 38.574, 0.41, 17.716, 0.467, 0.358, 0.576, 0.523, 0.472, 0.47, 0.477, 0.509, 0.353, 0.557, 0.364, 3.519, 0.548, 0.417, 0.398, 0.425, 0.455, 7.686, 1.445, 0.448, 0.392, 2.222, 0.655, 2.751, 0.374, 0.396, 2.553, 0.624, 0.655, 0.395, 0.434, 0.908, 0.506, 0.639, 0.636, 0.933, 0.571, 0.6, 1.77, 0.644, 0.952, 0.662, 0.408, 1.559, 0.629, 0.582, 0.996, 0.618, 1.095, 0.605, 0.586, 0.367, 0.421, 0.829, 1.17, 0.851, 1.559, 0.416, 0.98, 0.427, 0.898, 0.712, 0.323, 2.088, 0.967, 0.432, 0.34, 0.394, 0.502, 2.456, 1.907, 2.141, 0.337, 0.351, 0.432, 0.484, 5.48, 3.946, 1.23, 0.354, 2.217, 0.467, 0.914, 0.462, 0.695, 0.351, 0.539, 0.497, 0.712, 0.531, 0.611, 1.015, 0.351, 0.486, 1.028, 0.621, 8.533, 21.386, 0.371, 0.589, 0.727, 0.572, 0.44, 2.006, 0.387, 1.31, 0.457, 0.506, 0.351, 0.382, 4.87, 1.556, 0.515, 0.513, 0.592, 0.435, 1.408, 0.492, 0.392, 0.849, 0.447, 1.498, 84.751, 0.397, 0.443, 2.212, 0.719, 0.46, 3.501, 0.344, 7.202, 0.404, 1.127, 0.67, 5.615, 1.37, 0.594, 0.4, 0.382, 0.933, 0.961, 0.875, 1.184, 0.805, 0.424, 0.48, 2.009, 0.376, 0.748, 0.367, 0.669, 0.568, 0.442, 0.657, 0.492, 0.542, 0.438, 0.48, 0.717, 0.441, 1.073, 0.475, 0.737, 0.414, 0.539, 0.739, 0.684, 0.74, 0.386, 0.508, 3.856, 0.56, 0.405, 0.55, 0.418, 0.589, 1.652, 0.54, 0.503, 4.518, 0.463, 0.369, 0.978, 0.708, 0.698, 0.887, 0.398, 0.454, 0.72, 0.389, 0.402, 0.376, 0.679, 0.38, 0.42, 0.413, 0.52, 0.603, 1.529, 0.422, 0.949, 1.231, 0.441, 0.393, 0.877, 0.566, 0.359, 0.466, 0.487, 0.523, 0.484, 0.381, 0.404, 0.634, 0.525, 0.441, 0.672, 0.709, 0.483, 1.471, 0.611, 0.481, 0.994, 0.882, 1.499, 1.562, 0.395, 0.417, 0.447, 0.387, 0.494, 0.698, 0.461, 0.409, 0.572, 0.462, 1.359, 0.682, 0.344, 0.436, 0.362, 0.375, 0.459, 1.271, 0.512, 0.871, 0.442, 0.459, 14.333, 0.505, 0.435, 1.084, 0.761, 0.625, 0.414, 0.474, 0.818, 0.43, 1.476, 0.367, 1.776, 0.444, 1.208, 0.365, 0.536, 0.657, 15.78, 0.56, 0.475, 0.79, 0.459, 0.922, 0.447, 2.107, 0.428, 0.47, 3.969, 4.145, 0.404, 1.725, 6.443, 0.347, 0.686, 0.371, 0.43, 0.636, 1.86, 0.684, 0.531, 0.401, 1.683, 0.434, 4.16, 1.078, 0.374, 0.837, 0.562, 0.426, 0.376, 0.504, 0.435, 0.344, 1.375, 1.745, 2.659, 5.395, 5.407, 1.468, 0.358, 0.884, 0.376, 0.379, 0.787, 0.75, 0.346, 0.941, 0.767, 0.465, 0.786, 2.699, 0.488, 0.574, 0.68, 0.531, 0.512, 0.38, 0.508, 0.593, 0.386, 0.478, 58.401, 0.347, 0.394, 0.505, 0.42, 0.375, 0.589, 0.409, 0.497, 0.436, 0.421, 0.577, 0.34, 10.878, 1.083, 0.349, 0.36, 0.643, 0.347, 1.533, 1.643, 0.53, 0.796, 0.364, 1.061, 0.378, 0.624, 0.84, 0.37, 0.707, 1.268, 0.602, 1.076, 0.533, 2.33, 0.363, 1.394, 0.764, 0.691, 2.689, 0.395, 0.374, 1.278, 0.472, 1.137, 1.362, 0.439, 0.62, 0.485, 0.481, 3.378, 1.092, 1.604, 8.582, 0.612, 0.582, 0.636, 0.468, 0.335, 0.362, 0.522, 0.977, 0.581, 0.524, 0.576, 0.465, 2.327, 0.853, 0.579, 0.445, 0.491, 0.46, 1.48, 0.516, 1.401, 25.66, 0.52, 0.457, 1.31, 0.505, 5.582, 0.433, 0.423, 67.95, 0.425, 0.705, 0.57, 0.724, 0.553, 0.898, 1.516, 0.498, 0.504, 0.43, 0.482, 0.375, 1.499, 0.382, 0.641, 0.383, 0.402, 12.339, 0.432, 0.374, 0.628, 0.456, 0.474, 0.404, 0.456, 0.383, 0.545, 0.645, 0.461, 0.391, 0.443, 0.563, 0.476, 0.425, 1.711, 0.415, 0.878, 0.464, 0.418, 0.532, 0.391, 0.638, 0.951, 0.479, 0.378, 0.423, 2.074, 0.444, 0.693, 0.455, 3.465, 0.443, 3.721, 0.365, 0.546, 0.554, 0.695, 47.279, 0.775, 0.54, 0.363, 0.425, 0.815, 0.473, 1.332, 1.297, 0.52, 7.422, 0.595, 1.018, 0.355, 0.397, 0.479, 0.413, 0.461, 1.838, 0.491, 0.677, 0.383, 0.477, 0.431, 0.502, 0.649, 0.623, 4.759, 0.732, 0.683, 0.685, 10.107, 0.461, 0.436, 1.044, 0.455, 0.697, 0.443, 0.512, 0.552, 0.449, 3.84, 0.722, 0.906, 0.58, 0.435, 0.508, 0.551, 0.845, 0.386, 0.755, 0.811, 3.882, 0.51, 0.72, 1.085, 8.955, 0.483, 0.885, 0.444, 0.662, 0.485, 0.487, 0.526, 0.436, 0.6, 0.443, 1.108, 6.606, 0.436, 0.523, 0.774, 0.663, 0.479, 0.402, 0.513, 2.597, 0.497, 0.436, 0.69, 0.73, 0.872, 0.474, 0.375, 2.151, 0.627, 0.486, 0.496, 0.596, 0.624, 0.415, 0.466, 0.57, 0.842, 0.373, 0.598, 2.187, 0.501, 0.385, 0.89, 0.547, 0.563, 0.614, 0.606, 0.765, 0.539, 0.702, 0.433, 0.443, 0.419, 1.599, 0.58, 0.434, 0.607, 0.393, 0.417, 0.613, 0.859, 0.78, 0.487, 0.637, 0.377, 2.293, 0.521, 0.397, 0.459, 0.389, 2.556, 0.738, 0.548, 0.475, 1.448, 14.474, 0.941, 0.584, 0.898, 0.506, 0.665, 2.553, 0.491, 2.23, 0.453, 1.076, 8.064, 0.659, 1.583, 0.483, 0.588, 0.632, 0.427, 0.357, 3.637, 0.96, 3.019, 0.412, 0.443, 0.548, 2.898, 0.398, 0.436, 0.405, 1.059, 0.43, 1.444, 0.465, 0.976, 0.44, 0.448, 0.865, 0.436, 1.194, 1.032, 1.549, 1.748, 1.102, 0.35, 0.975, 0.512, 0.97, 0.455, 0.826, 2.169, 8.723, 0.461, 3.672, 0.523, 0.564, 0.817, 0.487, 1.012, 0.478, 2.768, 0.746, 0.425, 0.451, 1.824, 14.41, 0.553, 1.299, 2.471, 0.583, 0.4, 0.432, 0.37, 0.689, 0.631, 0.476, 0.475, 0.396, 0.422, 0.477, 0.398, 0.9, 0.431, 0.412, 0.672, 31.79, 0.88, 0.395, 0.555, 0.439, 1.387, 0.429, 1.657, 0.896, 0.423, 0.462, 11.317, 0.547, 1.058, 0.421, 0.836, 0.622, 0.452, 0.439, 1.895, 0.378, 2.122, 0.362, 0.478, 0.401, 0.511, 1.488, 9.028, 0.47, 0.415, 0.367, 0.819, 0.76, 1.18, 0.423, 0.584, 0.413, 1.975, 1.09, 0.571, 0.935, 0.511, 0.412, 1.351, 0.531, 0.446, 0.622, 1.077, 0.534, 4.307, 0.603, 2.558, 0.375, 1.096, 0.941, 0.403, 1.082, 3.263, 14.143, 0.697, 0.404, 0.5, 0.449, 0.518, 0.505, 0.415, 1.426, 0.423, 0.566, 0.634, 0.77, 0.57, 0.661, 0.391, 3.954, 0.812, 0.531, 0.528, 0.451, 1.234, 1.085, 0.382, 0.459, 7.25, 0.476, 1.725, 0.498, 0.441, 0.757, 1.299, 0.451, 0.848, 0.765, 3.193, 0.484, 0.692, 2.242, 0.94, 0.893, 3.321, 13.7, 1.055, 0.993, 0.461, 0.461, 0.603, 1.319, 1.144, 0.647, 0.402, 0.423, 0.981, 0.445, 0.637, 0.543, 0.517, 0.495, 0.48, 0.716, 1.213, 0.816, 0.426, 0.894, 2.253, 0.404, 1.063, 0.476, 0.547, 0.418, 0.515, 0.677, 0.37, 0.434, 0.513, 0.398, 0.879, 0.558, 0.465, 1.102, 2.662, 0.42, 0.477, 0.609, 0.754, 0.54, 0.439, 0.538, 5.283, 6.694, 0.811, 1.628, 1.481, 1.369, 0.529, 1.048, 1.003, 1.168, 0.507, 0.646, 0.603, 0.475, 1.029, 0.661, 1.39, 0.549, 0.541, 0.505, 0.582, 0.493, 0.482, 2.665, 0.573, 0.491, 8.141, 0.516, 0.438, 1.514, 13.694, 0.471, 0.608, 0.455, 0.401, 0.446, 0.755, 9.82, 0.727, 0.44, 2.542, 0.605, 3.005, 1.364, 0.556, 0.645, 1.668, 0.437, 0.705, 0.953, 0.443, 0.712, 0.49, 0.494, 1.164, 1.755, 0.675, 3.08, 0.401, 0.421, 163.22, 0.431, 0.514, 0.41, 0.498, 0.506, 0.486, 0.537, 1.204, 4.192, 0.487, 9.766, 3.747, 0.712, 0.471, 0.577, 11.191, 5.855, 2.4, 0.457, 1.276, 0.406, 0.542, 0.558, 1.007, 0.645, 1.805, 2.981, 0.996, 0.544, 0.631, 2.916, 0.63, 0.463, 0.447, 0.45, 0.429, 0.434, 3.744, 2.853, 0.49, 0.882, 0.583, 2.446, 0.375, 0.554, 0.445, 32.365, 0.402, 2.595, 1.558, 0.943, 0.403, 0.489, 2.231, 0.479, 1.435, 0.9, 0.918, 4.227, 0.447, 0.464, 0.443, 0.628, 3.256, 0.53, 0.457, 0.4, 0.44, 1.066, 0.42, 0.466, 0.494, 0.493, 0.408, 0.435, 0.753, 7.779, 1.813, 1.01, 0.445, 0.501, 0.936, 0.403, 0.445, 0.604, 0.385, 0.412, 0.675, 3.051, 0.761, 1.182, 0.426, 5.719, 0.58, 0.582, 0.496, 1.225, 0.648, 0.792, 3.93, 0.631, 0.623, 0.866, 0.399, 0.386, 0.648, 0.436, 0.449, 1.511, 0.472, 0.429, 0.795, 0.55, 0.868, 0.494, 1.935, 0.516, 4.26, 7.361, 0.405, 0.473, 0.586, 0.358, 0.679, 0.429, 0.473, 3.294, 0.479, 0.799, 0.749, 3.948, 0.514, 0.956, 7.255, 0.443, 1.175, 1.023, 1.236, 64.964, 0.9, 0.486, 0.469, 3.084, 0.796, 0.552, 9.041, 0.831, 0.436, 1.356, 0.418, 0.543, 6.525, 0.504, 1.627, 0.471, 0.412, 2.944, 0.763, 0.465, 0.482, 0.563, 0.703, 1.106, 2.21, 0.409, 0.476, 0.453, 0.423, 0.737, 0.44, 0.616, 0.758, 0.622, 0.883, 1.011, 0.827, 0.493, 8.535, 0.749, 0.913, 0.45, 0.422, 0.545, 7.974, 0.392, 1.051, 0.775, 0.524, 0.458, 0.527, 0.478, 0.846, 0.549, 0.391, 0.895, 1.427, 1.643, 0.372, 0.383, 0.807, 0.707, 0.463, 0.886, 0.5, 1.244, 0.796, 8.572, 0.687, 1.425, 0.954, 0.841, 0.686, 0.396, 16.045, 0.44, 0.423, 1.032, 2.985, 0.791, 0.715, 0.528, 2.182, 0.475, 0.544, 0.468, 0.618, 0.778, 0.464, 3.805, 0.502, 14.525, 0.401, 0.449, 1.592, 0.495, 0.511, 0.923, 0.637, 0.452, 0.5, 0.511, 0.685, 0.598, 0.475, 0.492, 1.411, 0.466, 0.52, 0.596, 0.595, 1.363, 3.459, 0.464, 12.92, 0.447, 0.433, 0.663, 0.518, 0.528, 0.93, 0.681, 0.49, 0.479, 0.566, 0.509, 0.438, 0.498, 0.608, 17.92, 0.455, 0.394, 0.539, 1.804, 3.847, 0.41, 1.315, 0.452, 0.636, 0.525, 0.48, 0.549, 1.283, 0.993, 3.835, 0.541, 0.966, 2.079, 0.743, 0.623, 0.755, 0.776, 0.473, 4.156, 0.407, 1.769, 2.685, 0.767, 0.459, 0.462, 48.401, 0.395, 4.351, 0.363, 0.37, 1.626, 0.541, 0.618, 0.493, 0.525, 0.44, 0.505, 0.459, 0.493, 0.641, 0.709, 2.333, 1.672, 0.804, 0.84, 2.528, 1.068, 0.476, 0.41, 0.526, 0.487, 1.16, 0.475, 2.805, 0.727, 9.585, 0.371, 0.412, 0.411, 0.815, 0.49, 0.549, 3.911, 0.703, 0.467, 0.883, 1.337, 0.475, 1.811, 0.613, 0.557, 1.871, 0.58, 0.494, 0.535, 0.401, 1.381, 0.459, 2.185, 2.474, 0.489, 0.746, 0.498, 1.069, 5.078, 0.483, 0.42, 0.527, 1.309, 0.947, 0.463, 1.308, 0.56, 0.608, 0.814, 0.512, 0.598, 0.39, 0.679, 162.465, 2.005, 0.523, 0.931, 0.857, 3.912, 0.674, 0.8, 0.509, 1.873, 0.916, 0.456, 0.449, 0.41, 0.384, 4.13, 0.477, 0.595, 5.52, 0.44, 0.392, 0.479, 0.571, 0.433, 1.531, 0.473, 0.429, 0.393, 0.466, 0.963, 1.384, 9.012, 0.882, 0.446, 0.511, 0.713, 0.662, 0.436, 2.615, 0.948, 0.497, 87.132, 1.26, 0.614, 0.707, 0.564, 1.005, 0.54, 8.759, 0.912, 2.88, 1.188, 0.504, 0.553, 13.776, 0.535, 0.491, 0.421, 0.498, 0.65, 0.843, 0.416, 0.449, 0.638, 0.572, 0.437, 0.648, 0.799, 1.072, 3.801, 0.757, 0.828, 0.499, 0.537, 0.544, 1.544, 1.142, 0.871, 0.833, 0.555, 0.633, 0.391, 0.471, 0.445, 0.449, 2.246, 0.485, 0.581, 0.375, 39.035, 0.787, 0.995, 1.033, 1.042, 0.424, 2.376, 0.767, 0.535, 1.05, 1.223, 0.597, 0.541, 0.483, 0.416, 11.756, 10.843, 0.559, 0.541, 0.45, 0.565, 2.689, 0.561, 1.567, 0.421, 0.445, 1.12, 0.788, 0.524, 0.479, 1.605, 1.089, 2.168, 1.208, 0.437, 0.449, 0.918, 0.928, 1.164, 0.511, 0.411, 0.771, 0.739, 15.571, 0.427, 0.404, 0.408, 0.451, 0.442, 0.724, 0.545, 0.56, 0.638, 0.459, 0.445, 0.517, 0.422, 0.51, 0.434, 1.105, 0.906, 0.544, 0.528, 0.446, 0.744, 0.754, 0.48, 0.487, 1.715, 0.501, 1.25, 0.4, 3.533, 0.53, 0.781, 0.837, 0.559, 0.637, 2.646, 5.899, 0.526, 0.878, 0.57, 14.411, 3.498, 0.431, 0.536, 1.503, 0.944, 0.468, 1.186, 0.53, 12.579, 0.457, 0.722, 0.529, 0.491, 0.458, 0.5, 0.747, 0.504, 0.403, 0.464, 0.795, 1.35, 0.431, 0.657, 0.46, 1.712, 0.429, 0.75, 0.94, 0.569, 0.406, 0.401, 0.537, 0.564, 0.669, 0.443, 0.47, 0.696, 0.65, 0.482, 0.692, 0.462, 0.824, 0.433, 0.663, 0.901, 0.539, 0.551, 0.586, 1.153, 0.506, 1.235, 1.897, 2.098, 0.394, 0.668, 5.639, 0.458, 0.691, 0.667, 0.918, 0.714, 0.702, 0.813, 0.793, 0.924, 0.884, 1.046, 0.963, 1.617, 0.428, 1.609, 0.495, 0.518, 0.913, 0.612, 0.467, 4.995, 0.425, 9.739, 0.47, 0.522, 1.857, 4.921, 0.474, 0.525, 0.582, 0.477, 0.508, 0.611, 0.596, 1.981, 0.941, 0.567, 0.422, 0.435, 0.578, 0.774, 0.563, 0.514, 0.556, 0.465, 0.439, 0.551, 14.484, 0.42, 0.601, 0.493, 1.395, 5.509, 0.866, 2.508, 0.447, 0.433, 2.284, 0.864, 0.45, 1.165, 0.571, 0.46, 0.838, 0.691, 0.618, 0.477, 0.608, 0.668, 0.465, 0.443, 0.552, 1.095, 0.738, 2.065, 0.606, 10.245, 8.025, 1.39, 0.589, 0.42, 0.421, 0.566, 0.422, 0.456, 1.554, 1.006, 0.799, 0.477, 0.491, 2.044, 0.632, 1.06, 0.607, 3.906, 0.434, 1.091, 0.515, 0.937, 1.223, 1.025, 0.419, 0.452, 0.5, 0.476, 0.494, 1.783, 0.806, 0.482, 0.575, 1.348, 0.765, 0.692, 2.698, 0.503, 0.68, 0.947, 0.876, 1.177, 0.849, 1.042, 0.536, 0.591, 0.424, 0.524, 0.478, 2.599, 0.774, 0.786, 21.546, 0.404, 1.147, 1.126, 0.482, 0.729, 0.4, 0.514, 0.46, 0.504, 0.744, 0.785, 0.493, 1.432, 0.511, 0.594, 1.27, 2.174, 0.533, 1.069, 2.954, 0.523, 0.643, 0.744, 0.558, 0.497, 0.773, 2.536, 0.47, 0.788, 0.892, 0.865, 1.659, 0.589, 1.251, 0.454, 6.439, 4.573, 0.408, 1.724, 0.42, 0.394, 0.379, 2.31, 1.465, 0.478, 1.531, 0.626, 0.561, 0.574, 0.583, 0.946, 0.514, 0.644, 0.439, 0.514, 0.674, 1.06, 0.569, 0.428, 0.552, 2.302, 0.554, 0.562, 0.903, 0.499, 0.452, 0.74, 0.538, 0.73, 0.44, 0.867, 0.414, 0.61, 0.451, 0.463, 0.432, 0.438, 1.608, 0.501, 4.301, 1.652, 1.724, 0.647, 0.64, 0.482, 0.522, 0.826, 0.439, 1.602, 0.601, 0.431, 0.46, 0.535, 0.448, 0.958, 0.578, 0.405, 1.656, 0.962, 0.888, 0.787, 0.605, 0.799, 0.844, 0.587, 0.411, 0.97, 0.468, 0.481, 0.452, 0.402, 0.432, 1.217, 0.624, 0.49, 0.939, 1.731, 0.741, 59.499, 0.567, 0.614, 0.387, 0.453, 0.448, 0.762, 1.11, 0.548, 20.468, 0.923, 0.702, 0.741, 0.479, 0.478, 0.434, 0.668, 0.58, 1.386, 1.198, 0.491, 0.429, 0.431, 0.403, 0.782, 0.484, 0.567, 0.445, 0.392, 1.547, 0.611, 2.32, 0.411, 0.744, 0.676, 0.497, 0.457, 0.559, 1.372, 0.582, 0.602, 2.843, 0.405, 0.71, 4.372, 1.458, 0.45, 0.53, 0.897, 0.581, 0.456, 1.196, 0.441, 0.602, 0.409, 0.467, 0.459, 0.712, 3.416, 0.67, 0.491, 0.493, 0.454, 0.558, 2.532, 0.709, 0.409, 0.409, 0.651, 0.7, 0.513, 0.416, 1.569, 0.662, 0.485, 1.076, 6.631, 5.532, 3.053, 0.449, 0.936, 0.586, 0.436, 0.455, 0.578, 0.71, 1.792, 0.752, 0.529, 0.548, 0.519, 0.478, 0.462, 0.431, 0.444, 0.498, 0.64, 2.208, 0.456, 3.832, 2.352, 1.832, 0.941, 1.545, 0.445, 0.515, 1.508, 0.94, 0.472, 0.543, 0.625, 0.611, 0.696, 0.405, 0.635, 0.848, 0.612, 1.787, 1.392, 0.403, 0.561, 0.607, 0.453, 0.446, 1.151, 14.379, 0.672, 0.377, 0.439, 0.52, 0.604, 1.703, 1.667, 0.49, 0.593, 0.7, 0.964, 0.53, 0.427, 0.484, 11.466, 0.861, 2.085, 0.467, 0.686, 1.001, 1.122, 0.468, 0.839, 0.505, 0.535, 0.7, 0.773, 0.553, 0.578, 2.296, 0.488, 0.441, 1.095, 1.01, 1.247, 1.014, 1.169, 1.238, 23.894, 0.417, 7.727, 0.474, 0.629, 0.557, 0.944, 0.615, 0.4, 0.797, 0.878, 0.897, 0.794, 0.642, 2.634, 1.158, 0.437, 0.494, 0.649, 0.493, 0.576, 0.535, 0.486, 0.501, 0.47, 3.397, 0.506, 3.09, 1.143, 0.435, 1.278, 0.717, 0.777, 0.768, 0.719, 0.779, 0.473, 0.526, 0.427, 8.028, 0.473, 0.392, 7.651, 0.641, 0.371, 1.128, 0.488, 0.512, 0.69, 0.647, 0.524, 1.333, 0.521, 0.369, 1.346, 3.693, 1.515, 2.245, 0.722, 1.811, 0.509, 0.35, 0.665, 0.66, 2.587, 2.55, 1.109, 0.575, 0.456, 0.531, 0.773, 0.861, 16.989, 0.494, 0.392, 0.42, 0.829, 0.705, 0.547, 0.396, 0.39, 2.484, 0.41, 0.423, 0.864, 0.761, 0.54, 0.501, 2.168, 0.508, 0.486, 1.462, 3.219, 0.433, 0.405, 0.453, 1.43, 0.575, 1.049, 0.617, 0.862, 0.508, 0.504, 1.309, 4.731, 3.997, 0.421, 0.387, 0.382, 0.494, 0.593, 0.46, 1.651, 0.413, 0.526, 0.792, 22.117, 0.986, 1.958, 0.653, 0.393, 0.459, 0.397, 0.388, 0.483, 0.58, 1.033, 0.413, 0.453, 0.463, 0.618, 1.061, 8.506, 0.554, 3.007, 0.663, 1.204, 0.421, 1.628, 1.068, 1.392, 0.625, 0.551, 0.477, 0.433, 0.785, 0.394, 19.882, 0.57, 0.458, 0.711, 0.511, 3.892, 0.45, 3.522, 0.447, 0.776, 1.036, 0.406, 0.988, 0.887, 0.445, 0.413, 1.352, 0.45, 1.83, 0.374, 0.386, 0.762, 50.273, 1.445, 0.517, 17.007, 0.534, 0.511, 0.42, 2.675, 0.429, 0.631, 0.475, 0.703, 6.261, 0.446, 1.795, 0.597, 0.6, 0.499, 0.946, 0.439, 1.824, 1.103, 10.385, 0.615, 0.664, 0.76, 1.661, 1.318, 1.055, 0.453, 0.452, 0.432, 2.923, 0.607, 0.445, 0.877, 0.406, 4.496, 0.82, 0.514, 0.557, 0.967, 1.826, 1.043, 0.542, 0.571, 2.64, 0.656, 5.895, 0.441, 0.44, 0.815, 1.073, 2.343, 4.22, 4.173, 0.505, 1.851, 0.945, 0.383, 0.484, 2.733, 0.417, 0.563, 0.462, 0.542, 0.851, 0.455, 1.849, 0.437, 0.482, 0.641, 0.505, 0.412, 0.461, 0.609, 0.57, 1.721, 0.533, 0.704, 0.449, 0.672, 0.425, 0.509, 2.709, 0.571, 3.255, 3.003, 0.573, 0.487, 0.418, 1.747, 0.876, 12.621, 10.713, 0.447, 0.984, 0.503, 0.433, 0.455, 0.653, 0.442, 0.641, 0.426, 0.469, 0.719, 0.518, 0.475, 0.946, 0.711, 0.475, 0.496, 0.485, 0.383, 0.625, 0.457, 27.508, 0.793, 2.16, 0.702, 0.911, 0.779, 4.837, 1.079, 0.641, 0.58, 0.403, 0.412, 4.044, 0.469, 1.108, 0.722, 0.412, 0.984, 0.454, 0.462, 0.743, 1.407, 0.676, 1.023, 0.503, 0.477, 0.542, 0.469, 1.515, 0.52, 0.457, 3.342, 0.52, 0.771, 0.401, 0.451, 0.55, 0.595, 0.506, 7.496, 0.417, 0.651, 0.451, 9.603, 0.885, 3.171, 0.439, 0.974, 4.076, 0.382, 0.39, 9.113, 0.525, 0.388, 1.433, 0.425, 0.5, 0.511, 0.476, 0.668, 0.625, 0.422, 0.533, 0.526, 0.443, 0.462, 0.608, 0.594, 0.589, 0.561, 0.683, 0.383, 0.703, 1.36, 0.586, 0.499, 0.482, 0.492, 0.495, 2.17, 0.395, 0.71, 0.47, 0.801, 0.847, 0.387, 0.59, 0.765, 0.743, 0.713, 0.548, 11.243, 0.471, 0.585, 0.461, 0.452, 0.383, 1.03, 0.452, 0.367, 0.543, 0.904, 0.474, 0.627, 0.456, 1.73, 181.005, 0.421, 1.529, 0.468, 0.485, 0.63, 1.247, 0.551, 0.412, 0.504, 1.685, 0.648, 0.466, 0.64, 0.901, 0.398, 5.657, 0.41, 1.02, 16.12, 0.747, 0.625, 0.541, 1.248, 5.301, 0.584, 0.569, 2.695, 0.539, 1.859, 0.616, 0.473, 0.534, 0.661, 1.208, 0.494, 69.313, 1.199, 0.447, 2.127, 90.39, 0.376, 2.619, 0.486, 0.537, 0.462, 1.314, 0.397, 1.502, 0.451, 0.679, 0.423, 0.923, 2.769, 0.39, 1.23, 0.434, 0.623, 0.621, 0.798, 0.396, 0.59, 2.89, 0.701, 0.553, 0.413, 0.547, 0.39, 0.488, 0.454, 0.597, 0.762, 0.847, 0.657, 0.388, 0.712, 1.464, 0.588, 0.795, 0.655, 0.798, 1.263, 0.923, 0.6, 2.251, 0.449, 0.531, 0.739, 0.528, 0.483, 0.534, 1.718, 2.244, 0.73, 0.732, 0.825, 0.404, 0.425, 0.465, 1.641, 1.769, 0.455, 0.893, 14.962, 0.504, 2.313, 0.529, 0.884, 1.718, 0.563, 1.538, 0.399, 3.814, 1.046, 2.951, 0.591, 0.979, 0.516, 0.428, 5.763, 0.579, 0.713, 0.88, 0.451, 7.792, 0.487, 0.675, 1.019, 0.453, 0.417, 0.88, 0.469, 0.462, 0.516, 0.658, 0.486, 0.445, 1.031, 0.554, 0.908, 0.768, 0.563, 2.251, 0.64, 1.552, 0.768, 0.628, 3.195, 0.419, 0.395, 0.45, 0.617, 0.805, 1.033, 0.395, 13.664, 0.506, 0.418, 0.491, 34.229, 2.763, 0.504, 1.321, 1.603, 0.462, 0.423, 0.684, 0.899, 0.651, 14.883, 0.618, 0.455, 0.448, 0.643, 0.604, 0.576, 0.73, 0.432, 0.568, 0.508, 0.505, 0.894, 0.906, 0.411, 0.904, 0.464, 4.099, 0.485, 0.515, 0.415, 5.807, 0.497, 0.821, 0.713, 0.433, 0.528, 0.752, 0.61, 0.521, 0.718, 0.873, 0.412, 0.549, 1.057, 0.731, 0.567, 0.487, 0.497, 0.825, 0.463, 0.419, 0.581, 0.453, 1.185, 0.526, 8.999, 0.561, 0.892, 9.251, 0.456, 1.981, 0.963, 11.867, 0.892, 0.536, 0.586, 0.638, 0.669, 0.447, 0.497, 0.47, 0.482, 0.485, 0.714, 0.403, 0.579, 0.413, 3.708, 0.503, 0.527, 0.706, 9.053, 0.465, 0.473, 0.61, 0.428, 0.761, 1.107, 0.615, 4.356, 0.763, 0.52, 0.55, 0.453, 0.485, 0.684, 0.424, 0.41, 1.411, 3.667, 0.538, 0.472, 2.302, 0.475, 0.506, 0.93, 0.425, 1.544, 0.499, 0.411, 5.7, 0.472, 0.678, 0.576, 0.477, 5.484, 0.649, 0.466, 0.577, 0.57, 4.132, 0.43, 0.449, 0.608, 0.735, 0.897, 2.365, 0.615, 0.656, 1.803, 11.783, 0.731, 0.604, 0.435, 0.453, 1.369, 0.474, 0.398, 0.605, 0.866, 0.443, 0.508, 1.465, 0.914, 0.444, 4.649, 0.532, 0.502, 0.947, 0.816, 0.606, 0.421, 0.493, 0.821, 0.667, 0.488, 0.638, 1.58, 0.711, 40.61, 0.638, 0.455, 0.927, 0.488, 0.731, 0.456, 0.521, 0.515, 0.654, 0.958, 0.464, 0.664, 0.529, 0.421, 0.53, 0.581, 1.461, 0.422, 1.437, 1.305, 0.547, 0.685, 0.489, 0.396, 0.793, 0.569, 0.657, 0.623, 0.471, 0.42, 1.41, 0.727, 22.657, 0.434, 0.606, 0.797, 0.384, 0.48, 0.972, 0.527, 0.467, 0.482, 1.691, 0.395, 6.481, 4.248, 0.585, 0.423, 0.462, 0.405, 0.472, 0.419, 2.374, 0.804, 0.618, 0.872, 0.487, 2.314, 0.563, 0.737, 0.451, 0.55, 0.689, 0.476, 0.694, 0.43, 0.507, 1.816, 0.623, 0.691, 0.405, 1.278, 0.551, 1.029, 2.755, 1.526, 0.466, 0.585, 0.439, 0.462, 0.886, 0.688, 1.186, 1.651, 0.417, 1.573, 0.514, 0.673, 0.423, 1.178, 0.484, 1.518, 2.111, 0.555, 0.571, 0.902, 0.482, 0.51, 0.498, 0.416, 0.462, 0.588, 14.737, 1.786, 2.473, 0.454, 0.774, 0.676, 0.45, 0.39, 0.461, 0.479, 0.553, 0.649, 0.926, 0.68, 0.568, 0.419, 0.631, 0.425, 0.728, 1.403, 0.433, 1.07, 0.428, 3.186, 0.684, 0.522, 0.723, 0.395, 13.187, 0.844, 0.408, 0.467, 0.692, 0.464, 2.146, 1.52, 0.48, 0.764, 0.5, 0.43, 0.756, 0.449, 0.508, 0.474, 0.699, 1.016, 0.468, 1.244, 0.456, 0.607, 0.98, 0.627, 1.648, 0.482, 0.491, 0.553, 1.036, 0.484, 0.939, 0.456, 1.09, 1.3, 0.425, 0.751, 0.679, 2.724, 0.504, 2.389, 1.248, 0.779, 0.548, 0.534, 1.322, 0.457, 0.511, 0.63, 4.387, 0.437, 0.617, 1.097, 0.664, 0.432, 3.36, 0.56, 0.465, 0.457, 0.451, 0.495, 0.479, 0.439, 0.517, 0.536, 0.543, 0.419, 0.421, 0.734, 0.565, 0.523, 6.487, 0.465, 1.154, 0.622, 0.925, 1.656, 0.957, 0.623, 0.476, 0.412, 0.495, 0.575, 0.407, 0.461, 0.464, 0.461, 1.132, 0.606, 0.461, 3.463, 0.515, 0.491, 0.395, 0.523, 0.823, 1.935, 0.63, 0.392, 0.541, 2.029, 0.371, 2.582, 0.402, 0.628, 0.474, 0.554, 0.545, 1.661, 0.907, 0.512, 0.656, 0.448, 0.717, 0.702, 0.505, 0.437, 0.822, 0.472, 1.172, 3.728, 4.586, 0.726, 0.708, 0.706, 0.456, 0.554, 0.807, 0.41, 0.421, 0.954, 0.437, 0.608, 0.582, 7.369, 0.395, 0.422, 0.524, 0.493, 0.787, 0.453, 60.948, 0.503, 0.986, 1.643, 1.372, 1.048, 0.746, 0.715, 1.208, 0.38, 0.899, 0.398, 0.675, 0.537, 1.107, 0.545, 0.468, 0.499, 14.878, 0.753, 1.314, 3.634, 0.566, 0.555, 3.752, 0.585, 0.479, 2.346, 0.81, 2.2, 0.491, 0.459, 0.518, 1.305, 0.585, 0.407, 1.474, 1.228, 0.561, 8.658, 0.945, 0.457, 0.748, 0.613, 0.829, 1.399, 0.702, 0.875, 0.645, 0.659, 0.449, 0.542, 0.47, 1.998, 0.529, 0.749, 9.028, 0.457, 0.638, 0.513, 1.877, 0.503, 17.796, 0.639, 9.459, 1.015, 0.602, 4.307, 1.979, 0.593, 0.438, 0.77, 0.729, 0.549, 0.442, 0.498, 0.544, 2.186, 0.441, 0.418, 0.479, 0.832, 0.468, 0.499, 0.944, 0.909, 7.702, 1.031, 2.111, 0.589, 1.071, 0.579, 0.448, 2.555, 0.435, 0.47, 0.506, 0.407, 0.585, 0.442, 0.451, 0.474, 0.595, 0.449, 0.753, 1.538, 0.687, 0.462, 0.796, 1.21, 1.16, 1.164, 2.17, 0.609, 2.969, 0.549, 2.786, 2.826, 1.259, 0.467, 0.458, 0.782, 2.918, 0.555, 2.477, 0.446, 0.435, 0.477, 0.875, 0.449, 0.7, 0.952, 0.888, 0.483, 0.955, 0.491, 0.444, 1.488, 0.547, 0.461, 0.581, 0.423, 0.719, 3.692, 0.453, 2.713, 0.47, 0.918, 3.375, 0.715, 0.774, 0.458, 0.587, 0.477, 0.546, 0.72, 0.516, 1.091, 0.454, 0.836, 0.451, 0.775, 0.486, 0.74, 0.609, 1.16, 1.384, 0.606, 1.808, 0.499, 0.397, 0.4, 0.503, 1.236, 0.554, 1.478, 0.434, 0.595, 2.771, 0.83, 0.887, 0.594, 0.517, 1.418, 3.458, 0.427, 0.414, 2.617, 1.173, 0.775, 0.41, 0.808, 0.509, 0.695, 0.8, 0.997, 0.503, 0.751, 1.369, 0.809, 0.444, 165.098, 0.446, 0.46, 0.486, 0.498, 0.486, 0.478, 0.499, 1.057, 2.556, 0.608, 1.179, 1.564, 0.479, 0.541, 14.397, 0.522, 0.418, 0.486, 0.46, 0.688, 1.249, 0.429, 0.512, 0.717, 3.277, 0.578, 0.616, 0.56, 0.721, 2.262, 1.973, 0.746, 14.392, 0.577, 0.429, 2.797, 0.612, 0.537, 0.584, 0.968, 0.838, 0.421, 8.496, 6.12, 0.5, 1.435, 3.724, 1.454, 0.536, 2.039, 0.652, 0.654, 0.582, 0.617, 0.791, 0.485, 0.523, 0.455, 0.429, 2.183, 0.55, 0.482, 0.511, 0.451, 1.527, 0.426, 1.178, 0.48, 1.111, 0.508, 1.282, 0.557, 2.34, 0.621, 0.66, 0.453, 3.051, 0.591, 0.55, 1.098, 0.489, 0.868, 0.482, 0.971, 1.661, 7.327, 0.607, 0.504, 0.71, 0.497, 1.06, 1.232, 0.549, 0.427, 0.543, 0.459, 0.492, 0.568, 0.863, 0.58, 0.54, 1.363, 0.875, 0.673, 0.934, 0.464, 0.729, 0.589, 1.697, 0.435, 0.872, 0.758, 0.672, 0.688, 0.508, 0.622, 0.544, 0.771, 0.762, 0.577, 0.439, 0.482, 0.512, 32.17, 2.653, 0.658, 0.962, 0.471, 1.0, 0.924, 0.479, 0.454, 0.456, 0.591, 1.295, 0.501, 0.82, 0.823, 0.711, 1.215, 0.503, 0.664, 0.668, 0.608, 0.585, 0.8, 0.509, 1.548, 0.705, 65.762, 1.31, 0.605, 0.635, 0.713, 0.678, 0.754, 0.581, 0.53, 1.187, 0.626, 0.656, 0.559, 0.461, 0.633, 0.477, 0.934, 0.516, 2.528, 0.484, 0.766, 0.689, 0.962, 3.997, 0.588, 0.71, 2.685, 1.496, 0.534, 5.043, 0.49, 3.812, 0.519, 0.558, 0.534, 1.155, 0.571, 0.468, 3.769, 1.073, 0.709, 3.897, 0.97, 0.912, 1.581, 4.361, 0.814, 1.126, 0.682, 0.713, 0.81, 0.468, 0.614, 0.504, 0.488, 2.082, 0.457, 0.416, 0.535, 0.539, 1.592, 0.884, 1.143, 0.487, 5.144, 0.594, 0.933, 0.477, 0.577, 0.505, 0.499, 6.651, 0.455, 0.447, 11.015, 0.405, 0.494, 0.536, 0.553, 2.179, 0.645, 0.81, 1.508, 0.492, 0.469, 0.455, 0.511, 0.597, 0.67, 0.57, 0.521, 0.677, 0.471, 0.875, 0.437, 0.51, 0.728, 0.616, 0.462, 0.996, 0.592, 0.499, 1.557, 0.51, 0.576, 1.479, 0.622, 9.683, 0.614, 0.823, 0.742, 0.739, 0.985, 0.526, 0.511, 0.452, 1.045, 1.139, 0.676, 2.261, 0.496, 0.534, 0.731, 0.776, 0.593, 3.622, 0.786, 0.561, 0.476, 8.9, 0.846, 8.107, 0.605, 0.551, 0.67, 0.729, 0.714, 0.69, 0.68, 1.27, 1.025, 1.643, 0.907, 0.748, 0.583, 0.59, 0.887, 0.626, 4.256, 2.292, 0.723, 0.736, 0.618, 0.695, 0.697, 1.013, 0.49, 0.463, 0.974, 0.762, 0.475, 0.866, 8.587, 0.739, 0.468, 0.531, 0.997, 0.583, 0.61, 0.835, 0.94, 0.635, 1.001, 0.516, 0.601, 0.717, 0.972, 0.544, 0.992, 1.866, 1.558, 0.678, 0.736, 0.62, 1.575, 0.649, 0.533, 0.546, 0.45, 0.451, 0.562, 1.615, 1.604, 0.415, 0.455, 0.626, 2.463, 0.829, 0.474, 0.818, 0.517, 0.568, 8.014, 0.593, 0.504, 0.484, 0.682, 21.59, 0.519, 2.042, 1.619, 0.447, 14.408, 20.524, 0.523, 0.737, 0.501, 0.509, 0.609, 0.673, 3.521, 0.948, 0.542, 2.935, 1.995, 0.807, 0.647, 2.26, 0.613, 1.101, 1.114, 0.613, 0.779, 4.303, 0.802, 0.506, 1.638, 3.888, 0.612, 0.715, 0.659, 0.471, 0.744, 0.536, 1.512, 0.767, 1.006, 4.541, 1.009, 0.767, 0.536, 0.549, 0.501, 0.634, 0.506, 0.867, 0.701, 1.196, 0.526, 0.495, 0.435, 0.472, 0.53, 0.606, 0.49, 1.345, 0.477, 0.475, 2.634, 0.483, 0.456, 0.439, 0.465, 0.425, 0.449, 0.505, 0.49, 0.516, 0.501, 1.582, 0.802, 0.852, 1.327, 1.305, 0.771, 0.692, 0.491, 0.701, 0.428, 0.483, 0.418, 0.456, 0.78, 0.45, 0.779, 0.651, 0.444, 0.436, 0.684, 4.239, 0.629, 0.474, 0.573, 0.488, 0.794, 1.18, 0.927, 0.611, 1.583, 0.565, 0.638, 0.522, 0.619, 0.627, 0.718, 1.344, 3.874, 0.537, 1.246, 0.844, 0.552, 0.534, 0.632, 0.555, 0.924, 0.692, 0.802, 0.682, 0.708, 0.622, 0.654, 1.255, 0.577, 0.62, 0.569, 0.834, 0.479, 0.507, 0.894, 0.553, 0.444, 0.499, 0.479, 0.801, 0.517, 0.472, 0.759, 2.528, 0.417, 0.541, 0.58, 1.952, 0.517, 0.841, 0.945, 0.56, 0.435, 0.614, 0.543, 0.485, 0.4, 0.656, 1.037, 1.348, 0.481, 0.43, 1.015, 1.301, 0.706, 2.123, 0.771, 0.484, 0.643, 1.726, 0.748, 0.996, 0.504, 0.522, 0.54, 1.358, 0.444, 1.145, 1.506, 0.752, 0.477, 0.421, 0.517, 0.43, 0.441, 0.457, 0.564, 1.199, 0.522, 5.622, 0.544, 0.97, 0.432, 0.378, 0.507, 23.888, 0.947, 0.585, 0.671, 0.805, 0.737, 0.574, 0.624, 0.617, 0.565, 2.37, 0.72, 0.633, 3.106, 0.503, 13.675, 2.618, 0.503, 0.522, 1.052, 1.051, 0.708, 0.559, 0.575, 0.786, 0.789, 0.837, 0.769, 0.478, 0.45, 0.604, 0.463, 0.677, 0.642, 1.581, 0.682, 0.517, 0.612, 0.764, 0.648, 0.573, 0.585, 0.646, 0.541, 0.617, 2.987, 0.615, 1.225, 0.776, 1.004, 1.038, 0.657, 1.69, 0.503, 12.529, 0.417, 0.641, 12.954, 1.03, 0.467, 5.729, 0.642, 1.821, 0.46, 0.466, 1.301, 0.487, 14.278, 0.456, 0.552, 0.728, 0.458, 0.671, 0.59, 0.948, 0.589, 0.718, 0.77, 0.599, 0.799, 1.655, 0.59, 0.708, 1.768, 0.749, 0.801, 0.875, 0.914, 7.505, 0.798, 0.486, 0.503, 1.772, 0.674, 0.765, 0.611, 0.712, 0.557, 0.924, 0.487, 0.599, 4.567, 0.753, 1.505, 0.605, 1.334, 1.108, 0.716, 0.531, 0.796, 1.285, 0.645, 0.73, 1.42, 60.117, 0.548, 0.757, 1.289, 4.17, 0.945, 0.787, 0.51, 5.799, 2.152, 0.77, 0.804, 0.79, 7.147, 5.634, 0.437, 0.449, 0.517, 0.636, 0.587, 0.451, 1.369, 5.542, 0.507, 0.437, 1.074, 1.219, 0.522, 2.277, 0.466, 11.116, 93.648, 0.494, 0.521, 1.163, 0.503, 0.878, 0.636, 0.495, 1.804, 1.068, 49.836, 2.442, 0.549, 0.761, 0.548, 0.633, 1.281, 2.217, 0.733, 0.652, 0.566, 1.133, 1.318, 0.514, 0.471, 0.787, 0.671, 0.466, 16.078, 0.555, 0.62, 0.634, 1.066, 0.979, 0.61, 0.667, 0.507, 0.583, 0.644, 0.723, 0.553, 5.587, 1.575, 0.926, 1.686, 0.824, 0.733, 3.458, 1.09, 0.799, 0.89, 0.662, 0.731, 0.672, 2.362, 0.882, 0.773, 0.596, 0.768, 0.642, 0.854, 0.724, 1.153, 0.52, 0.705, 0.742, 0.615, 0.498, 0.455, 0.54, 0.551, 1.719, 1.72, 0.514, 0.584, 0.564, 0.566, 0.481, 0.517, 0.551, 0.629, 1.145, 16.481, 3.929, 0.629, 0.592, 0.561, 0.955, 39.106, 2.071, 0.81, 0.753, 0.888, 0.867, 1.937, 0.893, 0.642, 1.916, 0.777, 8.601, 0.98, 0.662, 0.977, 0.497, 0.582, 0.559, 0.754, 0.653, 0.661, 0.588, 0.625, 0.575, 0.703, 0.653, 0.635, 0.846, 1.764, 0.585, 0.735, 10.288, 0.56, 7.493, 0.624, 1.056, 0.829, 0.498, 0.774, 0.602, 0.94, 0.761, 0.607, 0.865, 0.753, 1.493, 0.827, 1.139, 0.805, 11.739, 0.465, 1.055, 0.581, 0.553, 0.966, 1.054, 1.051, 1.054, 3.796, 0.868, 0.58, 0.564, 0.549, 3.647, 0.46, 0.558, 1.2, 0.458, 4.171, 1.552, 0.408, 0.634, 0.835, 0.964, 0.521, 0.509, 0.527, 0.646, 2.51, 0.505, 0.711, 0.58, 0.514, 0.5, 0.826, 0.524, 0.569, 0.84, 0.761, 0.52, 0.451, 0.643, 0.437, 0.42, 0.892, 0.557, 0.774, 0.805, 0.533, 0.433, 0.834, 0.516, 1.405, 1.248, 0.635, 0.877, 0.929, 6.46, 0.454, 0.424, 0.478, 0.559, 1.187, 0.425, 0.543, 0.473, 0.593, 0.576, 1.487, 0.449, 0.434, 0.507, 0.56, 10.881, 0.469, 0.619, 0.733, 0.517, 0.563, 0.73, 0.719, 0.597, 1.565, 1.129, 10.664, 0.509, 1.822, 1.745, 0.412, 0.695, 0.439, 0.729, 0.453, 0.553, 1.465, 1.047, 0.603, 0.42, 0.682, 0.48, 1.443, 0.683, 0.943, 1.571, 0.52, 0.568, 0.405, 0.443, 0.756, 0.48, 2.306, 1.202, 0.55, 0.56, 0.584, 0.428, 0.934, 0.457, 0.462, 0.613, 0.442, 0.532, 3.754, 0.501, 0.484, 0.477, 0.538, 0.806, 0.541, 0.592, 0.488, 0.719, 0.553, 0.437, 0.432, 0.708, 0.925, 0.422, 9.689, 0.446, 0.8, 0.461, 7.421, 0.508, 0.528, 0.544, 1.023, 0.504, 1.044, 3.641, 0.671, 8.93, 0.449, 0.474, 0.667, 0.884, 0.787, 0.482, 0.569, 1.342, 0.836, 0.654, 0.857, 0.511, 0.857, 1.148, 0.568, 1.01, 0.498, 0.473, 0.541, 0.881, 0.974, 0.532, 1.45, 0.43, 0.55, 0.489, 1.957, 0.599, 0.782, 0.458, 0.691, 0.418, 0.511, 0.513, 0.831, 1.318, 0.775, 0.483, 0.42, 0.9, 0.718, 0.503, 1.007, 2.744, 1.781, 0.601, 0.58, 0.567, 4.063, 0.648, 0.957, 1.638, 2.741, 0.659, 0.524, 1.237, 1.224, 1.0, 0.816, 1.044, 0.58, 0.791, 0.471, 0.482
    #         ]
    #     ], # Example encoder times for each category
    #     [
    #         [
    #             14.888, 12.605, 10.967, 16.196, 12.83, 13.625, 12.778, 12.656, 11.875, 12.628, 11.294, 11.585, 11.487, 47.161, 10.739, 10.985, 12.157, 12.018, 11.904, 10.818, 10.835, 11.232, 11.264, 10.726, 10.879, 10.387, 13.078, 10.595, 11.618, 10.342, 11.271, 11.413, 10.755, 11.139, 18.117, 13.638, 10.7, 12.877, 11.006, 11.194, 10.73, 12.39, 10.952, 33.626, 10.756, 11.759, 13.961, 11.691, 11.475, 11.466, 11.28, 10.874, 17.732, 10.571, 11.909, 22.256, 13.034, 10.713, 11.785, 12.557, 11.216, 11.934, 11.864, 11.85, 25.65, 11.336, 11.586, 12.48, 11.413, 10.75, 11.262, 10.751, 10.851, 14.666, 10.914, 11.354, 11.841, 14.473, 12.354, 13.608, 13.251, 11.555, 22.825, 11.617, 12.184, 15.03, 11.729, 12.353, 13.409, 12.387, 11.083, 11.534, 12.488, 13.89, 13.417, 10.983, 10.815, 11.38, 12.697, 20.744, 11.152, 12.206, 11.554, 12.222, 12.795, 10.539, 12.076, 14.204, 11.55, 12.437, 10.973, 12.929, 15.234, 10.579, 15.571, 17.627, 12.61, 40.992, 11.825, 14.611, 10.929, 10.577, 13.555, 15.619, 10.742, 14.218, 14.248, 12.559, 10.893, 12.934, 177.015, 11.547, 13.187, 12.746, 11.176, 12.581, 11.501, 11.406, 12.721, 11.734, 11.433, 11.508, 12.183, 11.509, 23.157, 11.857, 11.963, 12.628, 13.243, 12.269, 12.619, 12.2, 18.277, 11.561, 13.456, 13.522, 14.682, 12.457, 14.233, 11.218, 13.25, 12.048, 15.199, 11.521, 14.792, 11.952, 11.328, 12.647, 11.803, 24.907, 12.447, 12.779, 11.63, 13.564, 12.225, 11.791, 12.834, 11.643, 11.793, 100.063, 11.606, 12.541, 11.644, 15.427, 11.869, 13.703, 15.022, 19.483, 12.521, 11.37, 11.585, 11.496, 20.658, 12.233, 12.248, 12.128, 12.108, 12.177, 12.887, 13.143, 11.508, 11.434, 12.222, 11.655, 13.077, 12.122, 12.837, 13.068, 12.668, 11.938, 17.25, 12.874, 12.324, 11.671, 11.649, 11.842, 11.937, 12.495, 12.671, 12.109, 14.425, 12.659, 13.506, 14.122, 15.521, 11.953, 12.128, 13.061, 11.636, 25.949, 18.682, 11.767, 13.676, 11.935, 16.066, 12.067, 11.532, 11.811, 12.457, 11.963, 12.394, 12.492, 14.829, 11.902, 13.195, 14.346, 12.389, 12.009, 11.911, 11.563, 11.713, 12.081, 11.45, 13.682, 11.464, 12.982, 11.828, 13.949, 12.027, 11.835, 12.213, 13.811, 12.433, 25.218, 12.401, 11.989, 11.405, 12.108, 11.734, 32.58, 11.669, 12.153, 12.096, 13.871, 12.433, 12.626, 11.986, 11.863, 19.831, 12.607, 16.065, 12.369, 12.152, 12.014, 11.875, 12.596, 13.008, 17.196, 13.119, 12.145, 12.605, 12.063, 13.268, 11.85, 12.488, 12.505, 12.474, 17.477, 11.813, 11.82, 30.939, 12.155, 12.478, 12.392, 15.682, 12.239, 11.925, 14.949, 13.722, 17.693, 12.758, 15.039, 12.828, 13.22, 12.037, 12.626, 13.121, 26.1, 12.525, 18.16, 11.603, 11.926, 11.496, 11.942, 11.659, 14.205, 12.418, 11.544, 13.686, 13.168, 12.535, 12.096, 11.658, 12.023, 12.959, 12.019, 11.842, 12.098, 12.411, 13.37, 11.444, 12.425, 15.348, 12.209, 12.019, 11.656, 18.896, 13.342, 19.047, 12.118, 11.692, 13.095, 12.012, 11.909, 13.679, 20.465, 12.804, 11.669, 12.982, 69.678, 11.879, 12.434, 13.43, 15.478, 12.952, 12.609, 11.891, 20.123, 12.49, 14.159, 12.523, 12.146, 12.246, 11.713, 25.332, 13.178, 12.085, 12.11, 14.165, 12.43, 13.507, 76.731, 12.533, 12.002, 12.987, 12.489, 12.923, 12.593, 12.102, 12.345, 12.764, 13.483, 12.786, 12.249, 12.807, 13.075, 14.328, 13.274, 14.914, 13.603, 12.962, 13.049, 13.955, 13.684, 12.849, 12.24, 16.899, 12.958, 12.138, 13.747, 12.686, 13.395, 13.886, 12.118, 12.86, 12.548, 13.074, 12.29, 29.546, 12.003, 21.071, 18.715, 15.615, 13.6, 12.199, 19.768, 13.712, 14.909, 11.873, 11.635, 12.72, 13.407, 13.39, 15.705, 12.486, 13.715, 13.542, 11.993, 12.562, 12.898, 11.943, 12.476, 12.252, 13.956, 13.016, 12.139, 13.112, 14.077, 12.238, 14.273, 12.123, 11.976, 11.855, 12.318, 12.872, 12.229, 13.006, 12.829, 14.241, 13.652, 12.463, 11.969, 13.228, 14.933, 12.12, 12.421, 14.063, 12.759, 13.165, 12.476, 11.991, 12.103, 13.088, 13.36, 18.452, 21.955, 12.19, 12.068, 12.523, 11.859, 11.914, 58.179, 12.802, 12.552, 11.977, 13.391, 13.271, 12.219, 15.558, 12.144, 12.001, 12.625, 14.694, 27.67, 11.385, 11.803, 12.323, 12.408, 11.997, 13.156, 13.995, 11.104, 11.424, 11.351, 13.315, 11.488, 12.131, 11.654, 11.13, 11.355, 11.256, 11.556, 12.382, 11.498, 12.078, 12.024, 11.803, 13.301, 15.66, 12.885, 10.996, 15.322, 10.943, 11.079, 12.442, 12.158, 27.161, 11.727, 32.1, 11.477, 50.993, 30.904, 11.184, 11.713, 13.341, 11.21, 11.646, 14.432, 11.195, 11.193, 19.516, 13.108, 13.207, 13.695, 13.293, 11.282, 11.459, 11.38, 12.262, 12.019, 12.612, 11.885, 11.317, 12.47, 13.999, 12.022, 11.44, 11.135, 12.269, 13.176, 11.945, 11.59, 11.556, 13.786, 12.151, 11.894, 15.541, 13.466, 11.561, 16.579, 18.126, 13.563, 11.927, 12.148, 11.309, 11.947, 11.375, 11.899, 13.338, 19.957, 33.693, 11.319, 11.381, 12.593, 12.035, 11.497, 18.259, 12.406, 13.293, 14.825, 11.59, 11.443, 103.533, 13.804, 13.76, 16.228, 20.193, 13.959, 18.978, 13.026, 14.654, 12.764, 12.759, 14.342, 13.7, 12.1, 12.44, 11.6, 11.864, 11.675, 11.793, 12.076, 12.222, 11.93, 12.395, 11.708, 15.038, 14.116, 11.509, 13.217, 11.696, 15.835, 12.726, 15.193, 12.313, 12.102, 14.6, 12.746, 14.064, 11.521, 13.325, 12.277, 12.328, 12.02, 11.661, 12.028, 11.424, 14.111, 15.04, 12.297, 11.92, 13.033, 12.534, 14.513, 13.695, 11.694, 12.09, 12.02, 13.634, 12.702, 11.773, 12.105, 11.736, 13.124, 14.441, 28.188, 11.443, 14.224, 14.566, 11.717, 15.565, 15.357, 12.926, 13.071, 27.725, 14.15, 12.29, 14.871, 13.562, 17.998, 17.866, 19.635, 15.184, 14.214, 14.128, 13.397, 13.592, 15.853, 13.164, 15.416, 14.305, 12.075, 13.868, 15.31, 25.164, 12.44, 12.342, 12.376, 12.112, 15.638, 12.267, 15.965, 12.221, 13.378, 14.073, 11.697, 73.99, 12.022, 14.135, 12.872, 11.706, 12.051, 12.766, 25.461, 13.212, 12.121, 14.539, 13.47, 12.345, 11.472, 11.791, 12.839, 12.404, 13.71, 12.249, 12.083, 13.901, 13.525, 12.171, 12.13, 11.707, 16.324, 13.599, 20.601, 12.659, 11.545, 11.885, 12.27, 11.907, 13.732, 12.044, 12.192, 12.477, 12.699, 36.741, 12.38, 16.788, 11.893, 80.303, 12.323, 11.794, 13.52, 11.948, 12.787, 12.962, 11.892, 11.904, 24.447, 13.085, 12.606, 14.157, 14.154, 14.55, 11.783, 12.085, 13.03, 11.988, 12.284, 11.382, 13.034, 11.6, 13.275, 11.928, 14.971, 15.339, 12.611, 12.372, 61.214, 11.439, 11.852, 12.809, 12.283, 18.827, 11.851, 12.309, 11.824, 13.276, 11.525, 11.693, 13.059, 16.08, 12.951, 23.203, 11.536, 14.342, 14.909, 12.052, 16.442, 12.772, 11.442, 11.732, 14.297, 12.44, 15.703, 12.75, 20.787, 12.007, 12.063, 12.085, 12.927, 12.253, 18.18, 13.882, 12.164, 11.406, 14.398, 12.016, 12.228, 11.385, 13.646, 14.792, 12.072, 12.673, 14.619, 12.532, 15.227, 14.355, 11.599, 14.453, 12.352, 12.745, 11.636, 13.453, 12.409, 11.861, 12.656, 12.183, 11.814, 15.968, 11.539, 14.063, 12.012, 14.7, 27.533, 11.919, 11.877, 14.349, 13.515, 20.351, 13.165, 11.944, 11.839, 14.627, 14.999, 11.38, 14.936, 11.702, 11.994, 12.963, 12.512, 11.24, 14.583, 15.992, 14.186, 12.321, 12.125, 12.551, 13.971, 20.658, 15.243, 11.925, 14.057, 14.431, 11.817, 12.961, 26.638, 14.391, 11.451, 11.056, 11.877, 11.508, 11.561, 11.595, 12.31, 11.654, 45.558, 12.831, 12.315, 12.314, 14.25, 23.419, 12.386, 12.021, 11.445, 12.867, 13.25, 11.483, 11.268, 21.379, 11.357, 11.734, 12.639, 11.377, 14.854, 14.642, 12.531, 12.474, 11.419, 12.254, 15.577, 13.823, 15.4, 14.725, 15.586, 26.761, 11.079, 11.509, 11.637, 12.41, 11.867, 12.084, 12.713, 16.218, 12.592, 12.225, 12.325, 18.973, 12.492, 11.379, 12.611, 11.939, 16.655, 11.588, 14.187, 16.742, 26.155, 12.661, 11.284, 13.16, 11.713, 12.602, 12.492, 11.682, 11.565, 12.65, 11.617, 13.696, 11.79, 11.477, 11.463, 11.674, 11.1, 11.609, 11.339, 14.434, 11.454, 11.794, 11.263, 16.395, 17.506, 13.302, 12.372, 12.521, 11.959, 11.588, 14.135, 13.339, 13.841, 12.928, 11.407, 16.256, 19.916, 11.466, 26.431, 12.914, 11.552, 11.904, 21.601, 15.113, 14.595, 12.539, 13.205, 13.47, 12.178, 11.946, 12.683, 13.399, 14.698, 184.038, 11.71, 12.071, 12.199, 13.079, 16.392, 25.844, 12.134, 24.139, 20.474, 15.243, 12.156, 14.235, 14.629, 15.779, 12.259, 17.207, 13.251, 11.972, 16.012, 14.571, 12.598, 12.914, 11.217, 46.477, 14.298, 12.048, 12.91, 14.345, 12.121, 15.21, 11.485, 14.156, 12.205, 12.837, 12.083, 11.535, 11.641, 13.12, 20.49, 11.986, 12.165, 11.385, 11.362, 11.529, 13.683, 11.742, 16.697, 11.246, 11.988, 14.978, 11.685, 11.625, 11.412, 11.437, 12.078, 11.77, 11.608, 12.97, 15.163, 18.42, 11.405, 11.379, 12.009, 14.288, 12.518, 16.205, 18.912, 11.731, 12.405, 81.096, 11.423, 14.819, 20.842, 12.615, 13.006, 17.836, 12.816, 11.499, 14.583, 12.459, 12.099, 13.888, 11.457, 11.581, 14.211, 11.736, 11.957, 12.856, 20.413, 11.99, 12.668, 19.463, 12.067, 11.919, 11.491, 11.968, 11.669, 12.903, 12.924, 12.164, 11.549, 12.33, 12.734, 20.88, 14.088, 12.598, 28.575, 11.823, 14.519, 12.488, 17.038, 11.434, 11.452, 12.215, 14.928, 26.434, 12.495, 11.432, 12.084, 11.282, 11.575, 11.252, 12.515, 11.664, 11.916, 15.454, 25.704, 12.281, 11.783, 11.611, 11.451, 11.223, 11.457, 11.529, 29.991, 11.334, 16.127, 12.294, 11.654, 13.887, 13.07, 16.658, 12.041, 14.844, 11.903, 11.84, 16.09, 15.138, 12.113, 63.062, 15.716, 12.115, 12.819, 11.678, 11.538, 11.542, 10.948, 13.254, 13.044, 13.758, 11.892, 11.147, 12.089, 13.507, 22.199, 11.228, 11.466, 11.418, 15.669, 12.209, 12.553, 12.601, 12.98, 15.834, 13.461, 12.173, 15.562, 12.355, 11.893, 17.019, 11.264, 13.1, 15.855, 11.514, 13.164, 11.582, 181.652, 14.148, 12.97, 16.039, 12.311, 13.743, 12.377, 11.58, 16.093, 17.23, 11.31, 12.14, 12.928, 11.637, 12.241, 13.688, 22.048, 12.065, 16.335, 13.85, 12.529, 104.328, 14.9, 12.609, 21.174, 15.038, 12.913, 26.026, 12.26, 12.015, 12.88, 11.98, 12.343, 12.054, 13.21, 16.07, 12.483, 12.155, 13.743, 13.44, 12.888, 15.484, 15.159, 14.322, 15.496, 53.387, 13.829, 12.773, 14.706, 16.644, 13.436, 14.996, 23.642, 24.85, 12.288, 14.475, 13.918, 15.778, 16.192, 12.1, 13.994, 18.498, 15.743, 13.172, 13.173, 12.402, 29.543, 12.163, 11.962, 12.911, 14.225, 12.069, 12.32, 12.429, 13.03, 13.943, 12.215, 15.411, 13.957, 13.887, 13.331, 16.243, 13.232, 15.588, 20.318, 12.607, 27.559, 15.557, 13.395, 14.797, 13.06, 26.094, 13.687, 12.34, 12.677, 12.646, 13.426, 13.286, 15.035, 13.627, 13.039, 14.098, 12.555, 12.948, 11.896, 12.698, 12.323, 12.481, 12.501, 12.391, 12.335, 13.184, 14.267, 16.28, 18.015, 15.361, 12.768, 12.493, 14.46, 12.881, 13.294, 13.912, 14.054, 13.094, 12.0, 16.74, 21.803, 13.567, 19.154, 14.514, 11.869, 12.177, 14.241, 11.948, 12.686, 12.289, 12.213, 11.778, 26.917, 11.927, 14.309, 17.95, 14.276, 13.897, 13.058, 16.683, 12.345, 12.714, 12.189, 12.492, 12.367, 13.407, 14.11, 30.476, 14.469, 12.479, 12.267, 13.135, 13.393, 13.126, 13.742, 12.636, 15.422, 12.902, 13.742, 12.97, 11.712, 12.47, 13.787, 13.143, 13.0, 14.353, 12.308, 13.155, 13.404, 12.668, 13.3, 12.201, 15.322, 35.175, 12.837, 12.984, 13.248, 12.461, 12.565, 12.856, 13.076, 13.501, 13.747, 15.303, 12.049, 13.289, 12.836, 14.863, 12.809, 13.695, 12.971, 18.431, 16.36, 13.278, 11.973, 15.261, 13.263, 12.152, 12.148, 12.829, 12.299, 12.316, 12.608, 12.03, 14.174, 12.724, 11.862, 12.447, 11.996, 12.304, 12.994, 11.952, 13.913, 15.848, 14.771, 12.63, 12.146, 12.465, 13.504, 11.894, 13.526, 12.986, 15.355, 13.695, 12.616, 13.01, 12.105, 12.578, 12.775, 12.243, 13.405, 12.866, 14.356, 75.626, 13.05, 12.402, 13.571, 33.837, 13.11, 16.013, 12.022, 11.939, 14.056, 12.528, 11.854, 12.368, 11.777, 13.079, 14.357, 12.663, 12.612, 13.053, 16.042, 15.156, 12.394, 17.43, 12.53, 15.389, 13.36, 12.05, 11.975, 12.215, 15.436, 12.153, 12.002, 15.078, 12.341, 12.903, 12.463, 13.277, 12.95, 24.435, 15.043, 12.67, 12.294, 12.471, 15.739, 12.368, 12.038, 11.985, 12.384, 13.915, 15.637, 15.804, 14.024, 12.252, 14.137, 13.988, 12.891, 12.268, 16.698, 14.821, 16.535, 12.598, 12.334, 28.837, 12.588, 12.936, 14.248, 16.747, 12.64, 12.837, 11.979, 28.947, 14.189, 13.263, 12.849, 12.875, 12.915, 12.58, 14.669, 15.337, 13.816, 13.759, 13.904, 39.255, 20.453, 13.273, 13.115, 12.25, 13.292, 12.842, 15.628, 12.473, 12.531, 12.069, 12.452, 15.147, 15.136, 13.392, 12.816, 13.408, 13.628, 11.954, 20.699, 11.881, 20.033, 12.599, 11.729, 12.295, 12.821, 12.251, 15.788, 14.981, 13.368, 12.113, 12.12, 15.917, 12.75, 12.124, 12.592, 29.159, 12.028, 12.713, 12.124, 13.825, 13.463, 12.568, 12.029, 13.969, 13.046, 14.882, 12.017, 13.119, 12.351, 13.687, 12.971, 20.056, 12.113, 12.316, 12.181, 13.472, 12.852, 34.701, 13.984, 11.976, 13.131, 12.248, 12.608, 12.502, 12.393, 20.783, 14.697, 12.901, 14.299, 13.232, 12.66, 12.697, 32.535, 12.475, 12.504, 15.828, 15.128, 12.792, 12.732, 12.686, 13.0, 13.474, 12.13, 64.413, 13.296, 29.2, 12.572, 14.865, 12.299, 18.412, 13.355, 12.119, 12.95, 13.481, 23.176, 12.619, 14.011, 13.878, 12.512, 14.724, 12.749, 12.896, 16.821, 12.727, 14.109, 15.061, 14.485, 18.504, 12.168, 13.293, 18.893, 17.349, 14.274, 12.483, 14.742, 12.813, 12.798, 14.375, 14.311, 13.969, 12.944, 12.65, 13.586, 12.657, 14.199, 14.77, 17.33, 15.544, 12.37, 14.35, 34.474, 14.256, 12.317, 12.051, 12.294, 12.085, 13.271, 12.769, 12.503, 12.207, 12.361, 40.413, 14.152, 12.675, 17.296, 13.246, 15.007, 15.866, 13.106, 12.61, 12.859, 12.514, 13.545, 13.881, 15.269, 13.858, 12.71, 15.503, 12.653, 12.647, 12.534, 19.593, 14.743, 23.095, 15.507, 16.64, 12.656, 22.269, 13.197, 14.932, 14.009, 12.555, 11.96, 12.419, 12.198, 12.366, 13.408, 12.468, 13.197, 13.287, 12.092, 13.97, 12.608, 12.774, 12.58, 12.733, 13.855, 23.732, 12.417, 11.908, 14.976, 13.686, 13.242, 12.57, 196.401, 14.3, 12.787, 14.589, 14.002, 14.754, 12.99, 13.837, 18.495, 14.643, 29.341, 13.117, 19.262, 13.303, 18.493, 14.807, 15.947, 17.273, 87.56, 17.739, 111.138, 15.246, 12.815, 16.962, 14.09, 12.935, 13.425, 18.594, 14.593, 15.841, 13.507, 15.73, 12.941, 12.899, 15.319, 15.207, 14.212, 16.574, 14.356, 13.711, 14.47, 16.22, 15.793, 15.549, 14.577, 12.667, 17.061, 15.745, 12.991, 12.824, 18.988, 13.79, 28.888, 15.275, 15.152, 16.435, 18.86, 16.615, 13.575, 12.985, 19.068, 14.221, 20.955, 12.876, 15.998, 14.602, 15.902, 14.024, 14.911, 13.611, 14.019, 17.883, 15.523, 14.021, 16.207, 13.098, 15.544, 15.638, 27.658, 13.212, 51.996, 13.72, 15.511, 16.106, 16.757, 32.422, 16.079, 17.614, 13.55, 12.964, 13.426, 15.256, 13.115, 17.155, 13.108, 18.896, 14.351, 16.154, 13.057, 12.892, 13.556, 12.822, 13.708, 12.562, 13.103, 12.593, 13.143, 13.956, 22.386, 23.308, 15.248, 27.041, 13.982, 13.712, 13.73, 13.764, 12.898, 12.981, 13.507, 16.569, 14.297, 23.189, 13.525, 13.351, 13.283, 16.736, 12.569, 12.271, 12.637, 13.606, 16.427, 14.336, 12.901, 13.283, 14.0, 20.1, 14.435, 12.588, 18.611, 13.441, 16.63, 12.425, 12.752, 15.947, 12.905, 25.402, 12.776, 15.434, 13.559, 12.491, 12.826, 13.743, 13.35, 17.12, 16.562, 13.61, 12.387, 13.7, 14.498, 15.968, 55.155, 13.484, 13.319, 13.606, 15.288, 15.464, 15.855, 15.488, 13.406, 13.574, 13.178, 12.554, 12.66, 13.388, 16.027, 13.385, 36.533, 12.396, 13.29, 12.957, 12.659, 16.421, 19.459, 16.394, 12.629, 13.793, 17.442, 13.338, 12.883, 14.903, 14.051, 14.071, 12.847, 12.451, 14.364, 12.672, 13.81, 15.381, 14.117, 14.925, 12.991, 13.595, 14.076, 13.729, 13.274, 16.455, 15.538, 12.481, 12.78, 12.922, 15.41, 27.532, 16.328, 13.362, 12.453, 15.623, 12.78, 13.374, 12.516, 12.711, 14.638, 13.357, 15.846, 15.398, 12.723, 25.969, 14.042, 12.841, 15.507, 14.26, 12.961, 13.049, 12.265, 12.932, 12.903, 15.076, 14.003, 16.932, 13.966, 14.43, 12.848, 13.379, 13.953, 13.483, 14.753, 15.855, 13.033, 15.99, 14.259, 17.149, 12.476, 14.411, 15.457, 15.768, 14.371, 15.316, 14.081, 15.804, 15.607, 14.92, 21.757, 15.128, 15.449, 15.728, 15.473, 14.949, 14.697, 14.313, 13.703, 14.323, 19.217, 12.686, 16.8, 14.256, 12.194, 17.759, 14.552, 12.684, 12.883, 17.612, 16.246, 16.982, 16.045, 12.806, 15.961, 21.261, 13.126, 12.951, 16.833, 12.763, 13.894, 12.398, 20.999, 14.756, 12.802, 76.831, 13.105, 14.802, 14.163, 13.742, 13.711, 14.546, 13.882, 12.437, 28.532, 15.063, 16.011, 18.873, 14.216, 16.425, 16.038, 12.702, 13.587, 14.502, 14.805, 22.726, 12.99, 13.471, 14.342, 12.394, 13.52, 11.534, 13.299, 20.422, 11.553, 14.497, 30.748, 21.641, 12.188, 17.083, 11.668, 13.132, 11.97, 14.106, 13.1, 14.897, 13.748, 14.653, 20.295, 14.276, 12.759, 13.313, 13.645, 11.567, 12.027, 12.325, 11.598, 11.753, 12.877, 11.91, 12.889, 14.054, 14.06, 14.075, 14.763, 11.725, 14.57, 14.419, 11.666, 11.726, 12.017, 15.548, 11.874, 11.85, 12.917, 12.893, 11.97, 15.152, 15.9, 14.91, 12.402, 13.263, 11.836, 11.9, 12.756, 13.182, 12.062, 12.043, 13.0, 13.501, 11.814, 11.511, 12.561, 12.537, 13.713, 11.936, 11.603, 15.641, 11.754, 14.559, 12.309, 12.25, 12.167, 11.795, 12.45, 11.48, 181.463, 12.247, 12.357, 12.26, 16.394, 16.673, 18.104, 28.269, 12.601, 12.393, 13.136, 12.472, 15.848, 16.424, 14.522, 16.254, 27.971, 12.807, 15.301, 15.001, 14.035, 21.58, 18.73, 17.499, 13.876, 15.886, 15.761, 12.696, 12.433, 12.246, 14.626, 12.427, 14.574, 13.301, 13.099, 13.103, 14.729, 13.149, 15.718, 13.279, 16.095, 13.09, 14.554, 19.934, 13.013, 13.313, 13.569, 14.769, 12.823, 16.134, 15.411, 16.334, 14.72, 12.971, 13.481, 13.056, 12.857, 15.475, 12.22, 13.148, 12.729, 12.099, 48.831, 12.5, 12.871, 12.661, 12.226, 13.621, 12.529, 13.455, 13.17, 12.408, 12.386, 12.324, 13.993, 83.356, 13.888, 16.383, 12.777, 13.019, 12.795, 12.885, 15.482, 13.251, 14.362, 13.649, 16.589, 15.118, 15.501, 17.228, 16.289, 12.392, 13.396, 12.271, 17.405, 16.656, 14.235, 17.842, 13.431, 12.523, 12.503, 12.171, 15.892, 15.489, 15.654, 14.239, 13.093, 18.627, 13.324, 12.504, 19.221, 13.431, 23.84, 12.389, 15.192, 13.432, 14.179, 14.508, 12.665, 12.518, 16.175, 13.267, 15.442, 13.967, 14.209, 13.116, 16.906, 14.142, 23.415, 12.89, 13.253, 13.411, 14.269, 13.9, 14.519, 12.852, 15.402, 15.658, 12.875, 22.786, 23.023, 11.951, 13.064, 12.972, 13.556, 14.424, 13.251, 13.898, 14.735, 18.468, 12.688, 12.748, 13.313, 15.407, 15.718, 13.107, 21.867, 12.401, 13.075, 12.842, 12.496, 12.832, 15.776, 16.084, 14.883, 13.94, 13.601, 14.093, 12.385, 13.361, 13.898, 16.64, 12.996, 19.105, 12.976, 12.534, 23.118, 16.347, 39.124, 15.427, 16.917, 50.276, 12.57, 12.771, 12.584, 16.689, 15.874, 15.442, 14.672, 13.583, 13.317, 16.735, 15.098, 18.822, 14.933, 15.988, 12.886, 14.374, 17.91, 13.883, 12.689, 12.805, 15.233, 16.146, 15.527, 12.815, 14.228, 13.288, 12.502, 14.954, 14.156, 12.404, 15.504, 15.611, 14.401, 14.032, 16.662, 16.472, 15.055, 15.867, 15.939, 13.012, 13.623, 12.534, 19.716, 14.488, 12.656, 14.215, 16.61, 14.614, 12.836, 13.028, 13.684, 16.465, 17.116, 14.896, 13.701, 12.577, 12.814, 12.784, 13.28, 12.538, 13.435, 15.937, 16.309, 12.138, 15.923, 13.053, 15.465, 12.537, 14.507, 14.5, 13.203, 12.128, 12.283, 15.166, 13.932, 11.943, 13.935, 14.151, 12.488, 13.812, 15.608, 12.153, 13.516, 12.817, 13.789, 12.28, 12.278, 13.618, 16.68, 20.764, 12.963, 11.958, 37.743, 12.299, 14.65, 12.776, 12.574, 14.177, 12.469, 15.329, 31.994, 12.564, 14.024, 15.71, 16.367, 15.026, 12.48, 12.49, 13.525, 14.164, 12.578, 12.715, 12.767, 14.1, 14.167, 16.167, 17.185, 14.761, 16.355, 26.299, 12.842, 28.022, 18.56, 18.13, 12.162, 13.3, 28.176, 13.735, 12.374, 14.299, 14.305, 13.831, 13.766, 12.481, 13.848, 13.321, 24.494, 12.844, 13.756, 14.878, 13.193, 13.635, 13.679, 17.329, 13.874, 13.957, 12.883, 13.804, 12.57, 77.681, 12.021, 16.786, 13.08, 22.175, 14.689, 13.594, 24.925, 12.53, 12.93, 14.019, 18.781, 13.075, 13.624, 14.834, 27.485, 106.878, 13.394, 15.282, 12.568, 14.61, 64.635, 12.198, 12.596, 15.692, 13.002, 15.997, 13.069, 12.802, 12.719, 28.961, 12.536, 14.123, 13.304, 15.352, 12.742, 18.3, 14.073, 14.041, 15.494, 13.159, 12.637, 13.317, 14.643, 12.467, 15.516, 12.706, 17.201, 17.151, 12.459, 12.672, 15.334, 13.719, 12.48, 12.306, 14.555, 13.351, 32.733, 12.426, 13.564, 59.041, 13.073, 16.276, 14.196, 14.563, 22.098, 13.279, 15.839, 16.498, 12.669, 12.462, 12.422, 12.445, 12.813, 13.737, 23.147, 19.822, 14.394, 12.703, 13.325, 14.039, 12.858, 13.429, 16.582, 24.796, 13.439, 12.886, 13.647, 13.59, 16.661, 14.782, 15.885, 11.343, 12.327, 16.044, 11.592, 11.876, 11.637, 11.372, 13.023, 12.042, 11.199, 11.216, 11.434, 11.366, 11.339, 10.883, 12.393, 11.796, 11.205, 11.477, 13.811, 13.058, 18.089, 11.739, 11.051, 12.558, 12.996, 11.107, 11.971, 12.29, 22.411, 11.834, 11.298, 11.19, 11.331, 13.052, 22.355, 14.018, 12.426, 11.605, 12.796, 14.144, 13.273, 13.568, 12.41, 12.832, 11.269, 11.682, 12.237, 16.061, 12.189, 11.217, 11.973, 11.81, 14.006, 14.986, 11.815, 11.952, 11.927, 11.441, 11.547, 11.647, 15.32, 23.272, 11.733, 19.01, 12.804, 12.889, 15.229, 20.589, 11.607, 12.295, 11.508, 12.075, 12.272, 11.948, 13.053, 12.12, 11.452, 12.181, 13.02, 12.402, 12.266, 13.279, 11.467, 11.523, 12.069, 12.342, 11.411, 11.665, 14.183, 15.183, 13.603, 11.366, 14.99, 13.484, 14.356, 12.049, 12.503, 12.026, 12.369, 11.571, 184.352, 13.713, 16.48, 15.325, 13.87, 17.824, 16.232, 14.03, 13.678, 65.09, 13.793, 27.759, 13.38, 14.542, 15.549, 14.737, 17.406, 12.634, 13.52, 12.867, 14.982, 16.886, 34.761, 13.125, 15.101, 12.473, 13.644, 12.831, 13.741, 12.62, 13.705, 17.827, 14.236, 19.17, 14.702, 18.949, 17.038, 14.129, 13.007, 13.827, 15.979, 12.202, 27.898, 13.919, 19.274, 15.491, 13.54, 13.176, 13.0, 17.674, 17.186, 14.11, 14.212, 12.498, 12.531, 17.855, 14.48, 14.942, 12.508, 15.072, 13.989, 22.025, 18.644, 13.961, 12.304, 12.808, 15.179, 12.745, 13.618
    #         ], 
    #         [
    #             5.24, 0.535, 0.781, 5.854, 0.889, 1.839, 1.907, 1.172, 0.367, 1.57, 0.531, 0.512, 0.603, 38.07, 0.619, 0.653, 1.941, 1.496, 0.517, 1.034, 0.526, 1.23, 0.819, 0.756, 0.763, 0.308, 2.821, 0.551, 1.668, 0.235, 1.278, 1.196, 0.518, 0.484, 8.688, 3.403, 0.415, 2.32, 0.409, 0.358, 0.271, 1.306, 0.304, 23.935, 0.686, 1.155, 0.859, 0.867, 1.115, 1.247, 0.434, 0.447, 7.727, 0.452, 0.485, 13.135, 1.744, 0.454, 0.639, 0.261, 1.116, 0.647, 1.056, 1.065, 15.871, 0.26, 0.573, 0.418, 0.521, 0.316, 0.602, 0.95, 0.323, 5.052, 0.63, 0.65, 0.37, 3.139, 1.616, 1.789, 3.353, 1.741, 13.8, 0.502, 0.947, 4.478, 1.324, 0.71, 1.117, 0.905, 0.356, 0.69, 0.794, 3.874, 2.139, 0.502, 0.55, 0.554, 1.619, 11.474, 0.988, 1.152, 0.797, 0.598, 0.479, 0.497, 0.711, 4.374, 1.373, 1.303, 0.538, 3.318, 5.271, 0.427, 5.762, 6.661, 1.983, 32.635, 1.649, 4.541, 0.429, 0.458, 3.282, 6.384, 0.716, 3.539, 3.452, 1.072, 0.487, 0.659, 166.19, 0.63, 2.243, 1.682, 0.387, 0.987, 0.638, 0.519, 1.44, 0.567, 0.824, 0.541, 0.708, 0.521, 12.75, 0.585, 0.399, 0.309, 1.017, 0.978, 0.4, 1.014, 8.201, 0.378, 1.185, 2.333, 3.899, 1.072, 2.85, 0.488, 2.05, 0.729, 4.412, 0.637, 1.865, 0.545, 0.348, 0.639, 0.354, 14.303, 0.914, 1.416, 0.626, 2.377, 0.789, 0.582, 1.969, 0.45, 0.722, 89.614, 0.603, 0.587, 0.382, 4.349, 0.498, 2.456, 2.548, 8.734, 0.561, 0.366, 0.555, 0.419, 10.455, 0.873, 0.914, 0.574, 0.681, 0.473, 1.039, 1.013, 0.301, 0.322, 1.057, 0.483, 1.708, 0.956, 1.444, 1.217, 0.957, 0.674, 6.398, 1.775, 0.825, 0.418, 0.422, 0.629, 0.403, 0.822, 0.536, 0.875, 3.525, 1.618, 2.114, 2.857, 4.741, 0.4, 0.827, 0.706, 0.517, 16.005, 8.036, 0.417, 2.845, 0.55, 5.35, 0.813, 0.385, 0.438, 1.126, 0.656, 0.575, 0.665, 1.169, 0.683, 2.162, 1.227, 0.611, 0.841, 0.491, 0.5, 0.524, 0.828, 0.404, 2.411, 0.493, 1.848, 0.553, 2.991, 0.389, 0.509, 0.913, 2.511, 1.117, 15.291, 1.248, 0.495, 0.437, 0.584, 0.426, 22.325, 0.533, 0.912, 0.631, 2.855, 1.23, 1.046, 0.427, 0.461, 8.76, 1.535, 4.585, 0.844, 0.505, 0.617, 0.532, 0.894, 1.89, 6.43, 1.494, 0.818, 1.1, 0.648, 2.061, 0.834, 0.805, 1.341, 0.838, 7.21, 0.328, 0.43, 21.12, 0.855, 1.507, 1.148, 4.288, 0.889, 0.531, 3.106, 2.192, 6.303, 1.426, 4.021, 1.554, 2.349, 0.721, 1.359, 1.492, 16.23, 1.543, 7.532, 0.501, 0.483, 0.467, 0.459, 0.432, 2.341, 1.212, 0.315, 2.374, 1.2, 0.712, 0.727, 0.352, 0.51, 0.436, 0.444, 0.669, 1.051, 0.58, 0.887, 0.379, 0.822, 4.128, 0.429, 0.491, 0.443, 8.228, 2.029, 8.405, 0.982, 0.508, 1.758, 0.51, 0.586, 2.217, 10.306, 1.584, 0.341, 1.496, 60.841, 0.402, 0.994, 1.964, 3.999, 1.111, 1.171, 0.54, 9.175, 0.947, 3.043, 1.184, 0.536, 0.491, 0.302, 15.202, 1.971, 0.47, 0.71, 2.236, 0.854, 2.451, 66.431, 1.15, 0.371, 1.742, 0.917, 1.125, 0.722, 0.426, 0.688, 1.331, 1.991, 1.259, 0.338, 1.181, 1.308, 3.627, 0.828, 1.312, 0.94, 1.302, 0.617, 0.506, 2.305, 0.864, 0.764, 5.467, 1.463, 0.447, 2.261, 1.074, 1.824, 2.662, 0.495, 0.777, 1.011, 0.577, 0.448, 19.694, 0.405, 10.488, 7.381, 4.425, 1.952, 0.478, 8.843, 2.282, 3.214, 0.479, 0.398, 0.743, 1.796, 0.634, 4.203, 0.62, 2.712, 1.829, 0.409, 0.924, 1.481, 0.476, 1.071, 0.923, 2.725, 1.478, 0.42, 1.339, 2.582, 0.767, 0.734, 0.479, 0.307, 0.602, 0.723, 1.307, 0.532, 1.916, 1.008, 2.802, 2.18, 0.745, 0.465, 1.893, 3.845, 0.605, 0.945, 2.877, 0.852, 1.79, 0.723, 0.726, 0.475, 0.437, 1.113, 7.535, 11.119, 0.717, 0.6, 0.81, 0.421, 0.315, 49.332, 0.862, 0.749, 0.428, 2.415, 1.343, 0.823, 2.678, 0.6, 0.398, 1.116, 3.486, 17.495, 0.311, 0.426, 0.333, 0.575, 0.5, 2.157, 1.166, 0.729, 1.263, 0.886, 2.269, 0.81, 1.55, 1.488, 0.747, 0.581, 0.618, 0.625, 2.29, 0.725, 1.999, 1.294, 0.834, 3.221, 3.947, 0.755, 0.57, 4.723, 0.713, 0.805, 1.937, 0.513, 15.733, 1.227, 20.421, 0.734, 38.39, 17.718, 0.727, 0.723, 0.69, 0.675, 0.749, 3.636, 0.56, 0.671, 8.926, 0.647, 2.72, 2.961, 2.741, 1.025, 0.616, 0.999, 1.036, 1.224, 2.053, 1.324, 0.763, 1.902, 1.261, 1.474, 1.013, 0.597, 1.661, 2.09, 1.061, 0.997, 0.826, 2.871, 0.56, 0.698, 3.898, 2.257, 0.514, 5.602, 4.873, 2.282, 1.131, 0.89, 0.753, 0.82, 0.751, 1.284, 1.364, 9.195, 22.861, 0.96, 0.669, 2.019, 1.441, 0.627, 5.273, 1.861, 0.891, 1.579, 0.681, 1.0, 90.489, 0.643, 2.571, 3.543, 7.345, 1.202, 5.971, 1.564, 0.483, 1.444, 1.652, 0.869, 2.211, 0.868, 0.799, 0.662, 0.7, 0.607, 0.893, 1.328, 1.079, 0.85, 1.22, 0.948, 3.973, 0.726, 0.67, 1.946, 0.852, 4.649, 1.186, 1.367, 1.2, 1.078, 0.723, 0.904, 0.647, 0.792, 1.924, 1.196, 1.42, 1.09, 0.77, 0.558, 0.697, 0.578, 0.857, 0.947, 1.0, 1.674, 1.248, 2.088, 1.65, 0.689, 0.705, 0.784, 0.682, 1.551, 0.823, 0.583, 0.714, 1.546, 1.124, 14.387, 0.704, 1.673, 1.024, 1.182, 1.637, 1.777, 1.405, 0.608, 16.086, 0.707, 0.954, 0.95, 2.271, 4.106, 4.232, 7.673, 0.727, 0.566, 2.321, 0.97, 1.709, 4.305, 1.187, 1.145, 0.602, 0.74, 1.419, 4.067, 10.546, 1.538, 1.032, 0.936, 0.842, 1.481, 1.004, 2.682, 0.932, 0.828, 0.689, 0.759, 59.216, 0.531, 0.614, 0.621, 0.57, 0.595, 0.792, 11.519, 0.51, 0.799, 2.927, 1.028, 1.129, 0.753, 0.926, 1.637, 1.338, 2.504, 1.495, 1.215, 2.784, 1.353, 1.225, 1.478, 0.886, 3.545, 2.353, 9.002, 0.987, 0.602, 0.673, 1.202, 0.676, 2.346, 0.942, 0.688, 1.599, 1.658, 24.12, 1.44, 5.687, 0.604, 65.08, 0.924, 0.868, 2.054, 0.823, 0.699, 1.574, 0.821, 0.536, 12.512, 0.772, 0.704, 0.657, 0.683, 0.872, 0.615, 0.754, 1.734, 1.015, 0.642, 0.689, 1.508, 0.624, 2.09, 0.807, 3.598, 4.111, 0.761, 1.039, 47.809, 0.659, 0.944, 1.482, 1.484, 7.379, 0.971, 0.578, 0.581, 1.964, 0.805, 0.709, 1.02, 4.802, 1.156, 10.347, 0.568, 1.212, 0.883, 0.836, 3.946, 1.282, 0.668, 0.684, 0.961, 1.237, 4.07, 1.357, 8.9, 0.93, 0.795, 0.735, 0.796, 1.259, 6.647, 1.094, 0.95, 0.691, 2.784, 0.86, 1.302, 0.61, 2.471, 0.649, 0.943, 0.625, 1.117, 0.736, 2.28, 0.96, 0.877, 0.947, 1.037, 0.914, 0.593, 1.823, 0.702, 0.592, 1.191, 1.009, 0.709, 2.416, 0.601, 2.614, 1.011, 1.55, 14.777, 1.081, 0.837, 2.57, 2.307, 8.638, 1.908, 0.831, 0.806, 3.627, 3.488, 0.543, 3.071, 0.694, 1.206, 1.629, 1.187, 0.601, 0.979, 1.708, 2.961, 1.115, 1.112, 1.062, 2.561, 8.811, 3.918, 1.003, 1.255, 2.965, 0.94, 1.976, 14.585, 3.298, 0.721, 0.572, 1.01, 0.603, 0.55, 0.581, 0.993, 0.777, 32.383, 0.696, 1.48, 1.676, 1.035, 11.462, 1.276, 0.869, 0.761, 1.925, 2.228, 0.631, 0.576, 9.641, 0.653, 0.872, 1.588, 0.844, 2.084, 1.109, 1.195, 1.425, 0.733, 1.267, 4.633, 2.856, 1.182, 0.992, 4.076, 14.806, 0.583, 0.701, 0.616, 1.422, 0.9, 1.142, 0.799, 4.317, 0.672, 1.335, 1.104, 7.369, 1.74, 0.676, 1.626, 0.969, 3.45, 0.795, 2.745, 3.769, 14.306, 1.154, 0.638, 2.007, 0.783, 1.133, 0.817, 0.827, 0.629, 1.428, 0.873, 2.893, 1.13, 0.666, 0.681, 0.787, 0.689, 0.984, 0.563, 3.286, 0.614, 1.062, 0.742, 5.125, 6.892, 2.634, 1.369, 1.527, 1.205, 0.819, 0.991, 1.529, 0.65, 0.61, 0.607, 2.751, 8.022, 0.71, 14.308, 0.771, 0.597, 0.907, 9.879, 2.592, 3.241, 1.564, 1.816, 0.82, 1.063, 0.883, 1.345, 1.976, 3.035, 164.045, 0.673, 0.67, 0.689, 1.375, 4.321, 12.922, 0.773, 11.129, 7.906, 1.358, 0.52, 1.135, 1.912, 3.6, 0.876, 3.005, 0.645, 0.581, 3.8, 2.847, 1.129, 2.354, 0.596, 32.639, 3.818, 1.049, 2.466, 1.587, 1.365, 4.386, 0.641, 3.242, 0.731, 0.697, 1.178, 0.813, 0.66, 0.907, 8.961, 1.148, 1.179, 0.626, 0.724, 0.786, 3.078, 1.199, 5.937, 0.685, 1.517, 4.287, 1.106, 0.969, 0.783, 0.58, 1.46, 0.864, 0.967, 2.062, 4.111, 7.403, 0.887, 0.828, 0.676, 3.457, 1.143, 4.176, 7.716, 1.191, 1.963, 66.522, 0.691, 3.541, 9.063, 0.911, 1.42, 6.715, 1.816, 0.612, 3.305, 0.627, 0.929, 2.796, 0.597, 0.601, 0.887, 0.848, 1.166, 1.414, 8.612, 1.227, 0.574, 8.248, 1.138, 0.955, 0.625, 1.015, 0.737, 2.017, 1.718, 0.927, 0.782, 0.831, 1.747, 9.042, 1.946, 1.179, 15.843, 0.62, 3.61, 1.209, 2.483, 0.602, 0.693, 0.843, 3.956, 15.712, 1.711, 0.727, 1.221, 0.603, 0.923, 0.706, 1.663, 0.704, 0.875, 4.684, 13.209, 0.633, 0.918, 0.933, 0.735, 0.693, 0.617, 0.792, 17.799, 0.646, 5.114, 1.433, 0.699, 0.723, 1.437, 4.338, 1.106, 2.407, 0.96, 0.842, 4.252, 3.999, 0.805, 47.321, 4.4, 0.491, 1.691, 0.576, 0.756, 0.676, 0.725, 2.619, 2.184, 3.115, 1.16, 0.632, 1.301, 2.921, 10.066, 0.624, 0.871, 0.71, 4.244, 1.056, 1.498, 1.944, 2.081, 0.814, 0.686, 1.584, 4.388, 0.953, 1.094, 5.205, 0.582, 1.902, 1.452, 0.678, 0.974, 0.751, 165.006, 2.295, 1.401, 4.357, 0.898, 2.328, 0.617, 0.557, 4.295, 5.953, 0.606, 0.744, 1.657, 0.717, 0.658, 1.993, 9.874, 0.642, 0.98, 2.531, 1.084, 86.723, 0.939, 1.205, 8.835, 3.383, 1.315, 14.048, 0.666, 0.737, 1.158, 0.668, 0.929, 0.745, 1.588, 4.283, 0.91, 0.74, 2.404, 1.405, 0.826, 0.617, 0.57, 2.482, 0.722, 39.421, 1.648, 1.181, 2.647, 1.29, 1.538, 0.789, 11.114, 11.088, 0.714, 2.796, 1.776, 0.579, 1.467, 0.781, 2.323, 3.015, 0.578, 1.375, 1.318, 0.874, 15.973, 0.57, 0.587, 0.777, 0.595, 0.684, 0.668, 0.681, 1.238, 1.203, 0.728, 1.148, 0.644, 1.889, 1.317, 3.704, 1.147, 0.738, 8.135, 1.031, 14.58, 3.77, 1.646, 1.095, 1.176, 12.719, 1.003, 0.653, 0.899, 0.659, 0.893, 1.462, 0.791, 1.734, 1.321, 0.708, 0.616, 0.879, 0.569, 0.963, 0.786, 0.899, 0.71, 0.913, 0.789, 1.282, 2.71, 2.138, 5.83, 0.782, 1.032, 0.824, 1.039, 1.118, 1.637, 1.66, 1.707, 0.916, 0.695, 5.13, 9.922, 1.913, 4.716, 0.802, 0.632, 0.875, 2.398, 0.839, 0.791, 0.95, 0.713, 0.588, 14.825, 0.643, 1.521, 5.842, 2.655, 2.384, 1.05, 1.501, 0.872, 0.941, 0.779, 0.766, 0.695, 1.507, 2.346, 17.804, 1.723, 0.634, 0.713, 1.687, 1.48, 0.681, 2.355, 1.213, 3.946, 1.204, 1.746, 1.098, 0.54, 0.571, 2.009, 0.805, 1.725, 2.836, 0.79, 1.294, 1.68, 1.285, 0.78, 0.798, 3.031, 22.243, 1.209, 1.227, 0.821, 0.637, 0.808, 0.869, 1.529, 1.467, 2.369, 3.684, 0.733, 0.945, 0.925, 2.656, 1.324, 2.193, 1.662, 6.446, 4.657, 1.714, 0.549, 3.376, 1.677, 0.591, 0.78, 1.09, 0.721, 0.753, 1.199, 0.731, 2.616, 1.098, 0.678, 0.993, 0.744, 0.929, 0.798, 0.693, 1.668, 4.459, 2.942, 0.959, 0.639, 0.923, 1.757, 0.511, 0.617, 1.159, 1.68, 1.499, 1.095, 1.184, 0.762, 1.169, 0.62, 0.583, 1.527, 1.12, 2.132, 59.999, 0.744, 0.584, 1.431, 21.3, 1.239, 0.821, 0.686, 0.735, 2.25, 0.564, 0.563, 0.989, 0.737, 1.598, 2.556, 0.805, 0.792, 0.667, 1.6, 3.112, 0.75, 5.594, 0.714, 1.103, 1.241, 0.659, 0.577, 0.921, 3.981, 0.629, 0.588, 2.747, 0.55, 1.115, 0.628, 1.876, 1.282, 11.825, 3.211, 1.007, 0.515, 0.888, 2.325, 0.747, 0.68, 0.599, 0.695, 2.498, 3.938, 3.873, 2.134, 0.623, 2.136, 0.665, 0.861, 0.767, 1.141, 2.123, 1.42, 0.851, 0.704, 15.205, 0.806, 0.702, 1.914, 1.773, 0.924, 1.183, 0.613, 12.084, 2.261, 1.261, 1.152, 0.96, 0.824, 1.019, 2.509, 0.568, 1.595, 1.876, 2.04, 24.199, 7.936, 0.68, 1.072, 0.757, 1.282, 1.108, 3.452, 0.583, 0.757, 0.586, 0.653, 3.495, 3.197, 1.228, 1.727, 1.272, 1.09, 0.76, 8.132, 0.671, 7.549, 1.18, 0.7, 1.071, 1.585, 0.652, 4.489, 3.492, 2.15, 0.723, 0.949, 4.542, 1.41, 0.684, 1.338, 15.98, 0.514, 1.16, 0.681, 2.381, 0.564, 1.245, 0.711, 2.242, 1.548, 3.096, 0.602, 1.469, 1.174, 0.983, 1.301, 8.012, 0.556, 0.614, 0.619, 1.685, 1.053, 21.403, 2.228, 0.565, 0.567, 0.722, 1.144, 0.616, 1.144, 7.914, 2.96, 1.242, 2.278, 1.58, 0.71, 0.977, 17.782, 0.721, 0.884, 3.831, 3.376, 1.45, 1.091, 1.065, 1.362, 1.93, 0.49, 47.488, 1.845, 15.818, 0.594, 2.634, 0.726, 6.334, 1.672, 0.706, 1.235, 1.738, 10.104, 0.979, 1.997, 2.128, 0.646, 2.849, 0.635, 0.878, 4.74, 0.829, 2.359, 1.207, 2.839, 5.944, 0.555, 1.601, 5.815, 4.01, 2.384, 0.607, 2.567, 0.709, 1.013, 1.68, 0.611, 0.828, 0.619, 0.866, 1.779, 0.837, 0.672, 2.741, 3.258, 2.935, 0.574, 2.321, 20.659, 1.067, 0.746, 0.824, 0.755, 0.602, 0.962, 1.152, 0.859, 0.696, 0.749, 24.285, 2.569, 1.174, 4.81, 1.216, 0.734, 3.929, 1.28, 1.016, 1.085, 0.925, 1.708, 1.134, 0.767, 1.578, 0.638, 3.27, 0.89, 0.703, 0.706, 6.818, 0.794, 9.353, 2.949, 4.574, 0.59, 8.245, 1.419, 0.565, 0.82, 0.79, 0.597, 0.682, 0.792, 0.866, 1.015, 0.888, 1.517, 0.571, 0.728, 2.312, 0.839, 1.312, 0.664, 1.261, 0.927, 10.601, 0.765, 0.58, 1.259, 0.664, 1.013, 0.78, 167.638, 1.493, 0.688, 1.513, 0.695, 1.643, 0.782, 1.315, 5.076, 1.046, 15.028, 0.749, 5.811, 0.765, 2.745, 2.11, 0.733, 1.495, 65.501, 1.176, 87.826, 2.658, 0.625, 1.321, 1.545, 0.905, 1.018, 2.756, 1.309, 0.978, 0.963, 3.076, 0.931, 0.728, 0.632, 0.73, 1.297, 0.77, 1.589, 1.105, 1.138, 1.79, 2.354, 0.655, 1.016, 0.676, 3.506, 1.124, 0.81, 0.584, 3.107, 0.998, 14.506, 2.316, 2.221, 1.655, 3.9, 3.552, 1.332, 0.626, 5.692, 1.276, 7.424, 0.759, 1.102, 0.963, 0.56, 0.809, 0.77, 1.178, 1.046, 2.491, 1.785, 1.095, 3.236, 0.614, 1.215, 1.251, 13.29, 0.59, 34.453, 1.484, 1.616, 0.827, 1.237, 15.086, 0.652, 0.868, 0.985, 0.649, 0.678, 1.441, 0.951, 4.044, 0.691, 5.842, 0.921, 0.892, 0.935, 0.76, 1.321, 0.684, 1.439, 0.801, 1.007, 0.605, 0.66, 1.419, 8.938, 9.567, 2.065, 12.267, 1.127, 0.836, 0.877, 0.767, 0.765, 0.811, 0.715, 3.654, 0.95, 9.183, 0.777, 0.826, 1.184, 4.624, 0.724, 0.891, 0.956, 1.511, 3.545, 2.338, 0.741, 1.134, 1.698, 5.613, 0.944, 0.801, 5.766, 0.758, 4.11, 0.617, 1.025, 2.497, 0.723, 12.042, 0.868, 0.595, 1.468, 0.749, 0.94, 1.577, 1.005, 4.465, 1.075, 1.135, 0.701, 1.199, 0.767, 1.847, 38.466, 1.046, 0.983, 0.647, 0.875, 1.087, 0.948, 0.611, 1.603, 1.624, 1.264, 0.839, 0.912, 0.922, 0.741, 1.412, 22.469, 0.95, 1.097, 1.295, 0.865, 2.037, 6.875, 4.562, 0.755, 0.782, 2.581, 1.145, 1.116, 2.499, 0.836, 0.934, 0.924, 0.699, 2.091, 0.838, 1.456, 3.171, 1.605, 0.72, 1.026, 1.476, 1.711, 1.663, 0.701, 1.363, 3.326, 0.705, 1.215, 0.863, 0.634, 13.955, 3.863, 0.94, 0.869, 0.718, 0.869, 1.261, 0.948, 0.782, 0.893, 1.389, 1.113, 3.377, 1.054, 13.036, 1.023, 0.862, 2.315, 1.683, 0.929, 0.918, 0.652, 1.006, 1.098, 1.354, 1.262, 1.886, 0.752, 1.25, 1.057, 1.192, 1.347, 1.045, 2.734, 3.19, 1.014, 1.414, 0.68, 4.579, 0.757, 1.437, 2.188, 0.663, 0.64, 0.827, 0.612, 0.698, 0.58, 0.951, 6.638, 1.285, 1.249, 2.294, 0.808, 0.629, 0.703, 0.598, 1.214, 0.732, 3.65, 0.592, 1.015, 2.291, 0.744, 2.131, 2.683, 0.844, 0.942, 2.243, 0.864, 0.955, 0.963, 0.855, 1.244, 8.432, 1.082, 0.732, 1.046, 0.617, 1.003, 0.65, 7.884, 0.584, 0.834, 61.078, 1.307, 2.485, 1.549, 1.574, 0.999, 0.761, 1.345, 0.746, 15.452, 1.684, 3.803, 4.247, 0.79, 2.826, 2.454, 0.572, 1.509, 1.498, 1.466, 9.858, 0.851, 1.157, 1.788, 1.236, 0.698, 0.695, 2.284, 9.402, 0.855, 2.181, 18.223, 9.895, 1.289, 6.189, 0.671, 1.173, 0.69, 0.669, 2.284, 0.626, 1.011, 1.203, 8.401, 2.947, 1.399, 0.671, 2.904, 0.709, 0.722, 0.569, 0.53, 0.862, 1.962, 1.051, 2.043, 3.28, 3.292, 3.107, 4.004, 0.622, 3.738, 2.799, 0.552, 1.086, 0.565, 1.115, 1.148, 0.613, 1.741, 0.713, 0.696, 3.874, 2.883, 4.146, 1.155, 0.693, 0.733, 0.729, 1.324, 0.954, 0.995, 0.939, 2.304, 2.032, 0.645, 0.601, 1.512, 1.647, 2.918, 1.478, 0.652, 4.629, 0.501, 3.603, 0.894, 1.145, 1.243, 1.226, 1.757, 0.893, 165.228, 0.585, 0.575, 0.596, 3.46, 1.493, 1.749, 15.029, 0.585, 0.586, 1.668, 0.515, 3.758, 0.881, 0.916, 4.04, 14.843, 0.712, 3.085, 0.74, 1.617, 9.283, 6.491, 5.124, 1.698, 2.439, 0.765, 0.906, 0.711, 0.583, 2.485, 0.655, 1.801, 1.401, 1.256, 1.527, 2.779, 0.964, 3.279, 0.661, 1.485, 1.152, 2.467, 7.718, 0.917, 1.25, 1.437, 0.62, 0.609, 0.886, 0.88, 2.051, 1.143, 0.742, 1.975, 1.075, 1.109, 0.964, 0.809, 1.216, 0.715, 0.674, 34.621, 1.165, 1.093, 1.256, 0.608, 1.581, 0.847, 0.933, 1.302, 0.675, 0.596, 0.842, 1.888, 66.713, 0.678, 0.714, 0.652, 1.207, 0.754, 0.607, 0.621, 0.928, 2.931, 1.151, 4.572, 0.821, 4.036, 5.133, 4.146, 0.66, 1.297, 0.625, 4.46, 4.399, 1.645, 5.71, 1.555, 0.761, 0.786, 0.781, 2.389, 0.577, 0.624, 2.244, 1.378, 5.373, 1.123, 0.598, 6.646, 0.584, 10.821, 0.594, 2.404, 1.102, 1.6, 0.527, 0.569, 0.799, 0.817, 1.042, 0.684, 1.033, 1.16, 0.765, 1.833, 1.858, 9.869, 1.1, 1.112, 1.168, 0.538, 1.861, 2.413, 0.533, 0.827, 3.643, 0.895, 9.251, 9.01, 0.521, 0.917, 0.805, 1.511, 2.374, 1.349, 0.739, 1.232, 6.246, 1.014, 1.049, 1.291, 0.776, 1.439, 1.07, 9.074, 0.586, 1.053, 0.891, 1.105, 1.069, 0.88, 1.095, 2.61, 1.941, 1.109, 1.921, 0.667, 0.565, 1.957, 1.666, 0.918, 3.045, 0.892, 0.64, 8.177, 0.703, 21.982, 2.391, 1.799, 35.541, 0.9, 0.795, 1.118, 4.488, 3.182, 2.459, 2.638, 1.45, 1.267, 4.688, 1.129, 5.255, 0.936, 0.775, 0.904, 2.054, 5.272, 1.426, 0.597, 0.758, 1.143, 1.66, 0.71, 0.803, 0.831, 1.611, 0.607, 2.748, 0.575, 0.592, 0.698, 0.689, 1.955, 1.463, 2.508, 1.076, 0.888, 0.677, 0.581, 0.97, 1.098, 0.583, 4.652, 0.815, 0.741, 1.552, 1.124, 1.534, 0.577, 0.798, 1.674, 4.061, 1.53, 0.568, 0.698, 0.986, 1.088, 0.843, 1.4, 0.799, 1.093, 0.707, 1.244, 0.638, 1.019, 0.758, 2.945, 0.674, 2.298, 1.115, 1.353, 0.711, 0.763, 0.77, 2.083, 0.621, 2.162, 2.593, 0.947, 1.991, 1.508, 0.719, 1.651, 1.344, 1.997, 0.625, 0.695, 0.622, 1.483, 5.667, 1.198, 0.577, 24.052, 1.062, 1.24, 0.838, 0.702, 2.462, 0.833, 3.195, 15.917, 0.745, 1.866, 0.961, 0.865, 1.2, 0.957, 0.83, 0.913, 2.099, 0.809, 1.076, 0.68, 0.694, 0.693, 3.134, 1.512, 1.539, 1.951, 12.631, 0.861, 13.554, 5.747, 2.09, 0.591, 1.565, 14.332, 0.788, 0.691, 1.032, 0.691, 0.851, 2.067, 0.602, 1.922, 1.149, 7.855, 0.955, 2.142, 1.024, 1.032, 1.265, 0.731, 5.246, 1.717, 2.133, 0.707, 1.617, 0.798, 61.953, 0.699, 4.968, 1.459, 6.207, 2.657, 1.204, 11.963, 0.622, 0.852, 0.745, 7.179, 0.685, 2.07, 2.548, 12.029, 88.702, 1.316, 1.045, 0.719, 2.648, 51.094, 0.836, 0.695, 3.222, 0.854, 1.285, 1.539, 0.98, 0.804, 16.63, 0.839, 1.425, 0.889, 0.782, 0.824, 5.883, 2.135, 2.186, 3.927, 1.498, 1.094, 0.881, 2.928, 0.975, 0.819, 1.201, 1.311, 0.995, 0.823, 0.724, 1.973, 1.767, 0.653, 0.674, 0.601, 1.278, 19.296, 0.717, 1.14, 40.349, 1.15, 1.201, 2.367, 2.005, 8.841, 1.047, 0.987, 0.672, 0.938, 0.756, 0.724, 0.748, 1.008, 1.963, 10.495, 7.55, 1.19, 0.837, 0.97, 1.086, 0.899, 1.723, 1.593, 11.904, 1.226, 0.627, 1.485, 1.572, 4.206, 0.651, 3.856, 0.589, 1.315, 5.978, 0.663, 1.365, 0.644, 0.83, 2.817, 0.862, 0.626, 0.837, 1.078, 0.912, 0.734, 0.528, 1.067, 1.191, 0.734, 1.101, 2.428, 1.197, 7.536, 0.581, 0.681, 1.352, 0.678, 0.922, 1.629, 0.553, 11.932, 0.78, 0.996, 0.962, 1.039, 2.467, 11.637, 3.59, 0.822, 0.862, 0.652, 2.314, 0.672, 0.844, 1.867, 2.326, 0.746, 0.587, 1.027, 3.434, 0.778, 0.731, 0.991, 0.678, 0.66, 4.156, 0.714, 1.046, 0.807, 0.897, 0.678, 0.815, 1.052, 10.124, 0.992, 7.706, 0.662, 1.088, 4.699, 10.237, 0.628, 1.153, 0.964, 1.494, 1.064, 1.021, 1.674, 1.194, 0.533, 0.909, 1.134, 1.583, 0.632, 2.153, 0.949, 0.75, 0.615, 1.671, 0.635, 1.062, 0.883, 3.429, 2.085, 0.885, 4.542, 2.282, 3.033, 1.322, 2.024, 1.489, 1.004, 0.659, 174.686, 0.746, 1.432, 0.499, 0.85, 5.036, 2.01, 0.697, 0.972, 52.974, 1.684, 15.994, 1.195, 0.729, 3.646, 1.498, 2.8, 0.747, 0.604, 0.706, 2.581, 1.145, 23.634, 0.909, 0.62, 0.62, 1.731, 0.736, 1.085, 0.958, 1.069, 1.378, 1.026, 3.677, 0.595, 5.642, 2.938, 1.757, 0.814, 1.348, 1.867, 0.538, 14.418, 1.311, 2.94, 1.439, 0.801, 0.683, 1.178, 1.423, 1.847, 0.955, 1.165, 0.627, 0.726, 3.331, 0.619, 2.5, 0.578, 2.419, 1.044, 9.786, 6.591, 1.693, 0.626, 0.85, 0.636, 1.022, 1.438, 1.476, 4.088, 4.029, 0.645, 0.738, 0.886, 0.849, 34.782, 0.83, 0.865, 0.964, 0.966, 0.6, 1.18, 0.704, 1.085, 2.078, 0.817, 0.789, 1.094, 1.62, 0.731, 2.647, 0.996, 0.989, 1.545, 0.747, 1.613, 0.899, 2.406, 1.249, 2.743, 0.635, 4.44, 16.035, 1.138, 8.127, 0.674, 1.023, 1.352, 5.606, 2.935, 0.97, 1.203, 0.757, 0.823, 2.133, 9.797, 1.488, 3.315, 1.034, 1.433, 0.982, 0.647, 4.69, 0.885, 0.821, 1.104, 0.733, 3.8, 1.041, 0.981, 69.167, 0.912, 1.706, 5.385, 1.644, 5.228, 1.176, 8.261, 2.667, 0.752, 0.76, 3.867, 0.759, 0.839, 0.766, 6.112, 1.8, 1.593, 20.29, 45.189, 4.033, 1.065, 6.672, 1.916, 0.983, 2.093, 0.609, 90.233, 0.697, 3.048, 0.89, 0.736, 1.101, 1.132, 8.998, 1.139, 1.183, 1.024, 1.585, 1.175, 2.459, 0.584, 1.094, 0.747, 1.372, 9.292, 0.807, 3.354, 4.374, 1.477, 7.965, 1.288, 1.318, 1.736, 1.221, 0.655, 0.723, 0.789, 0.866, 0.681, 8.706, 1.681, 2.39, 0.979, 2.572, 3.84, 0.869, 0.635, 0.599, 0.613, 1.816, 1.404, 3.238, 1.658, 1.01, 1.527, 10.569, 1.622, 0.703, 2.408, 1.085, 9.358, 1.697, 1.288, 5.676, 1.289, 2.77, 0.646, 1.048, 0.632, 1.967, 0.651, 0.72, 0.858, 1.001, 0.915, 0.663, 2.096, 0.756, 0.733, 1.013, 0.756, 13.503, 1.998, 2.493, 1.039, 2.458, 0.628, 0.574, 4.688, 0.637, 1.112, 0.655, 1.324, 0.695, 0.815, 0.682, 1.87, 1.131, 1.005, 0.903, 1.25, 0.7, 1.302, 1.07, 4.213, 0.8, 0.636, 1.025, 0.981, 0.758, 1.045, 0.58, 0.584, 1.839, 0.767, 0.632, 1.012, 1.267, 0.829, 1.204, 17.577, 1.125, 2.493, 0.898, 0.548, 22.82, 0.715, 2.212, 4.862, 0.696, 1.129, 1.884, 3.656, 1.06, 0.535, 13.354, 1.254, 0.703, 1.151, 0.737, 0.737, 0.823, 3.739, 1.205, 1.045, 0.847, 0.842, 1.705, 0.655, 1.275, 1.18, 0.781, 1.759, 1.11, 1.568, 0.825, 0.698, 0.643, 0.756, 0.709, 0.8, 0.933, 2.171, 11.378, 0.992, 0.654, 8.856, 0.928, 1.049, 26.521, 0.639, 0.926, 0.851, 2.082, 8.703, 15.466, 2.344, 2.711, 66.148, 2.463, 0.793, 0.802, 0.538, 1.752, 15.508, 4.713, 2.413, 0.698, 0.801, 0.588, 1.825, 1.489, 1.203, 0.74, 0.876, 1.506, 0.96, 0.615, 0.626, 0.682, 0.907, 1.493, 0.94, 2.043, 1.171, 0.611, 0.727, 0.655, 3.788, 0.738, 2.368, 1.376, 4.055, 1.25, 1.09, 5.628, 1.234, 4.56, 0.654, 1.653, 0.675, 6.065, 0.57, 0.853, 1.564, 0.867, 3.477, 2.447, 3.099, 2.814, 3.118, 0.991, 0.924, 3.569, 3.686, 2.919, 4.457, 1.304, 0.782, 13.643, 6.779, 3.488, 1.315, 0.654, 18.21, 8.004, 1.227, 0.739, 3.675, 0.871, 0.986, 14.292, 0.71, 0.711, 0.864, 0.652, 3.943, 0.99, 6.087, 0.608, 3.253, 1.337, 2.111, 3.136, 0.996, 0.8, 0.668, 0.788, 11.794, 1.078, 1.647, 0.843, 0.736, 0.886, 10.561, 9.321, 0.938, 0.797, 0.898, 4.187, 0.619, 4.357, 60.658, 0.833, 1.279, 8.872, 1.103, 15.861, 0.711, 47.371, 0.689, 2.606, 0.594, 1.486, 0.81, 1.558, 0.551, 0.609, 0.71, 14.291, 2.523, 0.733, 2.082, 0.961, 3.278, 0.915, 0.767, 3.244, 0.931, 2.316, 0.574, 1.752, 1.549, 0.992, 0.857, 0.757, 0.783, 1.138, 0.631, 3.636, 1.188, 0.852, 1.045, 1.831, 1.937, 4.367, 2.838, 0.9, 0.621, 0.856, 0.788, 3.279, 1.576, 1.421, 3.64, 0.963, 1.864, 1.208, 2.325, 1.138, 4.181, 0.882, 1.0, 3.215, 0.845, 1.04, 1.353, 1.214, 1.299, 0.954, 1.34, 0.986, 3.082, 1.26, 0.962, 0.719, 0.535, 0.8, 0.591, 9.435, 1.408, 4.771, 0.71, 0.684, 0.892, 0.885, 2.36, 0.831, 1.313, 2.298, 0.783, 1.143, 0.885, 0.863, 1.979, 1.157, 1.912, 0.706, 2.62, 1.18, 1.007, 12.274, 34.048, 0.674, 0.823, 0.958, 170.401, 0.677, 0.53, 1.002, 1.948, 0.772, 2.097, 1.317, 15.49, 1.185, 0.944, 0.618, 2.241, 2.874, 4.659, 0.637, 3.538, 1.008, 0.905, 0.988, 0.767, 0.851, 3.117, 2.526, 5.002, 1.081, 5.694, 0.7, 1.312, 0.863, 0.606, 0.904, 0.836, 0.844, 1.947, 1.384, 2.047, 0.605, 0.679, 0.648, 11.75, 66.919, 0.944, 0.597, 1.498, 1.67, 1.037, 2.922, 8.227, 3.465, 4.654, 3.927, 9.877, 4.216, 0.822, 0.639, 1.508, 0.631, 2.199, 0.981, 1.247, 6.155, 1.419, 0.898, 3.864, 1.374, 0.768, 1.133, 0.664, 1.015, 0.967, 4.271, 1.473, 17.996, 1.769, 1.337, 26.108, 1.199, 3.312, 0.986, 16.857, 1.237, 1.308, 0.943, 1.288, 1.362, 1.515, 1.669, 0.976, 0.572, 0.822, 0.989, 1.317, 0.852, 2.823, 0.806, 11.301, 0.957, 0.839, 0.951, 1.985, 0.891, 6.638, 1.802, 1.516, 0.924, 0.924, 0.907, 0.741, 0.926, 0.827, 1.008, 2.128, 1.437, 2.889, 1.105, 3.38, 2.148, 1.099, 1.76, 0.707, 0.784, 3.165, 0.744, 0.554, 1.545, 0.687, 1.207, 1.38, 1.904, 0.806, 1.977, 0.776, 0.835, 0.896, 0.63, 7.632, 0.814, 1.094, 8.228, 1.286, 2.995, 1.065, 0.924, 0.679, 2.867, 2.655, 21.075, 0.778, 1.743, 1.12, 0.96, 1.21, 3.742, 1.097, 1.598, 3.391, 1.448, 0.994, 0.95, 2.816, 6.954, 5.971, 2.155, 1.098, 1.324, 5.88, 5.018, 8.773, 1.527, 0.842, 1.248, 5.131, 1.752, 1.403, 0.583, 1.161, 1.307, 0.885, 0.687, 1.063, 1.377, 1.085, 1.84, 2.951, 1.996, 0.702, 1.072, 0.625, 1.975, 0.985, 0.998, 1.446, 3.191, 1.336, 1.338, 1.298, 0.685, 0.879, 2.204, 1.179, 0.84, 1.247, 3.398, 0.941, 0.727, 0.909, 2.359, 0.893, 5.718, 0.64, 17.93, 0.979, 0.829, 0.716, 0.738, 1.22, 1.741, 1.404, 0.886, 0.758, 1.352, 1.39, 1.672, 0.625, 0.955, 7.456, 0.988, 0.663, 1.629, 0.615, 1.042, 1.477, 0.74, 0.972, 0.919, 0.645, 2.196, 1.152, 1.195, 90.907, 0.956, 0.567, 1.134, 0.963, 1.428, 0.852, 2.132, 6.122, 0.745, 3.626, 1.691, 2.589, 6.041, 1.378, 2.891, 0.579, 11.527, 0.955, 0.934, 1.555, 3.477, 0.954, 0.795, 0.854, 14.353, 1.422, 0.788, 3.125, 0.727, 1.824, 3.403, 1.309, 15.165, 1.488, 3.881, 2.4, 0.943, 2.447, 2.118, 1.252, 0.81, 0.95, 0.782, 0.846, 3.324, 1.347, 1.946, 1.063, 1.419, 1.171, 3.412, 1.055, 0.964, 1.783, 0.883, 3.422, 1.596, 0.799, 2.848, 0.766, 3.857, 13.893, 1.494, 7.496, 0.799, 1.092, 2.008, 1.961, 3.863, 1.047, 0.861, 4.686, 1.425, 4.894, 0.901, 1.281, 0.889, 0.958, 0.896, 10.418, 0.652, 1.182, 1.082, 0.909, 1.279, 23.429, 1.208, 1.542, 1.166, 0.774, 1.091, 1.601, 1.043, 0.987, 9.433, 1.779, 1.459, 1.11, 1.155, 52.277, 1.747, 1.106, 1.377, 2.423, 1.911, 2.425, 1.161, 0.967, 1.13, 1.345, 1.473, 0.948, 0.818, 0.958, 1.125, 1.15, 1.387, 1.79, 1.657, 0.906, 0.906, 1.01, 3.047, 1.368, 1.605, 5.44, 1.076, 10.586, 1.16, 1.441, 2.856, 1.724, 1.034, 0.948, 0.937, 1.055, 2.775, 1.007, 3.081, 0.929, 1.584, 1.593, 1.329, 1.017, 2.115, 1.035, 1.238, 11.534, 0.935, 1.829, 1.203, 2.431, 19.113, 0.834, 2.047, 0.838, 1.05, 1.236, 1.249, 1.22, 0.945, 1.082, 0.98, 1.109, 0.732, 2.151, 0.925, 1.246, 3.116, 1.405, 0.946, 1.088, 2.625, 0.796, 5.11, 1.185, 0.81, 0.689, 0.958, 0.833, 0.776, 3.013, 1.987, 5.643, 16.759, 0.848, 0.98, 22.893, 1.264, 1.049, 3.876, 4.697, 2.936, 1.033, 51.735, 3.706, 0.688, 0.795, 1.194, 1.242, 0.853, 1.15, 1.448, 0.692, 0.948, 0.981, 1.652, 1.207, 1.659, 1.112, 0.859, 2.348, 0.867, 1.193, 1.667, 0.793, 2.135, 1.209, 2.293, 0.987, 1.531, 1.031, 4.966, 1.031, 2.259, 1.156, 2.189, 1.276, 3.947, 16.92, 1.407, 1.66, 1.422, 2.037, 1.305, 3.67, 16.244, 1.443, 6.407, 2.597, 1.812, 0.746, 1.224, 1.511, 1.077, 0.82, 26.991, 2.641, 0.994, 1.73, 2.879, 9.455, 1.03, 2.177, 1.016, 5.409, 1.065, 0.911, 6.804, 1.604, 1.348, 0.924, 1.426, 0.859, 0.915, 0.905, 4.739, 0.866, 1.276, 1.047, 3.395, 1.467, 1.32, 9.483, 1.211, 70.254, 0.819, 1.327, 0.983, 1.116, 1.735, 1.201, 0.708, 1.888, 1.032, 0.825, 1.189, 1.584, 1.182, 0.825, 1.306, 1.486, 1.44, 1.816, 0.942, 19.96, 0.89, 62.498, 1.311, 0.967, 0.922, 2.068, 0.787, 4.354, 1.004, 6.473, 1.077, 1.17, 2.054, 3.028, 0.95, 9.647, 0.709, 1.506, 0.953, 1.085, 5.247, 1.221, 1.296, 13.157, 0.828, 0.913, 1.256, 0.698, 1.059, 1.983, 0.836, 1.181, 1.32, 1.356, 0.928, 1.405, 0.77, 1.05, 12.061, 18.29, 2.246, 1.01, 0.769, 6.037, 8.364, 6.857, 1.094, 1.443, 0.949, 1.703, 2.05, 1.066, 0.975, 2.794, 0.935, 1.231, 1.09, 1.362, 0.918, 1.08, 1.51, 2.106, 3.09, 8.805, 2.365, 0.986, 1.21, 2.712, 3.355, 1.031, 1.691, 2.537, 1.208, 0.982, 3.025, 2.811, 3.63, 3.285, 1.765, 1.657, 0.818, 2.077, 2.095, 1.195, 0.783, 1.196, 1.923, 2.658, 0.764, 0.939, 1.359, 4.669, 1.515, 1.889, 0.919, 2.738, 0.823, 0.965, 0.974, 1.399, 1.015, 1.166, 1.162, 11.276, 41.527, 1.927, 1.283, 1.886, 4.277, 2.42, 0.813, 1.415, 2.515, 3.927, 1.768, 3.234, 1.788, 1.282, 1.52, 0.808, 2.303, 1.148, 1.089, 26.198, 0.846, 1.793, 0.81, 0.797, 0.699, 2.077, 1.756, 1.145, 1.798, 1.106, 7.953, 0.775, 33.901, 1.113, 1.027, 1.159, 3.377, 1.012, 0.725, 0.841, 1.065, 4.044, 2.526, 1.346, 1.551, 1.442, 1.171, 1.081, 1.188, 9.115, 1.048, 11.474, 15.365, 0.904, 10.294, 1.505, 1.225, 0.988, 0.775, 1.684, 1.126, 7.53, 0.932, 3.359, 1.058, 2.358, 1.618, 1.101, 0.963, 9.447, 1.248, 0.94, 0.898, 3.383, 0.955, 1.149, 1.086, 2.646, 1.572, 1.431, 1.25, 0.877, 1.922, 2.185, 1.015, 1.048, 4.193, 0.817, 2.579, 5.64, 1.472, 0.904, 0.954, 0.766, 0.747, 1.16, 3.018, 0.836, 2.965, 1.016, 3.223, 1.623, 1.868, 2.001, 1.57, 0.818, 1.811, 1.751, 0.977, 1.216, 1.611, 1.096, 1.09, 6.194, 1.227, 1.393, 2.032, 1.169, 6.103, 1.015, 1.033, 0.82, 5.071, 4.096, 0.998, 3.656, 1.395, 1.149, 1.121, 1.652, 1.698, 3.539, 1.19, 1.837, 0.927, 0.966, 2.144, 1.119, 2.037, 2.371, 9.093, 1.964, 3.02, 8.229, 6.995, 0.781, 0.966, 0.786, 1.066, 4.831, 1.064, 1.587, 0.888, 0.855, 4.367, 1.539, 0.926, 0.959, 2.049, 14.651, 1.563, 3.504, 0.88, 1.48, 0.984, 10.537, 1.546, 13.95, 0.878, 1.123, 0.943, 0.887, 3.897, 3.05, 0.896, 0.965, 1.66, 90.202, 13.889, 3.4, 1.25, 1.2, 1.506, 7.204, 0.884, 1.236, 0.951, 7.121, 0.859, 1.453, 6.3, 1.133, 2.592, 0.96, 166.907, 7.284, 1.75, 3.142, 0.846, 1.135, 1.729, 1.934, 1.564, 0.888, 0.712, 2.452, 1.704, 2.593, 2.249, 1.478, 0.91, 3.633, 2.292, 1.241, 0.839, 1.065, 1.719, 1.619, 1.074, 1.09, 1.291, 2.862, 0.841, 1.17, 2.13, 1.024, 12.936, 5.853, 1.402, 1.267, 1.786, 0.957, 0.983, 3.576, 3.136, 0.806, 0.901, 1.606, 0.849, 1.159, 1.319, 1.426, 1.189, 0.905, 2.351, 1.005, 1.578, 0.792, 1.547, 0.903, 39.433, 3.449, 1.21, 0.792, 4.031, 1.022, 8.729, 1.415, 1.053, 1.116, 2.2, 0.84, 1.026, 0.859, 2.513, 1.003, 1.738, 1.026, 1.726, 0.921, 1.541, 1.127, 2.716, 0.936, 1.221, 1.142, 2.789, 1.026, 2.057, 0.885, 0.879, 0.828, 11.518, 0.942, 0.802, 3.696, 0.952, 2.107, 1.005, 1.539, 1.383, 0.903, 0.934, 1.29, 5.75, 1.558, 1.621, 1.067, 1.383, 0.938, 1.248, 1.87, 1.83, 1.073, 1.643, 3.047, 0.798, 0.828, 6.256, 1.119, 7.048, 1.268, 2.712, 3.174, 11.47, 8.934, 1.701, 8.305, 2.568, 0.854, 10.131, 3.411, 1.071, 0.768, 1.583, 2.176, 1.778, 67.108, 0.983, 5.22, 0.918, 0.864, 1.634, 2.071, 2.144, 1.087, 3.99, 0.828, 16.592, 1.94, 1.129, 13.626, 1.495, 1.893, 6.005, 0.861, 1.603, 1.417, 1.157, 3.077, 12.399, 1.919, 0.821, 61.201, 1.327, 1.781, 0.922, 1.324, 0.951, 2.283, 22.076, 0.992, 0.863, 1.618, 1.718, 1.88, 1.881, 1.398, 1.114, 4.77, 2.366, 1.17, 1.762, 0.885, 0.892, 7.03, 0.956, 3.101, 1.432, 1.224, 1.712, 2.933, 24.22, 2.204, 0.913, 4.774, 1.297, 1.038, 8.322, 2.915, 0.896, 18.148, 0.943, 0.768, 1.416, 1.734, 1.735, 16.259, 13.667, 2.431, 1.022, 0.772, 2.891, 1.585, 2.033, 1.092, 3.133, 2.118, 0.87, 0.855, 1.402, 0.768, 8.146, 0.886, 1.622, 0.807, 6.011, 3.014, 2.045, 4.279, 0.835, 1.447, 1.581, 2.033, 1.062, 15.052, 0.891, 1.183, 1.3, 0.785, 1.087, 5.029, 0.791, 1.358, 0.83, 2.285, 3.831, 1.015, 1.146, 2.877, 0.867, 0.866, 2.851, 1.225, 2.524, 0.989, 1.087, 0.772, 0.9, 0.943, 1.289, 1.146, 1.324, 4.703, 1.386, 0.684, 6.02, 86.689, 1.146, 2.084, 2.052, 1.542, 3.389, 0.944, 1.135, 1.068, 0.961, 1.43, 1.187, 0.771, 0.835, 0.79, 0.864, 2.579, 1.161, 3.875, 1.378, 0.797, 0.944, 1.33, 1.008, 1.749, 1.331, 9.311, 1.773, 0.748, 0.873, 1.127, 0.895, 1.213, 1.148, 1.11, 1.163, 1.803, 26.115, 1.861, 0.976, 0.772, 1.477, 4.692, 4.781, 1.368, 2.948, 0.907, 7.776, 1.021, 3.048, 1.091, 0.787, 0.892, 1.215, 16.909, 0.994, 0.87, 1.516, 0.908, 0.991, 0.952, 0.975, 2.256, 1.193, 2.224, 2.842, 1.528, 0.956, 3.089, 0.831, 0.93, 0.942, 1.159, 0.95, 1.326, 1.028, 0.986, 0.956, 1.064, 1.335, 0.938, 1.544, 1.1, 1.402, 0.822, 1.55, 0.96, 1.052, 0.899, 0.844, 1.202, 1.372, 0.795, 2.128, 3.093, 1.158, 1.037, 1.951, 1.514, 2.332, 0.821, 0.907, 1.094, 48.283, 0.927, 1.883, 1.249, 2.086, 1.12, 1.098, 2.895, 5.275, 1.036, 3.176, 5.188, 0.911, 1.178, 1.791, 0.973, 1.184, 0.766, 2.103, 6.077, 1.843, 2.26, 0.773, 8.071, 0.819, 1.858, 0.892, 1.285, 1.554, 1.336, 1.3, 2.5, 1.088, 0.932, 4.409, 4.493, 0.995, 1.225, 1.076, 0.901, 0.914, 1.282, 4.337, 1.518, 9.547, 0.934, 5.616, 3.106, 1.546, 3.238, 0.846, 2.398, 1.205, 0.864, 2.456, 4.061, 8.711, 1.095, 2.051, 1.333, 0.858, 0.79, 1.51, 4.568, 0.96, 0.921, 1.039, 1.089, 0.875, 2.887, 0.808, 1.643, 1.082, 0.897, 2.815, 1.539, 1.156, 1.163, 0.897, 1.073, 2.25, 0.783, 1.345, 14.987, 1.643, 1.319, 0.682, 0.818, 0.985, 1.086, 0.911, 0.963, 10.294, 0.893, 1.037, 35.111, 3.367, 10.543, 3.106, 1.675, 1.089, 2.157, 1.539, 1.468, 2.194, 4.905, 1.378, 0.873, 0.948, 0.941, 0.87, 3.802, 4.614, 1.598, 3.661, 1.238, 1.289, 2.449, 1.915, 30.267, 1.913, 1.947, 0.913, 0.854, 0.829, 1.209, 3.888, 1.662, 1.409, 4.19, 0.833, 0.864, 1.566, 2.138, 0.877, 1.282, 177.037, 0.776, 1.143, 1.92, 0.898, 1.002, 0.734, 1.044, 7.092, 0.727, 1.041, 2.12, 0.873, 1.402, 0.834, 1.62, 0.842, 15.558, 0.788, 6.164, 1.082, 0.826, 1.819, 0.788
    #         ]
    #     ],
    #     [
    #         [
    #             112.414, 135.002, 105.872, 111.72, 127.856, 118.045, 113.549, 107.024, 128.608, 125.919, 109.192, 154.941, 119.524, 288.725, 120.503, 126.601, 139.209, 232.746, 135.731, 128.051, 130.959, 138.168, 150.742, 138.76, 120.665, 122.741, 169.16, 132.617, 134.173, 129.845, 161.323, 163.462, 122.548, 124.594, 143.959, 209.3, 141.873, 139.619, 207.099, 131.979, 132.694, 146.181, 171.041, 134.188, 134.473, 127.968, 130.124, 142.675, 179.764, 154.399, 107.983, 112.658, 148.953, 171.709, 121.611, 120.297, 121.917, 125.255, 142.637, 247.78, 111.238, 142.395, 121.213, 119.399, 116.533, 130.011, 152.573, 132.452, 124.489, 180.237, 128.828, 120.003, 130.079, 204.569, 118.428, 101.598, 162.897, 112.591, 122.438, 122.112, 112.675, 104.06, 108.114, 132.817, 112.93, 119.014, 126.356, 144.908, 122.499, 107.566, 130.299, 112.421, 121.185, 107.129, 109.845, 101.701, 136.393, 304.223, 150.807, 126.549, 148.971, 117.068, 119.27, 123.099, 202.073, 141.549, 118.665, 116.873, 142.121, 130.366, 126.698, 138.739, 177.832, 115.876, 151.748, 124.96, 314.654, 126.956, 252.429, 134.637, 126.778, 187.869, 126.397, 129.8, 130.515, 149.619, 118.327, 132.382, 115.515
    #         ], 
    #         [
    #             2.449, 9.088, 1.809, 3.406, 9.288, 5.848, 6.129, 3.074, 6.388, 5.601, 1.906, 12.846, 3.66, 38.592, 4.75, 3.298, 5.829, 32.836, 4.36, 3.216, 1.68, 2.403, 8.327, 6.298, 3.812, 4.476, 9.991, 3.326, 4.487, 2.655, 7.513, 11.18, 2.342, 2.798, 5.208, 15.652, 6.842, 8.461, 14.58, 2.835, 2.872, 8.03, 7.009, 3.669, 3.668, 3.464, 3.032, 7.569, 17.358, 5.388, 1.87, 2.639, 8.65, 15.946, 5.003, 2.804, 3.74, 4.103, 11.794, 33.338, 2.657, 3.427, 2.706, 2.441, 2.632, 4.581, 5.043, 4.914, 4.01, 18.994, 5.253, 3.336, 5.087, 25.408, 5.963, 1.865, 16.351, 4.31, 6.016, 3.242, 3.393, 2.522, 1.783, 5.542, 3.581, 5.522, 5.702, 11.346, 5.947, 2.467, 6.513, 3.381, 7.081, 2.038, 3.51, 2.408, 6.214, 37.111, 5.623, 2.765, 15.843, 8.247, 7.776, 6.955, 18.236, 7.688, 7.943, 8.686, 11.892, 9.124, 7.641, 7.175, 21.381, 7.576, 8.083, 7.543, 53.417, 6.273, 40.203, 9.331, 6.565, 18.581, 6.989, 10.701, 6.878, 10.143, 5.775, 6.168, 6.119, 9.032, 13.12, 8.032, 5.557, 5.852, 10.678, 5.61, 8.156, 5.738, 5.248, 6.235, 22.791, 6.196, 4.855, 4.506, 5.833, 5.267, 6.483, 6.14, 9.435, 5.234, 10.698, 9.492, 12.933, 9.152, 17.292, 13.321, 9.705, 29.352, 11.867, 10.571, 10.418, 15.493, 17.011, 7.974, 9.86, 14.942, 10.474, 13.886, 68.038, 29.418, 34.223, 8.497, 11.837, 15.35, 11.36, 14.44, 21.654, 9.442, 10.023, 14.365, 12.738, 10.232, 10.177, 11.296, 18.366, 14.894, 11.745, 7.786, 8.54, 11.441, 10.853, 7.873, 11.088, 10.423, 12.392, 9.832, 10.9, 31.016, 12.784, 11.784, 17.86, 8.951, 7.266, 9.598, 9.105, 8.601, 9.864, 58.458, 10.119, 12.567, 11.837, 10.889, 9.731, 18.715, 7.194, 26.204, 12.497, 9.773, 12.292, 7.275, 8.96, 11.836, 8.467, 9.349, 8.486, 17.486, 9.051, 9.336, 10.592, 8.119, 7.883, 11.528, 9.491, 7.903, 8.998, 22.251, 8.518, 13.203, 16.401, 10.089, 25.006, 15.339, 52.148, 14.423, 11.349, 13.925, 28.786, 11.714, 12.821, 10.532, 10.54, 8.36, 12.052, 12.85, 11.043, 11.019, 11.646, 6.927, 7.168, 8.272, 54.382, 23.666, 15.727, 9.667, 11.375, 9.399, 10.821, 19.129, 7.478, 8.813, 19.257, 21.048, 9.4, 25.707, 9.082, 46.405, 9.157, 11.5, 9.526, 12.836, 14.05, 17.644, 8.001, 11.372, 8.815, 11.631, 7.762, 12.324, 11.214, 8.245, 7.776, 10.268, 23.889, 27.835, 9.667, 8.561, 9.098, 17.46, 8.428, 12.404, 17.825, 10.68, 13.737, 26.636, 18.048, 12.161, 14.282, 13.971, 16.738, 8.755, 7.545, 10.959, 10.832, 78.275, 14.027, 8.799, 11.906, 10.422, 42.791, 11.303, 9.146, 24.412, 9.112, 12.123, 10.156, 7.706, 7.775, 9.994, 17.108, 8.028, 12.055, 8.631, 8.526, 7.751, 8.706, 12.275, 10.436, 31.819, 10.194, 10.54, 13.281, 13.96, 16.255, 14.491, 11.655, 9.276, 13.829, 23.148, 8.671, 7.454, 9.156, 10.524, 9.216, 10.782, 7.104, 8.573, 21.146, 17.992, 7.154, 7.9, 10.672, 10.145, 13.321, 14.613, 11.567, 21.907, 7.96, 33.187, 12.491, 14.905, 9.409, 14.766, 10.987, 9.498, 8.624, 9.764, 8.332, 8.735, 15.397, 12.802, 8.173, 20.669, 9.858, 12.25, 10.398, 7.553, 10.738, 8.349, 8.697, 8.984, 10.134, 9.063, 11.902, 9.584, 9.795, 30.2, 9.171, 39.808, 8.459, 11.448, 10.025, 8.82, 7.892, 16.361, 7.746, 8.632, 9.583, 8.146, 8.15, 11.024, 21.734, 10.167, 10.043, 19.422, 11.197, 8.191, 12.624, 12.706, 8.592, 9.766, 10.086, 8.55, 7.957, 24.819, 8.095, 8.563, 11.158, 11.68, 8.365, 9.551, 7.718, 7.511, 7.485, 7.65, 15.498, 8.083, 8.178, 10.885, 10.26, 9.655, 9.346, 7.894, 9.503, 15.332, 8.473, 12.212, 8.556, 39.597, 8.392, 9.475
    #         ]
    #     ],
    #     [
    #         [
    #             156.833, 123.73, 148.495, 130.42, 142.9, 168.849, 309.422, 139.512, 235.728, 140.851, 114.624, 155.362, 123.58, 177.875, 139.333, 195.429, 126.705, 232.287, 166.327, 215.54, 158.47, 171.109, 138.52, 156.678, 213.697, 121.955, 224.506, 141.009, 149.582, 292.605, 130.428, 132.726, 142.007, 169.184, 208.142, 143.251, 250.238, 133.048, 191.627, 157.809, 135.828, 154.3, 147.159, 179.575, 154.151, 161.92, 144.652, 153.614, 364.714, 178.555, 178.625, 142.473, 233.628, 127.845, 166.165, 149.526, 182.741, 135.405, 301.641, 241.258, 181.24, 132.182, 154.905, 120.695, 141.192, 156.958, 126.195, 144.384, 126.822, 117.302, 211.042, 135.896, 151.307, 166.32, 170.789, 141.844, 148.622, 175.625, 214.303, 157.978, 153.438, 161.078, 154.002, 127.215, 436.239, 243.825, 156.721, 156.119, 188.91, 157.128, 159.919, 146.364, 196.151, 144.206, 148.28, 146.919, 134.443, 138.664
    #         ], 
    #         [
    #             11.626, 6.631, 10.366, 8.579, 7.0, 14.402, 45.188, 5.683, 24.882, 9.621, 4.291, 9.069, 3.219, 13.833, 5.093, 12.399, 2.821, 21.232, 12.615, 23.862, 10.199, 7.215, 4.0, 6.224, 12.888, 4.33, 26.677, 6.623, 9.014, 43.13, 3.361, 3.998, 7.748, 14.702, 26.391, 5.318, 26.387, 4.6, 14.339, 6.925, 4.072, 6.9, 5.468, 10.593, 6.074, 6.819, 9.403, 5.166, 57.873, 8.847, 20.616, 8.328, 22.659, 7.027, 13.466, 15.333, 24.46, 11.623, 77.301, 50.537, 26.396, 12.381, 13.246, 10.554, 9.556, 14.636, 9.833, 13.356, 9.662, 7.33, 35.96, 8.472, 8.617, 10.78, 13.899, 9.883, 15.192, 17.701, 32.353, 14.093, 14.63, 21.282, 13.146, 8.993, 90.958, 40.464, 15.535, 14.348, 22.399, 12.44, 15.219, 11.412, 28.114, 12.674, 13.53, 15.051, 9.309, 12.656, 35.942, 18.818, 20.86, 9.558, 8.976, 60.812, 21.535, 12.299, 22.519, 35.97, 15.638, 15.639, 16.369, 14.108, 27.455, 13.926, 13.152, 10.72, 10.871, 22.41, 15.775, 18.652, 52.434, 66.203, 10.159, 36.181, 15.838, 14.247, 12.182, 12.151, 11.585, 8.528, 68.083, 20.151, 15.952, 16.668, 10.324, 19.562, 29.931, 59.724, 11.312, 12.237, 12.819, 13.749, 7.905, 19.812, 13.496, 12.598, 41.8, 10.083, 11.009, 16.133, 14.505, 44.063, 25.633, 8.528, 9.103, 11.381, 72.426, 11.711, 10.027, 32.931, 17.132, 13.193, 13.443, 12.919, 12.894, 10.934, 9.009, 12.337, 24.933, 10.884, 14.809, 10.9, 11.024, 22.775, 7.431, 10.77, 13.44, 9.883, 31.329, 8.344, 16.041, 16.256, 27.638, 26.26, 14.85, 11.401, 10.329, 10.556, 13.869, 30.027, 15.909, 20.065, 19.285, 8.155, 8.947, 12.118, 17.583, 71.602, 54.683, 11.211, 12.253, 24.831, 9.374, 9.287, 13.556, 35.358, 28.987, 21.32, 22.361, 13.429, 14.617, 39.877, 8.079, 19.99, 14.307, 11.052, 8.54, 22.939, 16.234, 17.197, 12.454, 28.862, 26.47, 76.514, 12.56
    #         ]
    #     ],
    #     [
    #         [
    #             240.482, 227.767, 415.361, 308.528, 205.624, 227.19, 260.956, 379.287, 253.252, 285.451, 306.57, 360.98, 183.18, 317.597, 339.497, 280.78, 231.121, 283.315, 243.889, 462.413, 355.562, 280.387, 314.534, 553.762, 290.776, 239.212, 239.562, 194.68, 280.73, 250.186, 240.676, 310.115, 231.9, 470.472, 333.5, 291.727, 276.499, 244.01, 213.894, 318.362, 265.952, 449.245, 240.349, 312.345, 234.361, 278.624, 195.387, 290.487, 493.421, 297.336, 219.82, 216.685, 510.544, 238.699, 340.614, 381.53, 214.773, 229.728, 319.557, 246.642, 397.508, 204.324, 430.094, 328.584, 273.703, 233.429, 229.822, 343.981, 266.003, 290.178, 230.023, 299.526, 287.672, 403.771, 253.417, 296.33, 298.168, 206.393, 271.835, 538.219, 269.498, 251.199, 439.25, 282.531, 286.58, 233.57, 223.023, 223.604, 236.625, 421.695, 304.127, 430.647, 231.929, 221.791, 253.881, 329.325, 252.862, 495.507, 291.716, 220.44
    #         ], 
    #         [
    #             26.552, 17.744, 69.281, 42.408, 12.933, 16.628, 20.637, 38.093, 27.074, 39.611, 35.879, 57.607, 11.639, 44.153, 37.0, 22.546, 16.708, 27.942, 14.882, 60.832, 59.056, 27.964, 41.735, 67.142, 25.087, 16.427, 20.029, 13.022, 30.369, 35.945, 41.826, 45.393, 26.284, 78.984, 44.725, 37.035, 31.546, 30.108, 20.909, 52.755, 25.871, 72.972, 21.651, 38.862, 15.692, 24.723, 11.364, 25.355, 69.69, 36.474, 17.667, 15.117, 74.491, 23.754, 44.939, 47.312, 18.155, 17.88, 43.723, 23.701, 43.499, 14.42, 55.774, 29.638, 28.661, 18.827, 16.642, 36.233, 24.09, 29.536, 18.821, 31.214, 25.63, 56.387, 19.309, 32.107, 35.911, 13.402, 26.573, 88.096, 27.947, 19.631, 45.154, 32.803, 33.253, 19.537, 19.626, 16.859, 23.411, 79.672
    #         ]
    #     ],
    #     [
    #         [
    #             2408.222, 2412.166, 2421.783, 2394.005, 2315.384, 2342.905, 2335.557, 2351.777, 2321.749, 2332.322
    #         ], 
    #         [
    #             1028.948, 1033.743
    #         ]
    #     ]
    # ]

    # preprocessing_times = [
    #     [[5.218836/1000, 5.218836/1000], [7e-06, 7e-06]],  # No preprocessing time for the first six categories
    #     [[5.218836/1000, 5.218836/1000], [7e-06, 7e-06]]
    # ]

    # labels = ["(Filter=25)", "(No Filter)"]
    # xs_label = ["3", "6", "60\n(Decomposed Structured Model)", "120", "300", "3000\n(DeltaSherlock)", "3\n(Praxi)", "3000\n(Praxi)"]

    # # Setup figure and subplots
    # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    # bar_width = 0.3

    # # Function to plot bars
    # def plot_bars(ax, indices, xs_label_subset):
    #     bars = []  # List to store bar objects for legend
    #     for i in indices:
    #         for j, label in enumerate(labels):
    #             bar_position = i - bar_width/2 + j*bar_width
    #             ys = np.mean(ys_d4permodeltrainlatencybylabelspermodel_l[i][j])
    #             yerr = 1.96 * np.std(ys_d4permodeltrainlatencybylabelspermodel_l[i][j]) / np.sqrt(len(ys_d4permodeltrainlatencybylabelspermodel_l[i][j]))
    #             if i < 6:
    #                 additional_time = np.mean(encoder_times[i][j])
    #                 additional_yerr = 1.96 * np.std(encoder_times[i][j]) / np.sqrt(len(encoder_times[i][j]))
    #             else:
    #                 additional_time = np.mean(preprocessing_times[i-6][j])
    #                 additional_yerr = 1.96 * np.std(preprocessing_times[i-6][j]) / np.sqrt(len(preprocessing_times[i-6][j]))

    #             training_bar = ax.bar(bar_position, ys, bar_width, color='blue' if j == 0 else 'green', label="Training "+ label if i == indices[0] else "")
    #             additional_bar = ax.bar(bar_position, additional_time, bar_width, bottom=ys, color='lightblue' if j == 0 else 'lightgreen', label=('Preprocessing ') + label if i == indices[0] else "")
    #             # Add bar labels for total time
    #             # if 100000 >= (ys + additional_time)+label_y_offset and (ys + additional_time)+label_y_offset >= 10000:
    #             if i >= 5 and 80000 >= (ys + additional_time):
    #                 label_y_offset = -1000 if j == 0 else 7000
    #                 ax.text(bar_position, (ys + additional_time)+label_y_offset, f"{ys + additional_time:.1f}", ha='center', va='bottom', fontsize=16)
    #             elif i >= 5 and (ys + additional_time) > 80000:
    #                 label_y_offset = 10000
    #                 ax.text(bar_position, (ys + additional_time)+label_y_offset, f"{ys + additional_time:.1f}", ha='center', va='bottom', fontsize=16)
    #             else:
    #                 ax.bar_label(additional_bar, labels=[f"{ys + additional_time:.1f}"], padding=3, fontsize=16)

    #             total_error = np.sqrt(yerr**2 + additional_yerr**2)
    #             ax.errorbar(bar_position, ys + additional_time, yerr=total_error, fmt='o', color='red', capsize=5)

    #             # Collect bar objects for the legend
    #             if i == indices[0]:  # Only add once
    #                 bars.append(training_bar)
    #                 bars.append(additional_bar)

    #     ax.grid()

    #     # Set labels
    #     ax.set_xticks(indices)
    #     ax.set_xticklabels(xs_label_subset, fontsize=24)
    #     ax.tick_params(axis='y', labelsize=22)
    #     return bars  # Return bars for legend

    # # Call the plot function on both subplots
    # bars1 = plot_bars(ax1, np.arange(5), xs_label[:5])
    # plot_bars(ax2, np.arange(5, 8), xs_label[5:])

    # # # Set separate y-axis limits
    # # ax1.set_ylim(0, 10)  # Adjust as necessary for your data
    # # ax2.set_ylim(0, 4000)  # Adjust as necessary for your data

    # ax1.set_ylabel("Incremental Training (s)", fontsize=28)

    # # # Adjust the overall font size which includes the exponent in scientific notation
    # # plt.rcParams['font.size'] = 30  # Adjusts global font size
    # # plt.rcParams['text.latex.preamble'] = r'\usepackage{amsmath}'  # Ensure amsmath package is used
    # formatter_upper = ScalarFormatter(useMathText=True)
    # formatter_upper.set_scientific(True)
    # formatter_upper.set_powerlimits((-1,1))  # Use scientific notation
    # ax2.yaxis.set_major_formatter(formatter_upper)
    # ax2.yaxis.get_offset_text().set_fontsize(20)

    # # Create shared legend
    # labels = [bar.get_label() for bar in bars1]  # Get labels from the bars (assumes bars1 and bars2 have same labels)
    # # fig.legend(bars1, labels, loc='upper left', ncol=1, fontsize=20, bbox_to_anchor=(0.088, 1.03))
    # fig.legend(bars1, labels, loc='upper left', ncol=1, fontsize=19, bbox_to_anchor=(0.56, 0.8))
    # # # Add structured model X label
    # # fig.text(0.5, 0.0, 'Number of Package Labels per Incremental Training Step', ha='center', va='center', fontsize=24)
    # # Add common X label
    # fig.text(0.5, -0.07, 'Number of Package Labels per Incremental Training Step', ha='center', va='center', fontsize=28)

    # fig.tight_layout(rect=[0, -0.06, 1, 1])  # Adjust rect parameter as needed

    # # plt.tight_layout()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()


# ========================================================================================================================================================
# ============================================================================test_f1score_model_token_share_by_labels_per_model_with_rawinput============
    filename = "test_f1score_model_token_share_by_labels_per_model_with_rawinput_False100filter_data_4_SL_CrossValidation"
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    xs_label = [3, 60, "3000\n(DeltaSherlock XGBoost)", "3000\n(Praxi VW)"]
    xs = list(range(len(xs_label)))
    f1_score_label = "F1-Score"
    precision_label = "Precision"
    # token_share_label = "\% of Token Considered by Multiple Sub-Model"
    token_share_label = "\% of Duplicate Features"

    # Data for F1-Score
    ys_d4f1scorebycosinesim_l = [
        [[0.927]],
        [[0.976, 0.976]],
        [[1.000, 1.000]],
        [[0.995, 0.995]]
    ]

    # Data for Precision
    ys_d4f1precisonbycosinesim_l = [
        [[0.953]],
        [[0.972, 0.971]],
        [[1.000, 1.000]],
        [[0.995, 0.995]]
    ]

    # Data for Token Share
    ys_d4modelsharedtokenbycosinesim_l = [
        [[0.07460207953481496]],
        [[0.07408465973488396, 0.07413120014016875]],
        [[0, 0]],
        [[0, 0]]
    ]

    # Calculate means and confidence intervals for F1-Score
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1scorebycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1scorebycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1scorebycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1scorebycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot F1-Score
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=f1_score_label, marker="^", markersize=10)

    # Calculate means and confidence intervals for Precision
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1precisonbycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1precisonbycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1precisonbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1precisonbycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot Precision
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=precision_label, marker="*", markersize=10)

    # Calculate means and confidence intervals for Token Share
    ys_array_ts, ci_array_ts = [], []
    for m_i in range(len(ys_d4modelsharedtokenbycosinesim_l)):
        ys_array_ts.append(np.mean(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=(1)))
        ci_array_ts.append(1.96 * np.std(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4modelsharedtokenbycosinesim_l[m_i][0])))
    ys_array_ts = np.array(ys_array_ts).T
    ci_array_ts = np.array(ci_array_ts).T

    # Plot Token Share on secondary y-axis
    ax2 = ax.twinx()
    for ys, ci in zip(ys_array_ts, ci_array_ts):
        ax2.errorbar(xs, [100*y for y in ys], yerr=ci, fmt='o', capsize=10, label=token_share_label, marker="v", markersize=10, color='r')

    # Styling and labeling
    ax.set_xlabel("Package Labels per Incremental Training Step", fontsize=24)
    ax.set_xticks(xs)
    ax.set_xticklabels(xs_label, fontsize=20)
    ax.set_ylabel("Model Metrics", fontsize=24, color='b')
    ax.tick_params(axis='y', labelsize=20, labelcolor='b')
    ax2.set_ylabel("Feature \%", fontsize=24, color='r')
    ax2.tick_params(axis='y', labelsize=20, labelcolor='r')
    ax2.set_ylim(6.9, 7.5)
    ax.grid(True)
    # ax2.grid(True)

    # Adding legends
    ax.legend(title="Metric", title_fontsize=18, fontsize=18, loc="center left", bbox_to_anchor=(0.05, 0.5))
    ax2.legend(fontsize=18, loc="lower right")

    fig.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter as needed

    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()


# -----------------------------------------
    filename = "test_f1score_model_token_share_by_labels_per_model_with_rawinput_False100filter_data_4"
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    xs_label = [3, 6, 60, 120, 300, "3000(DeltaSherlock)"]
    xs = list(range(len(xs_label)))
    xs[-1] += 0.05
    f1_score_label = "F1-Score"
    precision_label = "Precision"
    # token_share_label = "\% of Token Considered by Multiple Sub-Model"
    token_share_label = "\% of Duplicate Features"

    # Data for F1-Score
    ys_d4f1scorebycosinesim_l = [
        [[0.751, 0.751, 0.751, 0.751, 0.751]],
        [[0.787, 0.798, 0.81, 0.798, 0.804, 0.797, 0.804, 0.78]],

        [[0.847, 0.847, 0.843, 0.85, 0.842, 0.847, 0.852, 0.849, 0.84]],
        [[0.849, 0.853, 0.845, 0.85, 0.856, 0.854, 0.85, 0.851, 0.857]],
        [[0.86, 0.85, 0.865, 0.858, 0.865, 0.866, 0.851, 0.852, 0.855]],
        [[0.867, 0.859]]
    ]

    # Data for Precision
    ys_d4f1precisonbycosinesim_l = [
        [[0.728, 0.728, 0.728, 0.728, 0.728]],
        [[0.765, 0.774, 0.787, 0.774, 0.781, 0.773, 0.78, 0.759]],
        [[0.822, 0.822, 0.818, 0.823, 0.815, 0.821, 0.828, 0.824, 0.814]],
        [[0.822, 0.829, 0.819, 0.825, 0.832, 0.829, 0.825, 0.827, 0.833]],
        [[0.843, 0.834, 0.84, 0.835, 0.84, 0.841, 0.833, 0.84, 0.83]],
        [[0.858, 0.85]]
    ]

    # Data for Token Share
    ys_d4modelsharedtokenbycosinesim_l = [
        [[0.07460207953481496, 0.07460207953481496, 0.07460207953481496, 0.07460207953481496, 0.07460207953481496]],
        [[0.07459879432973604, 0.07458127323598175, 0.0746004369322755, 0.07456703734730641, 0.07456046693714855, 0.07459988939809567, 0.07458674857777997, 0.07454568351429337, 0.07456156200550819]],
        [[0.07408465973488396, 0.07413120014016875, 0.07338764872397159, 0.07277714811347098, 0.07418595355815087, 0.0732535028499154, 0.0737342378597984, 0.07407097138038841, 0.07324693243975755]],
        [[0.07288829755197468, 0.07312099957839868, 0.07273225031072565, 0.07183976959761713, 0.0735376730892426, 0.07224275475396552, 0.07310183588210493, 0.07241249034971008, 0.07239277911923651]],
        [[0.0710995033864989, 0.069023253776617, 0.07085420807393901, 0.06938681647201826, 0.06944156989000039, 0.06893729091038509, 0.07039811210214798, 0.07146635128697909, 0.07046326866954669]],
        [[0, 0]]
    ]

    # Calculate means and confidence intervals for F1-Score
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1scorebycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1scorebycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1scorebycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1scorebycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot F1-Score
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=f1_score_label, marker="^", markersize=10)

    # Calculate means and confidence intervals for Precision
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1precisonbycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1precisonbycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1precisonbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1precisonbycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot Precision
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=precision_label, marker="*", markersize=10)

    # Calculate means and confidence intervals for Token Share
    ys_array_ts, ci_array_ts = [], []
    for m_i in range(len(ys_d4modelsharedtokenbycosinesim_l)):
        ys_array_ts.append(np.mean(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=(1)))
        ci_array_ts.append(1.96 * np.std(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4modelsharedtokenbycosinesim_l[m_i][0])))
    ys_array_ts = np.array(ys_array_ts).T
    ci_array_ts = np.array(ci_array_ts).T

    # Plot Token Share on secondary y-axis
    ax2 = ax.twinx()
    for ys, ci in zip(ys_array_ts, ci_array_ts):
        ax2.errorbar(xs, [100*y for y in ys], yerr=ci, fmt='o', capsize=10, label=token_share_label, marker="v", markersize=10, color='r')

    # Styling and labeling
    ax.set_xlabel("Package Labels per Sub-Models", fontsize=24)
    ax.set_xticks(xs)
    ax.set_xticklabels(xs_label, fontsize=20)
    ax.set_ylabel("Model Metrics", fontsize=24, color='b')
    ax.tick_params(axis='y', labelsize=20, labelcolor='b')
    ax2.set_ylabel("Feature \%", fontsize=24, color='r')
    ax2.tick_params(axis='y', labelsize=20, labelcolor='r')
    ax2.set_ylim(6.9, 7.5)
    ax.grid(True)
    # ax2.grid(True)

    # Adding legends
    ax.legend(title="Metric", title_fontsize=18, fontsize=18, loc="lower center", bbox_to_anchor=(0.40, -0.05))
    ax2.legend(fontsize=18, loc="center right", bbox_to_anchor=(1, 0.4))

    fig.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter as needed

    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()




# -----------------------------------------
    filename = "test_f1score_model_token_share_by_labels_per_model_with_rawinput_True25filter_data_4"
    fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    xs_label = [3, 6, 60, 120, 300, "3000(DeltaSherlock)"]
    xs = list(range(len(xs_label)))
    xs[-1] += 0.05
    f1_score_label = "F1-Score"
    precision_label = "Precision"
    # token_share_label = "\% of Token Considered by Multiple Sub-Model"
    token_share_label = "\% of Duplicate Features"

    # Data for F1-Score
    ys_d4f1scorebycosinesim_l = [
        [[0.815, 0.815]],
        [[0.856, 0.857, 0.856, 0.858, 0.856]],
        [[0.87]],
        [[0.868, 0.858]],
        [[0.871, 0.864]],
        [[0.864]]
    ]

    # Data for Precision
    ys_d4f1precisonbycosinesim_l = [
        [[0.793, 0.793]],
        [[0.83, 0.831, 0.829, 0.832, 0.83]],
        [[0.845]],
        [[0.841, 0.832]],
        [[0.846, 0.838]],
        [[0.842]]
    ]

    # Data for Token Share
    ys_d4modelsharedtokenbycosinesim_l = [
        [[0.06902090479288275, 0.06902090479288275, 0.06902090479288275]],
        [[0.06901759977437741, 0.06899997300901554, 0.06901925228363008, 0.06898565126215903, 0.06897904122514832]],
        [[0.06850036437829021]],
        [[0.06729678680592546, 0.06753089228338771]],
        [[0.06549720422976268, 0.06340843253438183]],
        [[0]]
    ]

    # Calculate means and confidence intervals for F1-Score
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1scorebycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1scorebycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1scorebycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1scorebycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot F1-Score
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=f1_score_label, marker="^", markersize=10)

    # Calculate means and confidence intervals for Precision
    ys_array_f1, ci_array_f1 = [], []
    for m_i in range(len(ys_d4f1precisonbycosinesim_l)):
        ys_array_f1.append(np.mean(ys_d4f1precisonbycosinesim_l[m_i], axis=(1)))
        ci_array_f1.append(1.96 * np.std(ys_d4f1precisonbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1precisonbycosinesim_l[m_i][0])))
    ys_array_f1 = np.array(ys_array_f1).T
    ci_array_f1 = np.array(ci_array_f1).T

    # Plot Precision
    for ys, ci in zip(ys_array_f1, ci_array_f1):
        ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=precision_label, marker="*", markersize=10)

    # Calculate means and confidence intervals for Token Share
    ys_array_ts, ci_array_ts = [], []
    for m_i in range(len(ys_d4modelsharedtokenbycosinesim_l)):
        ys_array_ts.append(np.mean(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=(1)))
        ci_array_ts.append(1.96 * np.std(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4modelsharedtokenbycosinesim_l[m_i][0])))
    ys_array_ts = np.array(ys_array_ts).T
    ci_array_ts = np.array(ci_array_ts).T

    # Plot Token Share on secondary y-axis
    ax2 = ax.twinx()
    for ys, ci in zip(ys_array_ts, ci_array_ts):
        ax2.errorbar(xs, [100*y for y in ys], yerr=ci, fmt='o', capsize=10, label=token_share_label, marker="v", markersize=10, color='r')

    # Styling and labeling
    ax.set_xlabel("Package Labels per Sub-Models", fontsize=24)
    ax.set_xticks(xs)
    ax.set_xticklabels(xs_label, fontsize=20)
    ax.set_ylabel("Model Metrics", fontsize=24, color='b')
    ax.tick_params(axis='y', labelsize=20, labelcolor='b')
    ax2.set_ylabel("Feature \%", fontsize=24, color='r')
    ax2.tick_params(axis='y', labelsize=20, labelcolor='r')
    ax2.set_ylim(6.25, 7.0)
    ax.grid(True)
    # ax2.grid(True)

    # Adding legends
    ax.legend(title="Metric", title_fontsize=18, fontsize=18, loc="lower center", bbox_to_anchor=(0.40, -0.05))
    ax2.legend(fontsize=18, loc="lower right", bbox_to_anchor=(1, -0.05))

    fig.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter as needed

    plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    plt.close()







# ========================================================================================================================================================
# ============================================================================per_model_inferencelatency_by_labels_per_model_with_rawinput_data_4=========
    # filename = "per_model_inferencelatency_by_labels_per_model_with_rawinput_data_4_Chameleon"
    # fig, ax = plt.subplots(1, 1, figsize=(4, 3))
    # xs_label = [3, 6, "3000\n(DeltaSherlock)"]
    # xs = list(range(len(xs_label)))
    # labels = ["No Filter"]
    # ys_d4permodelinferencelatencybylabelspermodel_l=[#models
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             3.08, 2.54, 2.99
    #         ]
    #     ],
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             3.5, 2.95, 3.46
    #         ]
    #     ],
    #     [
    #         [
    #             10.07, 9.4
    #         ]
    #     ],
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4permodelinferencelatencybylabelspermodel_l)):
    #     local_ys_array, local_ci_array = [], []
    #     for f_i in range(len(ys_d4permodelinferencelatencybylabelspermodel_l[m_i])):
    #         local_ys_array.append(np.mean(ys_d4permodelinferencelatencybylabelspermodel_l[m_i][f_i], axis=(0)))
    #         local_ci_array.append(1.96 * np.std(ys_d4permodelinferencelatencybylabelspermodel_l[m_i][f_i], axis=0)/np.sqrt(len(ys_d4permodelinferencelatencybylabelspermodel_l[m_i][f_i])))
    #     ys_array.append(local_ys_array)
    #     ci_array.append(local_ci_array)
    # ys_array = np.array(ys_array).T
    # ci_array = np.array(ci_array).T
    # for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
    # ax.set_xticks(xs)
    # ax.set_xticklabels(xs_label, fontsize=18)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
    # # ax.set_ylim(0.3,1)
    # # ax.set_xscale('log')
    # # ax.set_yscale("log")
    # ax.set_ylabel("Inference Time (s)", fontsize=20)
    # ax.grid()
    # # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # # -----------------------------------------
    # filename = "per_model_inferencelatency_by_labels_per_model_with_rawinput_data_4_NERC"
    # fig, ax = plt.subplots(1, 1, figsize=(4, 3))
    # xs_label = [3, "3000\n(DeltaSherlock)"]
    # xs = list(range(len(xs_label)))
    # labels = ["No Filter"]
    # ys_d4permodelinferencelatencybylabelspermodel_l=[#models
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             50, 55, 60
    #         ]
    #     ],
    #     [
    #         [
    #             33, 43, 40
    #         ]
    #     ],
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4permodelinferencelatencybylabelspermodel_l)):
    #     local_ys_array, local_ci_array = [], []
    #     for f_i in range(len(ys_d4permodelinferencelatencybylabelspermodel_l[m_i])):
    #         local_ys_array.append(np.mean(ys_d4permodelinferencelatencybylabelspermodel_l[m_i][f_i], axis=(0)))
    #         local_ci_array.append(1.96 * np.std(ys_d4permodelinferencelatencybylabelspermodel_l[m_i][f_i], axis=0)/np.sqrt(len(ys_d4permodelinferencelatencybylabelspermodel_l[m_i][f_i])))
    #     ys_array.append(local_ys_array)
    #     ci_array.append(local_ci_array)
    # ys_array = np.array(ys_array).T
    # ci_array = np.array(ci_array).T
    # for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
    # ax.set_xticks(xs)
    # ax.set_xticklabels(xs_label, fontsize=18)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
    # # ax.set_ylim(0.3,1)
    # # ax.set_xscale('log')
    # # ax.set_yscale("log")
    # ax.set_ylabel("Inference Time (s)", fontsize=20)
    # ax.grid()
    # # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # -----------------------------------------
    filename = "total_inference_time_by_labels_per_model_with_rawinput_True25filter_96sample_data_4"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[15.764593124389648, 13.836970090866089, 13.477382898330688, 12.042516231536865, 14.005075216293335]]
    total_clf_load_time_set1 = [[7.224096298217773, 7.03323769569397, 7.505751132965088, 9.247905731201172, 7.643913507461548]]
    total_data_load_time_set1 = [[7.02317476272583, 7.79384708404541, 7.417893171310425, 7.333470821380615, 8.649438619613647]]
    total_encoder_time_set1 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    total_inference_time_set1 = [[0.02560591697692871, 0.026439428329467773, 0.026050567626953125, 0.03408455848693848, 0.028303146362304688]]
    total_decoding_time_set1 = [[0.0019006729125976562, 0.0019347667694091797, 0.0019376277923583984, 0.002548694610595703, 0.002088785171508789]]
    total_time_set1 = [[31.954143047332764, 30.593761682510376, 30.32544779777527, 31.171023845672607, 32.44474768638611]]

    total_clf_decompressing_time_set2 = [[2.5380616188049316, 4.5007617473602295, 3.676270008087158]]
    total_clf_load_time_set2 = [[7.674092054367065, 6.740265369415283, 6.628811597824097]]
    total_data_load_time_set2 = [[9.164861679077148, 9.65386962890625, 8.21211862564087]]
    total_encoder_time_set2 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    total_inference_time_set2 = [[6.826249122619629, 7.0181725025177, 6.8797993659973145]]
    total_decoding_time_set2 = [[0.009405851364135742, 0.00936436653137207, 0.00953984260559082]]
    total_time_set2 = [[33.35287642478943, 35.00924324989319, 32.46582317352295]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [total_encoder_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [total_encoder_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange']

    # Plotting
    fig, ax = plt.subplots()
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()





# ========================================================================================================================================================
# ============================================================================detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_192sample_data_4_coo"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[14.214271068572998, 11.424229621887207, 14.370496988296509]]
    total_clf_load_time_set1 = [[7.305550813674927, 6.65357780456543, 7.137504577636719]]
    total_data_load_time_set1 = [[19.343135118484497, 16.416025638580322, 14.686767578125]]
    # total_encoder_time_set1 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    encoder_gen_mapping_time_set1 = [[0.5421335697174072, 0.5344305038452148, 0.5318853855133057]]
    encoder_get_feature_time_set1 = [[0.014863967895507812, 0.015505313873291016, 0.014655590057373047]]
    encoder_selector_time_set1 = [[0.9775185585021973, 0.9474830627441406, 0.9641199111938477]]
    encoder_mat_builder_time_set1 = [[0.0017881393432617188, 0.0018186569213867188, 0.0018553733825683594]]
    encoder_list_to_mat_time_set1 = [[0.15726447105407715, 0.1549973487854004, 0.15615391731262207]]
    total_inference_time_set1 = [[0.03154873847961426, 0.03263568878173828, 0.03185153007507324]]
    total_decoding_time_set1 = [[0.09236693382263184, 0.05791926383972168, 0.05998539924621582]]
    total_time_set1 = [[43.18622660636902, 36.7392783164978, 38.458709955215454]]

    total_clf_decompressing_time_set2 = [[2.7411389350891113, 3.6058781147003174, 2.6865200996398926]]
    total_clf_load_time_set2 = [[6.66372537612915, 6.671632766723633, 6.6716148853302]]
    total_data_load_time_set2 = [[16.06651782989502, 17.41927194595337, 18.434086084365845]]
    # total_encoder_time_set2 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    encoder_gen_mapping_time_set2 = [[0.6138122081756592, 0.6066784858703613, 0.6052720546722412]]
    encoder_get_feature_time_set2 = [[0.004528045654296875, 0.004506587982177734, 0.0046367645263671875]]
    encoder_selector_time_set2 = [[1.0821304321289062, 1.0794153213500977, 1.093968391418457]]
    encoder_mat_builder_time_set2 = [[0.1072537899017334, 0.1073305606842041, 0.11080574989318848]]
    encoder_list_to_mat_time_set2 = [[0.033544301986694336, 0.03353619575500488, 0.03954887390136719]]
    total_inference_time_set2 = [[13.857200145721436, 15.893882274627686, 14.133164882659912]]
    total_decoding_time_set2 = [[0.01883840560913086, 0.01852560043334961, 0.019051551818847656]]
    total_time_set2 = [[41.39731454849243, 45.659366846084595, 44.00324082374573]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen','cyan', 'yellow']

    # Plotting
    fig, ax = plt.subplots(1, 1, figsize=(15, 5))
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()

    # -----------------------------------------
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_96sample_data_4_coo"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[13.430506944656372, 12.69049882888794, 15.26503038406372]]
    total_clf_load_time_set1 = [[7.162744998931885, 7.937798261642456, 7.605685234069824]]
    total_data_load_time_set1 = [[8.019973516464233, 9.227576494216919, 8.07615041732788]]
    # total_encoder_time_set1 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    encoder_gen_mapping_time_set1 = [[0.5287468433380127, 0.5731692314147949, 0.558147668838501]]
    encoder_get_feature_time_set1 = [[0.014415502548217773, 0.017134428024291992, 0.015570878982543945]]
    encoder_selector_time_set1 = [[0.5390725135803223, 0.5247557163238525, 0.5774226188659668]]
    encoder_mat_builder_time_set1 = [[0.0009701251983642578, 0.0009982585906982422, 0.0010325908660888672]]
    encoder_list_to_mat_time_set1 = [[0.15552425384521484, 0.1760096549987793, 0.16386675834655762]]
    total_inference_time_set1 = [[0.025096893310546875, 0.029154300689697266, 0.02819037437438965]]
    total_decoding_time_set1 = [[0.03638482093811035, 0.03706765174865723, 0.040502309799194336]]
    total_time_set1 = [[30.277548789978027, 31.59302043914795, 32.713255167007446]]

    total_clf_decompressing_time_set2 = [[3.252439022064209, 3.385455846786499, 3.055346965789795]]
    total_clf_load_time_set2 = [[6.767310380935669, 8.262137174606323, 7.784078121185303]]
    total_data_load_time_set2 = [[9.106859683990479, 8.54998230934143, 7.889105796813965]]
    # total_encoder_time_set2 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    encoder_gen_mapping_time_set2 = [[0.591240406036377, 0.7099721431732178, 0.6318862438201904]]
    encoder_get_feature_time_set2 = [[0.004441022872924805, 0.004575252532958984, 0.004580259323120117]]
    encoder_selector_time_set2 = [[0.5193667411804199, 0.575005054473877, 0.5253713130950928]]
    encoder_mat_builder_time_set2 = [[0.05068397521972656, 0.05514645576477051, 0.05410313606262207]]
    encoder_list_to_mat_time_set2 = [[0.017007112503051758, 0.016924381256103516, 0.017632722854614258]]
    total_inference_time_set2 = [[7.564438819885254, 7.895132541656494, 6.900334358215332]]
    total_decoding_time_set2 = [[0.010154247283935547, 0.010138988494873047, 0.010035276412963867]]
    total_time_set2 = [[28.099493741989136, 29.680709838867188, 27.093430995941162]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen','cyan', 'yellow']

    # Plotting
    fig, ax = plt.subplots(1, 1, figsize=(15, 5))
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()




    # -----------------------------------------
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_96_192_sample_data_4_coo"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set0 = [[14.214271068572998, 11.424229621887207, 14.370496988296509]]
    total_clf_load_time_set0 = [[7.305550813674927, 6.65357780456543, 7.137504577636719]]
    total_data_load_time_set0 = [[19.343135118484497, 16.416025638580322, 14.686767578125]]
    # total_encoder_time_set0 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    encoder_gen_mapping_time_set0 = [[0.5421335697174072, 0.5344305038452148, 0.5318853855133057]]
    encoder_get_feature_time_set0 = [[0.014863967895507812, 0.015505313873291016, 0.014655590057373047]]
    encoder_selector_time_set0 = [[0.9775185585021973, 0.9474830627441406, 0.9641199111938477]]
    encoder_mat_builder_time_set0 = [[0.0017881393432617188, 0.0018186569213867188, 0.0018553733825683594]]
    encoder_list_to_mat_time_set0 = [[0.15726447105407715, 0.1549973487854004, 0.15615391731262207]]
    total_inference_time_set0 = [[0.03154873847961426, 0.03263568878173828, 0.03185153007507324]]
    total_decoding_time_set0 = [[0.09236693382263184, 0.05791926383972168, 0.05998539924621582]]
    total_time_set0 = [[43.18622660636902, 36.7392783164978, 38.458709955215454]]

    total_clf_decompressing_time_set1 = [[2.7411389350891113, 3.6058781147003174, 2.6865200996398926]]
    total_clf_load_time_set1 = [[6.66372537612915, 6.671632766723633, 6.6716148853302]]
    total_data_load_time_set1 = [[16.06651782989502, 17.41927194595337, 18.434086084365845]]
    # total_encoder_time_set1 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    encoder_gen_mapping_time_set1 = [[0.6138122081756592, 0.6066784858703613, 0.6052720546722412]]
    encoder_get_feature_time_set1 = [[0.004528045654296875, 0.004506587982177734, 0.0046367645263671875]]
    encoder_selector_time_set1 = [[1.0821304321289062, 1.0794153213500977, 1.093968391418457]]
    encoder_mat_builder_time_set1 = [[0.1072537899017334, 0.1073305606842041, 0.11080574989318848]]
    encoder_list_to_mat_time_set1 = [[0.033544301986694336, 0.03353619575500488, 0.03954887390136719]]
    total_inference_time_set1 = [[13.857200145721436, 15.893882274627686, 14.133164882659912]]
    total_decoding_time_set1 = [[0.01883840560913086, 0.01852560043334961, 0.019051551818847656]]
    total_time_set1 = [[41.39731454849243, 45.659366846084595, 44.00324082374573]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set0 = [encoder_gen_mapping_time_set0[0], encoder_get_feature_time_set0[0], encoder_selector_time_set0[0], encoder_mat_builder_time_set0[0], encoder_list_to_mat_time_set0[0], total_inference_time_set0[0], total_decoding_time_set0[0]]
    avg_components_set0, errors_set0 = zip(*[trial_stats(data) for data in data_set0])
    avg_total_time_set0 = sum(avg_components_set0)  # New total is the sum of the included components
    total_error_set0 = np.sqrt(sum(np.array(errors_set0) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature


    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set2 = [[13.430506944656372, 12.69049882888794, 15.26503038406372]]
    total_clf_load_time_set2 = [[7.162744998931885, 7.937798261642456, 7.605685234069824]]
    total_data_load_time_set2 = [[8.019973516464233, 9.227576494216919, 8.07615041732788]]
    # total_encoder_time_set2 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    encoder_gen_mapping_time_set2 = [[0.5287468433380127, 0.5731692314147949, 0.558147668838501]]
    encoder_get_feature_time_set2 = [[0.014415502548217773, 0.017134428024291992, 0.015570878982543945]]
    encoder_selector_time_set2 = [[0.5390725135803223, 0.5247557163238525, 0.5774226188659668]]
    encoder_mat_builder_time_set2 = [[0.0009701251983642578, 0.0009982585906982422, 0.0010325908660888672]]
    encoder_list_to_mat_time_set2 = [[0.15552425384521484, 0.1760096549987793, 0.16386675834655762]]
    total_inference_time_set2 = [[0.025096893310546875, 0.029154300689697266, 0.02819037437438965]]
    total_decoding_time_set2 = [[0.03638482093811035, 0.03706765174865723, 0.040502309799194336]]
    total_time_set2 = [[30.277548789978027, 31.59302043914795, 32.713255167007446]]

    total_clf_decompressing_time_set3 = [[3.252439022064209, 3.385455846786499, 3.055346965789795]]
    total_clf_load_time_set3 = [[6.767310380935669, 8.262137174606323, 7.784078121185303]]
    total_data_load_time_set3 = [[9.106859683990479, 8.54998230934143, 7.889105796813965]]
    # total_encoder_time_set3 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    encoder_gen_mapping_time_set3 = [[0.591240406036377, 0.7099721431732178, 0.6318862438201904]]
    encoder_get_feature_time_set3 = [[0.004441022872924805, 0.004575252532958984, 0.004580259323120117]]
    encoder_selector_time_set3 = [[0.5193667411804199, 0.575005054473877, 0.5253713130950928]]
    encoder_mat_builder_time_set3 = [[0.05068397521972656, 0.05514645576477051, 0.05410313606262207]]
    encoder_list_to_mat_time_set3 = [[0.017007112503051758, 0.016924381256103516, 0.017632722854614258]]
    total_inference_time_set3 = [[7.564438819885254, 7.895132541656494, 6.900334358215332]]
    total_decoding_time_set3 = [[0.010154247283935547, 0.010138988494873047, 0.010035276412963867]]
    total_time_set3 = [[28.099493741989136, 29.680709838867188, 27.093430995941162]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set3 = [encoder_gen_mapping_time_set3[0], encoder_get_feature_time_set3[0], encoder_selector_time_set3[0], encoder_mat_builder_time_set3[0], encoder_list_to_mat_time_set3[0], total_inference_time_set3[0], total_decoding_time_set3[0]]
    avg_components_set3, errors_set3 = zip(*[trial_stats(data) for data in data_set3])
    avg_total_time_set3 = sum(avg_components_set3)  # New total is the sum of the included components
    total_error_set3 = np.sqrt(sum(np.array(errors_set3) ** 2 / 4))  # Combine errors using quadrature


    # Example data setup
    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen', 'cyan', 'yellow']

    # Simplified average times for four sets
    avg_components = [
        avg_components_set2,  # Set 2
        avg_components_set3,  # Set 3
        avg_components_set0,  # Set 0
        avg_components_set1,  # Set 1
    ]

    # Errors (simplified and same structure)
    errors = [
        errors_set2,
        errors_set3,
        errors_set0,
        errors_set1,
    ]

    # Create a figure and a set of subplots
    fig, axs = plt.subplots(1, 2, figsize=(10, 3), sharey=True)

    # Function to plot stacked bars for a set
    def plot_stacked_bar(ax, position, component_averages, components, colors):
        bottom = 0
        bars = []
        for i, component_avg in enumerate(component_averages):
            bar = ax.bar(position, component_avg, width=0.35, color=colors[i], bottom=bottom, label=components[i] if position == 0 else None)
            bars.append(bar)
            bottom += component_avg
        return bars

    # Plot for each set in each subplot
    positions = [0, 1]  # Positions for the bars in each subplot
    for i, pos in enumerate(positions):
        bars = plot_stacked_bar(axs[0], pos, avg_components[i], components, colors)
        plot_stacked_bar(axs[1], pos, avg_components[i+2], components, colors)

    # Adding error bars to the total values
    for i, pos in enumerate(positions):
        axs[0].errorbar(pos, sum(avg_components[i]), yerr=np.sqrt(sum(np.array(errors[i])**2 / 4)), fmt='none', ecolor='red', capsize=5)
        axs[1].errorbar(pos, sum(avg_components[i+2]), yerr=np.sqrt(sum(np.array(errors[i+2])**2 / 4)), fmt='none', ecolor='red', capsize=5)

    # # Setting labels, ticks, and titles
    # axs[0].set_title('96 Images')
    # axs[1].set_title('192 Images')
    for ax, batch_size in zip(axs, ['96 Imgs', '192 Imgs']):
        ax.set_ylabel(f'Infer Time\n({batch_size})', fontsize=24)
        ax.set_xlabel('Number of Packages per Model', fontsize=24)
        ax.set_xticks([0, 1])
        ax.set_xticklabels(["3", "3000(DeltaSherlock)"])
        ax.tick_params(axis='both', which='major', labelsize=24)
        ax.tick_params(axis='both', which='minor', labelsize=18)
        ax.grid()
    # axs[0].legend(fontsize=18, loc="upper left")

    # Share one legend
    fig.legend(bars, components, loc='upper center', bbox_to_anchor=(0.5, 1.3), ncol=3, fontsize=18)

    # Adjust layout to fit the legend without overlapping
    plt.tight_layout(rect=[0, 0, 1, 0.9])

    # Save and show plot
    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()


    # -----------------------------------------
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_96sample_data_4_coo_MoE_with_selection_Mono_no_selection"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[13.430506944656372, 12.69049882888794, 15.26503038406372]]
    total_clf_load_time_set1 = [[7.162744998931885, 7.937798261642456, 7.605685234069824]]
    total_data_load_time_set1 = [[8.019973516464233, 9.227576494216919, 8.07615041732788]]
    # total_encoder_time_set1 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    encoder_gen_mapping_time_set1 = [[0.5287468433380127, 0.5731692314147949, 0.558147668838501]]
    encoder_get_feature_time_set1 = [[0.014415502548217773, 0.017134428024291992, 0.015570878982543945]]
    encoder_selector_time_set1 = [[0.5390725135803223, 0.5247557163238525, 0.5774226188659668]]
    encoder_mat_builder_time_set1 = [[0.0009701251983642578, 0.0009982585906982422, 0.0010325908660888672]]
    encoder_list_to_mat_time_set1 = [[0.15552425384521484, 0.1760096549987793, 0.16386675834655762]]
    total_inference_time_set1 = [[0.025096893310546875, 0.029154300689697266, 0.02819037437438965]]
    total_decoding_time_set1 = [[0.03638482093811035, 0.03706765174865723, 0.040502309799194336]]
    total_time_set1 = [[30.277548789978027, 31.59302043914795, 32.713255167007446]]

    total_clf_decompressing_time_set2 = [[4.561068296432495, 3.8028759956359863, 3.291346311569214]]
    total_clf_load_time_set2 = [[8.223542213439941, 8.133033514022827, 6.668471336364746]]
    total_data_load_time_set2 = [[8.237204313278198, 9.054539918899536, 8.055135726928711]]
    # total_encoder_time_set2 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    encoder_gen_mapping_time_set2 = [[0.6113758087158203, 0.6117997169494629, 0.6160824298858643]]
    encoder_get_feature_time_set2 = [[9.5367431640625e-07, 7.152557373046875e-07, 7.152557373046875e-07]]
    encoder_selector_time_set2 = [[5.984306335449219e-05, 5.507469177246094e-05, 4.9114227294921875e-05]]
    encoder_mat_builder_time_set2 = [[54.184863805770874, 55.86870455741882, 55.362404108047485]]
    encoder_list_to_mat_time_set2 = [[0.3432304859161377, 0.34188246726989746, 0.34864354133605957]]
    total_inference_time_set2 = [[7.597291469573975, 8.040897607803345, 8.193055868148804]]
    total_decoding_time_set2 = [[0.010508298873901367, 0.010384082794189453, 0.010284423828125]]
    total_time_set2 = [[84.04684829711914, 86.13081312179565, 82.81556463241577]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen','cyan', 'yellow']

    # Plotting
    fig, ax = plt.subplots(1, 1, figsize=(15, 5))
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()


    # -----------------------------------------
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_96sample_data_4"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[15.764593124389648, 13.836970090866089, 13.477382898330688, 12.042516231536865, 14.005075216293335]]
    total_clf_load_time_set1 = [[7.224096298217773, 7.03323769569397, 7.505751132965088, 9.247905731201172, 7.643913507461548]]
    total_data_load_time_set1 = [[7.02317476272583, 7.79384708404541, 7.417893171310425, 7.333470821380615, 8.649438619613647]]
    # total_encoder_time_set1 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    encoder_gen_mapping_time_set1 = [[0.5379502773284912, 0.533811092376709, 0.5249426364898682, 0.6920645236968994, 0.558577299118042]]
    encoder_get_feature_time_set1 = [[0.014641523361206055, 0.014966487884521484, 0.014775514602661133, 0.020236968994140625, 0.01575183868408203]]
    encoder_selector_time_set1 = [[0.4798893928527832, 0.45941781997680664, 0.45215582847595215, 0.7350425720214844, 0.6320500373840332]]
    encoder_mat_builder_time_set1 = [[0.35004591941833496, 0.34209752082824707, 0.3563539981842041, 0.42783498764038086, 0.35924553871154785]]
    encoder_list_to_mat_time_set1 = [[0.1675577163696289, 0.1722583770751953, 0.16690301895141602, 0.21413636207580566, 0.17938470840454102]]
    total_inference_time_set1 = [[0.02560591697692871, 0.026439428329467773, 0.026050567626953125, 0.03408455848693848, 0.028303146362304688]]
    total_decoding_time_set1 = [[0.0019006729125976562, 0.0019347667694091797, 0.0019376277923583984, 0.002548694610595703, 0.002088785171508789]]
    total_time_set1 = [[31.954143047332764, 30.593761682510376, 30.32544779777527, 31.171023845672607, 32.44474768638611]]

    total_clf_decompressing_time_set2 = [[2.5380616188049316, 4.5007617473602295, 3.676270008087158]]
    total_clf_load_time_set2 = [[7.674092054367065, 6.740265369415283, 6.628811597824097]]
    total_data_load_time_set2 = [[9.164861679077148, 9.65386962890625, 8.21211862564087]]
    # total_encoder_time_set2 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    encoder_gen_mapping_time_set2 = [[0.6098165512084961, 0.6042070388793945, 0.5955228805541992]]
    encoder_get_feature_time_set2 = [[0.004423856735229492, 0.004472970962524414, 0.004430055618286133]]
    encoder_selector_time_set2 = [[0.5646059513092041, 0.5770068168640137, 0.570749044418335]]
    encoder_mat_builder_time_set2 = [[5.7374560832977295, 5.676410436630249, 5.668671607971191]]
    encoder_list_to_mat_time_set2 = [[0.004965543746948242, 0.005433559417724609, 0.00496220588684082]]
    total_inference_time_set2 = [[6.826249122619629, 7.0181725025177, 6.8797993659973145]]
    total_decoding_time_set2 = [[0.009405851364135742, 0.00936436653137207, 0.00953984260559082]]
    total_time_set2 = [[33.35287642478943, 35.00924324989319, 32.46582317352295]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen','cyan', 'yellow']

    # Plotting
    fig, ax = plt.subplots(1, 1, figsize=(15, 5))
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()





    # -----------------------------------------
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_1sample_data_4"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[12.576352834701538, 12.261749744415283, 12.337924480438232, 13.471532821655273, 13.102944612503052, 11.770299434661865, 14.755093097686768, 11.704959630966187, 13.930732250213623]]
    total_clf_load_time_set1 = [[8.03196930885315, 9.084920406341553, 7.496171236038208, 7.797701358795166, 7.310502290725708, 7.641609191894531, 7.684532880783081, 9.466667175292969, 8.499563455581665]]
    total_data_load_time_set1 = [[0.15577340126037598, 0.05624580383300781, 0.04289555549621582, 0.09280228614807129, 0.048061370849609375, 0.07185721397399902, 0.15152668952941895, 0.2614626884460449, 0.045533180236816406]]
    # total_encoder_time_set1 = [[0.8384318351745605, 0.9804048538208008, 0.8090255260467529, 0.8751320838928223, 0.8211545944213867, 0.8605690002441406, 0.8970224857330322, 1.0060911178588867, 0.9055325984954834]]
    encoder_gen_mapping_time_set1 = [[0.5867629051208496, 0.6927309036254883, 0.5619876384735107, 0.61734938621521, 0.5726757049560547, 0.6066415309906006, 0.6330244541168213, 0.6941988468170166, 0.6364293098449707]]
    encoder_get_feature_time_set1 = [[0.017197370529174805, 0.0195920467376709, 0.01604437828063965, 0.017688512802124023, 0.01692795753479004, 0.016765117645263672, 0.017841577529907227, 0.022357702255249023, 0.018164873123168945]]
    encoder_selector_time_set1 = [[0.008812427520751953, 0.011204004287719727, 0.009389638900756836, 0.00973963737487793, 0.008255481719970703, 0.00939798355102539, 0.009195804595947266, 0.010721445083618164, 0.00975656509399414]]
    encoder_mat_builder_time_set1 = [[0.005405902862548828, 0.006162166595458984, 0.005379915237426758, 0.005664348602294922, 0.0053844451904296875, 0.005523204803466797, 0.0056514739990234375, 0.0062296390533447266, 0.005790233612060547]]
    encoder_list_to_mat_time_set1 = [[0.15892267227172852, 0.17757010459899902, 0.1560347080230713, 0.16008758544921875, 0.15724897384643555, 0.15807819366455078, 0.16446661949157715, 0.19530367851257324, 0.16756629943847656]]
    total_inference_time_set1 = [[0.016701698303222656, 0.019629478454589844, 0.01606440544128418, 0.017569303512573242, 0.017370939254760742, 0.0169677734375, 0.01761794090270996, 0.01955413818359375, 0.017991065979003906]]
    total_decoding_time_set1 = [[0.0006570816040039062, 0.0007910728454589844, 0.000682830810546875, 0.0007050037384033203, 0.0006947517395019531, 0.0007040500640869141, 0.0007078647613525391, 0.0007729530334472656, 0.0007004737854003906]]
    total_time_set1 = [[21.806591272354126, 22.603351831436157, 20.885945796966553, 22.434388399124146, 21.48725152015686, 20.545469522476196, 23.679903984069824, 22.663171768188477, 23.57577896118164]]

    total_clf_decompressing_time_set2 = [[3.3748786449432373, 2.652545213699341, 4.280938386917114, 3.292240858078003, 3.5788254737854004, 3.952855110168457, 4.79905366897583, 4.730808973312378, 3.217198371887207]]
    total_clf_load_time_set2 = [[7.508908748626709, 7.185784816741943, 7.324116230010986, 8.744511604309082, 8.47779393196106, 9.517568588256836, 7.459484100341797, 7.276854753494263, 9.140186548233032]]
    total_data_load_time_set2 = [[0.11790204048156738, 0.09383845329284668, 0.04489588737487793, 0.20633769035339355, 0.09059643745422363, 0.31734800338745117, 0.23385381698608398, 0.05802655220031738, 0.16172480583190918]]
    # total_encoder_time_set2 = [[0.7292325496673584, 0.729332447052002, 0.7746524810791016, 0.7520701885223389, 0.7643775939941406, 0.7392139434814453, 0.7678463459014893, 0.7339191436767578, 0.728668212890625]]
    encoder_gen_mapping_time_set2 = [[0.6045119762420654, 0.6007590293884277, 0.6515147686004639, 0.6276607513427734, 0.6397011280059814, 0.6139764785766602, 0.6445267200469971, 0.6108384132385254, 0.6051225662231445]]
    encoder_get_feature_time_set2 = [[0.00446319580078125, 0.004435300827026367, 0.004418611526489258, 0.004578828811645508, 0.007025480270385742, 0.004585981369018555, 0.005484819412231445, 0.004441499710083008, 0.0045011043548583984]]
    encoder_selector_time_set2 = [[0.007898330688476562, 0.006776094436645508, 0.006096363067626953, 0.006033658981323242, 0.005789518356323242, 0.007739543914794922, 0.006008148193359375, 0.0058591365814208984, 0.00615239143371582]]
    encoder_mat_builder_time_set2 = [[0.0625758171081543, 0.06720185279846191, 0.06266427040100098, 0.06219911575317383, 0.06183958053588867, 0.06244182586669922, 0.061699867248535156, 0.06268668174743652, 0.06139397621154785]]
    encoder_list_to_mat_time_set2 = [[0.0001957416534423828, 0.00018072128295898438, 0.00017881393432617188, 0.00018477439880371094, 0.0001800060272216797, 0.0003070831298828125, 0.00028634071350097656, 0.000293731689453125, 0.0002014636993408203]]
    total_inference_time_set2 = [[0.08936023712158203, 0.0869131088256836, 0.08446741104125977, 0.09904336929321289, 0.08483576774597168, 0.10666966438293457, 0.09701800346374512, 0.08715009689331055, 0.09555983543395996]]
    total_decoding_time_set2 = [[0.00018143653869628906, 0.00013375282287597656, 0.0001308917999267578, 0.00013446807861328125, 0.0001323223114013672, 0.0002167224884033203, 0.00016427040100097656, 0.0001552104949951172, 0.00014352798461914062]]
    total_time_set2 = [[11.98745846748352, 10.921641111373901, 12.67851209640503, 13.256442546844482, 13.158096313476562, 14.795198678970337, 13.53711748123169, 13.036462545394897, 13.499534130096436]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen','cyan', 'yellow']

    # Plotting
    fig, ax = plt.subplots(1, 1, figsize=(15, 5))
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()


    # -----------------------------------------
    filename = "detailed_total_inference_time_by_labels_per_model_with_rawinput_True25filter_1sample_data_4_coo"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[11.524986982345581, 10.80647873878479, 11.120130062103271]]
    total_clf_load_time_set1 = [[7.774563550949097, 7.838911294937134, 7.6550610065460205]]
    total_data_load_time_set1 = [[0.06558012962341309, 0.08062553405761719, 0.08618474006652832]]
    # total_encoder_time_set1 = [[0.8384318351745605, 0.9804048538208008, 0.8090255260467529, 0.8751320838928223, 0.8211545944213867, 0.8605690002441406, 0.8970224857330322, 1.0060911178588867, 0.9055325984954834]]
    encoder_gen_mapping_time_set1 = [[0.5608088970184326, 0.5708374977111816, 0.5714190006256104]]
    encoder_get_feature_time_set1 = [[0.016472578048706055, 0.017534732818603516, 0.017215967178344727]]
    encoder_selector_time_set1 = [[0.009605646133422852, 0.010025262832641602, 0.007492780685424805]]
    encoder_mat_builder_time_set1 = [[2.5510787963867188e-05, 2.4080276489257812e-05, 2.3365020751953125e-05]]
    encoder_list_to_mat_time_set1 = [[0.1586618423461914, 0.16147518157958984, 0.15582680702209473]]
    total_inference_time_set1 = [[0.015468835830688477, 0.015758275985717773, 0.01582503318786621]]
    total_decoding_time_set1 = [[0.0006585121154785156, 0.0006496906280517578, 0.0007159709930419922]]
    total_time_set1 = [[20.371043920516968, 19.741517066955566, 19.86724090576172]]

    total_clf_decompressing_time_set2 = [[3.0109710693359375, 3.0619213581085205, 4.273451328277588]]
    total_clf_load_time_set2 = [[7.994372844696045, 7.4710164070129395, 8.230432510375977]]
    total_data_load_time_set2 = [[0.09440088272094727, 0.24212360382080078, 0.275254487991333]]
    # total_encoder_time_set2 = [[0.7292325496673584, 0.729332447052002, 0.7746524810791016, 0.7520701885223389, 0.7643775939941406, 0.7392139434814453, 0.7678463459014893, 0.7339191436767578, 0.728668212890625]]
    encoder_gen_mapping_time_set2 = [[0.6063416004180908, 0.6150572299957275, 0.603813886642456]]
    encoder_get_feature_time_set2 = [[0.004423856735229492, 0.0045642852783203125, 0.0045316219329833984]]
    encoder_selector_time_set2 = [[0.005946636199951172, 0.005720615386962891, 0.0060405731201171875]]
    encoder_mat_builder_time_set2 = [[0.0009870529174804688, 0.0010085105895996094, 0.0009553432464599609]]
    encoder_list_to_mat_time_set2 = [[0.0006039142608642578, 0.0005991458892822266, 0.0006442070007324219]]
    total_inference_time_set2 = [[0.08663058280944824, 0.08965826034545898, 0.08496904373168945]]
    total_decoding_time_set2 = [[0.0001308917999267578, 0.00013399124145507812, 0.00013184547424316406]]
    total_time_set2 = [[12.020588636398315, 11.707062482833862, 13.693012237548828]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [encoder_gen_mapping_time_set1[0], encoder_get_feature_time_set1[0], encoder_selector_time_set1[0], encoder_mat_builder_time_set1[0], encoder_list_to_mat_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [encoder_gen_mapping_time_set2[0], encoder_get_feature_time_set2[0], encoder_selector_time_set2[0], encoder_mat_builder_time_set2[0], encoder_list_to_mat_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode: Load Feat-Idx Mapping', 'Encode: Subset Pos Weight Feats', 'Encode: Sample-Encoder Feat Intersect', 'Encode: Mat Builder', 'Encode: List to Mat', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange', 'lightblue', 'lightgreen','cyan', 'yellow']

    # Plotting
    fig, ax = plt.subplots(1, 1, figsize=(15, 5))
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()


# ========================================================================================================================================================
# ============================================================================total_time_by_labels_per_model_with_rawinput_True25filter===================
    filename = "total_time_by_labels_per_model_with_rawinput_True25filter_192sample_data_4_coo"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[14.214271068572998, 11.424229621887207, 14.370496988296509]]
    total_clf_load_time_set1 = [[7.305550813674927, 6.65357780456543, 7.137504577636719]]
    total_data_load_time_set1 = [[19.343135118484497, 16.416025638580322, 14.686767578125]]
    total_encoder_time_set1 = [[2.005190849304199, 1.973992109298706, 1.9878623485565186]]
    encoder_list_to_mat_time_set1 = [[0.15726447105407715, 0.1549973487854004, 0.15615391731262207]]
    total_inference_time_set1 = [[0.03154873847961426, 0.03263568878173828, 0.03185153007507324]]
    total_decoding_time_set1 = [[0.09236693382263184, 0.05791926383972168, 0.05998539924621582]]
    total_time_set1 = [[43.18622660636902, 36.7392783164978, 38.458709955215454]]

    total_clf_decompressing_time_set2 = [[2.7411389350891113, 3.6058781147003174, 2.6865200996398926]]
    total_clf_load_time_set2 = [[6.66372537612915, 6.671632766723633, 6.6716148853302]]
    total_data_load_time_set2 = [[16.06651782989502, 17.41927194595337, 18.434086084365845]]
    total_encoder_time_set2 = [[1.8948023319244385, 1.8851449489593506, 1.9087114334106445]]
    total_inference_time_set2 = [[13.857200145721436, 15.893882274627686, 14.133164882659912]]
    total_decoding_time_set2 = [[0.01883840560913086, 0.01852560043334961, 0.019051551818847656]]
    total_time_set2 = [[41.39731454849243, 45.659366846084595, 44.00324082374573]]

    # Calculate the averages and standard deviations for all components
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Process data and calculate statistics for Set 1
    avg_components_set1, errors_set1 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set1, total_clf_load_time_set1, total_data_load_time_set1,
        total_encoder_time_set1, total_inference_time_set1, total_decoding_time_set1
    ]])
    avg_total_time_set1, total_error_set1 = trial_stats(total_time_set1[0])
    avg_other_time_set1 = avg_total_time_set1 - sum(avg_components_set1)
    avg_components_set1 = list(avg_components_set1) + [avg_other_time_set1]
    errors_set1 = list(errors_set1) + [0]  # Assuming no error for 'Other Time'

    # Process data and calculate statistics for Set 2
    avg_components_set2, errors_set2 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set2, total_clf_load_time_set2, total_data_load_time_set2,
        total_encoder_time_set2, total_inference_time_set2, total_decoding_time_set2
    ]])
    avg_total_time_set2, total_error_set2 = trial_stats(total_time_set2[0])
    avg_other_time_set2 = avg_total_time_set2 - sum(avg_components_set2)
    avg_components_set2 = list(avg_components_set2) + [avg_other_time_set2]
    errors_set2 = list(errors_set2) + [0]  # Assuming no error for 'Other Time'

    components = ['CLF Unzip', 'CLF Load', 'Data Load', 'Encode', 'Inference', 'Decode', 'Other Time']
    colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightgoldenrodyellow', 'magenta', 'orange', 'grey']

    # Plotting
    fig, ax = plt.subplots()
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()

    # -----------------------------------------
    filename = "total_time_by_labels_per_model_with_rawinput_True25filter_96sample_data_4_coo"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[13.430506944656372, 12.69049882888794, 15.26503038406372]]
    total_clf_load_time_set1 = [[7.162744998931885, 7.937798261642456, 7.605685234069824]]
    total_data_load_time_set1 = [[8.019973516464233, 9.227576494216919, 8.07615041732788]]
    total_encoder_time_set1 = [[1.4228813648223877, 1.489600419998169, 1.503833532333374]]
    total_inference_time_set1 = [[0.025096893310546875, 0.029154300689697266, 0.02819037437438965]]
    total_decoding_time_set1 = [[0.03638482093811035, 0.03706765174865723, 0.040502309799194336]]
    total_time_set1 = [[30.277548789978027, 31.59302043914795, 32.713255167007446]]

    total_clf_decompressing_time_set2 = [[3.252439022064209, 3.385455846786499, 3.055346965789795]]
    total_clf_load_time_set2 = [[6.767310380935669, 8.262137174606323, 7.784078121185303]]
    total_data_load_time_set2 = [[9.106859683990479, 8.54998230934143, 7.889105796813965]]
    total_encoder_time_set2 = [[1.2347161769866943, 1.4138777256011963, 1.2853436470031738]]
    total_inference_time_set2 = [[7.564438819885254, 7.895132541656494, 6.900334358215332]]
    total_decoding_time_set2 = [[0.010154247283935547, 0.010138988494873047, 0.010035276412963867]]
    total_time_set2 = [[28.099493741989136, 29.680709838867188, 27.093430995941162]]

    # Calculate the averages and standard deviations for all components
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Process data and calculate statistics for Set 1
    avg_components_set1, errors_set1 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set1, total_clf_load_time_set1, total_data_load_time_set1,
        total_encoder_time_set1, total_inference_time_set1, total_decoding_time_set1
    ]])
    avg_total_time_set1, total_error_set1 = trial_stats(total_time_set1[0])
    avg_other_time_set1 = avg_total_time_set1 - sum(avg_components_set1)
    avg_components_set1 = list(avg_components_set1) + [avg_other_time_set1]
    errors_set1 = list(errors_set1) + [0]  # Assuming no error for 'Other Time'

    # Process data and calculate statistics for Set 2
    avg_components_set2, errors_set2 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set2, total_clf_load_time_set2, total_data_load_time_set2,
        total_encoder_time_set2, total_inference_time_set2, total_decoding_time_set2
    ]])
    avg_total_time_set2, total_error_set2 = trial_stats(total_time_set2[0])
    avg_other_time_set2 = avg_total_time_set2 - sum(avg_components_set2)
    avg_components_set2 = list(avg_components_set2) + [avg_other_time_set2]
    errors_set2 = list(errors_set2) + [0]  # Assuming no error for 'Other Time'

    components = ['CLF Unzip', 'CLF Load', 'Data Load', 'Encode', 'Inference', 'Decode', 'Other Time']
    colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightgoldenrodyellow', 'magenta', 'orange', 'grey']

    # Plotting
    fig, ax = plt.subplots()
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()

    # -----------------------------------------

    filename = "total_time_by_labels_per_model_with_rawinput_True25filter_96sample_data_4"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[15.764593124389648, 13.836970090866089, 13.477382898330688, 12.042516231536865, 14.005075216293335]]
    total_clf_load_time_set1 = [[7.224096298217773, 7.03323769569397, 7.505751132965088, 9.247905731201172, 7.643913507461548]]
    total_data_load_time_set1 = [[7.02317476272583, 7.79384708404541, 7.417893171310425, 7.333470821380615, 8.649438619613647]]
    total_encoder_time_set1 = [[1.7366256713867188, 1.7113926410675049, 1.706197738647461, 2.316041946411133, 1.9386999607086182]]
    total_inference_time_set1 = [[0.02560591697692871, 0.026439428329467773, 0.026050567626953125, 0.03408455848693848, 0.028303146362304688]]
    total_decoding_time_set1 = [[0.0019006729125976562, 0.0019347667694091797, 0.0019376277923583984, 0.002548694610595703, 0.002088785171508789]]
    total_time_set1 = [[31.954143047332764, 30.593761682510376, 30.32544779777527, 31.171023845672607, 32.44474768638611]]

    total_clf_decompressing_time_set2 = [[2.5380616188049316, 4.5007617473602295, 3.676270008087158]]
    total_clf_load_time_set2 = [[7.674092054367065, 6.740265369415283, 6.628811597824097]]
    total_data_load_time_set2 = [[9.164861679077148, 9.65386962890625, 8.21211862564087]]
    total_encoder_time_set2 = [[6.972375154495239, 6.928048372268677, 6.895395994186401]]
    total_inference_time_set2 = [[6.826249122619629, 7.0181725025177, 6.8797993659973145]]
    total_decoding_time_set2 = [[0.009405851364135742, 0.00936436653137207, 0.00953984260559082]]
    total_time_set2 = [[33.35287642478943, 35.00924324989319, 32.46582317352295]]

    # Calculate the averages and standard deviations for all components
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Process data and calculate statistics for Set 1
    avg_components_set1, errors_set1 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set1, total_clf_load_time_set1, total_data_load_time_set1,
        total_encoder_time_set1, total_inference_time_set1, total_decoding_time_set1
    ]])
    avg_total_time_set1, total_error_set1 = trial_stats(total_time_set1[0])
    avg_other_time_set1 = avg_total_time_set1 - sum(avg_components_set1)
    avg_components_set1 = list(avg_components_set1) + [avg_other_time_set1]
    errors_set1 = list(errors_set1) + [0]  # Assuming no error for 'Other Time'

    # Process data and calculate statistics for Set 2
    avg_components_set2, errors_set2 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set2, total_clf_load_time_set2, total_data_load_time_set2,
        total_encoder_time_set2, total_inference_time_set2, total_decoding_time_set2
    ]])
    avg_total_time_set2, total_error_set2 = trial_stats(total_time_set2[0])
    avg_other_time_set2 = avg_total_time_set2 - sum(avg_components_set2)
    avg_components_set2 = list(avg_components_set2) + [avg_other_time_set2]
    errors_set2 = list(errors_set2) + [0]  # Assuming no error for 'Other Time'

    components = ['CLF Unzip', 'CLF Load', 'Data Load', 'Encode', 'Inference', 'Decode', 'Other Time']
    colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightgoldenrodyellow', 'magenta', 'orange', 'grey']

    # Plotting
    fig, ax = plt.subplots()
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()


    # -----------------------------------------
    filename = "total_time_by_labels_per_model_with_rawinput_True25filter_1sample_data_4"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[12.576352834701538, 12.261749744415283, 12.337924480438232, 13.471532821655273, 13.102944612503052, 11.770299434661865, 14.755093097686768, 11.704959630966187, 13.930732250213623]]
    total_clf_load_time_set1 = [[8.03196930885315, 9.084920406341553, 7.496171236038208, 7.797701358795166, 7.310502290725708, 7.641609191894531, 7.684532880783081, 9.466667175292969, 8.499563455581665]]
    total_data_load_time_set1 = [[0.15577340126037598, 0.05624580383300781, 0.04289555549621582, 0.09280228614807129, 0.048061370849609375, 0.07185721397399902, 0.15152668952941895, 0.2614626884460449, 0.045533180236816406]]
    total_encoder_time_set1 = [[0.8384318351745605, 0.9804048538208008, 0.8090255260467529, 0.8751320838928223, 0.8211545944213867, 0.8605690002441406, 0.8970224857330322, 1.0060911178588867, 0.9055325984954834]]
    total_inference_time_set1 = [[0.016701698303222656, 0.019629478454589844, 0.01606440544128418, 0.017569303512573242, 0.017370939254760742, 0.0169677734375, 0.01761794090270996, 0.01955413818359375, 0.017991065979003906]]
    total_decoding_time_set1 = [[0.0006570816040039062, 0.0007910728454589844, 0.000682830810546875, 0.0007050037384033203, 0.0006947517395019531, 0.0007040500640869141, 0.0007078647613525391, 0.0007729530334472656, 0.0007004737854003906]]
    total_time_set1 = [[21.806591272354126, 22.603351831436157, 20.885945796966553, 22.434388399124146, 21.48725152015686, 20.545469522476196, 23.679903984069824, 22.663171768188477, 23.57577896118164]]

    total_clf_decompressing_time_set2 = [[3.3748786449432373, 2.652545213699341, 4.280938386917114, 3.292240858078003, 3.5788254737854004, 3.952855110168457, 4.79905366897583, 4.730808973312378, 3.217198371887207]]
    total_clf_load_time_set2 = [[7.508908748626709, 7.185784816741943, 7.324116230010986, 8.744511604309082, 8.47779393196106, 9.517568588256836, 7.459484100341797, 7.276854753494263, 9.140186548233032]]
    total_data_load_time_set2 = [[0.11790204048156738, 0.09383845329284668, 0.04489588737487793, 0.20633769035339355, 0.09059643745422363, 0.31734800338745117, 0.23385381698608398, 0.05802655220031738, 0.16172480583190918]]
    total_encoder_time_set2 = [[0.7292325496673584, 0.729332447052002, 0.7746524810791016, 0.7520701885223389, 0.7643775939941406, 0.7392139434814453, 0.7678463459014893, 0.7339191436767578, 0.728668212890625]]
    total_inference_time_set2 = [[0.08936023712158203, 0.0869131088256836, 0.08446741104125977, 0.09904336929321289, 0.08483576774597168, 0.10666966438293457, 0.09701800346374512, 0.08715009689331055, 0.09555983543395996]]
    total_decoding_time_set2 = [[0.00018143653869628906, 0.00013375282287597656, 0.0001308917999267578, 0.00013446807861328125, 0.0001323223114013672, 0.0002167224884033203, 0.00016427040100097656, 0.0001552104949951172, 0.00014352798461914062]]
    total_time_set2 = [[11.98745846748352, 10.921641111373901, 12.67851209640503, 13.256442546844482, 13.158096313476562, 14.795198678970337, 13.53711748123169, 13.036462545394897, 13.499534130096436]]

    # Calculate the averages and standard deviations for all components
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Process data and calculate statistics for Set 1
    avg_components_set1, errors_set1 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set1, total_clf_load_time_set1, total_data_load_time_set1,
        total_encoder_time_set1, total_inference_time_set1, total_decoding_time_set1
    ]])
    avg_total_time_set1, total_error_set1 = trial_stats(total_time_set1[0])
    avg_other_time_set1 = avg_total_time_set1 - sum(avg_components_set1)
    avg_components_set1 = list(avg_components_set1) + [avg_other_time_set1]
    errors_set1 = list(errors_set1) + [0]  # Assuming no error for 'Other Time'

    # Process data and calculate statistics for Set 2
    avg_components_set2, errors_set2 = zip(*[trial_stats(x[0]) for x in [
        total_clf_decompressing_time_set2, total_clf_load_time_set2, total_data_load_time_set2,
        total_encoder_time_set2, total_inference_time_set2, total_decoding_time_set2
    ]])
    avg_total_time_set2, total_error_set2 = trial_stats(total_time_set2[0])
    avg_other_time_set2 = avg_total_time_set2 - sum(avg_components_set2)
    avg_components_set2 = list(avg_components_set2) + [avg_other_time_set2]
    errors_set2 = list(errors_set2) + [0]  # Assuming no error for 'Other Time'

    components = ['CLF Unzip', 'CLF Load', 'Data Load', 'Encode', 'Inference', 'Decode', 'Other Time']
    colors = ['skyblue', 'lightgreen', 'lightcoral', 'lightgoldenrodyellow', 'magenta', 'orange', 'grey']

    # Plotting
    fig, ax = plt.subplots()
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()

# ========================================================================================================================================================
# ============================================================================total_inference_time_by_labels_per_model_with_rawinput_True25filter=========

    filename = "total_inference_time_by_labels_per_model_with_rawinput_True25filter_1sample_data_4"

    # Data for Set 1 and Set 2
    total_clf_decompressing_time_set1 = [[12.576352834701538, 12.261749744415283, 12.337924480438232, 13.471532821655273, 13.102944612503052, 11.770299434661865, 14.755093097686768, 11.704959630966187, 13.930732250213623]]
    total_clf_load_time_set1 = [[8.03196930885315, 9.084920406341553, 7.496171236038208, 7.797701358795166, 7.310502290725708, 7.641609191894531, 7.684532880783081, 9.466667175292969, 8.499563455581665]]
    total_data_load_time_set1 = [[0.15577340126037598, 0.05624580383300781, 0.04289555549621582, 0.09280228614807129, 0.048061370849609375, 0.07185721397399902, 0.15152668952941895, 0.2614626884460449, 0.045533180236816406]]
    total_encoder_time_set1 = [[0.8384318351745605, 0.9804048538208008, 0.8090255260467529, 0.8751320838928223, 0.8211545944213867, 0.8605690002441406, 0.8970224857330322, 1.0060911178588867, 0.9055325984954834]]
    total_inference_time_set1 = [[0.016701698303222656, 0.019629478454589844, 0.01606440544128418, 0.017569303512573242, 0.017370939254760742, 0.0169677734375, 0.01761794090270996, 0.01955413818359375, 0.017991065979003906]]
    total_decoding_time_set1 = [[0.0006570816040039062, 0.0007910728454589844, 0.000682830810546875, 0.0007050037384033203, 0.0006947517395019531, 0.0007040500640869141, 0.0007078647613525391, 0.0007729530334472656, 0.0007004737854003906]]
    total_time_set1 = [[21.806591272354126, 22.603351831436157, 20.885945796966553, 22.434388399124146, 21.48725152015686, 20.545469522476196, 23.679903984069824, 22.663171768188477, 23.57577896118164]]

    total_clf_decompressing_time_set2 = [[3.3748786449432373, 2.652545213699341, 4.280938386917114, 3.292240858078003, 3.5788254737854004, 3.952855110168457, 4.79905366897583, 4.730808973312378, 3.217198371887207]]
    total_clf_load_time_set2 = [[7.508908748626709, 7.185784816741943, 7.324116230010986, 8.744511604309082, 8.47779393196106, 9.517568588256836, 7.459484100341797, 7.276854753494263, 9.140186548233032]]
    total_data_load_time_set2 = [[0.11790204048156738, 0.09383845329284668, 0.04489588737487793, 0.20633769035339355, 0.09059643745422363, 0.31734800338745117, 0.23385381698608398, 0.05802655220031738, 0.16172480583190918]]
    total_encoder_time_set2 = [[0.7292325496673584, 0.729332447052002, 0.7746524810791016, 0.7520701885223389, 0.7643775939941406, 0.7392139434814453, 0.7678463459014893, 0.7339191436767578, 0.728668212890625]]
    total_inference_time_set2 = [[0.08936023712158203, 0.0869131088256836, 0.08446741104125977, 0.09904336929321289, 0.08483576774597168, 0.10666966438293457, 0.09701800346374512, 0.08715009689331055, 0.09555983543395996]]
    total_decoding_time_set2 = [[0.00018143653869628906, 0.00013375282287597656, 0.0001308917999267578, 0.00013446807861328125, 0.0001323223114013672, 0.0002167224884033203, 0.00016427040100097656, 0.0001552104949951172, 0.00014352798461914062]]
    total_time_set2 = [[11.98745846748352, 10.921641111373901, 12.67851209640503, 13.256442546844482, 13.158096313476562, 14.795198678970337, 13.53711748123169, 13.036462545394897, 13.499534130096436]]

    # Function to calculate mean and 2 standard deviations
    def trial_stats(trial_list):
        mean_val = np.mean(trial_list)
        std_dev = np.std(trial_list) * 2  # Calculate two standard deviations
        return mean_val, std_dev

    # Define indices of the components to keep ('Encode', 'Inference', 'Decode')
    indices = [3, 4, 5]  # Assuming 'Encode' is 3rd, 'Inference' is 4th, 'Decode' is 5th in the original list

    # Data extraction and processing for Set 1
    data_set1 = [total_encoder_time_set1[0], total_inference_time_set1[0], total_decoding_time_set1[0]]
    avg_components_set1, errors_set1 = zip(*[trial_stats(data) for data in data_set1])
    avg_total_time_set1 = sum(avg_components_set1)  # New total is the sum of the included components
    total_error_set1 = np.sqrt(sum(np.array(errors_set1) ** 2 / 4))  # Combine errors using quadrature

    # Data extraction and processing for Set 2
    data_set2 = [total_encoder_time_set2[0], total_inference_time_set2[0], total_decoding_time_set2[0]]
    avg_components_set2, errors_set2 = zip(*[trial_stats(data) for data in data_set2])
    avg_total_time_set2 = sum(avg_components_set2)  # New total is the sum of the included components
    total_error_set2 = np.sqrt(sum(np.array(errors_set2) ** 2 / 4))  # Combine errors using quadrature

    components = ['Encode', 'Inference', 'Decode']
    colors = ['lightcoral', 'magenta', 'orange']

    # Plotting
    fig, ax = plt.subplots()
    ind = np.arange(2)  # Number of sets
    width = 0.35       # the width of the bars

    # Function to plot stacked bars for a set
    def plot_stacked_bar(position, component_averages, components, colors):
        bottom = 0
        for i, component_avg in enumerate(component_averages):
            label = components[i] if position == 0 else None
            color = colors[i]
            ax.bar(position, component_avg, width, color=color, bottom=bottom, label=label)
            bottom += component_avg

    # Plot for each set
    plot_stacked_bar(ind[0], avg_components_set1, components, colors)
    plot_stacked_bar(ind[1], avg_components_set2, components, colors)

    # Adding error bars to the total values
    ax.errorbar(ind, [avg_total_time_set1, avg_total_time_set2], yerr=[total_error_set1, total_error_set2], fmt='none', ecolor='red', capsize=5, label='Total Time Error')

    ax.set_ylabel('Average Time', fontsize=24)
    ax.set_xlabel('Number of Package Labels per Model', fontsize=24)
    ax.set_xticks(ind)
    ax.set_xticklabels(["3", "3000\n(DeltaSherlock)"])
    ax.tick_params(axis='both', which='major', labelsize=24)
    ax.tick_params(axis='both', which='minor', labelsize=18)
    ax.legend(fontsize=18, loc="lower center")
    ax.grid()

    plt.savefig(fig_path + filename + '.pdf', bbox_inches='tight')
    plt.close()

# ========================================================================================================================================================


















    # filename = "test_f1score_model_token_share_by_labels_per_model_with_rawinput_True50filter_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs_label = [60, 120, 300, "3000 (DeltaSherlock)"]
    # xs = list(range(len(xs_label)))
    # f1_score_label = "F1-Score"
    # precision_label = "Precision"
    # token_share_label = "\% of Token Considered by Multiple Sub-Model"

    # # Data for F1-Score
    # ys_d4f1scorebycosinesim_l = [
    #     [[0.84, 0.851, 0.844, 0.835, 0.842]],
    #     [[0.857, 0.839, 0.854, 0.859, 0.852, 0.85, 0.847, 0.84, 0.847, 0.845]],
    #     [[0.856, 0.82, 0.854, 0.858, 0.859, 0.852, 0.855, 0.839, 0.864, 0.862]],
    #     [[0.859, 0.859, 0.859, 0.859, 0.859, 0.859, 0.859, 0.859, 0.859, 0.859]]
    # ]

    # # Data for Precision
    # ys_d4f1precisonbycosinesim_l = [
    #     [[0.813, 0.826, 0.818, 0.807, 0.816]],
    #     [[0.832, 0.812, 0.828, 0.833, 0.826, 0.825, 0.82, 0.814, 0.821, 0.817]],
    #     [[0.839, 0.817, 0.828, 0.836, 0.833, 0.826, 0.836, 0.814, 0.839, 0.835]],
    #     [[0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85]]
    # ]

    # # Data for Token Share
    # ys_d4modelsharedtokenbycosinesim_l = [
    #     [[0.07408465973488396, 0.07413120014016875, 0.07338764872397159, 0.07277714811347098, 0.07418595355815087]],
    #     [[0.07288829755197468, 0.07312099957839868, 0.07273225031072565, 0.07183976959761713, 0.0735376730892426, 0.07224275475396552, 0.07310183588210493, 0.07241249034971008, 0.07239277911923651]],
    #     [[0.0710995033864989, 0.069023253776617, 0.07085420807393901, 0.06938681647201826, 0.06944156989000039, 0.06893729091038509, 0.07039811210214798, 0.07146635128697909, 0.07046326866954669]],
    #     [[0, 0]]
    # ]

    # # Calculate means and confidence intervals for F1-Score
    # ys_array_f1, ci_array_f1 = [], []
    # for m_i in range(len(ys_d4f1scorebycosinesim_l)):
    #     ys_array_f1.append(np.mean(ys_d4f1scorebycosinesim_l[m_i], axis=(1)))
    #     ci_array_f1.append(1.96 * np.std(ys_d4f1scorebycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1scorebycosinesim_l[m_i][0])))
    # ys_array_f1 = np.array(ys_array_f1).T
    # ci_array_f1 = np.array(ci_array_f1).T

    # # Plot F1-Score
    # for ys, ci in zip(ys_array_f1, ci_array_f1):
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=f1_score_label, marker="^")

    # # Calculate means and confidence intervals for Precision
    # ys_array_f1, ci_array_f1 = [], []
    # for m_i in range(len(ys_d4f1precisonbycosinesim_l)):
    #     ys_array_f1.append(np.mean(ys_d4f1precisonbycosinesim_l[m_i], axis=(1)))
    #     ci_array_f1.append(1.96 * np.std(ys_d4f1precisonbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1precisonbycosinesim_l[m_i][0])))
    # ys_array_f1 = np.array(ys_array_f1).T
    # ci_array_f1 = np.array(ci_array_f1).T

    # # Plot Precision
    # for ys, ci in zip(ys_array_f1, ci_array_f1):
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=precision_label, marker="*")

    # # Calculate means and confidence intervals for Token Share
    # ys_array_ts, ci_array_ts = [], []
    # for m_i in range(len(ys_d4modelsharedtokenbycosinesim_l)):
    #     ys_array_ts.append(np.mean(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=(1)))
    #     ci_array_ts.append(1.96 * np.std(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4modelsharedtokenbycosinesim_l[m_i][0])))
    # ys_array_ts = np.array(ys_array_ts).T
    # ci_array_ts = np.array(ci_array_ts).T

    # # Plot Token Share on secondary y-axis
    # ax2 = ax.twinx()
    # for ys, ci in zip(ys_array_ts, ci_array_ts):
    #     ax2.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=token_share_label, marker="v", color='r')

    # # Styling and labeling
    # ax.set_xlabel("Package Labels per Sub-Models", fontsize=20)
    # ax.set_xticks(xs)
    # ax.set_xticklabels(xs_label, fontsize=18)
    # ax.set_ylabel("Model Metrics", fontsize=20, color='b')
    # ax.tick_params(axis='y', labelsize=18, labelcolor='b')
    # ax2.set_ylabel("\%", fontsize=20, color='r')
    # ax2.tick_params(axis='y', labelsize=18, labelcolor='r')
    # # ax2.set_ylim(0.069, 0.075)
    # ax.grid(True)
    # # ax2.grid(True)

    # # Adding legends
    # ax.legend(title="Metric", fontsize=12, loc="lower left")
    # ax2.legend(fontsize=12, loc="upper center")

    # fig.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter as needed

    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()


    # filename = "test_f1score_model_token_share_by_labels_per_model_with_rawinput_True100filter_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs_label = [60, 120, 300, 3000]
    # xs = list(range(len(xs_label)))
    # f1_score_label = "F1-Score"
    # token_share_label = "Token Considered by Multiple Sub-Model"

    # # Data for F1-Score
    # ys_d4f1scorebycosinesim_l = [
    #     [[0.845, 0.854, 0.846]],
    #     [[0.85, 0.859, 0.842]],
    #     [[0.827, 0.814, 0.824]],
    #     [[0.836, 0.836, 0.836]]
    # ]

    # # Data for Token Share
    # ys_d4modelsharedtokenbycosinesim_l = [
    #     [[0.07408465973488396*100, 0.07413120014016875*100, 0.07338764872397159*100]],
    #     [[0.07288829755197468*100, 0.07312099957839868*100, 0.07273225031072565*100]],
    #     [[0.0710995033864989*100, 0.069023253776617*100, 0.07085420807393901*100]],
    #     [[0.0, 0.0, 0.0]]
    # ]

    # # Calculate means and confidence intervals for F1-Score
    # ys_array_f1, ci_array_f1 = [], []
    # for m_i in range(len(ys_d4f1scorebycosinesim_l)):
    #     ys_array_f1.append(np.mean(ys_d4f1scorebycosinesim_l[m_i], axis=(1)))
    #     ci_array_f1.append(1.96 * np.std(ys_d4f1scorebycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4f1scorebycosinesim_l[m_i][0])))
    # ys_array_f1 = np.array(ys_array_f1).T
    # ci_array_f1 = np.array(ci_array_f1).T

    # # Plot F1-Score
    # for ys, ci in zip(ys_array_f1, ci_array_f1):
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=f1_score_label, marker="^")

    # # Calculate means and confidence intervals for Token Share
    # ys_array_ts, ci_array_ts = [], []
    # for m_i in range(len(ys_d4modelsharedtokenbycosinesim_l)):
    #     ys_array_ts.append(np.mean(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=(1)))
    #     ci_array_ts.append(1.96 * np.std(ys_d4modelsharedtokenbycosinesim_l[m_i], axis=1) / np.sqrt(len(ys_d4modelsharedtokenbycosinesim_l[m_i][0])))
    # ys_array_ts = np.array(ys_array_ts).T
    # ci_array_ts = np.array(ci_array_ts).T

    # # Plot Token Share on secondary y-axis
    # ax2 = ax.twinx()
    # for ys, ci in zip(ys_array_ts, ci_array_ts):
    #     ax2.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, label=token_share_label, marker="v", color='r')

    # # Styling and labeling
    # ax.set_xlabel("Package Labels per Sub-Models", fontsize=20)
    # ax.set_xticks(xs)
    # ax.set_xticklabels(xs_label)
    # ax.set_ylabel("F1-Score", fontsize=20, color='b')
    # ax.tick_params(axis='y', labelcolor='b')
    # ax2.set_ylabel("Percentage", fontsize=20, color='r')
    # ax2.tick_params(axis='y', labelcolor='r')
    # ax2.set_ylim(6.5, 7.5)
    # ax.grid(True)
    # # ax2.grid(True)

    # # Adding legends
    # ax.legend(fontsize=12, loc="center left")
    # ax2.legend(fontsize=12, loc="center right")

    # fig.tight_layout(rect=[0, 0, 0.95, 1])  # Adjust rect parameter as needed

    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()



    # filename = "trainlatency_by_N_models_with_rawinput_300filter_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs=[60, 120, 300, 3000]
    # labels = ("Total Training Time (s) for Submodels", )
    # ys_d4trainingtimerawinput_l=[#models
    #     [#dims
    #         [
    #             [2.236, 4.209, 2.428, 2.51, 3.049, 3.11, 2.607, 2.533, 3.219, 3.938, 2.08, 6.05, 4.248, 12.301, 3.214, 2.71, 2.705, 8.022, 2.603, 1.915, 1.512, 1.806, 4.082, 4.392, 1.77, 2.01, 4.226, 2.933, 2.818, 1.923, 3.963, 3.588, 2.467, 2.011, 2.946, 6.876, 2.447, 2.532, 6.21, 2.114, 2.018, 2.968, 3.954, 3.589, 2.191, 2.925, 2.187, 2.762, 5.256, 2.73], [2.234, 2.86, 4.443, 5.557, 3.663, 3.182, 2.515, 3.167, 3.608, 8.675, 1.584, 3.115, 2.161, 2.929, 2.93, 2.393, 3.052, 2.724, 2.692, 6.881, 2.583, 3.26, 2.743, 8.186, 2.19, 1.769, 5.494, 2.457, 2.925, 3.217, 2.459, 1.98, 1.939, 4.588, 2.421, 2.749, 3.017, 3.808, 3.288, 2.447, 3.125, 2.656, 2.631, 1.308, 2.299, 1.406, 4.316, 12.402, 4.02, 2.326], [4.645, 2.372, 2.247, 2.234, 7.856, 3.166, 2.464, 2.423, 3.644, 2.517, 2.389, 2.851, 5.925, 1.914, 2.443, 2.13, 12.786, 2.294, 8.741, 2.384, 1.947, 5.934, 2.177, 2.603, 2.768, 4.504, 2.873, 2.375, 2.054, 3.018, 3.329, 2.804, 1.984, 1.965, 3.333, 2.178, 2.471, 1.786, 2.153, 1.861, 8.07, 1.919, 2.212, 2.479, 2.814, 2.522, 3.072, 3.619, 4.129, 2.732]
    #         ]
    #     ],    
    #     [
    #         [
    #             [12.156, 6.961, 11.058, 7.813, 9.737, 13.431, 27.468, 8.145, 18.968, 7.589, 5.238, 10.372, 3.881, 10.532, 5.821, 13.131, 3.743, 17.957, 9.06, 15.217, 8.647, 10.563, 5.785, 7.895, 13.402], [5.677, 17.108, 7.737, 7.341, 22.429, 7.752, 4.823, 6.513, 10.254, 16.172, 7.265, 19.48, 6.355, 12.668, 8.653, 6.061, 10.186, 8.095, 12.045, 8.627, 9.406, 6.937, 6.506, 31.496, 11.758], [12.591, 8.109, 20.071, 7.757, 11.948, 9.663, 14.374, 8.164, 28.058, 20.674, 14.071, 7.695, 11.86, 5.301, 7.704, 10.981, 5.641, 9.189, 6.641, 5.436, 17.11, 5.688, 8.005, 8.844, 9.692]
    #         ]
    #     ],
    #     [
    #         [
    #             [49.414, 46.608, 101.057, 69.227, 40.1, 42.637, 48.874, 83.239, 45.403, 51.621], [59.401, 73.899, 24.249, 67.144, 68.697, 49.869, 42.909, 52.019, 43.25, 101.657], [72.174, 50.497, 58.942, 128.731, 53.453, 43.789, 45.134, 32.338, 60.207, 47.008]
    #         ]
    #     ],
    #     [
    #         [
    #             [5395.731], [5435.128], [5454.122]
    #         ]
    #     ]
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4trainingtimerawinput_l)):
    #     ys_array.append(np.mean(np.sum(ys_d4trainingtimerawinput_l[m_i],axis=(2,)), axis=(1)))
    #     ci_array.append(1.96 * np.std(np.sum(ys_d4trainingtimerawinput_l[m_i],axis=(2,)), axis=1)/np.sqrt(len(np.sum(ys_d4trainingtimerawinput_l[m_i],axis=(2,))[0])))
    # ys_array = np.array(ys_array).T
    # ci_array = np.array(ci_array).T
    # for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v", "o", "s"]):
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='^', capsize=10)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # ax.set_xscale('log')
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # ax.grid()
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()


    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_4"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 3))
    # xs_labels=[60, 120, 300, 3000]
    # xs=[60, 120, 300, 3000]
    # labels = ("Filter=300", "Filter=100")
    # ys_d4nonetrainlat_l=[#models
    #     [#filter or not
    #         [#CV [test_sample_batch_idx: 4,1,2,0,3 [shuffle_idx: 0,1,2]]
    #             2.236, 2.234, 4.645, 4.209, 2.86, 2.372, 2.428, 4.443, 2.247, 2.51, 5.557, 2.234, 3.049, 3.663, 7.856, 3.11, 3.182, 3.166, 2.607, 2.515, 2.464, 2.533, 3.167, 2.423, 3.219, 3.608, 3.644, 3.938, 8.675, 2.517, 2.08, 1.584, 2.389, 6.05, 3.115, 2.851, 4.248, 2.161, 5.925, 12.301, 2.929, 1.914, 3.214, 2.93, 2.443, 2.71, 2.393, 2.13, 2.705, 3.052, 12.786, 8.022, 2.724, 2.294, 2.603, 2.692, 8.741, 1.915, 6.881, 2.384, 1.512, 2.583, 1.947, 1.806, 3.26, 5.934, 4.082, 2.743, 2.177, 4.392, 8.186, 2.603, 1.77, 2.19, 2.768, 2.01, 1.769, 4.504, 4.226, 5.494, 2.873, 2.933, 2.457, 2.375, 2.818, 2.925, 2.054, 1.923, 3.217, 3.018, 3.963, 2.459, 3.329, 3.588, 1.98, 2.804, 2.467, 1.939, 1.984, 2.011, 4.588, 1.965, 2.946, 2.421, 3.333, 6.876, 2.749, 2.178, 2.447, 3.017, 2.471, 2.532, 3.808, 1.786, 6.21, 3.288, 2.153, 2.114, 2.447, 1.861, 2.018, 3.125, 8.07, 2.968, 2.656, 1.919, 3.954, 2.631, 2.212, 3.589, 1.308, 2.479, 2.191, 2.299, 2.814, 2.925, 1.406, 2.522, 2.187, 4.316, 3.072, 2.762, 12.402, 3.619, 5.256, 4.02, 4.129, 2.73, 2.326, 2.732            
    #         ],
    #         [
    #             2.095, 1.874, 4.702, 3.77, 1.841, 2.413, 1.934, 4.402, 2.421, 1.987, 5.203, 2.56, 3.314, 4.244, 7.664, 2.814, 2.476, 3.161, 2.738, 4.06, 2.043, 2.31, 2.776, 2.084, 3.373, 3.376, 3.647, 2.538, 8.541, 2.661, 2.131, 3.04, 2.506, 5.803, 3.799, 2.828, 2.509, 3.326, 5.685, 12.338, 2.028, 2.399, 2.51, 2.206, 2.461, 2.759, 2.868, 2.685, 2.558, 3.254, 12.503, 7.833, 2.82, 4.315, 2.766, 2.788, 8.704, 2.169, 6.495, 2.331, 1.937, 2.288, 1.655, 2.014, 2.944, 5.367, 4.179, 2.57, 1.74, 2.636, 8.317, 2.531, 1.893, 2.529, 2.151, 1.994, 2.509, 4.256, 3.953, 5.301, 1.396, 2.345, 2.472, 1.879, 2.459, 2.627, 2.219, 2.29, 4.271, 2.916, 4.337, 2.489, 3.079, 3.821, 2.391, 3.201, 1.972, 1.836, 1.925, 1.616, 4.455, 3.379, 2.595, 2.457, 3.03, 6.794, 2.886, 2.513, 2.53, 2.98, 2.471, 2.889, 3.631, 1.655, 6.477, 3.251, 2.05, 3.182, 2.316, 1.842, 2.072, 3.068, 7.88, 3.33, 3.234, 1.323, 3.89, 3.063, 3.247, 2.203, 1.401, 2.135, 1.744, 2.137, 3.258, 1.666, 1.395, 1.984, 1.866, 4.304, 2.762, 2.645, 12.962, 2.624, 5.255, 4.222, 4.203, 2.987, 2.1, 2.138
    #         ]
    #     ], 
    #     [
    #         [
    #             12.156, 5.677, 12.591, 6.961, 17.108, 8.109, 11.058, 7.737, 20.071, 7.813, 7.341, 7.757, 9.737, 22.429, 11.948, 13.431, 7.752, 9.663, 27.468, 4.823, 14.374, 8.145, 6.513, 8.164, 18.968, 10.254, 28.058, 7.589, 16.172, 20.674, 5.238, 7.265, 14.071, 10.372, 19.48, 7.695, 3.881, 6.355, 11.86, 10.532, 12.668, 5.301, 5.821, 8.653, 7.704, 13.131, 6.061, 10.981, 3.743, 10.186, 5.641, 17.957, 8.095, 9.189, 9.06, 12.045, 6.641, 15.217, 8.627, 5.436, 8.647, 9.406, 17.11, 10.563, 6.937, 5.688, 5.785, 6.506, 8.005, 7.895, 31.496, 8.844, 13.402, 11.758, 9.692
    #         ],
    #         [
    #             12.161, 5.68, 11.181, 6.54, 17.272, 7.886, 10.715, 7.483, 18.884, 7.405, 8.186, 7.045, 9.809, 22.311, 11.359, 13.818, 5.212, 9.695, 27.713, 8.151, 14.402, 8.118, 6.905, 7.806, 18.653, 9.886, 27.56, 7.684, 16.194, 20.89, 4.224, 6.94, 14.154, 10.173, 19.521, 7.262, 3.82, 6.629, 12.011, 9.966, 13.374, 5.536, 5.864, 8.844, 6.881, 13.045, 9.406, 10.546, 3.847, 10.267, 5.752, 18.465, 7.888, 8.894, 8.911, 12.071, 6.29, 14.755, 8.486, 5.05, 8.608, 9.19, 17.493, 10.4, 7.741, 6.191, 5.372, 5.943, 8.692, 7.692, 31.144, 8.131, 14.36, 10.619, 10.604
    #         ]
    #     ],   
    #     [
    #         [
    #             49.414, 59.401, 72.174, 46.608, 73.899, 50.497, 101.057, 24.249, 58.942, 69.227, 67.144, 128.731, 40.1, 68.697, 53.453, 42.637, 49.869, 43.789, 48.874, 42.909, 45.134, 83.239, 52.019, 32.338, 45.403, 43.25, 60.207, 51.621, 101.657, 47.008
    #         ],
    #         [
    #             50.013, 59.292, 73.023, 46.321, 75.352, 49.452, 100.204, 24.584, 59.266, 67.972, 66.658, 132.18, 40.797, 68.893, 53.657, 42.88, 50.518, 42.572, 48.995, 43.17, 45.268, 83.219, 53.171, 31.703, 45.601, 43.256, 59.359, 51.789, 103.644, 49.702
    #         ]
    #     ],  
    #     [
    #         [
    #             5395.731, 5435.128, 5454.122
    #         ],
    #         [
    #             5307.999, 5318.343, 5291.452
    #         ]
    #     ],
    # ]
    # ys_array, ci_array = [], []
    # for m_i in range(len(ys_d4nonetrainlat_l)):
    #     local_ys_array, local_ci_array = [], []
    #     for f_i in range(len(ys_d4nonetrainlat_l[m_i])):
    #         local_ys_array.append(np.mean(ys_d4nonetrainlat_l[m_i][f_i], axis=(0)))
    #         local_ci_array.append(1.96 * np.std(ys_d4nonetrainlat_l[m_i][f_i], axis=0)/np.sqrt(len(ys_d4nonetrainlat_l[m_i][f_i])))
    #     ys_array.append(local_ys_array)
    #     ci_array.append(local_ci_array)
    # ys_array = np.array(ys_array).T
    # ci_array = np.array(ci_array).T
    # for ys, ci, label, mark in zip(ys_array, ci_array, labels, ["^", "v"]):
    #     ax.scatter(xs, ys, label=label, marker=mark)
    #     ax.errorbar(xs, ys, yerr=ci, fmt='o', capsize=10, marker=mark)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Package Labels per Model", fontsize=20)
    # # ax.set_ylim(0.3,1)
    # ax.set_xscale('log')
    # # ax.set_yscale("log")
    # ax.set_ylabel("Incremental Training Time (s)", fontsize=20)
    # ax.grid()
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()




    # ###########################################################################




























    # # by_N_estimators
    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "inference_latency_by_N_estimators_with_data_0\&2"
    # labels = (
    #     "1*",
    #     "1",
    #     "5",
    #     "10",
    #     "50",
    #     "100"
    # )
    # cate_values_1 = {
    #     "M80": np.array([1.68, 1.68, 1.71, 1.73, 1.91, 2.03]),
    #     "M9": np.array([0.05, 0.0495, 0.050, 0.052, 0.058, 0.064])
    # }
    # cate_values_2 = {
    #     "M89": np.array([1.72, 1.72, 1.75, 1.76, 1.92, 2.00])
    # }
    # cate_values = [cate_values_1, cate_values_2]
    # plotting(fig_path, filename, cate_values, labels)

    # # N models
    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "inference_latency_by_N_models_with_data_0"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M12-M23-M80": np.array([0.03, 0.10, 1.87]),
    #     "M11-M18-MX": np.array([0.07, 0.23, 0]),
    #     "M7-M19-MX": np.array([0.02, 0.22, 0]),
    #     "M11-M20-MX": np.array([0.22, 1.23, 0]),
    #     "M7-MX-MX": np.array([0.07, 0, 0]),
    #     "M12-MX-MX": np.array([0.16, 0, 0]),
    #     "M10-MX-MX_1": np.array([1.07, 0, 0]),
    #     "M10-MX-MX_2": np.array([0.14, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0"
    # labels = (
    #     "8_1000trees","4_2000trees","1_8000trees_64jobs","8_8000trees_64jobs","4_8000trees_64jobs"
    # )
    # cate_values_1 = {
    #     "M12-M23-M80-M12_800t-M23_400t": np.array([0.567, 4.024, 954.138, 4.745, 14.930]),
    #     "M11-M18-MX-M11_800t-M18_400t": np.array([1.965, 9.069, 0, 13.004, 37.666]),
    #     "M7-M19-MX-M17_800t-M19_400t": np.array([0.391, 9.117, 0, 2.896, 46.874]),
    #     "M11-M20-MX-M11_800t-M20_400t": np.array([5.592, 163.841, 0, 41.572, 660.138]),
    #     "M7-MX-MX-M7_800t-MX": np.array([1.020, 0, 0, 8.108, 0]),
    #     "M12-MX-MX-M12_800t-MX": np.array([4.595, 0, 0, 33.791, 0]),
    #     "M10-MX-MX_1-M10_800t-MX": np.array([71.705, 0, 0, 567.631, 0]),
    #     "M10-MX-MX_2-M10_800t-MX": np.array([3.430, 0, 0, 23.669, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M80": np.array([4.351, 19.378, 1012.601]),
    #     "M10-M20-MX_1": np.array([4.476, 19.424, 0]),
    #     "M10-M20-MX_2": np.array([4.585, 19.025, 0]),
    #     "M10-M20-MX_3": np.array([4.337, 18.938, 0]),
    #     "M10-MX-MX_1": np.array([4.997, 0, 0]),
    #     "M10-MX-MX_2": np.array([4.649, 0, 0]),
    #     "M10-MX-MX_3": np.array([6.566, 0, 0]),
    #     "M10-MX-MX_4": np.array([4.633, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_randomint10000000_109319_64jobs"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M80": np.array([32.517, 170.592, 2211.328]),
    #     "M10-M20-MX_1": np.array([30.359, 184.956, 0]),
    #     "M10-M20-MX_2": np.array([33.489, 180.434, 0]),
    #     "M10-M20-MX_3": np.array([31.810, 174.204, 0]),
    #     "M10-MX-MX_1": np.array([29.711, 0, 0]),
    #     "M10-MX-MX_2": np.array([32.490, 0, 0]),
    #     "M10-MX-MX_3": np.array([30.686, 0, 0]),
    #     "M10-MX-MX_4": np.array([33.413, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_zeros_109319_4jobs"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([3.763, 15.673, 62.270, 1609.677]),
    #     "M10-M20-M40-MX_1": np.array([3.946, 15.368, 64.685, 0]),
    #     "M10-M20-M40-MX_2": np.array([3.891, 15.265, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([3.959, 16.010, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([3.846, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([3.881, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([3.975, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([3.967, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_zeros_109319_8jobs"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([3.916, 15.770, 62.100, 870.774]),
    #     "M10-M20-M40-MX_1": np.array([4.182, 15.187, 64.122, 0]),
    #     "M10-M20-M40-MX_2": np.array([3.854, 15.509, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([3.911, 15.700, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([3.835, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([3.966, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([3.861, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([3.918, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_zeros_109319_16jobs"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([3.978, 15.304, 63.182, 934.183]),
    #     "M10-M20-M40-MX_1": np.array([4.342, 14.966, 67.809, 0]),
    #     "M10-M20-M40-MX_2": np.array([3.833, 15.322, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([3.941, 15.755, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([4.139, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([4.078, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([3.850, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([3.854, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_zeros_109319_32jobs"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([4.062, 16.344, 69.733, 953.460]),
    #     "M10-M20-M40-MX_1": np.array([4.249, 16.941, 70.464, 0]),
    #     "M10-M20-M40-MX_2": np.array([4.023, 16.753, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([4.315, 16.776, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([4.178, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([3.963, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([4.115, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([4.303, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)



    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_zeros_109319_64jobs"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([4.141, 17.000, 72.818, 941.116]),
    #     "M10-M20-M40-MX_1": np.array([4.319, 16.714, 70.411, 0]),
    #     "M10-M20-M40-MX_2": np.array([4.381, 16.409, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([4.169, 17.238, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([4.085, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([4.419, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([4.298, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([4.306, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)



    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "train_latency_by_N_models_with_data_0_zeros_109319_128jobs"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([4.458, 18.530, 70.480, 989.714]),
    #     "M10-M20-M40-MX_1": np.array([4.408, 17.776, 70.406, 0]),
    #     "M10-M20-M40-MX_2": np.array([4.385, 18.414, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([4.235, 18.987, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([4.712, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([4.650, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([5.174, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([4.713, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "input_size_by_N_models_with_data_0"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M12-M23-M80": np.array([510, 4183, 109319]),
    #     "M11-M18-MX": np.array([3691, 13930, 0]),
    #     "M7-M19-MX": np.array([454, 13182, 0]),
    #     "M11-M20-MX": np.array([13495, 78424, 0]),
    #     "M7-MX-MX": np.array([3560, 0, 0]),
    #     "M12-MX-MX": np.array([9740, 0, 0]),
    #     "M10-MX-MX_1": np.array([70225, 0, 0]),
    #     "M10-MX-MX_2": np.array([8498, 0, 0]),
    # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "input_size_by_N_models_with_data_0"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M80": np.array([13664, 27329, 109319]),
    #     "M10-M20-MX_1": np.array([13664, 27329, 0]),
    #     "M10-M20-MX_2": np.array([13664, 27329, 0]),
    #     "M10-M20-MX_3": np.array([13664, 27329, 0]),
    #     "M10-MX-MX_1": np.array([13664, 0, 0]),
    #     "M10-MX-MX_2": np.array([13664, 0, 0]),
    #     "M10-MX-MX_3": np.array([13664, 0, 0]),
    #     "M10-MX-MX_4": np.array([13664, 0, 0]),
    # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "Traintime_by_Inputsize_for_Fixed_10_Labels"
    

    # data = np.array([])
    # labels = [None]*len(data)
    # cate_values_1 = {
    #     "": data
    # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "Numoftrees_by_N_models_with_data_0"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M12-M23-M80": np.array([1200, 2300, 8000]),
    #     "M11-M18-MX": np.array([1100, 1800, 0]),
    #     "M7-M19-MX": np.array([700, 1900, 0]),
    #     "M11-M20-MX": np.array([1100, 2000, 0]),
    #     "M7-MX-MX": np.array([700, 0, 0]),
    #     "M12-MX-MX": np.array([1200, 0, 0]),
    #     "M10-MX-MX_1": np.array([1000, 0, 0]),
    #     "M10-MX-MX_2": np.array([1000, 0, 0]),
    # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "Numoflabels_by_N_models_with_data_0"
    # labels = (
    #     "8","4","1"
    # )
    # cate_values_1 = {
    #     "M12-M23-M80": np.array([12, 23, 80]),
    #     "M11-M18-MX": np.array([11, 18, 0]),
    #     "M7-M19-MX": np.array([7, 19, 0]),
    #     "M11-M20-MX": np.array([11, 20, 0]),
    #     "M7-MX-MX": np.array([7, 0, 0]),
    #     "M12-MX-MX": np.array([12, 0, 0]),
    #     "M10-MX-MX_1": np.array([10, 0, 0]),
    #     "M10-MX-MX_2": np.array([10, 0, 0]),
    # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "outputsize_by_N_models_with_rawinput_data_0"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([13664, 27329, 54659, 109319]),
    #     "M10-M20-M40-MX_1": np.array([13664, 27329, 54659, 0]),
    #     "M10-M20-M40-MX_2": np.array([13664, 27329, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([13664, 27329, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([13664, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([13664, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([13664, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([13664, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "-": np.array([0, 0, 0])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels)



    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_N_models_with_rawinput_data_0"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([2.407, 18.840, 143.565, 1090.042]),
    #     "M10-M20-M40-MX_1": np.array([2.396, 18.788, 143.717, 0]),
    #     "M10-M20-M40-MX_2": np.array([2.413, 19.016, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([2.407, 18.862, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([2.406, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([2.396, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([2.440, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([2.396, 0, 0, 0]),
    # }
    # cate_values_2 = {
    #     "Estimated": np.array([8*2.4, 4*2.4*2*(4*math.log(25*20)/math.log(25*10)), 2*19.0*2*(4*math.log(25*40)/math.log(25*20)), 143.5*2*(4*math.log(25*80)/math.log(25*40))])
    # }
    # cate_values = [cate_values_1, cate_values_2]
    # plotting(fig_path, filename, cate_values, labels, xaxis_label="Number of Models", yaxis_label="Training Time(s)", title="Train Latency by N Models with the Same Train Dataset")

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatencypermodel_by_N_models_with_rawinput_data_0"
    # labels = (
    #     "10","20","40","80"
    # )
    # cate_values_1 = {
    #     "M10-M20-M40-M80": np.array([2.407, 18.840, 143.565, 1090.042]),
    #     # "M10-M20-M40-MX_1": np.array([2.396, 18.788, 143.717, 0]),
    #     # "M10-M20-M40-MX_2": np.array([2.413, 19.016, 0, 0]),
    #     # "M10-M20-M40-MX_3": np.array([2.407, 18.862, 0, 0]),
    #     # "M10-MX-MX-MX_1": np.array([2.406, 0, 0, 0]),
    #     # "M10-MX-MX-MX_2": np.array([2.396, 0, 0, 0]),
    #     # "M10-MX-MX-MX_3": np.array([2.440, 0, 0, 0]),
    #     # "M10-MX-MX-MX_4": np.array([2.396, 0, 0, 0]),
    # }
    # # cate_values_2 = {
    # #     "Estimated": np.array([8*2.4, 4*2.4*2*(4*math.log(25*20)/math.log(25*10)), 2*19.0*2*(4*math.log(25*40)/math.log(25*20)), 143.5*2*(4*math.log(25*80)/math.log(25*40))])
    # # }
    # cate_values = [cate_values_1]
    # plotting(fig_path, filename, cate_values, labels, xaxis_label="Number of Labels Per Model", yaxis_label="Training Time(s)", title="Train Latency by N Models with the Same Train Dataset")


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatencypermodel_by_N_models_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=["10","20","40","80"]
    # # labels = ("Observed", "Estimated")
    # ys=[2.407, 18.840, 143.565, 1090.042]
    # # for ys, label in zip(ys_l, labels):
    # p = ax.bar(xs, ys)
    # ax.bar_label(p)
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Packages", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "inferencelatency_by_N_models_with_rawinput_data_0"
    # labels = (
    #     "8","4","2","1"
    # )
    # cate_values_1_l = [{
    #     "M10-M20-M40-M80": np.array([0.026, 0.099, 0.179, 2.072]),
    #     "M10-M20-M40-MX_1": np.array([0.075, 0.090, 1.785, 0]),
    #     "M10-M20-M40-MX_2": np.array([0.025, 0.398, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([0.067, 1.325, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([0.236, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([0.157, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([1.110, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([0.149, 0, 0, 0]),
    # },{
    #     "M10-M20-M40-M80": np.array([0.026, 0.092, 0.171, 1.954]),
    #     "M10-M20-M40-MX_1": np.array([0.073, 0.085, 1.713, 0]),
    #     "M10-M20-M40-MX_2": np.array([0.023, 0.374, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([0.064, 1.236, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([0.234, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([0.148, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([1.086, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([0.142, 0, 0, 0]),
    # },{
    #     "M10-M20-M40-M80": np.array([0.024, 0.092, 0.171, 2.192]),
    #     "M10-M20-M40-MX_1": np.array([0.073, 0.088, 1.676, 0]),
    #     "M10-M20-M40-MX_2": np.array([0.023, 0.373, 0, 0]),
    #     "M10-M20-M40-MX_3": np.array([0.066, 1.224, 0, 0]),
    #     "M10-MX-MX-MX_1": np.array([0.235, 0, 0, 0]),
    #     "M10-MX-MX-MX_2": np.array([0.149, 0, 0, 0]),
    #     "M10-MX-MX-MX_3": np.array([1.072, 0, 0, 0]),
    #     "M10-MX-MX-MX_4": np.array([0.143, 0, 0, 0]),
    # }]
    # cate_values_1 = {"M10-M20-M40-M80": [],
    #     "M10-M20-M40-MX_1": [],
    #     "M10-M20-M40-MX_2": [],
    #     "M10-M20-M40-MX_3": [],
    #     "M10-MX-MX-MX_1": [],
    #     "M10-MX-MX-MX_2": [],
    #     "M10-MX-MX-MX_3": [],
    #     "M10-MX-MX-MX_4": []}
    # cate_stds_1 = {"errors": []}
    # for d in cate_values_1_l:
    #     for k, v in cate_values_1.items():
    #         cate_values_1[k].append(d[k])
    # for k, v in cate_values_1.items():
    #     cate_values_1[k] = np.vstack(cate_values_1[k])
    #     cate_stds_1[k] = np.var(cate_values_1[k], axis=0)
    #     cate_values_1[k] = np.mean(cate_values_1[k], axis=0)
    # cate_values = [cate_values_1]
    # cate_stds = [cate_stds_1]
    # plotting(fig_path, filename, cate_values, labels, cates_stds=cate_stds, xaxis_label="Number of Labels Per Model", yaxis_label="Inference Time(s)", title="Inference Latency by N Models with the Same Test Dataset")









    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_input_size_and_by_N_models_with_data_0_3d"
    # # Fixing random state for reproducibility
    # np.random.seed(19680801)

    # fig = plt.figure()
    # ax = fig.add_subplot(projection='3d')

    # xs=[13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319, 
    #     13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319, 
    #     13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319, 
    #     13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319]   # input sizes
    # ys=[80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 
    #     40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 
    #     20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 
    #     10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]   # number of labels
    # zs=[1.227, 2.012, 3.810, 5.275, 9.333, 12.124, 17.675, 34.274, 67.655, 136.472, 274.488, 546.612, 1096.709, 
    #     0.315, 0.550, 1.027, 1.514, 2.580, 3.246, 4.596, 8.739, 17.492, 34.972, 70.854, 143.565, 286.711, 
    #     0.229, 0.290, 0.406, 0.451, 0.700, 0.928, 1.255, 2.366, 4.464, 9.328, 18.840, 39.945, 80.171, 
    #     0.102, 0.103, 0.143, 0.156, 0.226, 0.278, 0.392, 0.664, 1.205, 2.407, 5.449, 11.784, 24.566]   # training latency
    # # xs=[13, 106, 854, 13, 106, 854, 13, 106, 854, 13, 106, 854]   # input sizes
    # # ys=[80, 80, 80, 40, 40, 40, 20, 20, 20, 10, 10, 10]   # number of labels
    # # zs=[1.227, 2.012, 9.333, 0.315, 0.550, 2.580, 0.229, 0.290, 0.700, 0.102, 0.103, 0.226]   # training latency

    # ax.scatter(xs, ys, zs, marker='o')

    # ax.set_xlabel('Feature Dimensions')
    # ax.set_ylabel('Labels Per Model')
    # ax.set_zlabel('Training Latency')

    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()




    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_inputsize_and_by_samplesize_with_data_3_25_3d"

    # fig = plt.figure()
    # ax = fig.add_subplot(projection='3d')

    # samplesize=[357.0, 419.0, 377.0, 357.0, 356.0, 336.0, 360.0, 339.0, 297.0, 338.0, 358.0, 378.0, 393.0, 397.0, 337.0, 375.0, 353.0, 374.0, 294.0, 355.0, 339.0, 330.0, 375.0, 375.0, 317.0, 334.0, 355.0, 335.0, 333.0, 396.0, 378.0, 349.0, 275.0, 395.0, 339.0, 318.0, 399.0, 299.0, 355.0, 357.0, 359.0, 336.0, 337.0, 378.0, 334.0, 334.0, 380.0, 355.0, 337.0, 375.0, 379.0, 357.0, 328.0, 396.0, 317.0, 331.0, 392.0, 358.0, 359.0, 378.0, 356.0, 338.0, 380.0, 399.0, 360.0, 299.0, 374.0, 359.0, 412.0, 278.0, 259.0, 259.0, 357.0, 357.0, 351.0, 395.0, 418.0, 335.0, 398.0, 357.0, 377.0, 313.0, 353.0, 391.0, 333.0, 375.0, 351.0, 316.0, 358.0, 334.0, 337.0, 353.0, 357.0, 318.0, 340.0, 320.0, 372.0, 298.0, 319.0, 418.0, 295.0, 397.0, 400.0, 359.0, 377.0, 395.0, 311.0, 337.0, 357.0, 339.0, 338.0, 319.0, 377.0, 379.0, 280.0, 398.0, 336.0, 332.0, 355.0, 318.0, 375.0, 376.0, 359.0, 336.0, 397.0, 394.0, 378.0, 358.0, 299.0, 337.0, 335.0, 359.0, 375.0, 397.0, 336.0, 339.0, 372.0, 398.0, 356.0, 275.0, 371.0, 296.0, 279.0, 299.0, 336.0, 375.0, 353.0, 336.0, 355.0, 297.0, 335.0, 356.0, 355.0, 353.0, 315.0, 399.0, 276.0, 339.0, 338.0, 359.0, 396.0, 300.0, 355.0, 351.0, 371.0, 337.0, 400.0, 377.0, 396.0, 377.0, 313.0, 330.0, 319.0, 355.0, 314.0, 393.0, 316.0, 378.0, 394.0, 339.0, 400.0, 400.0, 297.0, 340.0, 256.0, 375.0, 357.0, 356.0, 395.0, 398.0, 357.0, 372.0, 336.0, 335.0, 397.0, 358.0, 359.0, 360.0, 359.0, 371.0, 416.0, 375.0, 359.0, 335.0, 358.0, 358.0, 340.0, 336.0, 353.0, 354.0, 376.0, 299.0, 360.0, 334.0, 259.0, 318.0, 314.0, 380.0, 320.0, 377.0, 351.0, 340.0, 377.0, 337.0, 358.0, 319.0, 379.0, 370.0, 339.0, 393.0, 314.0, 378.0, 356.0, 338.0, 355.0, 299.0, 359.0, 392.0, 373.0, 359.0, 337.0, 358.0, 358.0, 298.0, 397.0, 331.0, 399.0, 354.0, 395.0, 376.0, 357.0, 360.0, 395.0, 359.0, 355.0, 357.0, 315.0, 298.0, 359.0, 319.0, 395.0, 355.0, 357.0, 299.0, 337.0, 295.0, 377.0, 355.0, 414.0, 350.0, 394.0, 332.0, 378.0, 316.0, 355.0, 376.0, 375.0, 378.0, 352.0, 315.0, 316.0, 393.0, 354.0, 339.0, 358.0, 259.0, 319.0, 299.0, 353.0, 360.0, 336.0, 319.0, 357.0, 340.0, 337.0, 319.0, 339.0, 316.0, 394.0, 355.0, 360.0, 379.0, 395.0, 348.0, 396.0, 357.0, 331.0, 376.0, 367.0, 338.0, 336.0, 376.0, 360.0, 357.0, 317.0, 338.0, 376.0, 296.0, 394.0, 333.0, 320.0, 313.0, 336.0, 376.0, 354.0, 378.0, 356.0, 360.0, 356.0, 377.0, 420.0, 391.0, 338.0, 356.0, 319.0, 376.0, 415.0, 339.0, 376.0, 337.0, 300.0, 400.0, 335.0, 396.0, 359.0, 319.0, 319.0, 298.0, 396.0, 310.0, 392.0, 380.0, 375.0, 336.0, 357.0, 355.0, 359.0, 296.0, 275.0, 291.0]
    # dimensions=[10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0]
    # traintimes=[1.548, 1.972, 1.678, 1.549, 1.506, 1.4, 1.53, 1.524, 1.134, 1.439, 1.493, 1.616, 1.877, 1.758, 1.373, 1.693, 1.508, 1.604, 1.137, 1.537, 1.426, 1.388, 1.682, 1.66, 1.287, 1.377, 1.376, 1.378, 1.366, 1.675, 1.674, 1.501, 0.944, 1.82, 1.402, 1.184, 1.811, 1.143, 1.468, 1.494, 1.532, 1.363, 1.395, 1.732, 1.452, 1.377, 1.681, 1.506, 1.432, 1.783, 1.697, 1.57, 1.383, 1.852, 1.269, 1.378, 1.771, 1.502, 1.536, 1.673, 1.527, 1.397, 1.689, 1.895, 1.529, 1.178, 1.715, 1.525, 1.945, 1.027, 0.927, 0.907, 0.524, 0.414, 0.458, 0.572, 0.513, 0.433, 0.582, 0.466, 0.482, 0.443, 0.426, 0.532, 0.463, 0.677, 0.457, 0.342, 0.471, 0.431, 0.459, 0.437, 0.481, 0.315, 0.518, 0.437, 0.498, 0.374, 0.431, 0.539, 0.413, 0.52, 0.552, 0.463, 0.483, 0.641, 0.402, 0.473, 0.417, 0.456, 0.59, 0.371, 0.474, 0.505, 0.366, 0.457, 0.608, 0.647, 0.429, 0.604, 0.745, 0.482, 0.507, 0.495, 0.566, 0.476, 0.502, 0.491, 0.507, 0.463, 0.478, 0.483, 0.525, 0.552, 0.385, 0.465, 0.493, 0.503, 0.496, 0.319, 0.533, 0.309, 0.386, 0.43, 0.388, 0.419, 0.41, 0.375, 0.367, 0.248, 0.341, 0.353, 0.279, 0.36, 0.332, 0.325, 0.287, 0.355, 0.254, 0.364, 0.443, 0.223, 0.369, 0.395, 0.444, 0.327, 0.41, 0.364, 0.419, 0.39, 0.36, 0.336, 0.349, 0.412, 0.326, 0.426, 0.386, 0.376, 0.416, 0.372, 0.351, 0.433, 0.316, 0.295, 0.263, 0.41, 0.295, 0.378, 0.401, 0.378, 0.352, 0.459, 0.33, 0.36, 0.44, 0.368, 0.392, 0.368, 0.371, 0.429, 0.439, 0.402, 0.405, 0.368, 0.373, 0.415, 0.393, 0.347, 0.381, 0.395, 0.418, 0.317, 0.398, 0.383, 0.283, 0.382, 0.817, 1.041, 0.804, 0.986, 0.93, 0.882, 0.999, 0.869, 0.955, 0.811, 1.022, 1.016, 0.815, 1.124, 0.773, 1.009, 0.96, 0.868, 0.927, 0.736, 0.946, 1.084, 1.014, 0.95, 0.839, 0.937, 0.933, 0.72, 1.096, 0.818, 1.11, 0.938, 1.059, 1.018, 0.937, 0.935, 1.066, 0.962, 0.94, 0.938, 0.817, 0.733, 0.938, 0.795, 1.13, 0.947, 0.938, 0.713, 0.849, 0.733, 1.012, 0.927, 1.196, 0.959, 1.086, 0.874, 1.018, 0.8, 0.948, 1.064, 1.012, 1.031, 0.955, 0.785, 0.823, 1.117, 0.95, 0.865, 0.951, 0.611, 0.808, 0.721, 2.067, 2.165, 2.045, 1.779, 2.155, 2.015, 2.009, 1.809, 1.878, 1.81, 2.49, 2.053, 2.102, 2.298, 2.488, 2.114, 2.432, 2.055, 2.033, 2.26, 2.266, 2.04, 1.947, 2.254, 2.177, 2.068, 1.752, 1.93, 2.272, 1.633, 2.561, 1.967, 1.706, 1.798, 1.99, 2.268, 2.084, 2.286, 2.081, 2.239, 2.183, 2.288, 2.754, 2.578, 1.886, 2.121, 1.74, 2.251, 2.749, 2.034, 2.298, 1.971, 1.607, 2.479, 1.97, 2.514, 2.083, 1.741, 1.734, 1.615, 2.539, 1.709, 2.469, 2.317, 2.256, 1.859, 2.158, 2.065, 2.091, 1.576, 1.409, 1.549]
    
    # colo = traintimes 
    # color_map = cm.ScalarMappable(cmap=cm.summer) 
    # color_map.set_array(colo) 
    # colo_normalized = [c/max(colo) for c in colo]
    # # ax.plot_trisurf(samplesize, dimensions, traintimes, cmap=cm.coolwarm, linewidth=0, antialiased=False)
    # ax.scatter(samplesize, dimensions, traintimes, facecolors=cm.summer(colo_normalized), edgecolor=cm.summer(colo_normalized), alpha=1)
    # # ax.scatter(samplesize, dimensions, facecolors=cm.PiYG(colo_normalized), edgecolor=cm.PiYG(colo_normalized), alpha=1)
    # # plt.colorbar(color_map,label='Training Latency (s)') 

    # ax.set_xlabel('Sample Size')
    # ax.set_ylabel('Feature Dimension Size')
    # ax.set_zlabel('Training Latency')
    # # ax.zaxis.labelpad = -4
    # ax.view_init(azim=270, elev=0)

    # # plt.show()
    # # fig.set_size_inches(6, 8)
    # fig.tight_layout()
    # # fig.subplots_adjust(left=-2) 
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()






    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_inputsize_and_by_samplesize_with_data_3_10_3d"

    # fig = plt.figure()
    # ax = fig.add_subplot(projection='3d')

    # samplesize=[856.0, 872.0, 896.0, 815.0, 806.0, 916.0, 849.0, 923.0, 895.0, 851.0, 773.0, 845.0, 974.0, 917.0, 851.0, 864.0, 893.0, 868.0, 874.0, 914.0, 794.0, 910.0, 770.0, 871.0, 750.0, 909.0, 862.0, 689.0, 655.0, 634.0, 892.0, 884.0, 794.0, 763.0, 789.0, 927.0, 754.0, 894.0, 886.0, 977.0, 927.0, 850.0, 904.0, 773.0, 835.0, 873.0, 836.0, 871.0, 814.0, 915.0, 773.0, 814.0, 811.0, 910.0, 908.0, 888.0, 912.0, 733.0, 715.0, 674.0, 930.0, 910.0, 874.0, 893.0, 917.0, 847.0, 833.0, 836.0, 929.0, 850.0, 851.0, 891.0, 779.0, 889.0, 807.0, 791.0, 828.0, 835.0, 850.0, 890.0, 933.0, 906.0, 767.0, 873.0, 863.0, 829.0, 749.0, 737.0, 715.0, 694.0, 872.0, 869.0, 851.0, 786.0, 807.0, 828.0, 897.0, 883.0, 914.0, 863.0, 810.0, 830.0, 883.0, 936.0, 808.0, 813.0, 912.0, 830.0, 869.0, 797.0, 936.0, 896.0, 850.0, 810.0, 859.0, 854.0, 892.0, 694.0, 714.0, 733.0, 856.0, 801.0, 855.0, 814.0, 832.0, 829.0, 846.0, 817.0, 933.0, 823.0, 891.0, 777.0, 910.0, 868.0, 890.0, 896.0, 839.0, 908.0, 856.0, 870.0, 767.0, 824.0, 949.0, 889.0, 856.0, 830.0, 893.0, 751.0, 735.0, 691.0]
    # dimensions=[10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0]
    # traintimes=[6.934, 7.13, 7.448, 6.346, 6.214, 7.82, 6.868, 7.988, 7.506, 6.899, 5.759, 6.852, 8.728, 7.82, 6.87, 7.046, 7.462, 7.118, 7.131, 7.794, 6.013, 7.739, 5.673, 7.187, 5.464, 7.775, 7.105, 4.659, 4.217, 3.96, 1.521, 2.004, 1.224, 1.27, 1.189, 1.542, 1.645, 1.961, 1.451, 1.801, 1.53, 2.028, 1.56, 1.175, 1.335, 1.447, 1.267, 1.423, 1.277, 1.477, 1.237, 1.277, 1.63, 2.064, 1.485, 1.467, 1.533, 1.119, 1.081, 0.996, 1.153, 1.545, 1.075, 1.082, 1.183, 1.029, 0.955, 0.977, 1.205, 1.024, 1.012, 1.09, 0.904, 1.09, 0.992, 1.356, 0.989, 1.018, 0.989, 1.109, 1.207, 1.137, 0.887, 1.086, 1.055, 1.012, 0.945, 0.968, 0.865, 1.056, 4.196, 4.138, 3.913, 3.469, 3.61, 3.689, 4.418, 4.229, 4.42, 4.087, 3.536, 3.654, 4.267, 4.571, 3.493, 3.631, 4.295, 3.689, 4.16, 3.438, 4.531, 4.401, 3.872, 3.51, 3.968, 3.897, 4.2, 2.776, 2.812, 2.971, 10.203, 9.079, 10.084, 9.181, 9.764, 9.593, 10.081, 9.308, 12.051, 9.63, 11.009, 8.458, 11.548, 10.519, 10.946, 11.1, 9.797, 11.51, 10.125, 10.545, 8.346, 9.56, 12.463, 11.048, 10.171, 9.644, 11.024, 7.95, 7.699, 6.843]
    
    # colo = traintimes 
    # color_map = cm.ScalarMappable(cmap=cm.summer) 
    # color_map.set_array(colo) 
    # colo_normalized = [c/max(colo) for c in colo]
    # # ax.plot_trisurf(samplesize, dimensions, traintimes, cmap=cm.coolwarm, linewidth=0, antialiased=False)
    # ax.scatter(samplesize, dimensions, traintimes, facecolors=cm.summer(colo_normalized), edgecolor=cm.summer(colo_normalized), alpha=1)
    # # ax.scatter(samplesize, dimensions, facecolors=cm.PiYG(colo_normalized), edgecolor=cm.PiYG(colo_normalized), alpha=1)
    # # plt.colorbar(color_map,label='Training Latency (s)') 

    # ax.set_xlabel('Sample Size')
    # ax.set_ylabel('Feature Dimension Size')
    # ax.set_zlabel('Training Latency')
    # # ax.zaxis.labelpad = -4
    # ax.view_init(azim=180, elev=0)

    # # plt.show()
    # # fig.set_size_inches(6, 8)
    # fig.tight_layout()
    # # fig.subplots_adjust(left=-2) 
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()





    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainf1score_by_inputsize_and_by_samplesize_with_data_3_heat"

    # fig = plt.figure()
    # ax = fig.add_subplot()

    # samplesize=[
    #     336.0, 333.0, 371.0, 373.0, 256.0, 379.0, 356.0, 379.0, 357.0, 353.0, 297.0, 358.0, 378.0, 336.0, 358.0, 339.0, 376.0, 378.0, 359.0, 335.0, 377.0, 372.0, 374.0, 399.0, 313.0, 379.0, 318.0, 334.0, 394.0, 374.0, 333.0, 379.0, 275.0, 374.0, 373.0, 349.0, 338.0, 378.0, 396.0, 378.0, 318.0, 375.0, 379.0, 353.0, 375.0, 398.0, 355.0, 255.0, 319.0, 335.0, 337.0, 360.0, 356.0, 380.0, 336.0, 377.0, 334.0, 336.0, 359.0, 360.0, 379.0, 360.0, 359.0, 336.0, 360.0, 372.0, 357.0, 376.0, 339.0, 296.0, 294.0, 257.0, 357.0, 419.0, 377.0, 357.0, 356.0, 336.0, 360.0, 339.0, 297.0, 338.0, 358.0, 378.0, 393.0, 397.0, 337.0, 375.0, 353.0, 374.0, 294.0, 355.0, 339.0, 330.0, 375.0, 375.0, 317.0, 334.0, 355.0, 335.0, 333.0, 396.0, 378.0, 349.0, 275.0, 395.0, 339.0, 318.0, 399.0, 299.0, 355.0, 357.0, 359.0, 336.0, 337.0, 378.0, 334.0, 334.0, 380.0, 355.0, 337.0, 375.0, 379.0, 357.0, 328.0, 396.0, 317.0, 331.0, 392.0, 358.0, 359.0, 378.0, 356.0, 338.0, 380.0, 399.0, 360.0, 299.0, 374.0, 359.0, 412.0, 278.0, 259.0, 259.0, 357.0, 357.0, 351.0, 395.0, 418.0, 335.0, 398.0, 357.0, 377.0, 313.0, 353.0, 391.0, 333.0, 375.0, 351.0, 316.0, 358.0, 334.0, 337.0, 353.0, 357.0, 318.0, 340.0, 320.0, 372.0, 298.0, 319.0, 418.0, 295.0, 397.0, 400.0, 359.0, 377.0, 395.0, 311.0, 337.0, 357.0, 339.0, 338.0, 319.0, 377.0, 379.0, 280.0, 398.0, 336.0, 332.0, 355.0, 318.0, 375.0, 376.0, 359.0, 336.0, 397.0, 394.0, 378.0, 358.0, 299.0, 337.0, 335.0, 359.0, 375.0, 397.0, 336.0, 339.0, 372.0, 398.0, 356.0, 275.0, 371.0, 296.0, 279.0, 299.0, 336.0, 375.0, 353.0, 336.0, 355.0, 297.0, 335.0, 356.0, 355.0, 353.0, 315.0, 399.0, 276.0, 339.0, 338.0, 359.0, 396.0, 300.0, 355.0, 351.0, 371.0, 337.0, 400.0, 377.0, 396.0, 377.0, 313.0, 330.0, 319.0, 355.0, 314.0, 393.0, 316.0, 378.0, 394.0, 339.0, 400.0, 400.0, 297.0, 340.0, 256.0, 375.0, 357.0, 356.0, 395.0, 398.0, 357.0, 372.0, 336.0, 335.0, 397.0, 358.0, 359.0, 360.0, 359.0, 371.0, 416.0, 375.0, 359.0, 335.0, 358.0, 358.0, 340.0, 336.0, 353.0, 354.0, 376.0, 299.0, 360.0, 334.0, 259.0, 318.0, 314.0, 380.0, 320.0, 377.0, 351.0, 340.0, 377.0, 337.0, 358.0, 319.0, 379.0, 370.0, 339.0, 393.0, 314.0, 378.0, 356.0, 338.0, 355.0, 299.0, 359.0, 392.0, 373.0, 359.0, 337.0, 358.0, 358.0, 298.0, 397.0, 331.0, 399.0, 354.0, 395.0, 376.0, 357.0, 360.0, 395.0, 359.0, 355.0, 357.0, 315.0, 298.0, 359.0, 319.0, 395.0, 355.0, 357.0, 299.0, 337.0, 295.0, 377.0, 355.0, 414.0, 350.0, 394.0, 332.0, 378.0, 316.0, 355.0, 376.0, 375.0, 378.0, 352.0, 315.0, 316.0, 393.0, 354.0, 339.0, 358.0, 259.0, 319.0, 299.0, 353.0, 360.0, 336.0, 319.0, 357.0, 340.0, 337.0, 319.0, 339.0, 316.0, 394.0, 355.0, 360.0, 379.0, 395.0, 348.0, 396.0, 357.0, 331.0, 376.0, 367.0, 338.0, 336.0, 376.0, 360.0, 357.0, 317.0, 338.0, 376.0, 296.0, 394.0, 333.0, 320.0, 313.0, 336.0, 376.0, 354.0, 378.0, 356.0, 360.0, 356.0, 377.0, 420.0, 391.0, 338.0, 356.0, 319.0, 376.0, 415.0, 339.0, 376.0, 337.0, 300.0, 400.0, 335.0, 396.0, 359.0, 319.0, 319.0, 298.0, 396.0, 310.0, 392.0, 380.0, 375.0, 336.0, 357.0, 355.0, 359.0, 296.0, 275.0, 291.0,
    #     933.0, 752.0, 934.0, 732.0, 873.0, 834.0, 837.0, 887.0, 784.0, 913.0, 949.0, 872.0, 865.0, 887.0, 832.0, 895.0, 772.0, 835.0, 848.0, 830.0, 889.0, 849.0, 952.0, 965.0, 828.0, 873.0, 811.0, 732.0, 657.0, 676.0, 856.0, 872.0, 896.0, 815.0, 806.0, 916.0, 849.0, 923.0, 895.0, 851.0, 773.0, 845.0, 974.0, 917.0, 851.0, 864.0, 893.0, 868.0, 874.0, 914.0, 794.0, 910.0, 770.0, 871.0, 750.0, 909.0, 862.0, 689.0, 655.0, 634.0, 892.0, 884.0, 794.0, 763.0, 789.0, 927.0, 754.0, 894.0, 886.0, 977.0, 927.0, 850.0, 904.0, 773.0, 835.0, 873.0, 836.0, 871.0, 814.0, 915.0, 773.0, 814.0, 811.0, 910.0, 908.0, 888.0, 912.0, 733.0, 715.0, 674.0, 930.0, 910.0, 874.0, 893.0, 917.0, 847.0, 833.0, 836.0, 929.0, 850.0, 851.0, 891.0, 779.0, 889.0, 807.0, 791.0, 828.0, 835.0, 850.0, 890.0, 933.0, 906.0, 767.0, 873.0, 863.0, 829.0, 749.0, 737.0, 715.0, 694.0, 872.0, 869.0, 851.0, 786.0, 807.0, 828.0, 897.0, 883.0, 914.0, 863.0, 810.0, 830.0, 883.0, 936.0, 808.0, 813.0, 912.0, 830.0, 869.0, 797.0, 936.0, 896.0, 850.0, 810.0, 859.0, 854.0, 892.0, 694.0, 714.0, 733.0, 856.0, 801.0, 855.0, 814.0, 832.0, 829.0, 846.0, 817.0, 933.0, 823.0, 891.0, 777.0, 910.0, 868.0, 890.0, 896.0, 839.0, 908.0, 856.0, 870.0, 767.0, 824.0, 949.0, 889.0, 856.0, 830.0, 893.0, 751.0, 735.0, 691.0
    # ]
    # dimensions=[
    #     1919.0, 812.0, 5972.0, 1005.0, 504.0, 1338.0, 854.0, 5483.0, 2373.0, 209.0, 2555.0, 701.0, 570.0, 264.0, 1060.0, 359.0, 1426.0, 558.0, 657.0, 791.0, 274.0, 1130.0, 2081.0, 3647.0, 483.0, 1309.0, 1076.0, 446.0, 570.0, 526.0, 2215.0, 934.0, 1170.0, 712.0, 447.0, 683.0, 787.0, 2179.0, 995.0, 6628.0, 651.0, 230.0, 604.0, 285.0, 3025.0, 1879.0, 6594.0, 281.0, 700.0, 2436.0, 6490.0, 2996.0, 2326.0, 2445.0, 6272.0, 399.0, 272.0, 1884.0, 2149.0, 1794.0, 460.0, 891.0, 1012.0, 3686.0, 499.0, 1250.0, 716.0, 997.0, 336.0, 632.0, 1143.0, 252.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0,
    #     3745.0, 1473.0, 1918.0, 6098.0, 2951.0, 4813.0, 2525.0, 3981.0, 6887.0, 8209.0, 3656.0, 2869.0, 826.0, 7237.0, 1211.0, 5554.0, 1921.0, 2998.0, 2778.0, 11220.0, 7947.0, 2094.0, 1190.0, 2327.0, 3749.0, 2375.0, 3150.0, 1771.0, 1453.0, 3085.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 10000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 1000.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 500.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 5000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0, 15000.0
    # ]   # number of labels
    # traintimes=[
    #     0.506, 0.435, 1.12, 0.371, 0.269, 0.659, 0.317, 1.055, 0.635, 0.242, 0.562, 0.433, 0.315, 0.333, 0.506, 0.254, 0.627, 0.403, 0.345, 0.436, 0.33, 0.518, 0.612, 0.904, 0.302, 0.617, 0.409, 0.329, 0.438, 0.355, 0.533, 0.555, 0.533, 0.65, 0.401, 0.415, 0.391, 0.654, 0.56, 1.189, 0.453, 0.341, 0.418, 0.331, 0.743, 0.774, 1.123, 0.223, 0.4, 0.635, 0.982, 0.675, 0.754, 0.626, 0.969, 0.425, 0.299, 0.989, 0.655, 0.536, 0.399, 0.593, 0.452, 0.705, 0.392, 0.55, 0.449, 0.53, 0.346, 0.335, 0.497, 0.234, 1.548, 1.972, 1.678, 1.549, 1.506, 1.4, 1.53, 1.524, 1.134, 1.439, 1.493, 1.616, 1.877, 1.758, 1.373, 1.693, 1.508, 1.604, 1.137, 1.537, 1.426, 1.388, 1.682, 1.66, 1.287, 1.377, 1.376, 1.378, 1.366, 1.675, 1.674, 1.501, 0.944, 1.82, 1.402, 1.184, 1.811, 1.143, 1.468, 1.494, 1.532, 1.363, 1.395, 1.732, 1.452, 1.377, 1.681, 1.506, 1.432, 1.783, 1.697, 1.57, 1.383, 1.852, 1.269, 1.378, 1.771, 1.502, 1.536, 1.673, 1.527, 1.397, 1.689, 1.895, 1.529, 1.178, 1.715, 1.525, 1.945, 1.027, 0.927, 0.907, 0.524, 0.414, 0.458, 0.572, 0.513, 0.433, 0.582, 0.466, 0.482, 0.443, 0.426, 0.532, 0.463, 0.677, 0.457, 0.342, 0.471, 0.431, 0.459, 0.437, 0.481, 0.315, 0.518, 0.437, 0.498, 0.374, 0.431, 0.539, 0.413, 0.52, 0.552, 0.463, 0.483, 0.641, 0.402, 0.473, 0.417, 0.456, 0.59, 0.371, 0.474, 0.505, 0.366, 0.457, 0.608, 0.647, 0.429, 0.604, 0.745, 0.482, 0.507, 0.495, 0.566, 0.476, 0.502, 0.491, 0.507, 0.463, 0.478, 0.483, 0.525, 0.552, 0.385, 0.465, 0.493, 0.503, 0.496, 0.319, 0.533, 0.309, 0.386, 0.43, 0.388, 0.419, 0.41, 0.375, 0.367, 0.248, 0.341, 0.353, 0.279, 0.36, 0.332, 0.325, 0.287, 0.355, 0.254, 0.364, 0.443, 0.223, 0.369, 0.395, 0.444, 0.327, 0.41, 0.364, 0.419, 0.39, 0.36, 0.336, 0.349, 0.412, 0.326, 0.426, 0.386, 0.376, 0.416, 0.372, 0.351, 0.433, 0.316, 0.295, 0.263, 0.41, 0.295, 0.378, 0.401, 0.378, 0.352, 0.459, 0.33, 0.36, 0.44, 0.368, 0.392, 0.368, 0.371, 0.429, 0.439, 0.402, 0.405, 0.368, 0.373, 0.415, 0.393, 0.347, 0.381, 0.395, 0.418, 0.317, 0.398, 0.383, 0.283, 0.382, 0.817, 1.041, 0.804, 0.986, 0.93, 0.882, 0.999, 0.869, 0.955, 0.811, 1.022, 1.016, 0.815, 1.124, 0.773, 1.009, 0.96, 0.868, 0.927, 0.736, 0.946, 1.084, 1.014, 0.95, 0.839, 0.937, 0.933, 0.72, 1.096, 0.818, 1.11, 0.938, 1.059, 1.018, 0.937, 0.935, 1.066, 0.962, 0.94, 0.938, 0.817, 0.733, 0.938, 0.795, 1.13, 0.947, 0.938, 0.713, 0.849, 0.733, 1.012, 0.927, 1.196, 0.959, 1.086, 0.874, 1.018, 0.8, 0.948, 1.064, 1.012, 1.031, 0.955, 0.785, 0.823, 1.117, 0.95, 0.865, 0.951, 0.611, 0.808, 0.721, 2.067, 2.165, 2.045, 1.779, 2.155, 2.015, 2.009, 1.809, 1.878, 1.81, 2.49, 2.053, 2.102, 2.298, 2.488, 2.114, 2.432, 2.055, 2.033, 2.26, 2.266, 2.04, 1.947, 2.254, 2.177, 2.068, 1.752, 1.93, 2.272, 1.633, 2.561, 1.967, 1.706, 1.798, 1.99, 2.268, 2.084, 2.286, 2.081, 2.239, 2.183, 2.288, 2.754, 2.578, 1.886, 2.121, 1.74, 2.251, 2.749, 2.034, 2.298, 1.971, 1.607, 2.479, 1.97, 2.514, 2.083, 1.741, 1.734, 1.615, 2.539, 1.709, 2.469, 2.317, 2.256, 1.859, 2.158, 2.065, 2.091, 1.576, 1.409, 1.549,
    #     3.562, 1.364, 2.353, 3.614, 2.632, 3.691, 2.229, 3.458, 4.212, 6.476, 3.767, 2.44, 1.397, 5.533, 1.259, 4.448, 1.708, 2.298, 2.432, 7.326, 5.842, 1.981, 1.689, 2.584, 2.925, 2.258, 2.379, 1.46, 1.141, 1.75, 6.934, 7.13, 7.448, 6.346, 6.214, 7.82, 6.868, 7.988, 7.506, 6.899, 5.759, 6.852, 8.728, 7.82, 6.87, 7.046, 7.462, 7.118, 7.131, 7.794, 6.013, 7.739, 5.673, 7.187, 5.464, 7.775, 7.105, 4.659, 4.217, 3.96, 1.521, 2.004, 1.224, 1.27, 1.189, 1.542, 1.645, 1.961, 1.451, 1.801, 1.53, 2.028, 1.56, 1.175, 1.335, 1.447, 1.267, 1.423, 1.277, 1.477, 1.237, 1.277, 1.63, 2.064, 1.485, 1.467, 1.533, 1.119, 1.081, 0.996, 1.153, 1.545, 1.075, 1.082, 1.183, 1.029, 0.955, 0.977, 1.205, 1.024, 1.012, 1.09, 0.904, 1.09, 0.992, 1.356, 0.989, 1.018, 0.989, 1.109, 1.207, 1.137, 0.887, 1.086, 1.055, 1.012, 0.945, 0.968, 0.865, 1.056, 4.196, 4.138, 3.913, 3.469, 3.61, 3.689, 4.418, 4.229, 4.42, 4.087, 3.536, 3.654, 4.267, 4.571, 3.493, 3.631, 4.295, 3.689, 4.16, 3.438, 4.531, 4.401, 3.872, 3.51, 3.968, 3.897, 4.2, 2.776, 2.812, 2.971, 10.203, 9.079, 10.084, 9.181, 9.764, 9.593, 10.081, 9.308, 12.051, 9.63, 11.009, 8.458, 11.548, 10.519, 10.946, 11.1, 9.797, 11.51, 10.125, 10.545, 8.346, 9.56, 12.463, 11.048, 10.171, 9.644, 11.024, 7.95, 7.699, 6.843
    # ]   # training latency

    # colo = traintimes 
    # color_map = cm.ScalarMappable(cmap=cm.PiYG) 
    # color_map.set_array(colo) 
    # colo_normalized = [c/max(colo) for c in colo]
    # # ax.scatter(samplesize, dimensions, traintimes, facecolors=cm.PiYG(colo_normalized), edgecolor=cm.PiYG(colo_normalized), alpha=1)
    # ax.scatter(samplesize, dimensions, facecolors=cm.PiYG(colo_normalized), edgecolor=cm.PiYG(colo_normalized), alpha=1)
    # plt.colorbar(color_map,label='Training Latency (s)') 

    # ax.set_xlabel('Sample Size')
    # ax.set_ylabel('Feature Dimension Size')
    # # ax.set_zlabel('Training Latency')
    # # ax.zaxis.labelpad = -4

    # # plt.show()
    # # fig.set_size_inches(6, 8)
    # fig.tight_layout()
    # # fig.subplots_adjust(left=-2) 
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()






    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatencypermodel_by_N_models_with_rawinput_data_3"
    # xs=[str(xlabel) for xlabel in [500//50,500//25,500//20,500//15+1,500//10,500//5,500//1]]
    # labels = ["model "+str(i+1) for i in range(46)]
    # ys0_l=[[0.164, 0.665, 1.129, 2.287, 6.121, 45.595, 9103.478]]
    # ys0mean_l = np.array(ys0_l).mean(axis=0).tolist()
    # ys0std_l  = np.array(ys0_l).std(axis=0).tolist()
    # # ys0conf_l = list(scipy.stats.t.interval(0.95, len(ys0_l)-1, loc=np.mean(ys0_l,axis=0), scale=scipy.stats.sem(ys0_l,axis=0)))
    # # ys1_l = [1286.38/(5*5)]
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 2, 0.4
    # p = ax.bar([idx for idx, _ in enumerate(ys0mean_l)], ys0mean_l, width/entry_count, yerr=ys0std_l)
    # # ax.errorbar([idx for idx, _ in enumerate(ys0mean_l)], ys0mean_l, yerr=ys0std_l)
    # # p = ax.bar([idx - width/entry_count/2 + 0*width/entry_count for idx, _ in enumerate(ys)], ys, width/entry_count, label="observed")
    # ax.bar_label(p)
    # # p = ax.bar([idx - width/entry_count/2 + 1*width/entry_count for idx, _ in enumerate(ys1_l)], ys1_l, width/entry_count, label="estimated")
    # # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    # # ax.legend(loc="best", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()



    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "nerccostandtrainlatencypermodel_by_N_models_with_rawinput_data_3"
    # xs=[str(xlabel) for xlabel in [500//50,500//25,500//20,500//15+1,500//10,500//5,500//1]]
    # labels = ["model "+str(i+1) for i in range(46)]
    # ys0_l=[[ys0/60/60*0.013*64 for ys0 in [0.421, 0.886, 1.335, 2.112, 5.392, 91.993, 9847.238]]]
    # ys0mean_l = np.array(ys0_l).mean(axis=0).tolist()
    # ys0std_l  = np.array(ys0_l).std(axis=0).tolist()
    # ys2_l=[[ys2/60/60*2.448 for ys2 in [0.421, 0.886, 1.335, 2.112, 5.392, 91.993, 9847.238]]]
    # ys2mean_l = np.array(ys2_l).mean(axis=0).tolist()
    # ys2std_l  = np.array(ys2_l).std(axis=0).tolist()
    # ys1_l=[[0.421, 0.886, 1.335, 2.112, 5.392, 91.993, 9847.238]]
    # ys1mean_l = np.array(ys1_l).mean(axis=0).tolist()
    # ys1std_l  = np.array(ys1_l).std(axis=0).tolist()
    # # ys0conf_l = list(scipy.stats.t.interval(0.95, len(ys0_l)-1, loc=np.mean(ys0_l,axis=0), scale=scipy.stats.sem(ys0_l,axis=0)))
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 3, 0.4
    # p = ax.bar([idx-width/entry_count-width/entry_count/2 for idx, _ in enumerate(ys0mean_l)], ys0mean_l, width/entry_count, yerr=ys0std_l, color='#0067ff', edgecolor="black", hatch="x", label="NERC VM (\$)")
    # p2 = ax.bar([idx-width/entry_count/2 for idx, _ in enumerate(ys2mean_l)], ys2mean_l, width/entry_count, yerr=ys2std_l, color='#00ff67', edgecolor="black", hatch="-", label="AWS EC2 (\$)")
    # # ax.bar_label(p)
    # # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    # ax.grid()
    # ax.legend(loc="upper left", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels", fontsize=20)
    # ax.set_ylabel("Resource Cost (\$)", fontsize=20)
    # ax1 = ax.twinx()
    # p = ax1.bar([idx+width/entry_count/2 for idx, _ in enumerate(ys1mean_l)], ys1mean_l, width/entry_count, yerr=ys1std_l, color='#ff6700', edgecolor="black", hatch="o", label="Time (s)")
    # # ax1.bar_label(p)
    # ax1.tick_params(axis='both', which='major', labelsize=20)
    # ax1.tick_params(axis='both', which='minor', labelsize=18)
    # ax1.set_ylabel("Training Time(s)", fontsize=20)
    # ax1.legend(loc="upper center", prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "nerccostandtrainlatencysummodel_by_N_models_with_rawinput_data_3"
    # xs=[str(xlabel) for xlabel in [500//50,500//25,500//20,500//15+1,500//10,500//5,500//1]]
    # labels = ["model "+str(i+1) for i in range(46)]
    # ys0_l=[[ys0/60/60*0.013*64 for ys0 in [20.14, 36.68, 51.58, 101.09, 249.6, 942.14, 9847.24]]]
    # ys0mean_l = np.array(ys0_l).mean(axis=0).tolist()
    # ys0std_l  = np.array(ys0_l).std(axis=0).tolist()
    # ys2_l=[[ys2/60/60*2.448 for ys2 in [20.14, 36.68, 51.58, 101.09, 249.6, 942.14, 9847.24]]]
    # ys2mean_l = np.array(ys2_l).mean(axis=0).tolist()
    # ys2std_l  = np.array(ys2_l).std(axis=0).tolist()
    # ys1_l=[
    #     [0.42, 0.89, 1.33, 2.11, 5.39, 91.99, 9847.24] ,
    #     [0.46, 0.81, 0.86, 1.36, 6.53, 84.55, 0] ,
    #     [0.34, 0.59, 1.1, 2.19, 5.14, 221.68, 0] ,
    #     [0.36, 0.86, 1.11, 2.41, 5.75, 237.0, 0] ,
    #     [0.28, 0.82, 1.28, 1.45, 33.52, 306.92, 0] ,
    #     [0.31, 0.87, 1.02, 2.2, 34.58, 0, 0] ,
    #     [0.36, 0.67, 1.32, 9.1, 26.02, 0, 0] ,
    #     [0.41, 0.59, 0.86, 2.88, 45.59, 0, 0] ,
    #     [0.32, 0.88, 3.38, 3.46, 53.61, 0, 0] ,
    #     [0.27, 0.74, 1.74, 13.32, 33.47, 0, 0] ,
    #     [0.36, 2.08, 1.06, 10.91, 0, 0, 0] ,
    #     [0.35, 1.21, 5.5, 8.48, 0, 0, 0] ,
    #     [0.36, 0.9, 2.04, 1.93, 0, 0, 0] ,
    #     [0.31, 1.18, 1.84, 26.65, 0, 0, 0] ,
    #     [0.29, 1.86, 3.45, 12.62, 0, 0, 0] ,
    #     [0.26, 1.42, 2.4, 0, 0, 0, 0] ,
    #     [0.32, 0.78, 1.08, 0, 0, 0, 0] ,
    #     [0.35, 2.21, 15.83, 0, 0, 0, 0] ,
    #     [0.32, 0.94, 2.06, 0, 0, 0, 0] ,
    #     [0.26, 1.68, 2.3, 0, 0, 0, 0] ,
    #     [0.57, 1.11, 0, 0, 0, 0, 0] ,
    #     [0.44, 9.68, 0, 0, 0, 0, 0] ,
    #     [0.43, 0.99, 0, 0, 0, 0, 0] ,
    #     [0.39, 1.31, 0, 0, 0, 0, 0] ,
    #     [0.31, 1.63, 0, 0, 0, 0, 0] ,
    #     [0.58, 0, 0, 0, 0, 0, 0] ,
    #     [0.18, 0, 0, 0, 0, 0, 0] ,
    #     [0.47, 0, 0, 0, 0, 0, 0] ,
    #     [0.33, 0, 0, 0, 0, 0, 0] ,
    #     [0.62, 0, 0, 0, 0, 0, 0] ,
    #     [0.4, 0, 0, 0, 0, 0, 0] ,
    #     [0.37, 0, 0, 0, 0, 0, 0] ,
    #     [0.29, 0, 0, 0, 0, 0, 0] ,
    #     [0.43, 0, 0, 0, 0, 0, 0] ,
    #     [0.41, 0, 0, 0, 0, 0, 0] ,
    #     [0.61, 0, 0, 0, 0, 0, 0] ,
    #     [0.44, 0, 0, 0, 0, 0, 0] ,
    #     [0.2, 0, 0, 0, 0, 0, 0] ,
    #     [0.6, 0, 0, 0, 0, 0, 0] ,
    #     [0.31, 0, 0, 0, 0, 0, 0] ,
    #     [0.27, 0, 0, 0, 0, 0, 0] ,
    #     [0.43, 0, 0, 0, 0, 0, 0] ,
    #     [0.5, 0, 0, 0, 0, 0, 0] ,
    #     [1.42, 0, 0, 0, 0, 0, 0] ,
    #     [0.56, 0, 0, 0, 0, 0, 0] ,
    #     [0.28, 0, 0, 0, 0, 0, 0]
    #     ]
    # # ys1mean_l = np.array(ys1_l).mean(axis=0).tolist()
    # # ys1std_l  = np.array(ys1_l).std(axis=0).tolist()
    # # ys0conf_l = list(scipy.stats.t.interval(0.95, len(ys0_l)-1, loc=np.mean(ys0_l,axis=0), scale=scipy.stats.sem(ys0_l,axis=0)))
    # fig, ax = plt.subplots(1, 1, figsize=(10, 4))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 3, 0.4
    # p = ax.bar([idx-width/entry_count-width/entry_count/2 for idx, _ in enumerate(ys0mean_l)], ys0mean_l, width/entry_count, yerr=ys0std_l, color='#0067ff', edgecolor="black", hatch="x", label="NERC VM (\$)")
    # p2 = ax.bar([idx-width/entry_count/2 for idx, _ in enumerate(ys2mean_l)], ys2mean_l, width/entry_count, yerr=ys2std_l, color='#00ff67', edgecolor="black", hatch="|", label="AWS EC2 (\$)")
    # # ax.bar_label(p)
    # # ax.set_title("Training Latency by N Models with Data 3", fontsize=20)
    # ax.grid()
    # ax.legend(loc="upper left", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # ax.set_ylabel("Resource Cost (\$)", fontsize=20)
    # ax1 = ax.twinx()
    # bottom = [0 for _ in range(len(ys1_l[0]))]
    # for row in ys1_l[:-1]:
    #     p = ax1.bar([idx+width/entry_count/2 for idx, _ in enumerate(row)], row, width/entry_count, bottom, color='#ff6700', edgecolor="black", hatch="o")
    #     bottom = [v1+v2 for v1,v2 in zip(bottom,row)]
    # p = ax1.bar([idx+width/entry_count/2 for idx, _ in enumerate(ys1_l[-1])], ys1_l[-1], width/entry_count, bottom, color='#ff6700', edgecolor="black", hatch="o", label="Total Training Time (s) for Submodels")
    # # p = ax1.bar([idx+width/entry_count/2 for idx, _ in enumerate(ys1mean_l)], ys1mean_l, width/entry_count, yerr=ys1std_l, color='#ff6700', edgecolor="black", hatch="o", label="Time (s)")
    # # ax1.bar_label(p)
    # ax1.tick_params(axis='both', which='major', labelsize=20)
    # ax1.tick_params(axis='both', which='minor', labelsize=18)
    # ax1.set_ylabel("Training Time(s)", fontsize=20)
    # ax1.legend(loc="center left", prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()


    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_N_models_with_rawinput_data_0"
    # xs=[str(xlabel) for xlabel in [10,20,40,80]]
    # labels = ["model "+str(i+1) for i in range(46)]
    # ys0_l=[[8*2.4, 4*2.4*2*(4*math.log(25*20)/math.log(25*10)), 2*19.0*2*(4*math.log(25*40)/math.log(25*20)), 143.5*2*(4*math.log(25*80)/math.log(25*40))]]
    # ys1_l=[
    #     [2.407, 18.840, 143.565, 1090.042],
    #     [2.396, 18.788, 143.717, 0],
    #     [2.413, 19.016, 0, 0],
    #     [2.407, 18.862, 0, 0],
    #     [2.406, 0, 0, 0],
    #     [2.396, 0, 0, 0],
    #     [2.440, 0, 0, 0],
    #     [2.396, 0, 0, 0]
    #     ]
    # fig, ax = plt.subplots(1, 1, figsize=(10, 4))
    # # bottom = np.zeros(len(xs))
    # entry_count, width = 2, 0.4
    # # p = ax.bar([idx-width/entry_count/2 for idx, _ in enumerate(ys0_l[0])], ys0_l[0], width/entry_count, color='#00ab00', edgecolor="black", hatch="x", label="Estimated")
    # # ax.bar_label(p)
    # bottom = [0 for _ in range(len(ys1_l[0]))]
    # # for row in ys1_l[:-1]:
    # #     p = ax.bar([idx+width/entry_count/2 for idx, _ in enumerate(row)], row, width/entry_count, bottom, color='#ff6700', edgecolor="black", hatch="o")
    # #     bottom = [v1+v2 for v1,v2 in zip(bottom,row)]
    # # p = ax.bar([idx+width/entry_count/2 for idx, _ in enumerate(ys1_l[-1])], ys1_l[-1], width/entry_count, bottom, color='#ff6700', edgecolor="black", hatch="o", label="Total Training Time (s) for Submodels")
    # for row in ys1_l[:-1]:
    #     p = ax.bar([idx for idx, _ in enumerate(row)], row, width/entry_count, bottom, color='#ff6700', edgecolor="black", hatch="o")
    #     bottom = [v1+v2 for v1,v2 in zip(bottom,row)]
    # p = ax.bar([idx for idx, _ in enumerate(ys1_l[-1])], ys1_l[-1], width/entry_count, bottom, color='#ff6700', edgecolor="black", hatch="o", label="Total Training Time (s) for Submodels")
    # ax.bar_label(p)    
    # ax.grid()
    # ax.legend(loc="upper left", prop={'size': 16})
    # ax.set_xticks(list(range(len(xs))))
    # ax.set_xticklabels(xs)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Number of Labels per Submodel", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()



    # by_input_size
    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "testf1score_by_input_size_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319]
    # labels = ("80 labels", "40 labels","20 labels","10 labels")
    # ys_l=[[0.077, 0.521, 0.697, 0.727, 0.806, 0.843, 0.847, 0.906, 0.935, 0.934, 0.948, 0.951, 0.954],
    #     [0.166, 0.609, 0.746, 0.789, 0.857, 0.846, 0.891, 0.896, 0.911, 0.905, 0.911, 0.904, 0.916],
    #     [0.210, 0.633, 0.758, 0.763, 0.829, 0.841, 0.828, 0.886, 0.889, 0.884, 0.902, 0.891, 0.898],
    #     [0.259, 0.588, 0.714, 0.775, 0.741, 0.836, 0.851, 0.837, 0.815, 0.843, 0.842, 0.846, 0.843]
    #     ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Input Dimensions", fontsize=20)
    # ax.set_ylabel("F1-Scores", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_input_size_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319]
    # labels = ("10 labels", "20 labels","40 labels","80 labels")
    # ys_l=[[0.102, 0.103, 0.143, 0.156, 0.226, 0.278, 0.392, 0.664, 1.205, 2.407, 5.449, 11.784, 24.566],
    #     [0.229, 0.290, 0.406, 0.451, 0.700, 0.928, 1.255, 2.366, 4.464, 9.328, 18.840, 39.945, 80.171],
    #     [0.315, 0.550, 1.027, 1.514, 2.580, 3.246, 4.596, 8.739, 17.492, 34.972, 70.854, 143.565, 286.711],
    #     [1.227, 2.012, 3.810, 5.275, 9.333, 12.124, 17.675, 34.274, 67.655, 136.472, 274.488, 546.612, 1096.709]
    #     ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Input Dimensions", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # filename = "inferencelatency_by_input_size_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # # xs=[13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319]
    # # labels = ("10 labels", "20 labels","40 labels","80 labels")
    # # ys_l=[[0.017+0.015+0.015+0.015+0.015+0.015+0.015+0.015, 0.017+0.024+0.017+0.017+0.017+0.018+0.018+0.018, 0.020+0.020+0.020+0.020+0.021+0.021+0.021+0.022, 0.022+0.023+0.023+0.023+0.024+0.023+0.023+0.024, 0.030+0.030+0.030+0.030+0.031+0.031+0.031+0.031, 0.034+0.036+0.035+0.034+0.035+0.035+0.035+0.035, 0.045+0.042+0.042+0.042+0.042+0.044+0.043+0.043, 0.065+0.065+0.067+0.066+0.065+0.065+0.065+0.065, 0.114+0.115+0.114+0.114+0.114+0.114+0.115+0.115, 0.212+0.214+0.214+0.212+0.214+0.213+0.213+0.218, 0.408+0.409+0.411+0.411+0.409+0.409+0.410+0.409, 0.810+0.817+0.817+0.815+0.814+0.809+0.814+0.813, 1.675+1.686+1.681+1.677+1.672+1.679+1.679+1.678],
    # #     [0.030+0.031+0.031+0.030, 0.031+0.032+0.031+0.032, 0.034+0.034+0.034+0.034, 0.036+0.037+0.037+0.037, 0.045+0.044+0.045+0.045, 0.047+0.047+0.048+0.050, 0.055+0.059+0.056+0.056, 0.079+0.079+0.079+0.081, 0.128+0.132+0.129+0.131, 0.226+0.226+0.225+0.227, 0.425+0.424+0.423+0.425, 0.831+0.830+0.831+0.836, 1.711+1.709+1.706+1.711],
    # #     [0.054+0.054, 0.056+0.058, 0.060+0.063, 0.061+0.061, 0.073+0.074, 0.079+0.081, 0.086+0.090, 0.112+0.122, 0.170+0.165, 0.268+0.263, 0.461+0.465, 0.875+0.883, 1.772+1.779],
    # #     [0.101, 0.107, 0.111, 0.122, 0.136, 0.149, 0.161, 0.199, 0.256, 0.380, 0.547, 0.979, 1.959]
    # #     ]
    # xs=[13664, 27329, 54659, 109319]
    # labels = ("10 labels per model", "20 labels per model","40 labels per model","80 labels per model")
    # ys_l=[[0.212+0.214+0.214+0.212+0.214+0.213+0.213+0.218, 0.408+0.409+0.411+0.411+0.409+0.409+0.410+0.409, 0.810+0.817+0.817+0.815+0.814+0.809+0.814+0.813, 1.675+1.686+1.681+1.677+1.672+1.679+1.679+1.678],
    #     [0.226+0.226+0.225+0.227, 0.425+0.424+0.423+0.425, 0.831+0.830+0.831+0.836, 1.711+1.709+1.706+1.711],
    #     [0.268+0.263, 0.461+0.465, 0.875+0.883, 1.772+1.779],
    #     [0.380, 0.547, 0.979, 1.959]
    #     ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.hlines(1.92, xmin=13664, xmax=109319)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Input Dimensions", fontsize=20)
    # ax.set_ylabel("Inference Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_input_size_with_rawinput_data_0_estimated"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319]
    # labels = ("Observed", "Estimated")
    # ys_l=[[1.227, 2.012, 3.810, 5.275, 9.333, 12.124, 17.675, 34.274, 67.655, 136.472, 274.488, 546.612, 1096.709],
    #     #   [1.227, 1.227*2, 1.227*2**2, 1.227*2**3, 1.227*2**4, 1.227*2**5, 1.227*2**6, 1.227*2**7, 1.227*2**8, 1.227*2**9, 1.227*2**10, 1.227*2**11, 1.227*2**12],
    #     # [1.227, 1.227*2, 2.012*2, 3.810*2, 5.275*2, 9.333*2, 12.124*2, 17.675*2, 34.274*2, 67.655*2, 136.472*2, 274.488*2, 546.612*2]
    #     [1096.709/2**12, 1096.709/2**11, 1096.709/2**10, 1096.709/2**9, 1096.709/2**8, 1096.709/2**7, 1096.709/2**6, 1096.709/2**5, 1096.709/2**4, 1096.709/2**3, 1096.709/2**2, 1096.709/2, 1096.709]
    #     ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Input Dimensions", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_input_size_with_rawinput_data_0_estimated_sanitycheck"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[13, 106, 284, 427, 854, 1138, 1708, 3416, 6832, 13664, 27329, 54659, 109319]
    # labels = ("Observed", "Estimated")
    # ys_l=[[1.227, 2.012, 3.810, 5.275, 9.333, 12.124, 17.675, 34.274, 67.655, 136.472, 274.488, 546.612, 1096.709],
    #       [1.227, 1.227*2, 1.227*2**2, 1.227*2**3, 1.227*2**4, 1.227*2**5, 1.227*2**6, 1.227*2**7, 1.227*2**8, 1.227*2**9, 1.227*2**10, 1.227*2**11, 1.227*2**12]
    #     ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.set_xlabel("Input Dimensions")
    # ax.set_ylabel("Training Time(s)")
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()





















    # by_labels_per_model

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("13 dims", "106 dims", "284 dims", "427 dims", "854 dims", "1138 dims", "1708 dims", "3416 dims", "6832 dims", "13664 dims", "27329 dims", "54659 dims", "109319 dims")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[0.102, 0.229, 0.315, 1.227], 
    #         [0.103, 0.29, 0.55, 2.012], 
    #         [0.143, 0.406, 1.027, 3.81], 
    #         [0.156, 0.451, 1.514, 5.275], 
    #         [0.226, 0.7, 2.58, 9.333], 
    #         [0.278, 0.928, 3.246, 12.124], 
    #         [0.392, 1.255, 4.596, 17.675], 
    #         [0.664, 2.366, 8.739, 34.274], 
    #         [1.205, 4.464, 17.492, 67.655], 
    #         [2.407, 9.328, 34.972, 136.472], 
    #         [5.449, 18.84, 70.854, 274.488], 
    #         [11.784, 39.945, 143.565, 546.612], 
    #         [24.566, 80.171, 286.711, 1096.709]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "inferencelatency_by_labels_per_model_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # # xs=[10, 20, 40, 80]
    # # labels = ("13 dims", "106 dims", "284 dims", "427 dims", "854 dims", "1138 dims", "1708 dims", "3416 dims", "6832 dims", "13664 dims", "27329 dims", "54659 dims", "109319 dims")
    # # # ys_l=list(map(list, zip(*ys_l)))
    # # # print(ys_l)
    # # ys_l = [[0.017+0.015+0.015+0.015+0.015+0.015+0.015+0.015, 0.030+0.031+0.031+0.030, 0.054+0.054, 0.101],
    # #         [0.017+0.024+0.017+0.017+0.017+0.018+0.018+0.018, 0.031+0.032+0.031+0.032, 0.056+0.058, 0.107],
    # #         [0.020+0.020+0.020+0.020+0.021+0.021+0.021+0.022, 0.034+0.034+0.034+0.034, 0.060+0.063, 0.111],
    # #         [0.022+0.023+0.023+0.023+0.024+0.023+0.023+0.024, 0.036+0.037+0.037+0.037, 0.061+0.061, 0.122],
    # #         [0.030+0.030+0.030+0.030+0.031+0.031+0.031+0.031, 0.045+0.044+0.045+0.045, 0.073+0.074, 0.136],
    # #         [0.034+0.036+0.035+0.034+0.035+0.035+0.035+0.035, 0.047+0.047+0.048+0.050, 0.079+0.081, 0.149],
    # #         [0.045+0.042+0.042+0.042+0.042+0.044+0.043+0.043, 0.055+0.059+0.056+0.056, 0.086+0.090, 0.161],
    # #         [0.065+0.065+0.067+0.066+0.065+0.065+0.065+0.065, 0.079+0.079+0.079+0.081, 0.112+0.122, 0.199],
    # #         [0.114+0.115+0.114+0.114+0.114+0.114+0.115+0.115, 0.128+0.132+0.129+0.131, 0.170+0.165, 0.256],
    # #         [0.212+0.214+0.214+0.212+0.214+0.213+0.213+0.218, 0.226+0.226+0.225+0.227, 0.268+0.263, 0.380],
    # #         [0.408+0.409+0.411+0.411+0.409+0.409+0.410+0.409, 0.425+0.424+0.423+0.425, 0.461+0.465, 0.547],
    # #         [0.810+0.817+0.817+0.815+0.814+0.809+0.814+0.813, 0.831+0.830+0.831+0.836, 0.875+0.883, 0.979],
    # #         [1.675+1.686+1.681+1.677+1.672+1.679+1.679+1.678, 1.711+1.709+1.706+1.711, 1.772+1.779, 1.959]
    # #         ]
    # xs=[10, 20, 40, 80]
    # labels = ("13664 dims", "27329 dims", "54659 dims", "109319 dims")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[0.212+0.214+0.214+0.212+0.214+0.213+0.213+0.218, 0.226+0.226+0.225+0.227, 0.268+0.263, 0.380],
    #         [0.408+0.409+0.411+0.411+0.409+0.409+0.410+0.409, 0.425+0.424+0.423+0.425, 0.461+0.465, 0.547],
    #         [0.810+0.817+0.817+0.815+0.814+0.809+0.814+0.813, 0.831+0.830+0.831+0.836, 0.875+0.883, 0.979],
    #         [1.675+1.686+1.681+1.677+1.672+1.679+1.679+1.678, 1.711+1.709+1.706+1.711, 1.772+1.779, 1.959]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Inference Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "testf1score_by_labels_per_model_with_rawinput_data_0"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("13 dims", "106 dims", "284 dims", "427 dims", "854 dims", "1138 dims", "1708 dims", "3416 dims", "6832 dims", "13664 dims", "27329 dims", "54659 dims", "109319 dims")
    # ys_l=[[0.259, 0.21, 0.166, 0.077], 
    #       [0.588, 0.633, 0.609, 0.521], 
    #       [0.714, 0.758, 0.746, 0.697], 
    #       [0.775, 0.763, 0.789, 0.727], 
    #       [0.741, 0.829, 0.857, 0.806], 
    #       [0.836, 0.841, 0.846, 0.843], 
    #       [0.851, 0.828, 0.891, 0.847], 
    #       [0.837, 0.886, 0.896, 0.906], 
    #       [0.815, 0.889, 0.911, 0.935], 
    #       [0.843, 0.884, 0.905, 0.934], 
    #       [0.842, 0.902, 0.911, 0.948], 
    #       [0.846, 0.891, 0.904, 0.951], 
    #       [0.843, 0.898, 0.916, 0.954]]
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("F1-Score", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "testf1score_by_labels_per_model_with_rawinput_data_3"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 5))
    # xs=[10, 20, 25, 34, 50, 100]
    # labels = ("500labels-F1-with-filter", "500labels-F1-no-filter")
    # # labels = ("500labels-F1-with-filter", "500labels-Precision-with-filter", "500labels-F1-no-filter", "500labels-Precision-no-filter")
    # ys_l=[
    #     [0.884, 0.885, 0.885, 0.883, 0.884, 0.901],
    #     # [0.834, 0.836, 0.837, 0.834, 0.834, 0.855],
    #     [0.618, 0.641, 0.655, 0.679, 0.696, 0.743],
    #     # [0.557, 0.58, 0.592, 0.617, 0.635, 0]
    # ]
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # xs=[10, 20, 40, 80]
    # labels = ("80labels-F1-with-filter", "80labels-F1-no-filter")
    # # labels = ("80labels-F1-with-filter", "80labels-Precision-with-filter", "80labels-F1-no-filter", "80labels-Precision-no-filter")
    # ys_l=[
    #     [0.883, 0.918, 0.957, 0.991],
    #     # [0.817, -1,-1,-1],
    #     [0.857, 0.903, 0.945, 0.998],
    #     # [0.843, 0.855, 0.868, 0.996]
    # ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # # ax.set_xscale('log')
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylim(0.3,1)
    # ax.set_ylabel("F1-Score", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_0_estimated"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated", "Estimated_nosorting")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[24.566, 80.171, 286.711, 1096.709],
    #         # [24.566,
    #         # 24.566*(4*math.log(25*20)/math.log(25*10)),
    #         # 80.171*(4*math.log(25*40)/math.log(25*20)), 
    #         # 286.711*(4*math.log(25*80)/math.log(25*40))]
    #         [1096.709/(4*math.log(25*80)/math.log(25*40))/(4*math.log(25*40)/math.log(25*20))/(4*math.log(25*20)/math.log(25*10)),
    #         1096.709/(4*math.log(25*80)/math.log(25*40))/(4*math.log(25*40)/math.log(25*20)), 
    #         1096.709/(4*math.log(25*80)/math.log(25*40)),
    #         1096.709],
    #         [1096.709/(4)/(4)/(4),
    #         1096.709/(4)/(4), 
    #         1096.709/(4),
    #         1096.709]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_3_estimated"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated", "Estimated_nosorting")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[24.566, 80.171, 286.711, 1096.709],
    #         # [24.566,
    #         # 24.566*(4*math.log(25*20)/math.log(25*10)),
    #         # 80.171*(4*math.log(25*40)/math.log(25*20)), 
    #         # 286.711*(4*math.log(25*80)/math.log(25*40))]
    #         [1096.709/(4*math.log(25*80)/math.log(25*40))/(4*math.log(25*40)/math.log(25*20))/(4*math.log(25*20)/math.log(25*10)),
    #         1096.709/(4*math.log(25*80)/math.log(25*40))/(4*math.log(25*40)/math.log(25*20)), 
    #         1096.709/(4*math.log(25*80)/math.log(25*40)),
    #         1096.709],
    #         [1096.709/(4)/(4)/(4),
    #         1096.709/(4)/(4), 
    #         1096.709/(4),
    #         1096.709]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_0_estimated_1njob_no_sorting"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[148.500, 555.019, 2153.236, 8474.915],
    #         # [148.500,
    #         # 148.500*(4*(math.log(25*20)+1)/(math.log(25*10)+1)),
    #         # 555.019*(4*(math.log(25*40)+1)/(math.log(25*20)+1)), 
    #         # 2153.236*(4*(math.log(25*80)+1)/(math.log(25*40)+1))]
    #         [148.500,
    #         148.500*(4),
    #         555.019*(4), 
    #         2153.236*(4)]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_0_estimated_1njob_doublesample_nosorting"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[282.00, 1080.01, 4254.03, 17168.33],
    #         # [282.00,
    #         # 282.00*(4*(math.log(50*20)+1)/(math.log(50*10)+1)),
    #         # 1080.01*(4*(math.log(50*40)+1)/(math.log(50*20)+1)), 
    #         # 4254.03*(4*(math.log(50*80)+1)/(math.log(50*40)+1))]
    #         [282.00,
    #         282.00*(4*1),
    #         1080.01*(4*1), 
    #         4254.03*(4*1)]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_randomint10000000_109319_data_0_estimated_1njob_doublesample"
    # # filename = "trainlatency_by_labels_per_model_with_randomint10000000_109319_data_0_estimated_1njob_doublesample_nosorting"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[546.535, 2094.348, 8248.998, 33385.295],
    #         [546.535,
    #         546.535*(4*(math.log(50*20)+1)/(math.log(50*10)+1)),
    #         2094.348*(4*(math.log(50*40)+1)/(math.log(50*20)+1)), 
    #         8248.998*(4*(math.log(50*80)+1)/(math.log(50*40)+1))]
    #         # [546.535,
    #         # 546.535*(4*1),
    #         # 2094.348*(4*1), 
    #         # 8248.998*(4*1)]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_rawinput_data_0_estimated_2njob_no_sorting"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[84.723, 288.412, 1085.795, 4272.973],
    #         # [84.723,
    #         # 84.723*(4*(math.log(25*20)+1)/(math.log(25*10)+1)),
    #         # 288.412*(4*(math.log(25*40)+1)/(math.log(25*20)+1)), 
    #         # 1085.795*(4*(math.log(25*80)+1)/(math.log(25*40)+1))]
    #         [84.723,
    #         84.723*(4),
    #         288.412*(4), 
    #         1085.795*(4)]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.tick_params(axis='both', which='major', labelsize=20)
    # ax.tick_params(axis='both', which='minor', labelsize=18)
    # ax.set_xlabel("Labels Per Model", fontsize=20)
    # ax.set_ylabel("Training Time(s)", fontsize=20)
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()

    # fig_path = '/home/cc/Praxi-study/Praxi-Pipeline/prediction_XGBoost_openshift_image/model_testing_scripts/figs/'
    # filename = "trainlatency_by_labels_per_model_with_randomint10000000_109319_estimated_sanitycheck"
    # fig, ax = plt.subplots(1, 1, figsize=(10, 7))
    # xs=[10, 20, 40, 80]
    # labels = ("Observed", "Estimated")
    # # ys_l=list(map(list, zip(*ys_l)))
    # # print(ys_l)
    # ys_l = [[6.733, 51.841, 397.018, 3195.553],
    #         [6.733,
    #          6.733*(4*math.log(25*20)/math.log(25*10)),
    #          6.733*(4*math.log(25*20)/math.log(25*10))*(4*math.log(25*40)/math.log(25*20)), 
    #          6.733*(4*math.log(25*20)/math.log(25*10))*(4*math.log(25*40)/math.log(25*20))*(4*math.log(25*80)/math.log(25*40))]
    #         ]
    # for ys, label in zip(ys_l, labels):
    #     ax.scatter(xs, ys, label=label)
    # ax.set_xlabel("Labels Per Model")
    # ax.set_ylabel("Training Time(s)")
    # plt.legend(prop={'size': 16})
    # # plt.show()
    # plt.savefig(fig_path+filename+'.pdf', bbox_inches='tight')
    # plt.close()