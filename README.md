# Praxi-Pipeline

## Overwiew
We are working on modularize and containerize Praxi into a pipeline, specicially Kubeflow Pipeline. The goal is to adapt Praxi into RHODS in NERC and this repo shows how to adapt a monolithic application into a pipeline. And then the next step is to adapt this Kubeflow Pipeline into RHODS Pipeline.

## Design
There are two components are under development, i.e., `taggen` and `prediction`. 
`taggen` will mount a volume (currently a manual persistent volume in k8s) and load the difference from it (later we need a method to load differences from layers in snapshot) to generate `tags` with `columbus`.
`prediction` will take the `tags` generated in the `taggen` step and make prediction based on a trained `vw` model and write its output into a persistent volume (how to reply directly to user is unknown).

We have to define the container images for `taggen` and `prediction` components, as there are serveral dependancies cannot be installed with pip, i.e., `columbus` and `vw`. The correponding files are in the two directories, i.e., `taggen_base_image` and `prediciton_base_image`.

![Design Diagram](https://github.com/Zongshun96/Praxi-Pipeline/blob/main/Figures/Praxi-Kubeflow-agentless-PoC.drawio.png?raw=true)


## Running
- Install kubeflow and sdk.

Some helpful tutorials.

https://docs.google.com/document/d/1LHMrcQJQWiq1pLyEHZPJScovWNdLJduE9e6BU-F_J_Y/edit

https://www.kubeflow.org/docs/components/pipelines/v1/sdk/install-sdk/

- Create a persistent volume.

```
kubectl create -f 'fake-snapshot-volume/fake-snapshot-pv.yaml'
```
Now you can see there is a new pv with `kubectl get pv`. We will use the name of this new pv later.

- Copy the changesets into the persistent volume (the volume should contain the changes in snapshot layers after we figure that out).

```
kubectl create -f 'fake-snapshot-volume/fake-deployment.yaml'

kubectl cp data/changesets root@{PODNAME}:/fake-snapshot/

kubectl delete -f 'fake-snapshot-volume/fake-deployment.yaml'

kubectl patch pv {PVNAME} -p '{"spec":{"claimRef": null}}' # see https://stackoverflow.com/questions/50667437/what-to-do-with-released-persistent-volume
```

References:

https://gist.githubusercontent.com/salayatana66/ceef347ec8f082bf08c1328e7a880407/raw/f02a7bd6e6662297605bab3d697c120c0e666be4/vw-29-apr-minikube6.yaml

https://towardsdatascience.com/serving-vowpal-wabbit-models-on-kubernetes-de0ed968f3b0

https://stackoverflow.com/questions/50667437/what-to-do-with-released-persistent-volume


- Build the pipeline component images.

There is a bash script `build.sh` in each base-image dir. E.g., for `prediction-base-image`,
```
cd prediction-base-image
bash build.sh
```

References

https://www.kubeflow.org/docs/components/pipelines/v1/sdk/python-function-components/#packages

https://www.kubeflow.org/docs/components/pipelines/v1/sdk/component-development/


- Package the pipeline and load it into Kubeflow Pipeline.

Run `Praxi-Pipeline.py`. It defines the function to run inside each base image,  the dataflow between components (base image + the Praxi function) and runs the pipeline in kubeflow. Please refer to [design section](#design) for the dataflow design.

References

https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/tutorials/Data%20passing%20in%20python%20components.ipynb

https://github.com/kubeflow/pipelines/issues/7667


- Check your kubeflow pipeline dashboard.

A new run will show up in your pipeline dashboard.

<!-- ![screenshot for a new run in pipeline dashboard](https://github.com/[username]/[reponame]/blob/[branch]/image.jpg?raw=true) -->




## Notes
Some test changesets are provided in `data/`.

The persistent volume yaml is provided in `fake-snapshot-volume/`.

Automatically delete PVC generated by pipeline when a run is deleted.
https://github.com/kubeflow/pipelines/issues/6649

